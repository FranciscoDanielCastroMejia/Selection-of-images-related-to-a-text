{
    "https://upload.wikimedia.org/wikipedia/commons/8/82/Nadeloehr.P1000481.jpg": "A sewing needle, with one of its pointed ends and one eye to thread the sewing thread on the other, might seem perhaps a negligible object. The sewing needle, however, played a prominent role tens of thousands of years ago in the social development of our predecessors. This, according to an article published last week in the magazine \u201cScience Advances\u201d by a group of researchers led by Ian Gilligan, University of Sydney, Australia. We went back 50,000 years in time. We will find that our species had already started migration from eastern Africa to Europe and Asia. The planet was then in the middle of the last glaciation, and as immigrants advanced northwards they found temperatures getting lower and lower. To protect themselves from the cold, clothing was essential, and in this sense a kind of poncho made from animal skin provided some protection. Such protection, however, was not complete as the air was slicing through the holes left by the poncho. A better option was tight clothing, although for this hub In this sense, they manufactured bone punches to make small perforations in animal skin pieces, which allowed them to join them using animal or vegetable fibers such as ligaments. A technological advance with respect to the bone punch was the bone needle, which is basically a punch with an eye or hole at one end. In an eye needle two functions are combined: drilling holes in the skin to sew and insert the fiber or ligament. This allowed our ancestors to manufacture more elaborate and more efficient garments. The eye needle constituted a technological advance that was developed only by our species. The oldest archaeological record of an eye needle is located in Siberia and has an age of 40,000 years. In the Caucasus and Europe there are records of 38,000 years and 26,000 years old, respectively. According to Gilligan and collaborators, the geographical location of the archaeological records is related to the prevailing environmental temperatures, indicating that the development of the eye needle was driven by the need to manufacture clothes adjusted to the body. As the authors say, depending on the prevailing temperature it is necessary to add additional layers of underwear.This clothing requires a more delicate manufacturing process, which involves a long and tedious work by inserting fibers into small holes.All this made it imperative to make the process of making clothes more efficient and delicate with new tools and sewing techniques.On the other hand, Gilligan and collaborators consider that it was not only the need to protect against the cold that prompted the development of the needle with eye, but that this development was also conditioned by social factors. That is, by the role that clothing plays as an element of social identification and in the creation of complex societies.In this sense, researchers note the custom among some societies to paint or tattoo the body. In a cold climate this is not possible, so the painting of the body would have been replaced by clothing and by ornaments sewn on it. With this, the clothing is transformed into dress, that is to say, changes its protective role against the cold in a role of integration and social differentiation. The importance of this needle, however, lies in the fact that it enabled the manufacture of more elaborate clothing. In the words of the researchers, \u201cThe importance of eye-to-eye needles does not lie in making clothes but rather in a greater manufacture of made clothes that, while technologically a small step, was going to mean a quantum leap in human societies where clothes were regularly worn... The transition to clothing as a dress transformed clothing from a physical need to a social need, ensuring the continuous use of clothing to the present.\u201d Regardless of the importance that the bone-to-eye needle has had in social development tens of thousands of years ago, one may wonder how the history of the world would have been without its invention. As Gilligan and collaborators point out, the eye-to-eye needle facilitated the manufacture of underwear and this in turn made migration to Siberia and later to our continent through Beringia. Would migration to America have been hindered without the eye-to-eye needle? To what extent are we indebted to such an apparently insignificant object?",
    "https://upload.wikimedia.org/wikipedia/commons/c/cd/Origin_of_Species_title_page.jpg": "In his book, \u201cSoon: A Delayed History of Procrastination, From Leonardo and Darwin to You and Me,\u201d writer Andrew Santaella wonders why it took Charles Darwin 20 years to publish his book on the origin of species, which is based on the discoveries he made during his five-year journey around the world aboard the Beagle. As Santaella comments, Darwin had already come to the conclusion that species were not immutable at as early a date as 1836, shortly after returning from his journey, but it was not until 1859 that he published his ideas on it. Instead of devoting himself to writing and making known his conclusions on the evolution of species, which he knew would provoke an intellectual revolution, Darwin devoted his time to other research. In particular, Santaella relates, he devoted himself for eight years to the study of the percebs, crustaceans that caused him an enthusiasm close to obsession. Darwin\u2019s enthusiasm for such crustaceans was such that his children would have thought that collecting specimens of percebes in alcohol, as his father did, was normal. So, Santaella wonders if Darwin\u2019s delay in writing and publishing his revolutionary ideas was an episode of procrastination. That is, an episode in which he left what he \u201cwould have done\u201d to do something else. On the other hand, regardless of whether Charles Darwin had the habit of postponing or delaying tasks, we know that procrastination is widespread and virtually all of us have practiced in some way or another. For example, differentiating some programmed activity and that is not particularly pleasing to us, in favor of an activity that causes us greater satisfaction. And since different activities may have negative consequences, whether individual or social, procrastination has taken on importance and has been the reason for scientific research to establish the causes and mechanisms that determine it. An example of this is an article published in 2024 in \u201cProceedings of the Annual Meeting of the Cognitive Science Society\u201d, which describes the results of a research on procrastination carried out with university students. The article was published by Sahiti Chebolu and Peter Dayanting of the Annual Meeting of the Cognitive Science Society. By Max Planck Institute for Biological Cybernetics, Germany. Since procrastination is presented in varied ways and involves different behaviors, to facilitate their research Chebolu and Dayan distinguished three fundamental modes of procrastination. In a first way, there is an attachment to a programmed delay that leaves insufficient time to finish the task. This may be because a maximum utility is sought or because there is a miscalculation of the time that actually takes in completing the task. In a second way, there is a deliberate delay despite the initial intention to act earlier. Finally, in a third way there are delays for not establishing a commitment to an action time and it fails with a deadline, or time is wasted in the process. Chebolu and Dayan focus procrastination as a series of temporary decisions that can be understood in mathematical terms. A decision can be made based on the immediate reward and the future consequence that such a decision would have. For example, the decision that a student will make to attend a party instead of studying for the exam that will have to be presented the next day. The student will have to choose between The decision, on the other hand, would also be determined by the degree of uncertainty that the student would have regarding his or her chances of passing the exam.In his or her research, Chebolu and Dayan made use of data on the academic performance of a group of 173 students from New York University. Specifically, on their performance in a laboratory that was part of a psychology course. Students had to meet a minimum of 7 hours of laboratory that could extend up to a maximum of 4 additional hours, which would give them additional points in their final qualification. They found that the students were divided into groups. Some of them carried out their task immediately, while others spaced the task along the course. And, of course, there were others who waited until the end of the course to carry it out. In all cases, not obstante, Chebolu and Dayan could set the behavior of the students according to their research approach.In a world where efficiency is privileged, Procrastination is seen as a problem that must be overcome, and certainly is to some extent. It should be mentioned, however, that some like Santaella wonder if Darwin\u2019s procrastination was part of his genius and if it would have helped him for his revolutionary discovery. In which case it would have been a positive feature. Even if it were, however, it would be dangerous for us to extrapolate it to the other mortals.",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/e/ee/ShipTracks_MODIS_2005may11.jpg/686px-ShipTracks_MODIS_2005may11.jpg": "A matter of the greatest topicality is, if not doubted, climate change, with its accompaniment of heat waves, droughts, and hurricanes of great magnitude. As the experts explain, the planet is warming slowly because the delicate balance that existed between the solar energy that receives the Earth, and that, by reflection or emission, is sent back to space. Thus, to mitigate climate change the experts consider three actions to follow. First, the emission of greenhouse gases to the atmosphere, which act as a layer that hinders the passage into the space of the heat emitted by, the surface of the planet -as the windscreen and windows of the windows of a car hinder the exit of the heat inside on a hot day. As a second action, it would be necessary to develop technologies to remove from the atmosphere the carbon dioxide -the main greenhouse gas - already accumulated. And, finally, the portion of solar radiation that is reflected by the atmosphere of return to space should be increased. One example in this regard is the eruption in 1815 of the Tambora volcano in Indonesia, which made 1816 \u201cThe year without summer\u201d. Let us remember that, in the summer of that year, due to the prevailing low temperatures, Mary Shelly had to remain locked in the company of other writers, including Lord Byron, in a village near Lake Geneva in Switzerland. As a result of this confinement, Shelly was inspired to write her famous novel \u201cFrankenstein.\u201d Although the origin of the novel \u201cFrankenstein\u201d is certainly fascinating, it is not the intention of this article to comment on that origin. And, yes, to comment on the mitigation of climate change by blocking solar radiation that comes directly from the sun. The anecdote of \u201cFrankenstein\u201d, however, illustrates us about a way to achieve such a blockade: through a layer of microscopic particles suspended in the atmosphere that reflect the radiation of the sun. It would not, of course, be intended to suspend in the atmosphere polluting gases and particles such as those generated by a volcanic eruption. The experts consider dispersing microscopic particles of salt into the clouds, which are known to be formed by small drops of water and ice crystals that reflect sunlight. By dispersing particles of salt into the clouds, the number of drops of water is increased and thus the fraction of sunlight reflected into space. This would make the clouds brighter and, in principle, would allow to regulate the Earth's climate.However, as experts point out, there are great obstacles to carrying out a project of this nature. A first problem is that the Earth's climate is so complex that it is difficult to predict the side effects of a climate intervention project. In addition, a global climate engineering project would require the participation of all the countries of the planet, which the experts consider unviable. Thus, a project or projects of climate engineering at the regional level is more feasible, and in that sense an article appeared this week in the journal \u201cNature Climate Change\u201d analyzes the effect it would have on the climate of the western United States -which has suffered from severe heat waves in recent years- a project of intervention The article was published by a group of researchers led by Jessica Wan of the University of California in San Diego. Specifically, Wan and collaborators investigated the effect that it would have on the American west to disperse salt particles in sea clouds in two regions of the Pacific Ocean: opposite the coast of California and near the Aleutian islands, at Alaska. They find that the two interventions significantly reduce the likelihood of extreme heat waves occurring. While counterintuitively, since intervention near Alaska would be more effective than that on the Californian coast. This effectiveness, however, would be reduced in both cases with the passage of years as climate change progresses and could even be negative. On the other hand, more alarmingly, both interventions could have negative repercussions in remote regions. In Europe, for example, heat waves would intensify in 2050. Thus, given the complex climate of the Earth, a climate engineering intervention in a certain region could cause negative effects in remote areas. climate does not go in that direction.",
    "https://upload.wikimedia.org/wikipedia/commons/a/a6/Hero_Twins.JPG": "According to the Popol Vuh, the twin heroes Hunap\u00fa and Imbalanqu\u00e9 came down to the underworld called by their main lords, Hun-Cam\u00e9 and Vucub-Cam\u00e9, who were trying to kill them upset by the noise they made playing the ball. A similar episode had happened some time ago with the father and uncle of the twins - likewise twins - attracted and killed by the Lords of the underworld, also by playing the ball. With the twin heroes, however, Hun-Cam\u00e9 and Vucub-Cam\u00e9 did not succeed.To fulfill their dark purposes, the Lords of the underworld made the twins pass through the Dark House, an obstacle that they crossed with intelligence. They immediately invited them to a ball game, with the assurance of defeating them, which did not happen. Likewise, they made them pass through the House of the Knives, with the intention that the knives would destroy them, which did not happen either. They could not beat the twin heroes nor the House of Fri, nor the House of the Tigers, nor the House of Fire. Murci\u00e9lagos, Hun-Cam\u00e9 and Vucub-Cam\u00e9 had an apparent victory, as Hunap\u00fa was beheaded. His twin brother, however, succeeded in resurrecting him. With the help of two fortune tellers, the twins made a plan to definitively deceive and defeat the Lords of the underworld. As part of this plan, Hunap\u00fa and Imbalanqu\u00e9 immolated themselves into a bonfire and caused their bones to be ground and thrown into the river. With this, Hun-Cam\u00e9 and Vucub-Cam\u00e9 claimed definitive victory. The twins, however, were resurrected on the fifth day and were seen in the water with the appearance of fish-men. According to Popol Vuh, \u201cThe next day two poor men with an aged face and a miserable appearance, dressed in ragos, and whose appearance he did not recommend them.\u201d However, despite this appearance, they were able to perform many wonders. They could, for example, burn a house and then return it to their former state. They were so amazed that Hun-Cam\u00e9 and Vucub-Cam\u00e9 were able to kill the beggars, who were not other than the twin heroes, who asked them to practice their magic with themselves. They agreed, but in a crafty manner they practiced it only partially, because while they killed the Lords of the underworld, they were no longer resurrected. Thus, the twin heroes triumphed definitively and avenged the deaths of their father and uncle. Then, according to Popol Vuh, \u201cThey climbed up in the middle of the light and instantly rose to heaven. One was struck by the sun and the other by the moon. Then the vault of the sky and the face of the earth was lit up. And they dwell in heaven.\u201d The Mayan myth of the twin heroes is at the center of an investigation reported in an article published this week in the magazine \u201cNature.\u201d This article was published by a group of researchers headed by Rodrigo Barquera of the Max Planck Institute for Evolutionary Anthropology, Germany, and the National School of Anthropology and History, Mexico. This article reports a genetic investigation of the remains of 64 people buried in a cave near sacred cenote in Chichen Itza, most of them between the years 800-1000 A.D., period of flowering of the city. Among other things, Chichen Itza is known for the practice of human sacrifices. There is also a widespread idea that such sacrifices were commonly practiced with young women. The genetic analysis carried out by Barquera and collaborators, however, shows that the remains of all 64 people investigated correspond to male children. Likewise, they find that at least 25 percent of children buried in the cave are related to at least another child in the same cave. Even more, they find even two pairs of twins, which is unlikely merely by chance. With a certain degree of kinship.And as for the twins, the finding refers us to the myth of the twin heroes of Popol Vuh, who were sons of a father also twin and who suffered repeated episodes of death and resurrection.At a distance, it is difficult to know the mood of those sacrificed before the experience, since ritual sacrifice could constitute a kind of honor in the light of the myth of the twin heroes.Today, except in very few cases and at least in our midst, we would possibly have considerable difficulties in convincing a person to submit to the experience.However, and the possibility of ending up in the firmament turned into a star.",
    "https://upload.wikimedia.org/wikipedia/commons/8/84/30_Rockefeller_Center_rooftop.jpg": "It is possible that Rome has been the first city in history to reach a million inhabitants, about two thousand years ago. Today, they followed their example of about five hundred cities, which make up a quarter of the world's population, and which exceed this population. Living in a city has advantages, and that is why cities were born and grew, in some cases in an excessive way. At the same time, however, urban life has disadvantages.In this sense, let's consider that the infrastructure of a city includes artificial concrete structures or other materials that have displaced natural elements such as trees or water ponds.These new elements interact with solar radiation differently than it did with the original vegetation or bodies of water, altering the environment and contributing to the so-called heat island effect. How can a tree mitigate the heat? An obvious response is blocking the rays of the sun and making shade. There are less obvious responses, however. Thus, while the leaves of the trees reflect towards the sky a certain part of the incident solar radiation, a concrete structure can absorb such radiation contributing to a dark light. In the same way, the trees evaporate into the environment water that they take from the soil and for this they absorb heat from the environment, which produces a cooling effect. By replacing vegetation with concrete, this effect is lost with the consequent increase in the environmental temperature.Like the vegetation, the bodies of water absorb the incident solar radiation and contribute to decrease the temperature in its vicinity.In addition, and like the evaporation of water in the leaves of the plants produces a decrease of temperature, the evaporation of water of the bodies produces a cooling effect. Thus, three culprits of the heat wave that we are suffering from: the climate change caused by the emission of greenhouse gases into the atmosphere, the phenomenon of El Ni\u00f1o, which would fortunately dissipate in the coming months, and the process of urbanization that destroys the natural environment and produces the effect of the heat island. To mitigate this last effect, specialists consider the deployment of a green and blue urban infrastructure, called GBGI, by its acronym, that in some way replaces the elements lost by the urbanization. Green includes elements based on vegetation, such as trees, lawns and hedges, while blue infrastructure includes bodies of water such as ponds, lakes and rivers. These two infrastructures would be complemented by a grey infrastructure that includes walls, facades and roofs covered with plants. Given the diversity of geographical regions with particular climates, the optimal GBGI infrastructure depends on the climate considered. In an article published last March in the magazine \u201cThe Innovation\u201d, the use of GBGI infrastructure to mitigate urban heat in four climates: tropical, dry, temperate and continental. The article was published by a group of researchers headed by Prashant Kumar of \u201cUniversity of Surrey\u201d, United Kingdom. Among the elements that have been effective in mitigating urban heat in different climates, Kumar and collaborators have cited: roof gardens, hedges, trees in the streets, botanical gardens, wetlands, forests, covered walls of vegetation and golf fields. According to Kumar and collaborators, roof gardens and pergolas have been the most successful infrastructures to mitigate urban warming in Japan and Korea of Japan and Korea. South. In Chinese cities, botanic gardens, wetlands, vegetation walls and ponds were successful. In their article, Kumar and collaborators come to conclusions based on a review of more than 200 articles on interventions with GBGI infrastructure throughout the planet, carried out to mitigate urban warming. They claim that the information they present can serve to set policies to combat such warming. They consider even the likely climate changes that will occur in the future due to the effect of global warming. Apart from the detailed information presented by Kumar and collaborators, and given that the problem of urban warming originated from the destruction of a natural environment and the construction in its place of an artificial one, it is not difficult to understand that the solution of the problem is to try to restore the original environment as much as possible. Otherwise, we will continue to have hot summers on two tracks: global warming and urban warming.",
    "https://upload.wikimedia.org/wikipedia/commons/7/7d/Tree.ring.arp.jpg": "Let us consider a hypothetical situation in which civilization as we know it collapses and an archaeologist of the future - let us say, from the XL century - who is investigating the causes that led to that collapse. Since much of the documentary information would have been destroyed, the archaeologist uses carbon 14 to date the events that preceded the catastrophe. How much could he find out? As we know, the carbon 14 technique was developed at the University of Chicago by chemist Willard Libby in the 1940s and like many genius ideas, its principle is very simple. Libby knew that cosmic rays that impact our planet generate carbon 14 in the high parts of the atmosphere from nitrogen. Carbon 14, however, is not stable and disintegrates into carbon 12 -which is a stable version and more common than carbon 14 - so that in a period of 5,730 years half of the original carbon 14 will have been converted into carbon 12. On the other hand, plants take carbon from the atmosphere to carry out the photosynthesis process, and part of carbon 14 generated by the cosmic rays ends in the 12. As long as a plant is kept alive, the disintegrated carbon 14 is replaced continuously and its concentration in the plant tissues remains constant. Once the plant is dead, however, the proportion of carbon 14 will gradually decrease to virtually extinguished. Thus, from the percentage of carbon 14 remaining in the tissues of a plant it will be possible to date the time that has elapsed since its death. Unfortunately, that date has a margin of uncertainty of some decades, according to specialists, which could be excessive in certain cases. For example, while our archaeologist of the XL century may suspect that in the 20th century there were armed conflicts on a large scale given the rise in the concentration of carbon 12 in the atmosphere - which indicates that there was an increase in the burning of fossil fuels, possibly by war activities - he will have difficulty in reaching the conclusion that in the first half of the 20th century there were two world wars separated by an interval of two decades and not one war without interruption. Likewise, he will have difficulties in separating the increase, which he will surely observe in time, which he will surely observe the conclusion that in the first half of the 20th century there were two world wars separated by two decades and not a single war without interruption. , in the concentration of carbon 14 in the atmosphere, same as we know it was the product of the nuclear tests that were carried out during the Cold War in the decades of the 50s and 60s.In the face of these difficulties, our archaeologist of the future would have resources, and will be able to combine carbon 14 with dendrochronology, the science that allows revealing the secrets of the past engraved on the rings of the trunk of trees.In particular, he could make use of the results of an article published this week in the journal \u201cNature Communications\u201d by a group of researchers headed by Andrej Maczkowski of the University of Bern, Switzerland. He could do so, of course, in case the manuscript of that article survived the catastrophe.In his article, Maczkowski and collaborators date with a precision of a year various activities of tree felling and construction of wooden structures carried out between the years 5328-5140 B.C., in an archaeological site of prehistory in northern Greece. The researchers used sequences of tree rings that anchored in time making use of the event called Miya. ke, which is known to have occurred in 5,259 B.C. The Miyake events produce a temporary increase in the generation of carbon 14 in the upper layers of the atmosphere because of causes that are not completely clarified, but that according to experts, would be associated with an elevation of solar activity. The sudden increase of carbon 14 in the atmosphere by a Miyake event is recorded in the ring or rings of the trunk of the trees that correspond to the years when a particular event occurred, which allows to date such rings very precisely. To such a degree of precision that we can know in which year, more than 7,000 years ago, such or such a tree, was cut off, which was used for such or such a wooden construction. It is idle, of course, to speculate about what a hypothetical archaeologist might come to find out about a civilization that flourished and hypothetically collapsed two thousand years earlier. Depending on the magnitude of the catastrophe, civilization could have been returned to prehistory, in which case it could not even exist in the XL century, investigating the past. , however, science in two thousand years will have advanced to such an extent that the methods employed by the archaeologists of the present would seem curious.",
    "https://upload.wikimedia.org/wikipedia/commons/0/05/Tilia_tomentosa_coupe_MHNT.jpg": "Referring to events of which he witnessed in 536 A.D., the historian Procopio wrote in his work \u201cHistory of Wars\u201d: \u201cAnd during this year there was a omen of the most terrible. Because the sun gave its light without brightness, like the moon, throughout this year, and it resembled the sun much in eclipse, because the rays it threw were not clear, like those it usually cast. And from the moment this happened, men were not free from war or pestilence or anything else that led to death. And it was the time when Justinian was in the tenth year of his reign.\u201d According to specialists, what Procopio witnessed was the result of a volcanic eruption that threw into the atmosphere large quantities of gases and ash that darkened the light of the sun. The result was a volcanic winter that produced the coldest year in the last two millennia. The episode reported by Procopio has not been unique throughout history. Thus, for example, the year 1916, known as \u201c In recent years, the eruption of the Pinatubo volcano in the Philippines in 1991 caused a decrease in global temperature, although not as severe as the eruption of the Tambora volcano in Indonesia a year earlier. Similar to its temporary decline due to natural causes, the global temperature has experienced natural temporal increases throughout history. In addition, for some two centuries, the natural variability of the global temperature has been added to a continuous increase in greenhouse gas emissions to the atmosphere. And as a result, the summer of 2023 has been the hottest of the last 2,000 years. To this conclusion, an article published this week in the journal \u201cNature\u201d by a group of researchers led by Jan Esper of Johannes Gutenberg University, in Mainz, Germany. To reach this conclusion, Esper and collaborators reconstructed the air temperature during the months of June to August over the last 2,000 years. Since only measurements of air temperature are available from 1850 to arrive at this conclusion, Esper and collaborators reconstructed air temperature during the months of June to August. , the researchers had to reconstruct these two thousand years ago. For this they made use of the information about the climate that is engraved on the trunk of the trees. As it is known, the trunks of the trees show rings, of light and dark colors alternately. The light color corresponds to the accelerated growth of the trunk during the months of spring and summer, while the dark color is given by a slower growth during autumn and winter. Thus, each pair of light and dark rings corresponds to a year of life of the tree, so that counting the number of rings it is possible to find out the age of a living tree. In the case of a dead tree, that number corresponds to the age that it was at the time of death. In addition to the age of a tree, its trunk keeps information about the Earth's climate in the past. This is because the thickness of a ring depends on the temperature and environmental humidity prevailing at the time of growing, so that studying such thickness is possible to determine the changing climatic conditions under which the tree developed, particularly in terms of environmental temperature. Since in the southern hemisphere there are less temperature measurements than in the northern hemisphere and because in the lower latitudes the seasons are less marked and therefore the pattern of rings is less informative, they limited their study to latitudes in the northern hemisphere between 30 and 90 degrees.The combination of measured and reconstructed temperatures, employing more than 10,000 trees, led Esper and collaborators that the summer of 2023 has been the hottest in the last two thousand years, with a temperature that exceeded at least 0.5 degrees Celsius to the temperature of 246 A.D., which is the highest that occurred before we started burning fossil fuels. Moreover, compared to the record low temperature that occurred during the reign of Justiniano, the temperature of 2023 was 4 degrees Celsius higher. Given these numbers, Esper and collaborators conclude: \u201cAlthough 2023 is consistent with a trend of warming induced by greenhouse gases that is amplified by the El Ni\u00f1o event, this extreme emphasizes the urgency of implementing international agreements for the reduction of carbon emissions.\u201d Although it was expected according to the trend, and even without sharing Procopio\u2019s pessimism about the consequences that climate change can bring, it does not fail to impress us that last year has been the hottest in two thousand years. At the same time we crossed our fingers so that the current one does not overcome it.",
    "https://upload.wikimedia.org/wikipedia/commons/1/17/Mapadefertilidad2024.png": "Two of the characteristics of today\u2019s times are climate change and declining fertility rates. As we are aware, climate change is becoming increasingly present with extreme events, such as Hurricane Otis, which devastated Acapulco last October, and the current heat wave. Fertility rates, on the other hand, have been declining since the second half of last century, reaching values in many countries that are even below 2.1 births per woman, which is considered to be the minimum rate necessary to maintain a balance between those born and those dying. This is the case of countries such as Japan, South Korea, Italy and Spain, among others, which face a decline in population in the coming decades. As we know, climate change is due to the emission of gases into the atmosphere that has led to an increase in global temperature of 1.2 degrees centigrade compared to their pre-industrial values. The decline in fertility rate, on the other hand, has multiple causes, including the development of contraceptives in the 1960s, and the incorporation of contraceptives into pre-industrial values. We would not think that there was a connection between climate change and declining fertility rates. There is anecdotal evidence, however, that uncertainty about what climate change holds for the future produces a state of anxiety that has an effect on couples\u2019 plans to father a child, which could face a world collapsed by the climate disaster. Terms such as eco-anxiety and single-handedness have even been invented. According to Wikipedia, the latter \u201cis a neologism that describes a form of anguish, mental or existential stress, caused by environmental deterioration.\u201d In order to go beyond the anecdotal evidence and, where appropriate, to establish on solid grounds the influence that climate change has on couples\u2019 decision to have children, a group of researchers led by Hope Dillarstone of University College London, London, United Kingdom, the task was to carry out a comprehensive documentary review to determine how and why environmental concerns can affect the decision to The researchers published the results of their work last November in the magazine \u201cPLOS CLIMATE\u201d. Dillarstone and collaborators carried out a comprehensive review of the existing publications on climate change, mental health and well-being concerns, and reproductive decision-making. They examined 446 documents of which they chose 13 that correspond to studies carried out between 2012 and 2022. The studies involved 10,788 participants and were carried out in the United States, Canada, New Zealand and in European countries. The participants in the studies expressed concerns about the quality of life that a child would face in the future that would be born, in a world devastated by climate change. Likewise, they expressed concern about aggravating with children, the situation of an already overpopulated and overexploited world. According to Dillarstone and collaborators, in 12 of the 13 studies analyzed these concerns constitute a strong incentive to have fewer children or not to have any.The documentary research carried out by Dillarstone and collaborators involved mainly studies carried out in countries of the so-called Global North, is a strong incentive to have fewer children. In these circumstances, they consider that a similar study should be carried out with countries of the Global South, among which Mexico is among them. On the other hand, apart from the motivation or motivation of couples to limit the number of children, the fact is that the fertility rate has been drastically reduced, both in countries of the Global North and in the Global South. We could conclude that, subject to what specialists say, we could not perhaps blame completely for the fall in fertility to climate change, as it began in the last century before there was a public awareness of that change. But if we are to believe Dillarstone and collaborators, climate change does not seem to be entirely blameless either.",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/8/82/Carbon_cycle-cute_diagram.svg/600px-Carbon_cycle-cute_diagram.svg.png": "According to specialists, coal used as fuel originated from plants buried during the carboniferous period of the Earth, about 300-350 million years ago. In the same way, it is commonly assumed that oil and natural gas, also used as fuels, would have been formed from organic matter buried many millions of years ago, which was transformed by the great pressures and high temperatures to which it was subjected. Moreover, and aside from the assumptions about the formation of fossil fuels, what is a fact is that they were trapped under the surface of the planet for millions of years, until very recently - in geological terms - they began to extract and burn in an accelerated manner.This, as we know, has caused a climate crisis.The chemical element that is at the center of the climate crisis is carbon. By burning a fossil fuel, coal, oil or natural gas, carbon dioxide is produced that accumulates in the atmosphere and acts as a cover that reflects the heat emitted from the surface of the earth that is heated accordingly. In general terms, we are talking about electrifying the economy as a measure of mitigation of climate change. In some cases, however, electricity is not a solution. For example, suppose that it is intended to fly a commercial plane with solar energy. Since this energy is very diluted, it could not be obtained at the moment by means of solar panels placed in the fuselage of the plane and it would have to be stored previously in a battery bank. This bank, however, would have an excessive weight and the whole arrangement would be unviable. It would be difficult or impossible to dispense with high energy density sources, such as fossil fuels. For applications where renewable energy does not provide a feasible solution and we still intend to combat climate change, other options would have to be used. For example, the use of fuels that do not contain coal. As another possibility could be \u201creuse\u201d coal previously generated, multiple times if possible, instead of extracting more coal from the subsoil. In this regard, in an article appeared this week in the journal \u201cNature Reviews Chemis Chemis. This article was published by a group of researchers led by Wendy Shaw of Pacific Northwest National Laboratory in Washington State. It should be noted that Shaw and collaborators not only consider the defosilization of the economy to solve the problem of climate change, but consider it the most widespread problem of carbon pollution. In this sense, we know that there is a serious problem of plastic pollution, which are materials that contain coal as one of its constituents. Likewise, they consider pollution by municipal waste, by agricultural waste and by methane gas, which are all sources of carbon pollution. In particular, methane is made up of coal and hydrogen and is known to be a highly polluting greenhouse gas, many times more potent than carbon dioxide. Shaw and collaborators look at a world in which carbon atoms are not wasted, but are recycled for one application or as a raw material for other manufacturing processes. As sources of raw materials they consider the main sources of carbon dioxide. Shaw and collaborators look at a world in which carbon atoms are not wasted, but are recycled for one application or as a raw material for other manufacturing processes. The authors also see a world in which fossil fuels are replaced by other carbon-free fuels, such as hydrogen or ammonia. Hydrogen is particularly attractive because water is only obtained as waste from its combustion. Despite this great advantage, however, hydrogen also has disadvantages.One of them is its extremely low liquefaction temperature, of less than 253 degrees Celsius. Thus, we could not fill the fuel tank of our car with liquid hydrogen, as we can fill it with gasoline.For all of the above, carbon appears to be the villain of history, which does not cease to be unfair and misleading.On the one hand, like all living beings, we are in good measure made of coal.On the other hand, coal was placidly sleeping for millions of years under the surface of the earth and is not in any way guilty of carbon pollution. Misuse we've made of him.",
    "https://upload.wikimedia.org/wikipedia/commons/2/25/Drivers%2C_Processes%2C_and_Impacts_of_Sinking_Cities.png": "How much does a city weigh? That is, what is the total weight of its buildings and buildings? In an article published in January 2021 in the magazine \u201cAdvance Earth and Space Sciences\u201d, Tom Parsons, of the U.S. Geological Survey gives us an answer, concerning the area of the bay of San Francisco, California. According to Parsons, taking into account only buildings and not infrastructure works, San Francisco weighs 1.6 billion tons. While the work to be done to calculate the weight of a city would seem idle, it is necessary to consider that, according to specialists, in 2050, 70 percent of the population of the planet will live in cities, which implies that the volume of urban buildings will grow substantially. If the floor were \u201cfirm like a rock\u201d, there would be no problem in placing on it all the weight we would like. Unfortunately, we know that this is not necessarily true and that many cities in the world are sinking slowly, so it is necessary to ask if the weight of their buildings plays any role in this regard. According to experts, the weight of urban buildings is one of the factors contributing to the sinking of the soil. Another factor is the extraction of groundwater to meet the drinking water needs of the population. In one way or another, to assess the gravity of the problem it is necessary to know the speed with which the Chinese cities are sinking, and this is precisely the topic of an article published last April 19 in the magazine \u201cScience\u201d, published by a group of researchers headed by Zurui Ao of the South China Normal University. Ao and collaborators measured the sinking of the soil of the largest Chinese cities throughout the years 2015 to 2022. Specifically, they considered 82 cities that include 74 percent of the urban population of China. For their research, they made use of a technique known as \u201cSynthetic Opening Radar Interferometry\u201d, which allows measuring vertical movements of the soil from a few millimetres, from a satellite to hundreds of kilometers on the surface of the Earth. The technique, moreover, allows to observe large areas of land with a great detail. 45 percent are sinking at a speed greater than 3 millimetres per year, while 16 percent are doing it at a speed greater than 10 millimetres per year. This affects 29 percent and 7 percent of the urban population, respectively. According to the authors: \u201cSinking seems to be associated with several factors, such as the extraction of groundwater and the weight of buildings.\u201d Given the size of China\u2019s population, the previous numbers are shocking. Indeed, as Ao and collaborators point out, if their results are scaled up to the entire urban population of China, 270 million people are living in an area that is sinking at a speed greater than 3 millimetres per year, representing one third of Europe\u2019s population. Likewise, 67 million people in China are affected by a collapse of the land greater than 10 millimetres per year, equivalent to the total population of France. In addition to being affected by the sinking of the land, coastal cities in China are threatened by global warming, which is raising the sea level by the melting of the polar ice. In these circumstances, the authors consider that in 2120 there will be a high risk of flooding in coastal cities, unless measures such as the construction of protection dams are taken.As a strategy to mitigate the sinking of the land, Ao and collaborators propose that the key to addressing the sinking of China's cities could be in the sustained and long-term control of groundwater extraction. In this regard, they note that long-term water extraction control has managed to stabilize the sinking in Tokyo and Osaka in Japan, while incomplete and short-term control has proved ineffective, as exemplified by the experience of Quer\u00e9taro. Land collapses occur in cities around the world and Mexico is not the exception. In particular, it is not our city, which shows signs of sinking in several areas. We could perhaps rule out that such sinking is due to the weight of urban buildings, which are not particularly massive. Thus, as a more likely cause, we can think about the extraction of groundwater.",
    "https://upload.wikimedia.org/wikipedia/commons/4/49/Plagiomnium_affine_laminazellen.jpeg": "The American writer Ray Bradbury published in 1950 the book \u201cMartian Chronicles\u201d in which he describes the colonization of the planet Mars. In that book, Bradbury put together a series of short stories previously published separately. According to the first of these stories, which is entitled \u201cThe Summer of the Rocket\u201d, the colonization of Mars began in January 1999, when a rocket started from the U.S. state of Ohio with the first mission to Mars. On that occasion: \u201cThe rocket created the good weather, and for a few moments it was summer on Earth.\u201d The colonizers found in Mars an ancient civilization, already in decline. Although Bradbury does not describe in detail the physical aspect of Martians, if he points out differences with humans. Thus, Ylla and Mr. K, a pair of Martians who appear in the second story, \u201cThey had the clear complexion, a little brown, of all Martians, the yellow and torn eyes, the soft and musical voices.\u201d Without the subtlety and poetic abilities of Bradbury, they have described extraterrestrials more explicitly, in some cases possibly abusing the imagination. In this sense, at first, aliens were often green, although over the years they acquired other colors. And as for their body, extraterrestrials would have vaguely human form, but with clearly non-human characteristics. The fact, of course, is that we do not know with certainty what extraterrestrials look like. In fact, we do not have the certainty that they exist, although we would be surprised that it did not, given the immensity of the universe and the number of planets capable of harboring life. We could very probably rule out the existence of higher forms of life in our neighborhood, in our solar system. We would thus have to look in the neighborhood of other stars. To begin, we would have to identify planets with conditions similar to those of the earth. In this regard, more than 5,500 planets outside our solar system have been detected, of which more than 30 are similar. The photosynthesis, by which plants produce organic matter in our environment. This footprint is well known and is characteristic of green plants, which reflect not only green plants, and hence their color, without also infrared radiation. If this footprint is revealed on a distant planet, there would be an indication that it houses life. We contrast this strategy that is based on life as we know it on Earth to seek life on other planets, with the views of novelists and film directors who assume that extraterrestrial life is different, to a greater or lesser extent, than we have on Earth. In support of the latter, however, an article appeared this week argues that we should not only look for life signs provided by the photosynthesis of green plants, but that we should extend the search to forms of photosynthesis based on purple bacteria that print a different footprint. The article was published this week in the magazine \u201cMonthly Notics of the Royal Astronomical Society\u201d, by a group of researchers headed by Ligia Fonseca Coelho of Cornell University. with Fonseca Coelho: \u201cGreen is the color that we associate most with life on the Earth\u2019s surface, where conditions favored the evolution of organisms that perform oxygen-producing photosynthesis using the green chlorophyll pigment a. But a planet similar to Earth that orbits another star might look very different, potentially covered by bacteria that receive little or no visible light, as in some environments on Earth, and instead use invisible infrared radiation to boost photosynthesis. Instead of green, many of these bacteria on Earth contain purple pigments, and the purple worlds in which they are dominant would produce a distinctive \u201cdigital luminous footprint\u201d, detectable by next-generation terrestrial and space telescopes.\u201d According to Fonseca Coelho and collaborators, we must seek life not only in the green worlds like ours but also in the potentially purple worlds, which will be possible in the near future as the new telescopes become operational. Unfortunately, even if we discover that our planet is not the only place in the Universe that harbors life, with certainty We will still have the doubt about the color of the inhabitants of those worlds, if there were. Will they be green or purple? This could be relevant to novelists and film directors.",
    "https://upload.wikimedia.org/wikipedia/commons/7/73/Tonga_ESA363260.jpg": "As we know, this week a football game was held in the city of Monterrey between the Monterrey and Inter Miami teams, with Leo Messi in their ranks. On the occasion of this match, the famous Argentine football player Mario Kempes visited Monterrey, who was world champion with Argentina in 1978. During his visit, Kempes complained about the traffic of the city in the following way: \u201cWhat we have seen is fine, what happens is that good traffic usually here in Mexico is quite complicated, and Monterrey is no less, I hope that in any way that as that great possibility of World is approaching, arrangements will be made to make the return and return easier.\u201d Otherwise, we know that car traffic is not an exclusive problem of our country and that it is experienced by many cities throughout the world. On the other hand, while traffic is not the only discomfort we face who live in urban areas and would be missing fingers to list them, we have decided to stay in the cities because of the advantages they also have. In fact, cities were born thousands of years ago because at some point it turned out In an article published last week in the journal \u201cJournal of Archaeological Method and Theory\u201d, the results of a study on the early stages of the development of low density urban areas in Tongatapu are reported. Tongatapu is the main island of Tonga, a South Pacific island country of 100,000 inhabitants, which by its size occupies 186th place among the countries of the world. The article was published by Phillip Parton and Geoffrey Clark of the National University of Australia. As Parton and Clark comment, Tonga was first occupied in 900 BC and flourished from 1300 AD, until its collapse in the early 19th century, partly due to the impact of diseases introduced by foreigners. During its splendour, Tonga developed monumental architecture, commercial traffic networks and political and social institutions. Additionally, given its isolation in the middle of the Pacific Ocean, Tonga\u2019s primitive urban settlements developed without external influence, and its study reveals valuable information about urban evolution. Parton and Clark used topographic data from Tongatapu obtained in their research, Parton and Clark used topographic data from Tongatapu. By Lidar\u2019s technique, which is to launch a beam of laser light from an airplane to the surface of the ground, measuring the time it takes to return after reflecting on that surface. From this time on, it is possible to determine the elevations and depressions of the land. Lidar\u2019s use provides an enormous amount of data that cannot be obtained through traditional archaeologicals. In particular, Parton and Clark were interested in locating artificial earth mounds that are common in Tobgatapu and that are known to have been constructed for different purposes, either as tombs, or as platforms for the construction of houses or public spaces. In addition to the mounds, Lidar reveals networks of paths that link them, as well as fortifications and constructions to practice sport. Parton and Clark describe the process of urbanization of Tobgatapu, which would be initiated when the population is increased within the boundaries of populated areas and generates what it calls agglomeration effects: \u201cThe agglomeration causes changes in the way in which the settlements are built as the towns begin to make more efficient use by the inhabitants. The social institutions also bring about changes in the way in which a settlement is built, by competing for spaces to perform its functions with other uses of land, such as residential, subsistence and other productive uses.\u201d Based on their study, Parton and Clark conclude that settlements in the Pacific have considerable potential to contribute to debates on settlement formation, urbanization and sustainability, and will contribute to our knowledge of urbanization and development of complex societies. Certainly, the better we understand the process of city formation, we will be able to develop measures to counter the disadvantages of living in one of them. One city, however, is a very complex object of study - even more than the climate of the planet - and to understand that buttons will push for change in one direction or another, will not be something we achieve in the near future. However, let us hope that Monterrey can improve, even a little bit, the traffic of the city during the world-wide football season.",
    "https://upload.wikimedia.org/wikipedia/commons/2/2c/Illustration_different_solar_climate_intervention_techniques.png": "In his poem \u201cDarkness\u201d, Lord Byron describes an apocalyptic world in which,\u201cThe bright sun went out, and the stars Vagaban diluting through the eternal space, No rays, no routes and the icy earthIt was blind and darkening in the air without moon;\u201dByron wrote \u201cDarkness\u201d in 1816, a year known as \u201cThe year that did not have summer\u201d, which was particularly cold by a decrease in solar radiation that reached the surface of the earth. This phenomenon was due to the eruption of the Tambora volcano a year earlier. On April 5, 1815, the Tambora volcano, located on Sumbawa Island in southern Indonesia, erupted, reaching a peak of activity on April 10, when it occurred, the largest volcanic explosion recorded in history, heard thousands of kilometers away. Prior to this explosion, the volcano had a height of 4,300 meters above sea level, which was reduced to 2,850 meters after the explosion. These drops acted as a layer that partially reflected the sun's radiation that decreased its intensity when it reached the surface of our planet. This caused a drop in temperature in Europe and North America. Similar effects have occurred with other volcanic eruptions. For example, the eruption of the Krakatoa volcano in August 1883 resulted in a decrease of 0.4 degrees Celsius in the northern hemisphere, while the eruption of the Pinatubo volcano in June 1991 had similar effects over several months. The decrease in temperature that has led to the emission of gases into the atmosphere during volcanic eruptions has inspired some scientists who have proposed artificially injecting aerosols into the atmosphere as a means of countering global warming. In 2017, David Keith and Frank Keutch of Harvard University, made public their plans to study the spread of aerosols in the atmosphere. To this end, they proposed to raise a balloon and a suspended gondola with a load of several kilograms of aerosols. At this altitude, they would release the load and the balloon, equipped with the appropriate measuring instruments, would descend through the cloud of particles to study its dispersion in the atmosphere.This project would serve as an antecedent for subsequent aerosol dispersion projects in order to reduce solar radiation. Keith's and Keutch's proposal, however, proved highly controversial. His critics argued that the earth's climate is too complex and that artificially reducing the amount of solar radiation reaching the earth could have serious side effects of altering the global climate that are difficult to anticipate. In this regard, an article published this week in the MIT Technology Review magazine reflects views expressed by Jennie Stephens of Northeastern University: \u201cThe experiment put forward by Keith and Keutch was particularly dangerous, because Harvard's funding, attention and prestige conferred legitimacy on planetary scale interventions that, in his opinion, will never be able to be governed or controlled in a secure way.\u201d Further, Stephens argues that \u201ceven if researchers had the best intentions, solar geoengineering would ultimately be implemented by people or nations with money and power in the way that most benefits their interests, even if that would have disastrous consequences for other areas. Some research, for example, suggests that solar geoengineering could significantly reduce rainfall in certain areas and reduce yields from some basic crops. While a block of nations might decide to use geoengineering to relieve heat waves, what if that would reduce summer monsoons and food supplies in parts of India or West Africa?\u201d Critics received by Keith and Keutch\u2019s project made their effect and Harvard University announced last month the final cancellation of the project. Unfortunately, this may not mean that similar projects will not be carried out in other research centers. If, possibly not as open as Harvard University proceeded to avoid criticism. In this sense, let us hope that, after two hundred years, we will never have a new Lord writing an apocalyptic poem about a climate disaster. Artificial. Non-natural.",
    "https://upload.wikimedia.org/wikipedia/commons/5/5e/Ameca_Generation_1.jpg": "Seeing Ameca in action, the humanoid robot advertised as the most advanced in the world, produces a strange sensation. On the one hand, to emphasize its robot condition, the body of Ameca lets it see all its circuits and mechanisms that allow it to gain life. On the other hand, the face of the robot is covered by a grey-colored rubber skin that, once again, emphasizes its non-human nature - that allows it to gesticulate and remarkably reproduce human facial expressions. However, while seeing Ameca gesticular and interacting with humans using artificial intelligence is a spectacle, it is clear that the robot still lacks a good way to reach human non-verbal communication capacity, particularly the ability to communicate through facial expressions. In fact, according to experts, while verbal communication between humans and robots is rapidly progressing through artificial intelligence, non-verbal communication through facial gestures is not advanced with the same speed. Non-verbal communication between humans and robots is addressed in an article that appeared this week in the magazine \u201cScience Robots\u201d, published by a group of facial gestures. researchers led by Yuhang Hu of Columbia University in New York, who are particularly interested in communication through smile exchange. As you point out in your article: \u201cFew gestures are more affectionate than a smile. But, when two people smile at each other simultaneously, the effect is amplified.... Putting it in simple terms, if a smile is simultaneous, it is more likely to be genuine.\u201d Thus, an effective exchange of smiles between humans and robots would improve their interaction and make it more similar to the interaction between humans.For a robot to smile simultaneously with a human, it has to anticipate its smile. That is to say, it has to distinguish the subtle changes that occur in its face from the human that anticipate it. And, of course, it must know how to respond to the smile with another equivalent.Hu and collaborators built an anthropomorphic robot head that they called Emo, covered with a soft silicone skin and with 26 actuators to generate facial expressions that resemble humans. The robot was equipped with cameras in both eyes, which gave it a vision similar to the human. The eye module moves the eyeballs, eyelids, and eyebrows, while the mouth module allows the complex movements of the lips to be reproduced accurately. Emo was initially subjected to a training process so that he could learn to relate, looking in a mirror, a facial expression given with the action of a certain actuator. The knowledge acquired by the robot during the training was later used during his interaction with a human when he had to respond to a certain smile. The robot was equally subject to a second training so that it was able to identify the small facial changes that preceded a human smile. For this purpose, 970 videos of 45 human participants were used. 80 percent of those videos were used in training, while the rest was used to validate it. According to Hu and collaborators, their results demonstrate that it is possible to build a robot with sufficiently complex movements, which can be trained to generate an early facial expression in its interaction with a human. They recognize, however, that the success of its results can only be measured by the reaction that In these conditions, they consider that: \u201cAn essential future step is to validate the emotional effect of these expressions on the interactions between humans and robots in different contexts in the real world to determine their psychological effects.\u201d Certainly, seeing Ameca with her pale blue face and her metal body, gesticulating, moving her arms and answering questions, produces a strange feeling. What would be our reaction to a humanoid robot that moves and reacts in an indistinguishable way from that of a human?",
    "https://upload.wikimedia.org/wikipedia/commons/c/ca/IEA_International_Energy_Agency_Map.png": "With the energy transition, the demand for oil is expected to reach a maximum value at some point and then gradually decrease to the extent that fossil fuels are replaced by renewable energy sources, such as the sun and wind. Based on the exponential growth of renewable energies and electric cars, the International Energy Agency of the Organization for Economic Cooperation and Development, predicts in its report \u201cWorld Energy Perspective 2023\u201d that the maximum demand for oil will be reached by the end of this decade. This is essential to ensure that the increase in the temperature of the planet does not exceed the limit of 1.5 degrees centigrade with respect to its pre-industrial values, a limit that experts have set to avoid a climate disaster. Not everyone is so optimistic, however. For example, at the CERAWeek conference held in Houston, TX last week, the executive director of the oil company Saudi Aramco described as a fantasy that will be completely replaced by oil and natural gas. In fact, he notes that the demand for such fuels will grow in the coming years and that the Agency International Energy is wrong, because it focuses only on industrialized countries and not on underdeveloped countries in the process of industrialization that will require large amounts of energy. On the \u201cSuper Spiked\u201d website, analyst Arjun Murti argues in the same direction. According to Murti, each of the billion people living in the United States, Canada, Western Europe, Japan, Australia and New Zealand \u2013 the world of rich people \u2013 use 13 barrels of oil on average annually, while the remaining 7 billion people living in the underdeveloped world only use an average of 3 barrels per year. Thus, even if the underdeveloped world did not consume per capita energy equivalent to that of rich countries, there would be a future demand for energy several times higher than current demand. We can expect, argue Murti, that the demand for oil will continue to increase at least for the next ten years. And he concludes: \u201cThe idea that crude oil will not play any role and will decrease globally is pure fantasy. On the other hand, in its \u201cWorld Energy Outlook 2023\u201d, the International Energy Agency writes: \u201cToday, the average global surface temperature is already around 1.2 degrees Celsius above pre-industrial levels, causing heat waves and other extreme weather events, and greenhouse gas emissions have not yet reached their peak. The energy sector is also the main cause of contaminated air that more than 90 percent of the world\u2019s population is forced to breathe, linked to more than 6 million premature deaths a year.\u201d The International Energy Agency recognizes that the global energy context is complex. However, at the same time, it considers that the emergence of a new clean energy economy, headed by photovoltaic solar energy and electric vehicles, offers hope about the way forward to overcome the energy crisis. In this regard, it notes that investments in clean energy have grown forty percent since 2020, and that these investments have not only been aimed at reducing greenhouse gas emissions, but also other objectives. In about five years we will be able to find out if the International Energy Agency is right and the energy transition will move forward fast enough for oil demand to peak before the end of the decade. Or, if oil companies and skeptical analysts are right and the fossil fuel market \u2013 and not the renewable energy market \u2013 in developing countries will grow fast enough to sustain the business, and thus aggravate the problem of climate change.",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/OpenAI_Logo.svg/512px-OpenAI_Logo.svg.png": "As we know, with the irruption of artificial intelligence numerous jobs will be lost because artificial intelligence has skills that in some cases surpass human ones. To know these skills we consult ChatGPT, which is precisely the product of artificial intelligence. Specifically, we asked him the following question: what are the five skills in which artificial intelligence surpasses humans? As a response, chat makes us know that we are overcome by artificial intelligence in terms of processing and analysis of large volumes of data that it can perform in a faster and more efficient way. Likewise, we are overcome in performing repetitive tasks, both in speed and precision, as well as in recognizing complex patterns of data, text, images or signals, and in games such as chess and Go, which require the deployment of a complex strategy. In addition, unlike ours, artificial intelligence does its work without experiencing fatigue.Fortually, humans have skills in which we overcome (at least for now) artificial intelligence. To know ChatGPT's opinion on this question we asked you: According to chat, humans have a capacity to think creatively, to generate innovative ideas and to find solutions to complex problems, which have not yet been fully replicated by artificial intelligence. Likewise, humans outperform artificial intelligence in emotional intelligence that allows us to understand our emotions and those of others and to guide our behavior accordingly. According to ChatGPT, artificial intelligence lacks the ability to understand and experience emotions in a genuine way. Among other advantages that we humans have over artificial intelligence, we include the ability to make decisions that are close to ethics. Artificial intelligence, in contrast, can only make decisions based on data and ready rules. Likewise, while humans have the flexibility to adapt to changing environments, artificial intelligence still does not achieve equivalent adaptability. Finally, humans practice nonverbal communication, which includes body language, voice tone and facial expressions, skills that are essential to social interaction. In this sense, artificial intelligence still has limited capacity. In contrast, for the \u201cZ\u201d generation (1977-2012), the corresponding numbers are 38 per cent and 33 per cent. The scenario has been isolated from artificial intelligence, while 29 per cent are strongly influenced by artificial intelligence. In contrast, for the \u201cZ\u201d generation (1977-2012) the corresponding numbers are 38 per cent and 33 per cent. In this sense, the LinkedIn network, owned by Microsoft, contemplates the work of the future grouped into three groups. A first group composed of works in which artificial intelligence collaborates and human workers that provide complementary skills. A second group in which artificial intelligence plays a dominant role, with complementary activities playing a minor role. Finally, in a third group, human work is relatively protected from artificial intelligence. In the previous scenario, all generations of workers are exposed to artificial intelligence, but for the newer generations this exposure is greater. It is to the degree that it raises strange collaborations (advantages, otherwise) between humans and algorithms, counting the latter even with some capabilities that surpass human ones. Certainly, as ChatGPT itself recognizes, humans have capabilities that artificial intelligence will have to overcome. However, that this is maintained in the future is something that is still to be seen.",
    "https://upload.wikimedia.org/wikipedia/commons/b/bf/Iceberg_at_Baffin_Bay.jpg": "On May 18, 1854, he left England for the Arctic the expedition headed by John Franklin, with the mission of finding the so-called Northwest Pass, which would connect the Atlantic and Pacific Oceans by a maze of frozen canals between the islands to the north of Canada. As we know, the expedition, which was composed of the ships Erebus and Terror and a crew of 129 men between officers and sailors, had a tragic end and never returned to England. Neither the ships nor the expeditionaries, which all died in the attempt. The expedition was last sighted by whale ships on July 22 in the Bay of Baffin and then disappeared when the ships were trapped in the ice. Only until recent dates were the remains of the ships sunken in the Canadian Arctic discovered. In the year 2014 was found the Erebus and in 2016 the Terror. As for the crew, it is now known that, desperate after spending two winters trapped in the ice, they decided to leave the ships and walk south trying to reach Canadian mainland territory. However, they did not reach their goal. And they all died on the way. They joined the 24 crew members, including Captain Franklin, who had already died during the long wait. Otherwise, we know now that, in one way or another, the expedition would most likely not have managed to find the desired passage, by the ice blocking the navigation between the islands of the Canadian Arctic. In fact, it would have been more than half a century before the Norwegian Roald Amundsen managed to cross it for the first time in 1906, on a voyage that took him three years. Had Franklin tried to make his search for the Northwest Pass in the present time - a time machine, for example - he would have encountered much less obstacles, because climate change is causing a gradual decrease in the volume of Arctic ice that facilitates sea traffic. In relation to the latter, an article appeared on 5 March in the magazine \u201cNature Reviews Earth and Environment\u201d, makes a review of the knowledge that experts have about the loss of ice that is suffering the Arctic Ocean from climate change and conclude that there could be occasions during the summer The article was published by a group of researchers led by Alexandra Jahn of the University of Colorado in Boulder. It should be noted that for Jahn and collaborators an Arctic ocean free of ice does not imply that the sea is completely devoid of ice. Instead, for them, the ocean is free of ice when its ice-covered surface is less than one million square kilometers, equivalent to half of our country\u2019s territorial extension. To put this into perspective, it should be noted that one million square kilometers is just 20 percent of the surface of the Arctic ocean that was covered with ice in the summer of the 1980s. As Jahn and collaborators point out: \u201cThe Arctic sea ice has substantially decreased since the beginning of satellite observations in 1978, and is expected to continue to do so in the future. In fact, ice-free conditions could occur in the month of September in the 2020s or 2030s, and in the middle of the present century they are likely to occur, regardless of which the gas emission scenario may occur. It is expected that between 2035 and 2067 conditions will occur consistently without ice, which implies a transition to an Arctic frequently free of ice. This, in a scenario of high emissions, with a small delay possible in scenarios of lower emissions.\"While the predictions that experts can make about something as complex as climate change and the precise effect that it may have on Arctic ice, is a fact that the volume of said ice is decreasing. And that decrease has had an unexpected consequence: it is hindering the research work being carried out by the Canadian government agency Parks Canada with the remains of the Erebus and Terror to uncover the mysteries still contained about John Franklin's bad expedition. Indeed, according to a report from the British newspaper The Guardian, \"Work with the remains of sunken ships is particularly urgent, because, being in shallow waters, they are being whipped and mistreated by the increasingly severe storms as climate change seizes the region.\" Arctic 180 years ago hit the road with Franklin's expedition, while now, the little ice makes it difficult to find out the details of how the disaster happened.",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/0/04/ChatGPT_logo.svg/512px-ChatGPT_logo.svg.png": "In a gradual way we have lost as a species the privileged place we once thought we had in the world. Thus, when Nicolas Copernicus in the sixteenth century made public his model of solar system in which the planets revolve around the Sun and not around the Earth, we lost the place that, as the center of the universe, we had for thousands of years. Similarly, when Charles Darwin in the nineteenth century announced his theory about the origin of species, ours turned out to be another species, which evolved and changed drastically over millions of years as did all the others; although maintaining a prominent place as the smartest of all. To our uneasiness, however, with the eruption of artificial intelligence we could be in danger of losing this last bastion. The possibility has already been glimpsed for several decades. For example, in the film \u201c2001 Odyss\u00e9e del Espacio\u201d by director Stanley Kubrick premiered in 1968, the Discovery 1 ship makes a journey to Jupiter on a secret mission with five crew members on board. HAL 9000, a super computer equipped with artificial intelligence. In a sequence of the film, HAL revolts and kills four of the five crew members of the ship. Under the circumstances, the surviving crew member is given the task of deactivating one by one the computer circuits, which tries to convince him to stop. It does not succeed and HAL is finally deactivated, not before reaching into a song. Without the fact that machines equipped with human intelligence have been the subject of speculation by experts, and authors of fiction works since the second half of the twentieth century, it was not until recent dates that began to become reality as a result of the development of increasingly powerful computers. In this sense, on the Internet we can freely access chats endowed with artificial intelligence, such as ChatGPT and Gemini, which provide structured responses to questions or requests that are formulated to them. How far chats like ChatGPT are endowed with intelligence equivalent to human intelligence? An article appeared in the magazine \u201cScient Reports\u201d the past. February 10 addresses this question, particularly as regards the creative capabilities of chat. This article was published by a group of researchers led by Kent Hubert of the University of Arkansas. Experts distinguish between convergent thinking and divergent thinking. The first focuses on finding the optimal solution to a given problem, while the second freely seeks multiple solutions to that problem. Hubert and collaborators focused their research on the divergent creativity of ChatGPT chat and its comparison with corresponding human creativity. For this purpose, they pooled a group of 151 volunteers and subjected them to three types of tests to measure their level of divergent creativity: \u201calternative uses\u201d, \u201cconsequences\u201d and \u201cdifferent partnerships.\u201d Thus, participants were asked in a finite time to provide as many alternative uses as they could for a \u201ctenedor\u201d and for a \u201cagreement\u201d, and measured both the number of uses proposed, and the originality and elaboration (number of words) of their responses. They were also asked to elaborate as many responses as they could to the consequences of the following: \u201cthat they did not\u201d In addition, to measure their divergent creativity, they were asked to provide ten substantive names with as different meanings as they could. In this case, the differences between the words provided by a standard test were measured. Finally, for comparison purposes, ChatGPT was subjected to the same tests. The researchers found that: \u201cIn general, GPT-4 was more original and elaborate than humans in each of the divergent thought tasks, even when the number of responses was taken into account. In other words, GPT-4 demonstrated greater creative potential in a complete battery of divergent thinking tasks (i.e., task of alternative uses, task of consequences and task of divergent associations).\u201d However, they note that while ChatGPT chat showed creative superiority over us, such creativity was not activated by itself, but with the help of humans. Despite this last observation, and given the speed with which technology progresses, one might wonder: how long before the creativity of ours could take place. The computers go off on their own and we lose our last bastion?",
    "https://upload.wikimedia.org/wikipedia/commons/9/9c/Regi%C3%B3n_Huasteca.png": "According to CONAGUA data, on February 15, this year, 80 per cent of the national territory is affected by some degree of drought. In this sense, CONAGUA considers five categories, which in ascending order of affectation are: abnormally dry, moderate drought, severe drought, extreme drought and exceptional drought.The areas of our country with the highest category of drought are found, especially, in the states of Chihuahua, Sonora, Durango and San Luis Potos\u00ed.In our state, the entire Huasteca region suffers from exceptional drought.The municipality of San Luis Potos\u00ed, for its part, is affected by extreme drought.Water is an input that is indispensable to us, so that drought forces us to replace the water that does not provide us with rains.In this regard, we know that the water we use is classified mainly of two types: surface and underground.The sources of surface water are the rivers, lakes or dams that feed on rain, while groundwater is stored in porous rock in the subsoil. . The extraction of groundwater, however, may result in a decrease in the level of an aquifer if water is extracted at a faster rate than the natural recharge rate of the aquifer, which we know occurs in a multitude of cases. Indeed, it is sufficient to consider that one of the effects of the over-extraction of groundwater is the sinking of the soil and the formation of cracks, of which we have numerous examples.Beyond anecdotal cases, an article published last January in the journal \u201cNature\u201d reports the results of a study carried out to document the trend of water levels in the last decades of water wells in 40 countries. The article was published by a group of researchers headed by Scott Jasechko of the University of California in Santa Barbara. Jasechko and collaborators compiled and analyzed national statistics data to determine how water levels of 170,000 wells have changed in 1,693 aquifers. They found that, throughout the present century, 71 percent of wells decreased their water level. In contrast, only 6 percent of aquifers increased their water level by more than 10 centimetres per year, while 1 percent did so by more than 50 centimetres per year. Additionally, researchers compared these trends with those observed over the last two decades of the last century and found that in 30 percent of wells the speed with which the water level decreased became faster in the present century. Thus, Jasechko and collaborators found that the problem has grown as time went by. On the other hand, researchers find that this problem tends to be worse in the areas of cultivation in arid or semi-arid climates. Likewise, they found a correlation between the decrease in rainfall throughout the year and the decrease in the level of aquifers. In this sense, we might expect the recharge of an aquifer to be slower due to the absence of rains, at the same time that its exploitation is increased to supply surface water. In spite of its pessimistic results with regard to the increasing collapse of aquifer levels, the study by Jasechko and collaborators also calls for optimism. Thus, researchers find cases in which such dejection has slowed or even reversed through appropriate policies of aquifer exploitation. They caution, however, that the speed with which the depth of wells is growing, in cases where this is happening, is greater than the speed with which this depth is decreasing in cases of success. One way or another, it should be recognized that the considerations about the dejection of aquifer levels are passing at this time to a second plane, since the urgent thing for now is to replenish the water that nature is evading us. But the study of Jasechko and collaborators should not be thrown out of the way as soon as the predicament happens.",
    "https://upload.wikimedia.org/wikipedia/commons/1/12/UASLP.1.png": "With the advent of computers and artificial intelligence, many professions are in danger of disappearing. Let us consider, for example, that of a scholar with encyclopedic knowledge in a given topic or topic. Of course, there is no profession of scholar as such. On the other hand, there is the Internet in which they are stored an immense amount of data that virtually anyone can access. Thus, for example, without we do not remember the date and circumstances of such or such historical fact, we can easily find out on the Internet. Otherwise, a scholar is not only a data warehouse, but, in addition to that, he has the ability to analyze them and to reach conclusions, in which for now we do not exceed the machines. The profession of scholar is not then in danger of disappearing. At least for the moment, but anything could happen in the future to the extent that artificial intelligence algorithms available to the general public are substantiated. In these circumstances, we must be careful when we consult information from the Internet. In particular, since anyone can upload information to the network, we cannot be assured of artificial intelligence algorithms available to the general public. We must thus have a critical attitude to evaluate the information we obtain. Critical thinking is one of the skills they consider essential in the digital age, in which computers and their algorithms are increasingly present and cause accelerated changes. And this is not only in the day-to-day, but also in the professional field. Critical thinking, on the other hand, is not the only essential skill for professional performance. Others are creativity and innovation, the ability to solve problems, the flexibility to adapt to changes, the ability to work as a team, and the emotional intelligence to interact with other people. Fostering new skills must then be part of academic programs of professional training at the university level, particularly those programs classified within the STEM area, an acronym in English for the terms Science, Technology, Engineering and Mathematics. STEM education contemplates multidisciplinary training in areas of science and engineering, and emphasizes the development in the student of new professional skills. This education, which is considered key to the future, is receiving a great boost. Today, according to figures from \u201cNational Science Foundation\u201d, a new professional skills. On Thursday, February 15th, on the occasion of the celebration of the 30th anniversary of the UASLP Bachelor's Degree in Physical Engineering, we had the opportunity to reflect on STEM education at our University. We will mention that this bachelor's degree began in the summer of 1993 as part of the academic offer of the Faculty of Sciences. According to the academic vocation of the Bachelor's Degree, which seeks to train specialists in scientific and technological fields, all academic activities are carried out in the facilities of the Institute of Optic Communication Research of the UASLP and are in charge of its researchers. Since its creation, the program of the Bachelor's Degree in Physical Engineering included characteristics of STEM education. Namely, a multidisciplinary education in the areas of physics, mathematics, computing, electronics and optics, covering both theoretical and practical aspects. As for the latter, the emphasis is on learning through projects. Thus, the student learns to propose a project and to work on its solution. He does so, in conjunction with other students. He trains in this way in group work and in the development of project. The theoretical courses, on the other hand, encourage him to develop critical thinking. Graduates of the Bachelor\u2019s degree have joined both the academy and the teachers as well as the productive sector. Most of them work in Mexico, but there are also those who reside abroad. About half of the graduates have sought to continue with postgraduate studies. Of these, 22 percent have reached a doctoral degree, in institutions both in Mexico and abroad. The Bachelor\u2019s degree in Physical Engineering of the UASLP was born three decades ago, at the same time that the STEM concept began to be delineated in the United States, but there were no contact points. Still, we can find many of the characteristics of STEM education in the Physical Engineering program, including the promotion of skills that are considered key for the 21st century. Being a project born entirely in the UASLP and given its success, we consider that the Bachelor\u2019s degree in Physical Engineering is a possible model for STEM education in Mexico.",
    "https://upload.wikimedia.org/wikipedia/commons/2/25/Cerebro_corte_frontal_Alzheimer.jpg": "According to the \u201cAlzheimer\u2019s Association\u201d, approximately 11 percent of Americans over 65 years of age suffer from Alzheimer\u2019s disease. In contrast, the prevalence of Alzheimer\u2019s disease in the Tsiman\u00e9 population over 60 years of age is just over 1 percent. Tsiman\u00e9 are a people who live in the lowlands of Bolivia and practice a pre-industrial lifestyle with a high physical activity and a low fat diet that keeps them overweight. In addition to the low prevalence of Alzheimer\u2019s, Tsiname are known for having a low incidence of cardiovascular disease. This suggests that there is a correlation between the lifestyle and incidence of Alzheimer\u2019s disease and other dementias. In this sense, an article appeared last January 25 in the magazine \u201cJournal of Alzheimer Disease\u201d concludes that there is little evidence of Alzheimer\u2019s disease in its advanced stages in historical records of the Greco-Roman world. That article was published by Caleb Finch and Stanley Burnstein, of the University of Southern California and the State University of California, respectively. There were no technical terms describing Alzheimer's disease, Finch and Burnstein searched for passages in texts that alluded to a loss of mental capacity with age and found that Hippocrates in the fourth century B.C. listed diseases of old age, including digestive, physical, deafness, and loss of sight, and insomnia, but found no allusions to the loss of mental capacity. Likewise, they find that Aristotle, also in the fourth century B.C., described cognitive deterioration with age: \u201cOld men and those who have already passed their best age have mostly characters that are opposed to those of youth. They live in memory rather than in hope.... They speak incessantly of the past because they find pleasure in memories.\u201d Aristotle's text, however, did not include a description of a severe loss of cognitive capacity characteristic of Alzheimer's disease. Finch and Burnstein also consulted texts from ancient Rome in search of allusions of mental illnesses associated with age. . Cicero writes in the first century B.C.: \u201cThe foolishness of the elderly, which is usually called delirium is characteristic of irresponsible old ones, but not of all the old ones.\u201d Cicero, however, did not include mental decay as one of the four evils of old age, namely: the end of an active life, physical weakness, the cessation of pleasures and the closeness to death. Thus, the loss of memory with age was somewhat unusual in Rome as it was in Greece. However, Finch and Burnstein find a greater number of incidences of severe mental affectations with age in Rome compared to Greece. Thus, Juvenal wrote in the second century A.D.: \u201cMost of the damage to the extremities is dementia, which does not know the names of the slaves or the face of the friend with whom he had the night before or to those whom he begot and made grow.\u201d Speculan Finch and Burnstein that the increase in the number of mentions to mental deterioration with age is associated with an increase in atmospheric pollution and Another possible explanation, the researchers ventured, is lead contamination, because it is known that the Romans added a lead-containing compound to wine as a sweetening agent. Similarly, the pipes that led to the water that drank the population contained lead. Researchers conclude that, while they identified Greek and Roman texts describing cases of mental deterioration with age, the cases of severe deterioration equivalent to that currently observed with Alzheimer\u2019s disease or other mental illnesses are scarce. These, in turn, were apparently less frequent in Greece than in Rome, suggesting that they are related to environmental factors. Of course, two thousand years away it is difficult to reach solid conclusions, but the low incidence of Alzheimer\u2019s disease among the Tsiman\u00e9s \u2013 who live in a pre-industrial society, subject to conditions similar to those of the ancient Greeks and Romans \u2013 suggests that additional historical research be carried out.",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/5/58/Greenhouse_Effect.svg/600px-Greenhouse_Effect.svg.png": "The Moon is not a welcoming place for visitors. Among other things because it has no air to breathe, besides that the temperatures that are experienced there can range between 120 degrees Celsius during the day and less than 150 degrees Celsius during the night. These temperature variations, which are due to the fact that the Moon does not have an atmosphere that regulates its temperature and to the long duration of lunar days and nights that extend for two weeks, make it impossible to survive on the Moon without special equipment. While on Earth we do not reach these extremes, we know that there are places with variations of temperature that can become uncomfortable. In dry places, for example - as is the case of our city - the light nights produce fresh mornings due to the loss of heat due to the absence of clouds that reflect the heat emitted by the surface of the Earth. At the same time, in cloudless days the flow of solar radiation increases the environmental temperature considerably. In the current situation, where the planet is experiencing climate change, one may wonder to what extent such change is affecting the temperature differences between day and night. This article was published by an international group of researchers headed by Ziquian Zhong of Beijing Normal University, and concludes that in the last 30 years, due to the effect of climate change, the increase in daytime temperatures exceeds the increase in night temperatures. This means that the gap between the two temperatures is growing. The difference in temperature increases between day and night, known as \u201casymmetric increase\u201d, has been observed since the second half of the last century. Between 1961 and 1990, this increase was negative, which means that the difference between daytime and night temperatures was decreasing. In its article, Zhong and collaborators find that in the last three decades this trend has reversed, so that the daytime temperatures are growing faster than the night temperatures and the gap between the two temperatures is increasing. Specifically, researchers find that between 1961 and 1990 in 81 percent of the earth\u2019s surface the asymmetric increase was negative, while since 1991 this increase has become positive in Zhong and collaborators based their study on two sets of weather observations covering the entire planet, although they do not do so in a sufficiently broad way for South America and Africa. In these conditions, researchers find that both sets of observations yield similar results for North America, Europe, Asia and Australia. This is not the case for South America and Africa, possibly due to insufficient data, the researchers conclude. The causes that led to this change of trends are complex, as is the Earth\u2019s climate. However, they consider Zhong and collaborators that this change is associated with a decrease in cloudiness. In the words of these researchers: \u201cWe found that the change in the trend of asymmetrical warming is closely related to changes in solar radiation associated with total cloudiness. This finding offers a new vision and a different perspective on climate change in recent decades. Since clouds may continue to have positive feedback on global warming through radiation flows, the phenomenon of increase in daytime temperature above night temperature may persist and potentially intensify in the future. Therefore, more attention is needed. to this phenomenon of asymmetrical warming, from the perspective of addressing the challenges posed by global warming.\"We would not expect, of course, that the gap between daytime and night temperatures would reach the levels observed on the Moon - not even those of Mars, which would also be lethal. According to experts, however, greater temperature gaps could affect food production and even our health. In this sense, they could lead to a higher heart rate and blood pressure, and an increase in cardiovascular and respiratory diseases. Thus, with asymmetric warming we add a further strip to the tiger of global warming.",
    "https://upload.wikimedia.org/wikipedia/commons/8/88/William_Livingstone_House%2C_Brush_Park%2C_Detroit_%28417140528%29.jpg": "To celebrate today's football game between the Lions of Detroit teams and the 49ers of San Francisco for the championship of the National Football Conference, the facade of the Michigan Central Station building in Detroit was illuminated with the word \u201cLIONS\u201d, with seven-story high letters. In this sense, it should be remembered that for three decades the team had not had an equivalent success.The Michigan Central Station was inaugurated in December 1913 and was kept in service as a railway station until the year 1988, when it was definitively closed.From that moment on, the building deteriorated gradually, becoming a symbol of the decline of the city of Detroit.In these conditions it was acquired by the Ford company that is restoring it.As we know, as part of the de-industrialization process that has suffered the midwestern and northeastern North American generation of the so-called herrumbe strip, Detroit has lost two thirds of its population since 1950 and suffered an urban deterioration that included the Michigan Central Station building.Detroit is perhaps the most example. This article was published by a group of researchers headed by Uttara Sutradhar of the University of Illinois in Chicago. In their article, Sutradhar and collaborators consider about 30,000 cities - defined as agglomerates of inhabitants - that they classify as urban, suburban, peri-urban and rural, depending on their location, number of houses-habitation and number of inhabitants. In their article, Sutradhar and collaborators consider about 30,000 cities - defined as agglomerates of inhabitants - that they classify as urban, suburban, peri-urban and rural, depending on their location, number of houses-habitation and number of inhabitants. They find Sutradhar and collaborators who collaborate on the basis of daily transfer time. In addition, researchers consider four geographic areas of the United States: north-east, mid-west, west and south. They find Sutradhar and collaborators who 43 percent of the cities studied are decreasing their population, including the largest cities in the middle west, while 40 percent are increasing it and in the remaining 17 percent the population is fluctuating. As for future trends, researchers find that, while all urban cities in the western and southern geographic areas will have gained population in the year 2100, in the north-eastern and mid-western areas about 17 percent of urban cities will lose it to some degree. Overall, the 30,000 cities studied would lose in the year 2100 to 25 percent of their population.The North American cities may lose inhabitants because they move to the suburbs or to other cities.In any case, as Sutradhar and collaborators point out, the loss of inhabitants leaves underutilized urban infrastructure that has to be dismantled and pressured the city's finances by the decrease in the number of taxpayers.In Mexico, where the decline in population has only occurred on our scale of time in specific cases, the process that is happening in our neighbor to the north seems perhaps somewhat distant. We have to judge by what we see in our city, far from an urban shrinkage, we are witnessing accelerated growth by the trade agreement with the United States and Canada. We crossed our fingers, however, for everything to go on without novelty. Otherwise, let us hope Detroit recovers. And not only as far as football is concerned.",
    "https://upload.wikimedia.org/wikipedia/commons/1/1a/Solar_power_satellite_sandwich_or_abascus_concept.jpg": "On January 16, the California Institute of Technology (Caltech) published a statement in which it reported the successful completion of the \u201cSpace Solar Power Demonstrator\u201d project (SSPD-1) which aimed to evaluate three key technologies for the use of solar energy from space. The sun is a virtually inexhaustible source of energy, but at the same time intermittent, not available during hours of the night. Thus, collecting solar energy in space, where the Sun shines permanently, has clear advantages and according to some experts could contribute to mitigating the climate crisis. For this purpose, projects such as Caltech\u2019s have been designed to place in an Earth orbit mirrors that reflect the light of the Sun and focus it on solar panels for conversion into electrical energy. The electrical energy thus generated will be converted into microwave radiation that are directed towards a receiving station on the earth that transforms it back into electrical energy for distribution. The SSPD-1 project had the purpose of carrying out three experiments: DOLCE, ALBA and MAPLE. DOLCE, according to Caltech\u2019s statement, \u201cis the purpose of conducting three experiments: a structure measuring 1.8x1.8 meters that demonstrates the novel architecture, packaging scheme and deployment mechanisms of a scalable modular structure that will eventually form a constellation of kilometre scale that will serve as an electrical power plant.\u201d According to the same statement, ALBA \u201cis a collection of 32 different types of photovoltaic cells to allow an assessment of the types of cells that can withstand demanding spatial environments,\u201d while MAPLE \u201cis a set of light and flexible microwave power transmitters based on customized integrated circuits with precise synchronization control to selectively focus energy on two different receivers to demonstrate the transmission of wireless energy remotely into space.\u201d According to Caltech\u2019s communication, the three experiments were successfully conducted and will serve as a starting point for developing space solar energy. In particular, it was possible to demonstrate the sending of energy by microwave between two points in space, as well as from space to the researchers\u2019 laboratory in Caltech. On the other hand, at the margin of the successful results of the SSPD-1 project, space solar energy according to some experts is still far from being a reality. Energy losses that inevitably occur due to the conversion of solar energy into electric power and hence into microwaves and again into electric power, but mainly because of the high cost of placing a solar installation with dimensions of kilometers into orbit. In relation to the latter, it should be noted that it is optimally necessary to place the solar installation as a satellite of the Earth at a fixed point in the firmament, that is, in a geosynchronous orbit with a rotation period of 24 hours, so that the satellite turns at the same speed as the rotation of the Earth. The height of a synchronous orbit is about 35,000 kilometers, approximately a tenth of the Earth-moon distance. A lower orbit would reduce the cost of deploying the solar installation, but at the same time it would rotate at a greater speed than the Earth and several solar satellites would be needed to provide continuous energy to a given point on the Earth surface. Currently, more powerful rockets are being developed capable of placing into orbit large weights -150 tons in the case of SpaceX Starship - and safely at some point it will be possible to assemble into a geo-synchronous orbit. These satellites would be able to provide energy from a clean and practically inexhaustible source. Moreover, continuously, since a space solar installation is not subject to the day-night cycle or to the vicissitudes of the Earth's climate, as microwave radiation would reach the Earth's surface even through a layer of clouds.There would, however, be some precision to be made. First, to evaluate space solar energy as a clean source of energy, it would have to be taken into account that putting into geosynchronous orbits kilometric structures requires burning huge quantities of fuel that generate polluting waste. And second, that a satellite in a geosynchronous orbit is not subject to the Earth's climate, but to the climate of space with high-energy radiations that degrade the efficiency of solar panels. Thus, as usual, there would be gains, but not at zero cost.",
    "https://upload.wikimedia.org/wikipedia/commons/0/0e/Kaffe_og_mandarin_%285198912077%29.jpg": "Today we can purchase with a few weights an ordinary plastic comb, about 20 centimetres long, divided into two sections, one with 75 teeth and another with 40 teeth. Thus, we can comb at a cost essentially equal to zero. This was not the case in the past, when combs were crafted using materials such as wood, bone or ivory and had a price much higher than that of a plastic comb. In this sense, we should consider the enormous effort that was necessary to craft a bone or ivory comb with dozens of teeth separated by just over a millimeter.The cost of a plastic comb today is so low because they are manufactured in series, using materials of very low cost.As we know, the plastics industry, which are artificial materials that do not exist in nature, had its origin in the first decades of the last century, and it has been so successful that we can find them practically everywhere. At present, the annual production of plastics worldwide is close to 400 million tons. Unfortunately, once plastics are so successful that we can find them everywhere. They are known to undergo a fragmentation process over time, generating what is known as microplastics, defined as plastic particles with dimensions between 5 millimetres and a micrometer. To appreciate this last dimension, it should be remembered that the diameter of a human hair is around 100 micrometers. It is also known that microplastics are further fragmented, resulting in nano plastics, defined as plastic particles with dimensions less than a micrometer. Nano plastics are a cause for concern among experts, since because of their small size they can cross biological barriers and penetrate into the human body, with toxicity that is still unknown. Nano plastics are virtually everywhere on planet Earth, including in the water we drink and in the food we eat. In particular, they are known to be present in bottled drinking water in plastic containers, and in this regard, an article appeared this week in the magazine \u201cProceedings of the National Academy of Science. The article was published by a group of researchers led by Naixin Quian at Columbia University in New York. To carry out their study, Quian and collaborators developed a technique that allows the detection of particles as small as a tenth of a micrometer, while determining their chemical composition. Researchers detected an average of 240,000 particles per litre of water, 90 percent of which are nano plastics. This represents 100 to 1000 times more particles than previously reported. Researchers were able to detect 7 different types of plastics in the water analyzed. These, however, represent only 10 percent of all particles detected. That is, the chemical identity of 90 percent of these particles is unknown.Based on the types of nano plastics identified, Quian and collaborators suggest that some of the pollutants could have been released from the plastic bottle during transport or storage. In other cases, pollutants may have been generated during the production of water, possibly by the membrane used in the Thus, this process would have produced water contaminated with nanoplastics. The International Association of Bottled Water reacted negatively to the article by Quian and collaborators and in some way discredited its method of determining nanoplastics. Thus, on the website of that association we can read: \u201cCyprus standardized methods are currently lacking and there is no scientific consensus on the possible impacts on the health of nano and microplastic particles. Therefore, media reports on these particles in drinking water do nothing but unnecessarily scare consumers.\u201d It is difficult to disqualify the results of Quian and collaborators whose article went through a rigorous peer review process. On the other hand, according to experts, there would be no lack of studies on the toxicity of nanoplastics. In conclusion, the emergence of plastics not only allowed us to make cheap combs to fix our hair, as well as countless other objects that changed our lives, but also brought invisible contamination whose toxicity is to be determined.",
    "https://upload.wikimedia.org/wikipedia/commons/7/7a/Anatomy-1751201_1280.png": "To what extent will the irruption of artificial intelligence change the labour market? What are the professions that are most in danger of disappearing from the emergence of this technology? To find an answer we came to Bard, the Google chatbot that, like other chatbots, provides structured answers to specific questions, based on information stored on the Internet. Since Bard himself is a product of artificial intelligence, we are confident that he has provided us with an informed answer. Specifically, we asked the chatbot the following question: What jobs will disappear by Bard? His answer is summarized below. \u201cIt is difficult to predict exactly which jobs will disappear due to the arrival of Bard or other similar artificial intelligences. However, we can analyze the types of tasks that these technologies could automate, and therefore put at risk certain jobs.\u201d As jobs that have a high probability of automation, the chatbot considers those that involve routine and repetitive tasks, as \u201cBard can process information and perform repetitive tasks much faster than humans.\u201d With regard to the latter, the chatbot comments: \u201cAlthough Bard can generate basic content such as reports or summaries, it still lacks the creativity and nuances of human writers. However, it could automate aspects such as market research or data analysis for content creation.\u201d In its response, the chatbot also considers jobs with less risk of disappearing, but with chances of transformation. This involves jobs that combine routine and creative tasks, in which case, \u201cBard could automate routine tasks leaving humans the creative and strategic part.\u201d This could benefit jobs such as journalism, so that \u201cBard can help with research, data verification and data analysis, allowing journalists to focus on storytelling and in-depth reporting.\u201d Artificial intelligence can also transform the work of software developers. According to the chatbot, \u201cBard can generate code and automate repetitive tasks, releasing developers to focus on design, architecture and problem solving.\u201d transform teaching: \u201cBard can customize learning materials and provide automated feedback, allowing teachers to focus on the individual needs of students and on interaction in the classroom.\u201d Thus, if we are to believe Bard, whose opinions are shared by experts, artificial intelligence will have a great impact on the labour market, eliminating or transforming jobs, and at the same time creating others with new qualifications. In this sense, the World Economic Forum in its \u201cReport 2020 on the Future of Employment\u201d lists jobs with increasing and decreasing demands. Among the jobs on the downside, it includes the following: data capturist, administrative and executive secretary, bookkeeper and bookkeeper, mechanic and repairer, financial analyst and bank cashier, among others. On the other hand, rising jobs include: analyst and data scientist, specialist in artificial intelligence and automatic learning, specialist in \u201cbig data\u201d, specialist in digital marketing, specialist in automation, internet specialist in things, project manager and robotics engineer, among many others. According to Bard, in the future, the following skills will be key: critical thinking and problem solving, creativity and innovation, and social and emotional intelligence. For the rest, at least for the time being digital machines are conceived as human collaborators, forming a duo with a \u201chybrid intelligence\u201d. Each member of the duo specializes in a certain type of activities that complement each other in order to enhance their capabilities and perform together tasks beyond what they could carry out independently. However, it should be asked whether, given the speed at which digital technologies are advancing, there will not be a time when machines will not be an advantage in their association with humans. It should be noted, however, that Bard does not contemplate this possibility.",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/b/be/Cruise_Automation_Bolt_EV_third_generation_in_San_Francisco.jpg/320px-Cruise_Automation_Bolt_EV_third_generation_in_San_Francisco.jpg": "The year that ends today is undoubtedly the year of artificial intelligence. As we recall, it was November 30, 2022 that the OpenAI company launched ChatGPT chatbot, capable of processing large amounts of information and providing coherent answers to questions and requests made by the user. ChatGTP\u2019s success was instantaneous and in less than a year reached 100 million users weekly. Following the launch of OpenAI, throughout 2023 other companies, including Google, Amazon, Microsoft and IBM, also released their own versions of chatbot. On the other hand, 2023 was not a positive year for another application of artificial intelligence: autonomous cars. In fact, the magazine \u201cMIT Technology Review\u201d includes the robotaxis, or driverless rental cars, of the company Cruise in its list of the worst technological failures of the year. This, together with the Titan submarine that imploded when it plunged 3,500 meters in the Atlantic Ocean trying to reach the remains of the Titanic, and the supposed development of an environmental superdriver made public by Korean researchers and turned out Cruise is a company owned by General Motors, a car manufacturer, which maintained a robotaxis service in the city of San Francisco, California. In the beginning Cruise was only allowed to operate its taxi service on a restricted schedule of less traffic, but on August 10 it obtained permission to operate on an open schedule. It did not last much, however, because a series of traffic incidents forced it to reduce by half the number of robotaxis in service. Worse, on October 24, the license to operate autonomous taxis was revoked by an incident in which a person suffered serious injuries and in which one of his robotaxis was involved. In that incident, which occurred on October 2, a woman was run over by a vehicle driven by a human and thrown in the path of the robotaxi circulating next to her. Without stopping, the robotaxi struck the woman and passed her over before stopping briefly. Crusier moved at low speed to get away from traffic, dragging the woman by about six meters. With the revocation of his permit, Crusier can only operate robotaxis if they carry on board a human safety driver who can take control of the vehicle in an emergency, so that his autonomy would be limited. It should be noted, however, that such autonomy was limited and that the operation of Cruise's robotaxis is monitored remotely by human safety drivers. In this sense, an article published last November in the New York Times newspaper, points out that the fleet of Cruise's robotaxis is remotely supported by a team of security drivers - on average 1.5 drivers per car in circulation - who intervene in its operation every 4-8 kilometers of travel. That is, in the handling of taxis without driver it involves a number of security drivers greater than the number of human drivers that would be needed to handle an equivalent number of non-autonomous taxis. For example, that as a result of an accident has ended up above a person, which must lead him to remain static. Otherwise, from such an affair we may be able to learn some things. First, that really autonomous cars are not yet around the corner. And second, that even if the problems of training of autonomous cars for cities like San Francisco, with orderly traffic, were solved, they will not necessarily have been solved for cities with less urban order, where cars would have to overcome all kinds of unexpected situations, from the presence of a pot capable of smashing a rim, to the quick and aggressive handling of (human) drivers who at all costs want to advance the car in front of them or cross with the traffic light almost red.",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Cassiopeia_A_%28MIRI_Image%29_%282023-121-01GWQBBY77MHGFV3M3N63KDCEJ%29.png/599px-Cassiopeia_A_%28MIRI_Image%29_%282023-121-01GWQBBY77MHGFV3M3N63KDCEJ%29.png": "The day of tomorrow will have passed two years since NASA launched the James Webb telescope into space on December 25, 2021, and placed it in an orbit around the Sun at a distance of 1.5 million kilometers from our planet - approximately four times the Earth-moon distance. This telescope is equipped with two infrared cameras, which over the past two years have provided us with spectacular images of the Universe with an unprecedented resolution. One of these images was released by NASA on December 10th and will be part of a calendar of advent included in the Christmas decoration of the White House this year. The image in question corresponds to Cassiopeia A, an object in the distant firmament of the Earth about 11,000 light years. Astronomers know that this object corresponds to a remnant of supernova, that is, of a star that collapsed at the end of their life releasing a huge amount of energy. That image was taken with infrared light that is invisible to the human eye. Using false color, however, NASA translated the infrared light into visible light and built an image that may be. The image of Cassiopeia A, which can be seen in the NASA statement, is indeed spectacular and could be used to decorate a Christmas tree as pointed out by the space agency. It shows us a bright ring expanding 10 light years in diameter, with an intricate structure and orange and pink colors. View from Earth, the star explosion would have occurred about 350 years ago. It should be remembered, however, that Cassiopeia A\u2019s image corresponds to an event that occurred 11,000 years ago, which is the time it took for the light to reach us. In addition to its spectacularity, Cassiopeia A is attractive because it contains a mystery. Indeed, given the enormous amount of energy that a supernova releases, it is difficult not to see its appearance in the firmament. The supernova that originated Cassiopeia A would thus have been observed some 350 years ago. There is, however, no incontrovertible historical evidence that it has been, although the matter is controversial. In this sense, it has been argued that the supernova was seen to have been observed. by the British Royal Astronomer John Flamsteed on August 16, 1680, who reported the observation of a star known as 3 near Cassiopeia A, in a position where no star is observed today. However, there is no agreement among experts that Flamsteed has actually observed the supernova and the matter remains unclarified.In a comment published in November 2009 in the magazine \u201cNature\u201d comments Geoff Brumfiel: \u201cThe remains of the supernova known as Cassiopeia A, have been a mystery for astronomers. Supernovae usually produce an extremely dense object such as a black hole or a neutron star. But for decades an object with these characteristics has not been observed in the center of Cassiopeia A.\u201d Thus, in 1999 the Chandra X-ray observatory identified a compact object in the right place. This object, however, does not correspond to what the experts expected, according to Craig Heinke of the University of Alberta in Canada. However, Heinke and his colleague Wynnn Ho of the University of Southampton in the United Kingdom consider that with this discovery it is possible to explain to Cassiopeia A, that it would contain a neutron star in its center. There would, however, be alternative explanations in such a way that there is no broad explanation for the nature of Cassiopeia A. Did Flamsteed observe in the seventeenth century the supernova that generated Cassiopeia A? And in any case, what is the intimate nature of this star object? We do not know for sure for the moment, and we will have to wait for more future studies. Not knowing the answers to these questions, however, does not prevent us from admiring the pictorial beauty of Cassiopeia A's images, nor using them as Christmas ornaments of great originality. Nor admire us the technological wonder that produced spectacular images millions of kilometers from Earth.",
    "https://upload.wikimedia.org/wikipedia/en/5/59/West_blue.png": "In 1900, 41 percent of American workers were farmers, while in 2000 this percentage was reduced to 2 percent. This drastic reduction was due to the mechanization of agriculture and the consequent increase in agricultural productivity, which reduced the number of workers needed to maintain food production. This reduction is a dramatic example of the loss of jobs due to technological advancement; in this case, because of the development of agricultural machinery that made the production of American farmers efficient. The case is not unique, of course, and the loss of jobs is a common occurrence when new technology breaks in. Thus, professionals with typing skills found that they were no longer useful for finding a job. In the same way as the professionals of last century\u2019s photography found that their skills to reveal photographic negatives and print photographs were obsolete when digital cameras appeared. Secretarial or professional photography works, on the other hand, did not disappear, but were transformed, demanding new skills: to handle the word processor of a computer or to print photographs. The destruction of jobs and the creation of new ones with different skills occurs in the face of the emergence of a new technology, a process that has happened quickly in the case of computer technology. Particularly in terms of artificial intelligence and data mining, which are disruptive technologies that aim to make disappear and at the same time create many jobs in a number of areas. Let us consider, by way of example, the profession of lawyer and in particular the concept of \u201ccomputer lawyer\u201d coined by a group of researchers led by Dell Zhang of Thomson Reuters Lab., in the article entitled \u201cMaking a computer lawyer\u201d. That article appeared last April in the memoirs of the congress \u201cSIAM International Conference on Data Mining\u201d, and was commented by the authors last December 1 in \u201cSIAM News\u201d. According to Zhang and collaborators, the concept of computer lawyer refers to: \u201cIntelligent software capable of helping human lawyers with a wide range of complex high-level legal tasks\u201d. , the software would go beyond simply carrying out mundane legal information processing tasks, such as drafting legal briefs for the prosecution or defense in court that can be performed by aides, and would assist human lawyers with complex tasks, including the preparation of indictment or defense briefs before the court. The computer lawyer would have access to an extensive legal database and once he reaches a certain degree of maturity, \u201che could begin to exhibit emerging skills, one of which is legal reasoning.\u201d As Zhang and collaborators comment, a future computer lawyer must meet certain requirements. First, he should be updated and kept up to date with changes in the legal field. To facilitate this process he may employ techniques of continuous learning, automatic learning and data mining. He should also reason within the legal scope of the relevant jurisdiction, and his legal opinions and judgements should be derived from relevant laws and rules. Computer lawyers should be able to \u201ccapture subtle details and nuances in the instructions of other legal lawyers or clients. They should also be teachable, in the sense that they continue to learn from relevant laws and regulations. Zhang and collaborators do not expect computer lawyers to replace human lawyers, \u201cbut to collaborate with them as competent and reliable partners.\u201d However, if we look at the characteristics listed in their article, future computer lawyers would learn and keep up to date as human, reason as human, write their writings as human, and communicate with other lawyers as human. Thus, as lawyers, they would be short of being indistinguishable from humans. And given the speed at which artificial intelligence technology is advancing, one wonders whether the time will come when, as happened with farmers, typists and photographers, human lawyers will have trouble finding a job. This would be to be seen, but what is clear is that such a possibility must be taken into account in the training plans of new lawyers (human).",
    "https://upload.wikimedia.org/wikipedia/commons/0/04/Limiting_global_warming_to_2_degrees_Celsius_-_options_to_reduce_greenhouse_gas_emissions_%28PBL%29-es.png": "Days before the launch of the United Nations Climate Change Conference in Dubai from 30 November to 12 December of this year, the International Energy Agency (IEA) released the document: \u201cThe oil and gas industries in net zero transitions\u201d, which analyses the role of these industries in mitigating climate change. As we know, the 2015 Paris agreements set as a goal to limit to 2 degrees Celsius the increase in the temperature of the planet with respect to its pre-industrial values, and urge efforts to ensure that this increase does not exceed 1.5 degrees Celsius and the IEA document states that the gas and oil industries must take an active role in the mitigation of global warming. According to the IEA, the possibility of limiting global warming to 1.5 degrees Celsius is still open. However, this agency notes that, while solar energy has experienced a boom and purchases of electric cars have skyrocketed - one in five electric cars sold worldwide in 2023 will be electric-, achieving a net zero emission in 2050 requires In particular, the active participation of all companies in the energy sector is required. The IEA points out that there are two misconceptions regarding the role of energy companies in mitigating global warming. The first of these is that \u201cenergy transitions can only be driven by a change in energy demand,\u201d so that the role of energy companies would simply be to wait for demand to drop and reduce production accordingly. Far from this, according to the IEA, \u201cNo one committed to change should wait for another to act first. Successful and orderly transitions are those in which suppliers work with consumers and governments to expand new markets for low-emission products and services.\u201d According to a second misconception, carbon capture and storage as a means of limiting atmospheric pollution is not feasible as a strategy, to try to maintain the current level of fuel consumption. As the IEA explains: \u201cIf oil and natural gas consumption evolve as currently projected policies will require the inconceivable capture of 32 billion tons of carbon by 2050 to limit the current level of fuel consumption. This would require an electric power equivalent to the global demand for electricity by 2022, and more than 3.5 million dollars in annual investments from today to mid-century, which is equivalent to the average annual revenues of the entire industry in recent years. It is expected that the demand for fossil fuels will peak at the end of this decade. Beyond this point, however, with the current trend the demand for such fuels will not decline fast enough to limit global warming to 1.5 degrees Celsius. Today, on the other hand, 800 billion dollars are invested annually in the oil and gas sector, which is twice as much as it will be needed in 2030 to limit warming to 1.5 \u00b0C. Thus, the IEA, in a scenario where the demand for oil and gas falls - the use of these fuels would fall by more than 75% in 2050 - energy companies will not need to carry out new fossil fuel projects and will be able to devote 50 percent of their investment to the development of clean energy projects. However, some companies will be able to use their technological knowledge to develop new clean energy projects, others will direct their investments to other fields. The IEA document emphasizes that there is a dialogue between oil and gas producers and consumers: \u201cDialogue between all parts of the oil and gas value chains remains essential to achieve an orderly abandonment of fossil fuels and to ensure that today\u2019s producers have a significant interest in the clean energy economy... Energy transitions can occur without the participation of the oil and gas industry, but the journey to net zero will be more costly and difficult to travel if they are not on board.\u201d On our side, we might perhaps expect an industry that has annual profits of millions of dollars, to be willing to participate in solving a problem that it helped to create.",
    "https://upload.wikimedia.org/wikipedia/en/2/2e/Napoleon_Film_poster.jpg": "In a scene in the film \u201c2001: Odyssey of Space\u201d by director Stanley Kubrick, we can see a stewardess on board a spaceship with a charola in her hands, walking horizontally through the walls of the enclosure and then head over the roof of it. This is done by wearing shoes that stick to the surfaces and by virtue of the fact that there is no gravity in space, so that the concepts above and below lose their meaning. Likewise, in another scene in the same film we see astronauts traveling to Jupiter who exercise on a curved surface inside a ship that rotates to simulate gravity force. To film these scenes, Kubrick advised himself with experts and produced a film that is credible from the point of view of the laws of physics. For this reason, and for many other elements produced by the Kubrick genius, \u201c2001: Odyssey of Space\u201d, released in 1968, he established a reference for the science fiction films. \u201c by director Ridley Scott, who some specialists have criticized for his lack of historical accuracy. In particular, it is pointed out that, during his invasion of Egypt at the end of the eighteenth century, Napoleon never bombarded the pyramid of Giza as it appears in the film. In fact, Napoleon had a great appreciation for Egypt, as evidenced by the fact that he carried with him as part of the military expedition, a battalion of more than 160 artists and scientists from all disciplines who studied and documented the Egyptian past, and with whom Napoleon created the \u201cInstitute of Egypt\u201d in Cairo. Bombing the pyramid of Giza \u2013 one of the seven wonders of antiquity \u2013 does not then seem to be an action that Napoleon would have considered carrying out. Likewise, the experts consider that the scene of the Scott film where Napoleon assists the execution of Maria Antonieta never occurred. At the time of such execution, in October 1793 in Paris, Napoleon would have been found in the city of Tolon in southern France fighting the revoltists against the republic. In fact, the military success that Napoleon had in To In another inaccuracy, Marie Antoinette would have worn her hair short at the time of her execution and not long as she appeared in the film. On the other hand, she was surprised that, in response to the criticisms of the inaccuracies of her film, director Scott had asked her critics: Were they there? No, they were not there, then how can they know? In the same tenor, the director of a science fiction film where one hears a rumble when something explodes in space - of which there are examples - could answer to anyone who mentioned that the event was impossible, because in space there is no air and therefore there is no sound: Were they there to corroborate it? Incidentally, at some point, Stanley Kubrick planned to make a film about Napoleon. Without his intentions finally materialized, the information he collected for this purpose was used to film the film \u201cBarry Lyndon\u201d of 1975, in which an Irish young man participated as a combatant in the Seven Year War between Europe. In those years, of course, there was no electric light, and in order to place the film at the time, Kubrick filmed the interior scenes using candlelight exclusively.The cinema is an entertainment industry and therefore we could expect film directors to take some historical or other liberties to maximize the chances of a film achieving commercial success. However, it would be necessary to ask whether this justifies falsifying historical facts or presenting scenes in which the principles of physics are violated, without the director making it obvious that this is the case. Moreover, directors like Stanley Kubrick demonstrate that the cinema business is not necessarily against reflecting the world, past and present, as it is.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d3/Astronaut_Riding_a_Horse_%28SDXL%29.jpg": "\u201cSeeing to believe,\u201d says the saying, alluding to the fact that the sense of sight is indispensable and sufficient to perceive the world as it is. Thus, if the eyes are indicating this or that situation, we must assume it as true. It seems, however, that artificial intelligence is fretting with the saying, at least with regard to the perception of a person\u2019s image on the screen of a computer, which we might conclude corresponds to a real person, but that it could actually have been constructed by means of an artificial intelligence algorithm. Do we have the ability to distinguish whether the photograph of the face of a person appearing on the computer screen corresponds to that of a physical person or whether it is an image synthesized by a computer program? In an article published this week in the magazine \u201cPsychological Science\u201d, a group of researchers headed by Elizabeth Miller of the National University of Australia, address this question. At a stage of their research project, Miller and collaborators made use of a set of 100 photographs of the face of real people and 100 facial images of fictitious people generated by a researcher at the National University of Australia. As part of the experiment, they presented 100 images of this set to a group of 124 white adults and asked them to decide which of these images were real and which were false. They found that 66 percent of the false images were classified as real, while 51 percent of the actual photographs were correctly classified as belonging to real people. That is, a majority of the participants gave an incorrect answer regarding the images generated by artificial intelligence and concluded that they belonged to real people. They were, for the most part, deceived by the artificial intelligence algorithm that built them. This is a phenomenon that researchers call artificial intelligence hyperrealism. In contrast, the responses with respect to the photographs of real people were as often correct as they were incorrect, which implies that, on average, the participants were unable to distinguish their origin.Miller and collaborators point out that the tendency to incorrectly classify the images of white faces generated by computer is not observed with images, real or fictitious, of color personar, which in a balanced way are classified correctly or incorrectly. This would explain the results of his experiment, since the artificial intelligence algorithm that was used to generate the images was mostly trained with the faces of white people. Thus, the computer specialized in generating images of white people, rather than people of color. And it specialized to such an extent that it is able to deceive us. The preferential generation of white images by computer could have a racial impact. In the words of Amy Dawel, one of the authors of the reference article: \u201cIf AI\u2019s white faces are consistently perceived as more realistic, this technology could have serious implications for people of color by ultimately reinforcing racial prejudices online. This problem is already evident in current artificial intelligence technologies used to create professional-looking photographs. When used with people of color, artificial intelligence alters their skin and eye color to those of white people.\u201d Elizabeth Miller comments: \u201cIn a worrying way, people who thought that the faces generated by artificial intelligence were real, very often were paradoxically the most convinced that their judgments were correct. . This means that people who confuse the impostors of artificial intelligence with real people do not know that they are deceived.\u201d Of all the above, it seems that, in fact, the hyperrealism of artificial intelligence is putting in check the saying \u201cSee to believe\u201d, attributed to Thomas the Apostle and that it would therefore have two millennia of antiquity. It also threatens the saying \u201cAn image is worth more than a thousand words\u201d, for what value would an image that can be misleading? Otherwise, while artificial intelligence is the source of the problem, it also provides its solution. Thus, Miller and collaborators report in their article the development of an artificial intelligence algorithm that detects false faces with an accuracy of 94 percent.",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/2/29/Projected_Change_in_Temperatures.svg/600px-Projected_Change_in_Temperatures.svg.png": "We know that the body must maintain a temperature of about 37 degrees Celsius and for this it must dissipate the excess heat generated by its metabolism through different mechanisms.One of these mechanisms involves the sweat, which acts as a refrigerant that absorbs heat from the body when it evaporates in contact with the skin.The efficiency of sweating as a body cooling mechanism, however, depends on the environmental conditions, specifically the atmospheric humidity.We can understand this fact in the following way.When the sweat in contact with the skin evaporates, it does so by taking a certain amount of heat and thus contributing to decrease the temperature of the body.For the sweat to evaporate, however, the atmosphere must be able to receive it and this depends on the amount of water vapor that already contains; that is to say, the atmospheric humidity. Thus, if the atmosphere is saturated with moisture, the sweat will not be able to evaporate and will lose its capacity as a refrigerant.In case the air saturation is not complete, the sweat will retain this capacity, but reduced to a greater or lesser degree depending on the degree of saturation of humidity. We know from experience that, in fact, sweat loses its cooling capacity in humid environments, so that the discomfort that produces a temperature of, for example, 40 degrees Celsius, is greater in a humid climate than in a dry one. This fact is familiar to us and does not cause us too much concern. It could, however, become a headache due to the climate change that is producing extreme heat events. In relation to the latter, experts consider that the maximum humid bulb temperature compatible with the functioning of the body is 35 degrees Celsius. Beyond this value, the body could not regulate its temperature and death could occur. It should be noted that a humid bulb temperature - measured with a thermometer whose bulb is wrapped in a damp cloth - is a measure, not only of the temperature of the air, but also of the atmospheric humidity, and that in some way reflects the degree of discomfort we experience. If atmospheric humidity is 100 percent, the temperature of humid bulb coincides with the temperature of the bulb. On the other hand, with an atmospheric humidity of 75 percent, a humid bulb temperature of 35 degrees Celsius corresponds to an air temperature of 41 degrees Celsius. According to experts, only by exception have episodes occurred, for short periods of time, that have reached a humid bulb temperature of 35 degrees Celsius. These episodes, however, will be more frequent as climate change advances, according to an article published last October 9 in the journal \u201cProceeding of the National Academy of Sciences\u201d of the United States. The article was published by a group of researchers headed by Daniel Vecellio of Pennsylvania State University. Vecellio and collaborators consider four scenarios, with atmospheric temperature increases of 1.5, 2, 3 and 4 degrees Celsius with respect to their pre-industrial values. They note that we have already exceeded 1 degree Celsius of increase and that, if the emission of greenhouse gases is not mitigated, we would reach 3 degrees Celsius in the year 2100. The researchers find four particularly vulnerable areas: northern India, eastern China, the Middle East and sub-Saharan Africa. For example, with an increase of 2 degrees Celsius in atmospheric temperature, the city of Lahore, Pakistan, would experience 147 hours per year with humid bulb temperatures exceeding 35 degrees Celsius, while an increase of 3 degrees Celsius would raise this number of hours to 447. Similar numbers are obtained for the city of Bandar Abbas in Iran. A special case is the city of Al Hudaydah Ade in Yemen, which would experience 300 days per year with excess temperature, if the atmospheric temperature increased by 4 degrees Celsius, which would make it uninhabitable. In addition, it should be mentioned that the most affected areas are among the most populated in the world. With respect to our country, fortunately the situation would not look so good and there would only be consequences for the north-west region and the Gulf coast of Mexico if the atmospheric temperature increased by 4 degrees Celsius. collaborators: \u201cThese results indicate that a significant portion of the world\u2019s population will experience, for the first time in human history, prolonged exposures to uncompensable extreme humid heat.\u201d Certainly, the situation in the coming decades does not look very promising.",
    "https://upload.wikimedia.org/wikipedia/commons/3/36/Two_transmission_towers.jpg": "On September 4, 1882, the \u201cPearl Street Station\u201d plant came into operation to provide electricity to New York City. The plant, built by Thomas Alva Edison\u2019s Electric Illuminating Company, was the first commercial station at the central level to generate and distribute electricity. The electricity business in the 19th century generated intense commercial disputes. One of the most well-known is the so-called \u201cwar of currents\u201d, which confronted Edison and the direct current, on the one hand, and George Westinghouse and the alternating current, on the other. We remember that in the last two decades of the 19th century two electrical technologies coexisted that disputed supremacy: direct current and alternating current. In an alternate current system, the direction of the current changes alternately, while in a direct current system the current always has the same direction. With the alternating current, used by Westinghouse, it is possible to increase or reduce voltage in a relatively simple way. In the Westinghouse system, the voltage of the transmission line was raised to thousands of volts and was reduced to a safe level just before the power was delivered to the user. Edison's direct current system, in contrast, did not have the ability to increase and reduce the voltage of the transmission line and this limited the distance to which it could transmit the electrical energy.In this situation of disadvantage, Edison made use of all kinds of tricks. For example, he sought to create the impression that the alternating current is dangerous and capable of killing a person by accident. To delve into this direction, Edison made it clear that the electric chair, newly instrumented as a method of execution, used alternating current, which proved its lethality. Edison himself contributed to the development of the electric chair, as reported in the book \u201cEdison and the electric chair\u201d by author Mark Essig. However, in the end, with all and contrition, the alternating current was imposed to direct current. This has been made possible by the development of technologies to harness the energy of the sun or wind, which are distributed over the entire surface of the planet, albeit in a uniform manner. In particular, the progressive price reduction that solar panels are experiencing makes their installation more and more attractive in rooms. How widespread will this trend be in the future and to what extent will consumers generate their own energy and not depend on a central facility? An article published last November in the magazine \u201cJoule\u201d by a group of researchers headed by Max Kleinebrahm of the Karlsruhe Institute of Technology, Germany, seek to answer this question.Kleinebrahm and collaborators carried out a study to determine the potential for 41 million homes in European Union countries, plus the United Kingdom and Norway. They assessed this potential, both for the present time and for 2050. For this purpose, they selected 4,000 representative housing houses. In this sense, it is necessary to consider that the regions included in the study include climate-various areas, from the south to the north of Europe. Based on their study, researchers find that today, from a technical point of view, 53 per cent of the 41 million housing houses considered could achieve total independence from the public electricity network. They also project that by 2050 this number reaches 75 per cent. From an economic point of view, however, in order to achieve total energy independence consumers would have to pay more than they would pay to the public network. Thus, in 2050, up to 2 million households would be totally independent if their owners were willing to pay 50 per cent more than they would pay to continue connected to the public network. We could hope that, in the coming decades, if somewhat weakened, the model of electricity generation in the Central installations that emerged from the war of currents. In contrast to the electric chair, which fortunately almost disappeared from the map.",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/2/2c/Pacific_hurricane_tracks_1980-2005.jpg/800px-Pacific_hurricane_tracks_1980-2005.jpg": "In a report issued at 4 p.m. on Monday, October 23, the National Hurricane Center of the United States reported on the probable trajectory of tropical storm Otis at that time: \u201cAlthough Otis is expected to remain in a moderate shearing wind environment, abundant humidity and warm sea surface temperatures should favor its gradual strengthening until it touches land. Models have been on the rise and it now seems likely that Otis will be close to reaching hurricane force when it reaches the coast.\u201d The National Hurricane Center closed its bulletin with two key messages: \u201c(1) Heavy rains by Otis will start impacting areas in southwestern Mexico earlier this week. This rain will produce sudden storms and urban floods, as well as landslides in higher terrain areas. 2) Tropical storm conditions are expected and hurricane conditions may occur from Tuesday evening along parts of the southern coast of Mexico, resulting in a tropical storm warning and a hurricane alert.\u201d , in a report issued at ten o\u2019clock this evening on Tuesday, October 24, the National Hurricane Center dramatically modified its predictions. According to the second report: \u201cA nightmare scenario is taking place this afternoon in southern Mexico as Otis is rapidly strengthening and approaching the coast. Satellite images show that Otis has intensified during the last hours and is expected to reach wind speeds of 260 kilometers per hour, which will turn it into a Category 5 hurricane. Otis has explosively intensified its wind speed at 175 kilometers per hour during the last 24 hours, a mark only surpassed by Hurricane Patricia in 2015.\u201d As we know, the prediction of the National Hurricane Center and Otis reached Acapulco a few hours later, after midnight, as a Category 5 hurricane, with winds of more than 260 kilometers per hour and giving little time for the city\u2019s inhabitants to take the necessary precautions. For experts, Otis is an extreme example of the \u201cquickening\u201d phenomenon of a hurricane that has increased in recent years. We will mention that an article published in the journal \u201cScientic Reports\u201d last October 19 by Andra Garnez of Rowand University in the United States, finds that the rate of growth of hurricane intensity in the Atlantic Ocean has risen by about 30 percent in the period 2001-2020 compared to the period 1971-1990.To grow, hurricanes take energy from warm water on the surface of the ocean, and in this sense experts consider that global warming, by raising the temperature of the oceans, increases the possibility that a hurricane will experience the phenomenon of rapid intensification. In the case of Otis, the ocean temperature near Acapulco was 31 degrees Celsius, unusually high, which would have given the conditions for the hurricane to grow at the speed at which it did. An article published in November 2022 in the magazine \u201cNature Communications\u201d by a group of researchers headed by Kieran Bhatia of Guy Carpentier, New York, also finds an increase in the number of hurricanes that experienced a rapid intensification in the period 1982. -2017. Bhatia and collaborators attribute this increase to global warming due to the increasing emission of greenhouse gases into the atmosphere.On the other hand, according to experts, although the advance of climate science is considerable and allows prediction of climate events in advance, the phenomenon of rapid intensification of hurricanes is not yet sufficiently understood. In these circumstances, to the extent that, inevitably, the concentration of greenhouse gases in the atmosphere will increase in the years to come, before reaching eventual stabilization, it is critical that climate science advance enough to predict, if this were the case, the imminent rapid intensification of an ongoing hurricane. And the tragic events of Acapulco last Wednesday are more than explicit in this regard. We will conclude by recalling that Hurricane Patricia, which holds the second place in the list of rapid intensification of hurricanes, also developed in the Pacific Ocean and touched land on the coast of Jalisco.",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/HONDA_ASIMO.jpg/450px-HONDA_ASIMO.jpg": "The well-known science fiction writer Isaac Asimov published in 1940 the short story or novel entitled, \u201cRobbie\u201d, in which he tells the story of Gloria, an eight-year-old girl, and her playmate Robbie, a humanoid robot who interacted with Gloria as another boy or girl playmate would. It was such that Gloria\u2019s attachment to Robbie, that her parents were concerned about the possibility that Gloria\u2019s relationship with the robot might somehow disturb their future social adaptation, just as parents might now be about their children\u2019s attachment to mobile phones and social networks. Beyond getting into the story of Gloria and Robbie and the unfruitful efforts of their parents to separate them, we would simply point out that Asimov was a visionary who wrote his novel at a time when the first digital computer of general use had not yet been built, which occurred in 1946. And that, of course, without computers it would not be possible to build a robot with Robbie\u2019s characteristics. In his novels, Asimov became a well-known science fiction writer Isaac Asimov. He spent decades in his time and imagined a future in which robots carry out activities that are traditionally carried out by humans more efficiently. He goes even further and raises the possibility of interactions between humans and robots in equal terms, such as the one he describes between Gloria and Robbie. Consistent with Asimov\u2019s vision, robots play an increasingly important role in the world. We know, for example, that they are employed in automobile factories and that their use in the industry in general and in a large number of applications is increasing. Thus, we are presented with a scenario in which robots are used, not only as tools to perform functions more quickly and efficiently, but in roles of equality with humans, such as those imagined by Asimov eighty years ago, in which a girl interacts closely with a robot. In this context, an article appeared on October 18 in the magazine \u201cFrontiers in Robotics and AI\u201d, reports the results of an experiment carried out to determine the efficiency of a group of workers from an electronic card factory carrying out In terms of equality, with a robot. Specifically, workers are charged with visually reviewing the electronic cards produced by the factory in search of faults that affect its operation. Cards are also reviewed by a robot for double verification. The article was published by a group of researchers led by Dietlind Helene Cymek, of the Technical University of Berlin. Cymek and collaborators knew that, while a double review aims to reduce the number of faulty cards that are not detected, a worker can put less effort into his activity when he works as a team than when he does it individually. The reasons for this behavior are several. For example, knowing a worker who another partner previously reviewed the card, will put less effort into his own review. Additionally, since the reward he would receive for identifying all defective cards is shared with another partner, he has less incentive to give his maximum effort, even if he was the only one responsible for the work. The research carried out by Cymek and collaborators, on the other hand, has an original element: the collaboration in the The study reported in the reference article involved 42 workers, divided into two groups. The members of one of the groups worked individually, while those of the other group did so in collaboration with a robot. In the latter case, the workers received circuits that had previously been reviewed by the robot, which was their knowledge. The study showed that the workers who worked alone found an average of 4.2 defects, while those who worked as a team with the robot found an average of only 3.3 defects. Thus, Cymek and collaborators found that the same effect of \u201csocial support\u201d that occurs when a person works as a team with other people, also occurs when people work as a team with a robot, which would be perceived as highly efficient by virtue of their technological perfection. It should be seen if, in the vision of Asimov, this perception extends in the future to other areas of interaction with robots. For example, the one that fictitiously occurred between Gloria and Robbie.",
    "https://upload.wikimedia.org/wikipedia/commons/2/21/Moon_Crescent_-_False_Color_Mosaic.jpg": "Last August, India became the fourth country that manages to place a probe on the surface of the Moon. The first country to do so was the Soviet Union in 1966, followed by the United States that same year. Subsequently, in 2013, China became the third country to use a probe softly. In this year there have also been failed attempts to place a probe on the Moon, specifically from Russia and Japan, in the latter case led by a private company. Thus, after a long pause since the 1970s of the last century, there is a renewed interest in exploring the Moon, not only by governments of technologically advanced countries, but also by private companies. In particular, the most ambitious programme is NASA\u2019s Artemis, which, in collaboration with space agencies in Japan, Canada, Australia, Israel and European countries, seeks to resume manned missions to the Moon in 2025, and to establish permanent exploration bases leading to the exploitation of the Moon\u2019s mineral resources and to serve as a basis for a future manned mission to Mars. In this context, it is necessary to remember that the surface of the Moon is covered by a thick layer of a fine powder called regolito, which would easily be dispersed through the passage of a vehicle and would remain suspended for a long time before settling down, since on the Moon the force of gravity is small compared to the Earth\u2019s gravity. Moreover, since there is no air on the Moon that erodes the surface of the regolito particles and smoothes their contours, they constitute an abrasive dust that damages the instruments and mechanisms of the explorers. Given these disadvantages, there is a need to pave the roads used by lunar explorers. This is not an easy task, however. To begin with, the materials needed for this paving could not be transported from our planet, which would be prohibitively expensive. Thus, it would be necessary to use lunar materials and develop methods to process them and build a firm surface for the passage of land. A publication published this week in the journal \u201cScientific Reports\u201d describes experiments carried out to investigate the possibility of using lunar regolite as a raw material for paving roads on the Moon. The article was published by a group of researchers headed by Juan Carlos Gin\u00e9s-Palomares of the University of Aalen, Germany. In their article, Gin\u00e9s-Palomares and collaborators report the manufacture of a kind of bricks or tiles using a commercial powder whose composition emulates that of the lunar regolite, and a high-power infrared laser. For this, they placed a layer of dust in a crucible and melted it locally with the heat of the laser, displacing it along its surface. Thus they built a tile of triangular shape and corrugated contours, with a hole in the center. The tiles can be linked to one another to cover a surface and provide a firm floor. For the manufacture of tiles on the Moon, however, a high-power laser such as the one employed by Gin\u00e9s-Palomares will not be available. The solution proposed by Gin\u00e9s-Palomares and collaborators to pave the roads of the Moon is one of the proposals that have been made to solve the problem of the powders of regolito that would be formed at the passage of the vehicles. For those who have circulated in a car through an unpaved gap in a dry climate, it is not difficult to understand that the dust that would lift the lunar vehicle is a major problem, given its abrasive characteristics and the extended time that it lasts in suspension. Moreover, given that the regolito is electrically charged and is therefore very sticky and would stick to the costume of the explorers, who would take it into the lunar shelter where it would constitute a health problem for those who inhabit it. The lunar regolito will then be a danger, perhaps not the greatest, for the miners and explorers who will live on the Moon exploiting their mineral resources. sense, perhaps we might think that, given the mineral riches of the Moon, the risk will be justified. Others will instead wonder, emulating the classics: but what need?",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/f/f5/PBs2023.svg/498px-PBs2023.svg.png": "It is said that the evils never come alone, and this is certainly valid in terms of the evils that afflict planet Earth. Indeed, as we know, our planet is suffering a climate problem because of the high and increasing concentration of greenhouse gases in the atmosphere, which have increased 40 percent since the beginning of the Industrial Revolution some 250 years ago. Likewise, there are losses of biodiversity, and problems of environmental pollution and acidification of the oceans, among other calamities. These are not independent, but are linked to each other in various ways. Thus, plastic pollution is the product of industrial activity, which in turn generates greenhouse gases that are responsible for acidification of marine waters. In an article published in 2009 in the journal \u201cNature\u201d by a group of researchers headed by Johan Rockstrom of the University of Stockholm, nine \u201cplanetary borders\u201d are identified that should not be transgressed if we are to preserve the planet\u2019s environment, as has prevailed over the last 10,000 years since the end of the year. These borders refer to environmental problems associated with, climate change, the emission of aerosols to the atmosphere, loss of biodiversity, acidification of the oceans, thinning of the ozone layer in the stratosphere, alteration of nitrogen and phosphorus cycles by fertilizer production, environmental pollution by chemical waste, changes in water use, and transformation of natural habitats into urban or agricultural areas. At the time of publication of their article, Rockstrom and collaborators conclude that the planetary boundaries, associated with the concentration of greenhouse gases in the atmosphere, the alteration of the nitrogen cycle, and the loss of biodiversity had already been transgressed. As for the first border, in 2009, the concentration of greenhouse gases had exceeded the proposed limit: 25 per cent above its pre-industrial values. Similarly, the removal of nitrogen from the atmosphere had exceeded by a factor of four the boundary proposed as safe. According to Rockstrom and collaborators, the nitrogen removed from the atmosphere ends in the last term as a pollutant. In relation to the loss of biodiversity, Rockstrom and collaborators point out that it has reached a value of 100 to 1000 times greater than could be expected in a natural way. This value has no precedent since the last mass extinction of species that occurred 65 million years ago. According to the authors of the article, the main cause of the loss of biodiversity is the conversion of natural ecosystems into urban areas or for agricultural use. Last September 13th appeared in the magazine \u201cScience Advances\u201d an update of the original study of Rockstrom and collaborators. The new article, in which Rockstrom is co-author, carries as principal author Katherine Richardson of the University of Copenhagen. According to that article, 14 years away from the original study, the number of transgressed planetary boundaries grew from three to six, so that the only borders that have not been overcome are those relating to ocean acidification, the concentration of aerosols in the atmosphere and the level of ozone in the stratosphere. , however, it is about to reach its border, while the concentration of atmospheric aerosols exceeds its border regionally in some cases. In addition, the loss of biodiversity, climate change and nitrogen pollution increased its level of transgression compared to that observed in 2009.Under these conditions, Richardson and collaborators conclude that the transgression of six of nine planetary borders, \u201csuggests that the Earth is now far outside the safe operating space for humanity.\u201d... and that, \u201cthere is an urgent need for more powerful scientific and political tools to analyse the entire integrated earth system with reliability and regularity and to guide political processes to avoid altering the state of the earth system beyond tolerable levels for today\u2019s societies.\u201d Thus, we could conclude by saying that, in fact, the problems do not come alone and that climate change is accompanied by a series of calamities that include loss of biodiversity, ocean acidification and pollution of the environment by various agents, among others. And that all these calamities, in addition, are linked to one another.",
    "https://upload.wikimedia.org/wikipedia/commons/e/e6/Toyota_FCV_reveal_25_June_2014_-_by_Bertel_Schmitt_02.jpg": "When the automobile industry was born at the end of the 19th century and the beginning of the 20th century, electric vehicles competed effectively with internal combustion cars. As we know, the competition was won by gasoline cars, despite the fact that their electrical version was mechanically simpler and more attractive because of the quietness of their operation. Electric cars had, however, a disadvantage: their reduced range of displacement due to the limited energy storage capacity of their electric batteries. Cars with internal combustion engines, on the other hand, benefited from the high energy density contained in gasoline. Thus, over the 20th century and so forth, the number of gasoline cars has increased irrepressibly. And with this, they have become a threat to the environment, which has led electric cars, with renewed batteries, to return to the scene as a less polluting option to replace gasoline cars. A second option for this purpose is hydrogen cars, in which hydrogen is burned and heat and water is generated as waste. In another version of this automobile, hydrogen reacts with hydrogen. In addition to its use in the automobile industry, hydrogen is conceived as the fuel of a hydrogen economy in which it becomes a non-polluting substitute for fossil fuels in a wide range of applications. For this purpose, hydrogen must be obtained using means that produce low levels of greenhouse gases. In this sense, hydrogen would be obtained by decomposing water into hydrogen and oxygen through the electrolysis process. The electricity needed to carry out this process would be obtained from a clean source of energy, whether solar or wind. In addition to the above, a hydrogen economy would use hydrogen obtained by electrolysis for the various applications currently given to hydrogen, including the production of ammonia for fertilizers and other chemicals. To investigate hydrogen generation in a context of hydrogen economy, a group of researchers led by Davide Tonelli of the Catholic University of Louvaina, Belgium, was given the task of investigating the limits for The results of this research appeared on September 8 in the journal \u201cNature Communications\u201d. Specifically, Tonelli and collaborators investigated the availability of territorial areas, both globally and in different countries, to establish wind generators or solar panels for the electrolysis of water in a hydrogen economy. They find that, while it would be necessary to use less than one percent of the water available globally to generate the hydrogen that would be needed in 2050, water is not a resource that is evenly distributed among all countries. Thus, some countries would encounter problems of water scarcity to meet their hydrogen needs. Similarly, while some countries have large territorial extensions, others would have problems in finding places for the installation of solar panels or wind turbines that would be needed, and would become hydrogen importers. Based on their analysis, Tonelli and collaborators find that countries such as Canada and Australia, Argentina, Bolivia and Paraguay, as well as countries in southern and central Africa, have sufficient resources to become exporters of hydrogen. In contrast, other countries such as Japan, South Korea, the Dominican Republic, and Western European countries will have problems meeting their hydrogen needs. Mexico, in that sense, is in an intermediate position. Thus, a hundred years after the emergence of oil as fuel, the world is forced to look for cleaner fuels.In particular, the traffic of cars has grown to such a degree that it has become a kind of plague that threatens the environment \u2013 as well as our urban tranquility. Will the hydrogen economy be a solution to the problem? The decades to come will tell us.",
    "https://upload.wikimedia.org/wikipedia/commons/a/ad/Kalambo_Falls.jpg": "The semiconductor chip or integrated circuit, which incorporates tens of billions of electronic elements in silicon wafers in an area of one square centimeter, is undoubtedly the most complex object ever built. To manufacture a semiconductor chip, a machine of extreme complexity is used as a tool, in which hundreds of thousands of components are integrated at a cost of hundreds of millions of dollars. This machine is essential for the manufacture of chips, and allows us to record on the silicon wafer the patterns that will give rise to its electronic elements. In retrospect, certainly much had to happen over millions of years of evolution so that our species developed the capacity to manufacture such extraordinarily complex devices and machines. In this sense, the experts tell us that the genus Homo, to which we belong, originated about two and a half million years ago and that throughout this time several Homo species emerged, of which only ours survive. As our archaic ancestors evolved, their brain grew in volume, developed stone tools and eventually dominated the use of fire. the appearance of modern man, which would have happened some 300,000 years ago according to the experts. The resistance of the stone to wear over time has facilitated that the evidence of stone tools manufactured millions of years ago has reached our days in a relatively efficient way. It has not happened the same with the possible wood tools - material that rots easily exposed to the environment - that would have been manufactured hundreds of thousands of years ago. That is why it was surprising that it was discovered in the vicinity of Lake Tanganyika, near the border between Zambia and Tanzania, a carpentry work carried out almost half a million years ago. The article was published in the magazine \u201cNature\u201d by a group of researchers headed by Lawrence Barham, University of Liverpool in the United Kingdom. In their article, Barham and collaborators report the discovery, buried in sand, of two trunks joined transversally together by means of notched by purpose. This arrangement was probably part of a fishing platform or of a house. The logs managed to arrive until our days because they remained submerged in wet sand, which delayed by means of notched by purpose. The sand in which they were found buried was dated to an age of 476,000 years, which is before the appearance of the modern man. Barham says: \u201cThis finding has changed my way of thinking about our first ancestors. Forget the label \u201cStone Age\u201d, look what these people were doing: they did something new and great with wood. They used their intelligence, imagination and abilities to create something they had never seen before, something that had never existed before. They transformed their environment to make life easier, even if it was just making a platform to sit by the river to perform their daily tasks. These people looked more like us than we thought and were less nomadic than they thought.\u201d The discovery of Braham and collaborators show, that even before the appearance of our species, our forerunners were on the way to make devices and machines with a growing sophistication. While at first progress was slow, in the long run progress has been impressive: we went from assembling wooden structures with some tree trunks to use them as fishing platforms. To assemble tens of billions of electronic components in a silicon pill to make integrated circuits. All this in the course of half a million years. And to those who objected that half a million years is not exactly a short time, it would be necessary to remind them that the sophistication of the devices and machines built has accelerated dramatically in the last two centuries by the systematic application of the scientific method to the development of technology. And that we would not have to wait all this time to witness technological advances as great as those that separate the ensambles from logs, from the ensambles of electronic components in the integrated circuits.",
    "https://upload.wikimedia.org/wikipedia/commons/0/05/Boeing_777-200ER_Malaysia_AL_%28MAS%29_9M-MRO_-_color.jpg": "As was announced by the media at the time, Malaysia Airlines Flight 370, which took off from Kuala Lumpur in the early morning hours of 8 March 2014 on its way to Beijing, never reached its destination and its fate was wrapped in the greatest of mysteries. It is accepted that the plane crashed somewhere in the Indian Ocean near Australia, killing all the people on board - 239, between passengers and crew members - but it is not known for certain what really happened to it. What we do know is that shortly after taking off from Kuala Lumpur, at 1:21 a.m. on 8 March, the Malaysian Airlines pilot last communicated with the airport air control upon leaving Malay airspace. From this point, the flight should have entered Vietnam\u2019s airspace, but apparently never did. Instead, it took a sudden turn towards the southwest, crossed into the Strait of Malacca, and disappeared from the radar. From that point on, there was no certainty about the route that followed. We know, on the other hand, that the plane continued in the air at least until 8:19. This we know because it sent seven routine automatic signals that were picked up by a satellite from the Inmarsat telecommunications company, the last one at 8:19. From the signals captured by the satellite, it was possible to determine that the probable place where the plane would have crashed is located somewhere around a thousand-kilometre-long arch located opposite the west coast of Australia. While having this information is better than having no information about where in the Indian Ocean flight 370 would have crashed, searching for a plane submerged several kilometres in such a small area is not a simple task. In fact, the remains of the Malay aircraft were not found and their search was suspended several years ago. Let us remember, however, that in July 2015, more than a year after the accident, a wingeron of the plane of the Malay aircraft was found and its search was suspended several years ago. Malaysia Airlines was found on the coast of R\u00e9union, an island located opposite the coast of Madagascar, 6,000 kilometres from the site where the flight was supposed to have crashed.The wing was transported there by sea currents.Based on this finding, some researchers have tried to reconstruct the path that followed the wing to R\u00e9union and determine the place where the crash plane is located.An example of these efforts is an article published last August 23 in the magazine \u201cAGU Advances\u201d, in which it is proposed to determine that trajectory from the study of crustaceans that colonized the aller\u00f3n from the time of the accident.The article was published by a group of researchers headed by Nasser Al-Kattan, from the University of South Florida.In a specific way, Al-Kattan and collaborators studied in the laboratory the same class of crustaceans that were found attached to the alleron, with the aim of determining how the content of a certain isotope of oxygen in its calcareous cover, according to the With this information, and based on the contents of this isotope on the crustacean cover found in the aleron, they determined the ocean temperatures to which these crustaceans had been exposed on their voyage to R\u00e9union. This information, together with a knowledge of the ocean temperatures, would allow them to determine their trajectory from the point of the accident. It is worth mentioning that the latter is easier said than done, as there are multiple paths that could produce the same results in terms of the composition of the crustacean cover. The knowledge that they provide, however, serves as a guide to try, finally, to find the remains of the damaged aircraft. In this sense, Al-Kattan and collaborators expect that the French government, who is in the position of the aleron, to make available to the researchers more specimens of the crustaceans attached to it. If the proposals of Al-Kattan and the injured plane are successful, and with this the black box, indispensable to determine the causes of the disaster, the mystery of the flight will finally be revealed. 370, around which multiple hypotheses have been woven, none with a sufficiently firm base. And all this with the help of a crustacean \u2013\u201cAnatifera Lepas \u2013 which, moreover, does not look anything extraordinary.",
    "https://upload.wikimedia.org/wikipedia/commons/9/91/Abraham_Archibald_Anderson_-_Thomas_Alva_Edison_-_Google_Art_Project.jpg": "An interesting photograph, which can be found on the Internet, shows Thomas Alva Edison in the foreground sleeping under a tree, and further back to the president of the United States, Warren Harding, sitting on a chair reading a newspaper. The photograph was taken in Maryland in July 1921 at a summer camp. While the picture is also curious, it should be remembered that Edison used to sleep holding spheres with both hands, so that when he fell asleep the spheres would fall to the ground and wake him up. Edison carried out this strange practice as a means to stimulate his creativity as an inventor. His idea was that, by entering the first phase of the dream, his brain would be free to find a solution to the problem he intended to solve. And once he found it, he would have to wake up quickly to make him aware and avoid it being lost.The technique used by Edison would have worked, if we were to judge by the more than a thousand patents that were granted to him throughout his career. For example, in an article published in the December 2021 issue of the magazine \u201cScience Advances\u201d, experiments are reported that show that the intermediate zone between vigil and sleep is a point of great creativity. The article was published by a research group headed by Celia Lacaux de la Sorbonne Universit\u00e9. As we know, there are two stages during sleep, an initial stage, which in turn is divided into three sub-caps, N1, N2 and N3, and a second stage characterized by a fast eye movement, called REM by its acronyms. Lacaux and collaborators set out to investigate the sub-cap, N1 at the beginning of the dream. For this purpose, they joined a group of 103 volunteers who were provided with a mathematical problem that could be quickly solved by following a hidden rule. The discovery of this rule would be a measure of creativity.To initiate the experiment, participants made 30 attempts to find the solution, discarding those who could find the hidden rule.All others were asked to rest for 20 minutes with their eyes closed, holding an object. If one of the participants dropped the object, indicating that he had entered the N1 phase of sleep, he was asked to manifest the chain of thoughts he had before waking up from the noise of the object when hitting the ground. At this stage the participants were divided into three groups, a first group with those who remained awake during the 20 minutes, a second group of those who reached the N1 phase of sleep without going into a deeper sleep, and a third group that advanced to the N2 stage l sleep. Lacaux and collaborators found that those who stayed at least 15 seconds in the N1 stage of sleep during the 20 minutes period tripled the probability of finding the hidden rule compared to those who remained awake during this period. This advantage, however, disappeared for those who advanced to a deeper stage of sleep. Lacaux's results and collaborators are supported by a study published last May 15 in the journal Scientific Reports by a group of researchers headed by Adam Har Har Horowitz of Massachusetts Institute Technology. , Horowitz and collaborators find that the first stage of sleep is an ideal point of creativity. They also find that creativity can be stimulated in a given topic, inducing dreams relative to that topic in stage N1.Apart from Edison's experiences, there are other anecdotal evidences about the role of sleep in creativity. In this sense, Salvador Dal\u00ed would have used a technique similar to Edison's to find inspiration. Also, it is legend that chemist August Kekul\u00e9 devised the structure of benzene, which has the shape of a ring, after dreaming of a snake that bitten the tail. Such then it seems that we could stimulate our creativity and solve the problem we bring to the head in a relatively simple way following Edison's procedure: let's sit quietly in a reclining chair with an object in our hand and try to reconcile the dream. Once we fall asleep and the object falls to the ground, hopefully we will have the solution to our problem. Otherwise, we will have little lost with having made the attempt.",
    "https://upload.wikimedia.org/wikipedia/commons/7/7d/Fukushima_I_by_Digital_Globe.jpg": "On Thursday, 24 August, the Government of Japan confirmed that it had begun the release into the ocean of radioactive water contaminated with radioactive elements from the damaged Fukushima nuclear plant. As we recall, on 11 March 2011, an earthquake near the north-east coast of Japan caused a major nuclear disaster. At the time of the earthquake, the reactors at the Fukushima power plant were automatically shut down, as expected, causing emergency power plants to enter into operation to maintain the reactor cooling systems. The earthquake, however, caused a tsunami with waves of 14 meters high that exceeded the protection barrier of the reactors facing the sea, flooding them and inutilizing the emergency plants. In these circumstances, the reactor cores were overheated and melted, releasing large quantities of radioactive elements into the atmosphere. Since then, permanent sea water has been injected into the reactors in order to keep the nuclear fuel \u2013 which still generates heat from the reactor \u2013 and to prevent further leakage of radiation. , is contaminated by contact with said fuel so that it is not returned to the sea, but is stored in an installation with more than 1,000 tanks. To date, however, these tanks have accumulated more than a million tons of water and have reached the limit of their capacity, so it is now sought to return it to the sea. Return would not be done in a gradual manner, but in a very gradual manner; indeed, it would take several decades to complete, given that the volume of water accumulated would be sufficient to fill more than 500 Olympic pools. To avoid polluting the ocean with radioactive waste, water is subjected to a specially designed filtering process, which, according to the Japanese Government and the company Tokyo Electric Power, owns the nuclear plant, effectively eliminates pollutants. It would eliminate them to such a degree that decontaminated water would be so pure that it would be even drinking. While the International Atomic Energy Agency approves the Japanese Government\u2019s plan, not everyone agrees. For example, the magazine \u201cScience\u201d quotes in its issue of 24 January to Ken Buesseler, of Woods Hole Oceanographic Institution, who states that \u201cthere is no data with sufficient quantity and quality to support what the company owns the plant claims, and that more information is needed.\u201d Likewise, Feres Dalnoki Veress, of Middlebury Institute of International Studies, in California, states that we do not really know that pollutants contain water, as only small volumes of a quarter of the storage tanks have been analysed. The Chinese Government, for its part, was opposed to the decision of the Japanese Government and announced that the ban it maintains for the import of sea products from the Fukushima region will extend to all sea products coming from Japan. South Korea, more moderately, considers that the important thing is for Japan to follow scientific standards and provide information in a transparent manner. The Chernobyl accident of 1986, that of the Three Mile Island of 1979, and the Fukushima event, is part of the \u201cTop Three\u201d of the accidents associated with nuclear power. The three major nuclear accidents, however, show that such accidents can occur and that, if they do occur, they can have catastrophic consequences. Fukushima\u2019s, in particular \u2013 regardless of controversial views on the Japanese government\u2019s decision \u2013 will require decades of effort and multimillion dollar investments that could amount to more than $100 billion to remedy the disaster. Let us hope that in the future the \u201cTop Three\u201d of nuclear accidents will not become a \u201cTop Four\u201d and that instead we will be betting on energies such as the solar one, which, in addition to inexhaustible, is undoubtedly considerably more friendly.",
    "https://upload.wikimedia.org/wikipedia/commons/d/de/Stwlan.dam.jpg": "We know that the amount of solar energy that reaches our planet is thousands of times greater than we need to meet our global needs. We also know that the contest of this energy is essential to combat climate change and that we have the technology necessary to capture it and convert it into electrical energy. Thus, the energy of the Sun is abundant, inexhaustible, cheap, relatively clean and exploitable. The Sun, however, also has a defect that has prevented it from becoming our main source of energy: it shines only during the day. Given this circumstance, exotic initiatives have been given \u2013 to say the least \u2013 that propose to place solar panels in space to capture and send energy to the Earth through a microwave beam. Solar panels would be placed in a place where the Sun is never hidden, so that we would dispose of uninterrupted energy. Returning to Earth, we could continuously use solar panels in combination with some energy storage system. The panels would capture the energy of the Sun during the day, and store the unused portion for hours without solar light. Unfortunately, this is easier said than done, so that solar energy has not had as wide a use as it would have been desirable. How could the energy captured by solar panels be stored? The first option that perhaps comes to mind is a battery bank, as large as it would have been necessary. A battery is certainly the right option to, for example, drive an electric car. For a massive storage of energy, however, we could consider another option, namely, the use of the Earth's gravitational force. In this sense, let's imagine two water ponds placed at different heights and a pump powered by electricity provided by solar panels, which raises water from the lower pond to the upper one. Water in its high position acquires energy in the form of gravitational energy, acting as a giant battery. To recover the stored energy, water is sent back to the lower pond through a turbine, which in turn drives an electricity generator, as it happens in a conventional hydropower plant. The technique of storing energy using the Earth's gravitational force is not new, and in fact, was used for the first time, and was used for the first time. In Europe more than a century ago. Today, however, the interest in using it as a means to store the energy of the Sun or the wind has grown. Thus, the installed capacity at the global level of hydroelectric plants that use water pumping is equivalent to more than one hundred times the capacity of the Laguna Verde nuclear power plant, in the state of Veracruz. In the context of the fight against climate change it is important to ask about the impact of hydroelectric plants with water pumping have on the generation of greenhouse gases, and it should be considered that the construction of the plant itself with its two water ponds and its subsequent maintenance implies the emission of a certain amount of atmospheric pollutants. In this sense, an article published this week in the magazine \u201cEnviromental Science and Technology\u201d makes an assessment of these emissions and compares them with the characteristic emissions of other energy storage means, including compressed air and three kinds of batteries. The article was published by a group of researchers headed by Timothy Simon of the National Renewable Energy Laboratory, in Golden, Colorado. As a result of their work, Simon and collaborators conclude that, By a considerable margin, the storage of energy using the Earth's gravitational force is the medium that emits the least atmospheric pollutants. To make its assessment, the researchers considered all greenhouse gases generated during the construction of the two ponds and the pumping and electricity generation systems. They assume that the plant would have a useful life of 80 years, and that it would have to be maintained at age 40.In contrast, they do not consider the costs of dismantling at the end of its life.On a global level, it is estimated that there are about 600,000 potential sites to install a hydroelectric plant with water pumping.In these circumstances, the world's electricity needs could be met - without interruptions - entirely by large extensions of solar panels and giant batteries that operate with the gravitational force of the Earth. It is a scheme that, in addition, will contribute to mitigating climate change.",
    "https://upload.wikimedia.org/wikipedia/commons/5/54/Atomic_bombing_of_Japan.jpg": "On the morning of August 6, 1945, 78 years ago, a U.S. B-29 bomber, nicknamed Enola Gay, left the island of Tinian for Hiroshima on the Japanese coast, with a uranium bomb on board. Arriving at Hiroshima at 8:15 a.m. Enola Gay blew up the bomb over the city. For the occasion, the bomber was accompanied by two other planes; one of them, nicknamed Great Artist, was equipped with measuring instruments to document the physical effects of the bomb; the other, he was carrying on board equipment to photograph the explosion.As we know, Hiroshima's nuclear bombing is the first of the only two occasions on which a nuclear bomb has been used against the population. The second occurred three days later, when another B-29 bomber dropped a plutonium nuclear bomb on the city of Nagasaki in southern Japan. Overall, the bombings of Hiroshima and Nagasaki resulted in more than 200,000 deaths, both at the time of the explosion, and subsequently due to radiation-induced diseases. The nuclear bombs destroyed by Hiroshima and Nagasaki were part of the war effort of the United States during World War II, in a context of competition with Germany, which was thought to be developing its own bomb. Germany, however, surrendered in May 1945, so that when the United States decided to launch the bomb on Japan months after this surrender, there was no longer any Nazi danger. According to some, there would have been no need to use the nuclear bomb against the Japanese population. Expressing views in this regard, a group of scientists sent in June 1945 to the Secretary of War of the United States a document analysing the political and social consequences that the use of the nuclear bomb against the Japanese population might have. The group was made up of three physicists, three chemists and a biologist, and was chaired by James Franck of the University of Chicago, Nobel Prize for Physics 1925. The document, which can be consulted on the Internet page of the \u201cBulletin of the Atomic Scientists\u201d, was sent before the first nuclear explosion of history in the desert was carried out. In their paper, Franck and collaborators expressed concern that, with the use of the nuclear bomb against Japan, an arms race would be unleashed, as indeed happened, in which several countries sought to develop nuclear weapons. To prevent this, they considered the possibility of keeping the nuclear technology possessed by the United States secret. They themselves, however, argue that this could only delay the problem for a few years, as there were several countries with sufficient knowledge to develop nuclear weapons in the short term. And in this regard they were right, as the Soviet Union detonated its first nuclear bomb in 1949. They also considered the possibility of controlling the production of uranium and other fissile materials, which they also concluded was impractical. In particular, and given that the Soviet Union was their main concern, they did not believe it possible that a country covering one fifth of the planet did not have uranium deposits.In addition to the above, they argued that, at the event of a nuclear war, the United States would be at a disadvantage with regard to the Soviet Union. Because, because of its vast territory, the Soviet Union could disperse its population centres in a more effective way than the United States could do in order to mitigate the impact of a nuclear attack.Franck and collaborators conclude that the only way available to dispel the nuclear danger is to reach an arms control agreement, and in that sense it was not advisable to start the nuclear era with an attack on the Japanese population that would make it difficult for the United States to take the lead in achieving an arms control agreement.A past bull, we know that the United States did not follow the scientists' recommendations and detonated two nuclear bombs on the Japanese civilian population.This certainly accelerated Japanese surrender, but at the same time did not help to avoid the arms race that gave rise to the Cold War between the United States and the Soviet Union.",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/8/89/NXP_PCF8577C_LCD_driver_with_I%C2%B2C_%28Colour_Corrected%29.jpg/885px-NXP_PCF8577C_LCD_driver_with_I%C2%B2C_%28Colour_Corrected%29.jpg": "When the English rock groups, with Los Beatles in the lead, arrived in the United States in the 1960s, the so-called \u201cBritish invasion,\u201d dominated the American music scene for a good number of years. This, despite the fact that these bands played a modified version of rock and roll developed by American musicians such as Elvis Presley, Buddy Holly and Chuck Berry, among many others. Today, in some ways history is repeated. Specifically, in relation to the microcircuits or semiconductor chips, invented in the United States, but whose manufacture is carried out today mostly in South Korea and Taiwan. The history of semiconductor chips dates back to the end of the 1940s, specifically to the month of December 1947, when Walter Brattain and John Bardeen demonstrated the operation of the first transistor of history at the Bell laboratories of the ATT company in New Jersey. From this demonstration, the technology of the transistors progressed quickly and in September 1958, Jack Kilby, from the North American company Texas Instruments demonstrated the operation of a circuit in which it integrated several electronic components into a single pill. By its discoveries, both Brattain and Bardeen, and Kilby, were awarded the Nobel Prize in Physics. Half a year after the demonstration by Kilby, Robert Noyce, of the American company Fairchild Semiconductor, demonstrated the operation of the microcircuit or chip, basically as we know it now. From that moment, the technology and complexity of the microcircuits advanced at an enormous speed, to the extent that today the microcircuits can incorporate tens of billions of transistors into a tablet with an area of one square centimeter. Not surprisingly, it has been said that the silicon microcircuit is the most sophisticated artificial object that has been built. The semiconductor chip is also one of the inventions that have had the most transcendence in the history of civilization. Thus, the microcircuit has enabled a large amount of technologies, including computing, the Internet, autonomous automobiles, cellular phones and geolocation devices. In the future, to the extent that the applications of artificial intelligence are developed, the impact of semiconductor chips will increase simultaneously. On the other hand, while silicon microcircuit is an American invention, only 12 percent of the semiconductor chips used globally are produced in the United States, Taiwan and South Korea being the largest manufacturers of these devices. According to the magazine MIT Technology Review, this is because in the United States the costs of chip production are 40 percent higher than in Asian countries, due to differences in wages and construction costs, as well as government incentives. Given these circumstances, and in order to encourage the production of semiconductors in the territory of the United States, the US congress approved last year the \u201cCHIPS and Science Act\u201d, by which it intends to make financially attractive the construction of semiconductor factories within its borders. In this context, the city of Syracusa in the State of New York has seen an opportunity to overcome the crisis in which it is As we know, Siracusa is situated in the so-called Oxide Belt and, like other cities in that belt, notably Detroit, has suffered for several decades from a process of deindustrialization due to the crisis of the traditional automobile, coal and steel industries. Taking advantage of the CHIPS and Science Act, the company Micron, manufacturer of semiconductor chips, has developed a project to install up to four semiconductor factories north of Siracusa with a total investment that could reach $100,000 million. With this investment, in the area of Siracusa, the traditional heavy industry, typical of the industrialization of the United States of the first half of the twentieth century, has been replaced by the semiconductor industry of the twenty-first century, which will transform our civilization profoundly.The semiconductor chip, the most complex object ever built, has become an element of first strategic importance.If in the decade of the sixties the Americans tolerated - and even enjoyed - the British invasion, today cannot afford to tolerate a lack of control. in the manufacture of semiconductor chips to such an extent that they will invest hundreds of billions of dollars to conjure it.",
    "https://upload.wikimedia.org/wikipedia/commons/3/35/Trinity_Site_Obelisk_National_Historic_Landmark.jpg": "At 5:30 a.m. on July 16, 1945, a group of teenagers who were camping near Ruidoso, New Mexico, were awakened by an explosion. In an interview given to National Geographics magazine, Barbara Kent, one of the group\u2019s teenagers, recalls the incident: \u201cWe were all shocked... and then suddenly there was a big cloud over our heads and lights in the sky. They even hurt our eyes when we looked up. The whole sky became strange. It was as if a tremendous sun came out.\u201d Hours after the explosion began to fall white flakes from the sky. Thinking that they were snowflakes, the girls started to play with them, rubbing them in the face. Something strange, however, as the flakes were not cold but hot. Despite this unusual fact, the girls, only 13 years old, thought that this was because of the heat it did. Unfortunately, the flakes were not snow, but the product of the first nuclear explosion in history and were exposed to radioactive waste. The explosion took place in the desert of New Mexico, near the city of Alamogordo, about 60 kilometers from the camp where the teenagers were located. Alamogordo\u2019s nuclear bomb, as well as the bombs that subsequently destroyed the Japanese cities of Hiroshima and Nagasaki at the end of World War II, were the result of the Manhattan project, carried out in an ultra-secret manner by the United States Government as part of the war effort. The scientific leader of the project was Robert Oppenheimer, who will surely become popular, as he is the protagonist of the film that bears his name and that was premiered in the cinemas this week. The New Mexico desert was chosen to carry out the first nuclear explosion in history - named as Trinity test - because of its low population density. However, because of the ultra-secret nature of the operation, thousands of people who were tens of kilometers from the site of the explosion - as happened with the teenage girls of Ruidoso camp - were not alerted to their imminence and were exposed to high doses of radiation. The article, which has yet to undergo a formal review, was written by a group of researchers headed by S\u00e9bastien Philippe of Princeton University. In their work, Philippe and collaborators combined government data and climatic data, with sophisticated calculations of the movement of the atmospheric layers to determine the dispersion of radioactive pollutants during the ten days following the Trinity test. The calculations show that the radioactive pollutants were dispersed in the northeast direction, eventually reaching all states of the American Union, with the exception of Washington and Oregon. The highest concentrations were found along a strip that covers a good part of the North American middle. These contaminants also crossed into Canada and Mexico. In the latter case along the entire border, from California to Texas. Philippe and collaborators find that the radioactive cloud reached Crawford Lake, Ontario, Canada, on July 20, 1945, with a peak of concentration two days later. Since the Trinity test was carried out with plutonium, July 20, 1945 marks the date when plutonium was deposited at the bottom of Crawford Lake for the first time. Thus, experts propose that this lake be the site marking the beginning of the Anthropocene, a new geological epoch that would follow the Holocene \u2013 which has been in existence since the end of the last glaciation. Anthropocene is characterized by a geological stratum with a footprint that marks the human presence on Earth, in this case, a layer of plutonium at the bottom of Crawford Lake. Thus, we have faith that, in a distant future, a geologist \u2013 human or non-human \u2013 by exploring the bottom of Crawford Lake -or whatever is left of it - we find a layer of plutonium that indicates the geological moment when humans began to modify your planet - or whatever's left of it.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d7/First_cultured_hamburger_fried.png": "Without attempting to create a sense of guilt among those who love a good cut of meat, we must mention that, according to experts, the production of one kilogram of beef generates a volume of greenhouse gases equivalent to 100 kilograms of carbon dioxide. This includes carbon dioxide produced by the feeding of cows, as well as the methane generated by their digestion, which is a greenhouse gas more powerful than carbon dioxide. Overall, it is estimated that the production of edible meat constitutes 15% of the total emission of greenhouse gases. Given the above numbers, as a strategy to reduce the emission of greenhouse gases, it has been proposed to replace the edible meat produced by traditional methods, by cultivated meat. In this direction, in 2020 Singapore was the first country to approve the meat grown for human consumption. The United States, for its part, has just done its own thing and more than 150 companies in that country are preparing to introduce the meat grown in the anacheles of supermarkets. In addition to potentially helping to alleviate the climate crisis, farmed meat aligns with the ideas on the protection of animals currently in vogue. Certainly, although cultivated meat would undoubtedly have a positive impact on cows, pigs and cattle in general - which will certainly breathe relieved - it is not clear that the climate of the planet will be equally benefited. An article appeared last April on the site \u201cbioRxiv\u201d is not very positive in this regard. That article, which has not yet been through a review process by other colleagues, was prepared by a group of researchers headed by Derrick Risner, from the University of California in Davis. In its article, Risner and collaborators consider two extreme cases, In one case, they assume that the farmed meat industry will use the methods employed by the pharmaceutical industry, which requires the purification of the materials used in the manufacture of the medicines to eliminate contaminants. On the other hand, in a second case, researchers assume that the manufacture of farmed meat will employ ingredients with the purity employed by the current industry. In one scenario or another, Risner and collaborators find drastically different environmental impacts.In fact, assuming that the cultivated meat will be manufactured without using ultra-purity ingredients, the environmental impact will be positive and the volume of greenhouse gases emitted per kilogram of meat produced will be reduced.In contrast, using ultra-purity ingredients would increase that volume by up to a factor of ten.If this were the case, from the point of view of the climate of the planet, the remedy would be worse than the disease.In a understandable way, the conclusions of Risnar and collaborators have not been to the liking of the companies that are working on the marketing of the cultivated meat. They question, for example, that there is a need to employ ultra-purity materials in its manufacture. And without the use of ultra-purity materials, apparently the cultivated meat would be a remedy to alleviate the climate crisis. Will the cultivated meat reach the shelves of supermarkets? It might be necessary to wait a few years to find out. Otherwise, if it were the case, it would have to compare its taste and texture with the taste and texture of the real meat. We are fanatics of, for example, pork chops and in a restaurant we serve cultivated pork chops, it will not be enough to announce them as such. Unless we are convinced environmentalists and/or supporters of animal protection, and we are willing, in any situation, to make a sacrifice.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d5/Reverse_osmosis_desalination_plant.JPG": "As we know, water covers approximately 70 percent of the surface of our planet. In volume, land water, including oceans, rivers, lakes, underground reservoirs and water vapor in the atmosphere, exceeds 1.4 billion cubic kilometers. This number is too large for us to conceive of, but if we divide it among the world\u2019s population, it turns out that each of us has about two hundred billion liters of fresh water. Although this number is still beyond our comprehension, it is clear that we would not consume such a volume of water even if we lived a thousand years. Moreover, it should be noted that, of the total water on the surface of the Earth, just 2.5 percent is fresh water and that, of this, 98 percent is frozen. However, by doing the corresponding calculations, we can convince ourselves that, even so, we should not have problems with the supply of fresh water for our personal use. We know, however, that we use water in different ways and that we have problems with this supply because of a number of factors, among which climate change is found. With regard to this, on the UN-Water website we can read the following: \u201cWater and climate change are closely related. Extreme weather events are making water scarcer, more unpredictable, more polluted or all three things. These impacts throughout the water cycle threaten sustainable development, biodiversity and people\u2019s access to water and sanitation.\u201d One option that experts manage to combat the water crisis that the planet is travesting through is the desalination of ocean water. Water can be desalted by distillation, that is, boiling and condensing the steam that is produced on a cold surface. Another way is through the process known as reverse osmosis. In this process, salt water is forced to pass by pressure through a semi-permeable membrane, which allows the passage of water at the same time as it prevents the passage of the dissolved salt in it. A third scheme to desalize water uses electrodialysis technique. This technique uses semi-permeable membranes that, selectively, allow the passage of one of the In this sense, to remove sodium chloride - common salt - water is forced to pass through a duct bordered by two membranes, one that allows the passage of sodium and blocks the passage of chlorine, and the other that does the opposite. All this helped by electricity. The three previous desalination processes require large amounts of energy that translate into high costs for the water produced. Thus, the desalination plants of sea water have progressed slowly. As the technology of water desalination advances, however, these plants will become more economically competitive. In this regard, one can mention an article that appeared last April in the ACS Energy Letters magazine, published by a group of researchers headed by Nayeong Kim, University of Illinois in Urbana-Champaign, which reports the development of an electrodialysis cell in which has replaced one of the semi-permeable membranes, at the same time that the energy demanded by its operation has been substantially reduced. , according to Kim and collaborators, will contribute to reducing the cost of desalination of water. We can hope that in the future the world will obtain from the sea the fresh water it needs, in the same way that it will obtain from the Sun the energy necessary to operate the desalination plants. After all, the oceans constitute the largest source of water that we have at our disposal, just as the Sun is with respect to energy. Nothing is free, however, and the desalination of large quantities of marine water will also generate large quantities of waste water with large concentrations of salt that, poured back into the sea, could generate local great environmental impacts if not done judiciously. The saline contamination would thus join air pollution and climate change with its cause of heat and cold waves, as well as floods and droughts. As a reflection that, indeed, the planet has remained small.",
    "https://upload.wikimedia.org/wikipedia/commons/f/f1/WikiAir_Ohio_01_-_Northwest_of_I-270.JPG": "An ancient photograph of San Luis Potos\u00ed is a reliable testimony of the image of the city at the time it was taken. In the same way, a series of photographs taken over a period of time illustrate us about the temporal evolution of that image. Thus, photographs of our city printed in the book \u201cEl San Luis que se fue\u201d, published by Pro San Luis Monumental, show us that at the beginning of the twentieth century the cathedral only had a tower, just like the temple of San Miguelito. Likewise, a photograph of the year 1920 shows us that, unfortunately, the buildings that occupied the two corners of the street of Zaragoza have disappeared at the end of the Plaza de Armas.The photograph, of course, is a two-dimensional projection of the urban image and gives us only a pale idea of how the city would have looked in the past, especially if the photograph was in black and white. Imagine for a moment that we could overcome this limitation and that, in some way, we could immerse ourselves, in three dimensions and in all colors, in an already disappeared urban environment; that we could, for example, walk What are the chances that the latter could happen? Would it be possible, for example, to use a virtual reality helmet to immerse us in a projection created by a computer, an urban environment that has disappeared? Certainly, such an environment could be recreated in a film set, as is common when a film is filmed. Unfortunately, we may not have enough information to ensure that such recreation was reliable.This is not the case in other latitudes, as an article appeared this week in the magazine Plos One, showing the reconstruction of two neighborhoods in the city of Columbus, Ohio, as they looked more than half a century ago.This article was published by a group of researchers headed by Yue Lin, from Ohio State University. Lin and collaborators based their work on the Sanborn maps, employed by insurance companies to assess the fire risks of a property.These maps, which were continuously updated, accumulate data on buildings. The Sanborn maps contain a wealth of information about each of the buildings in a neighborhood, including the building materials they were made of, their dimensions and their contours, and the location of windows and doors. They also included information about the local fire department, the location of the water and gas outlets available in an emergency, as well as information about the public buildings, churches and businesses in the neighborhood. Sanborn maps are no longer used by insurance companies, but the large amount of data they contain makes them reference materials for a large number of researches, including, the study of the evolution of the urban environment of cities in the United States, urban renewal programmes, and the construction of fast roads for the circulation of automobiles, which constituted dividing lines of urban areas. Given the large amount of information contained in the Sanborn maps, Lin and collaborators used artificial intelligence techniques to extract it quickly and efficiently. The information acquired enabled them to develop computer maps of two neighbourhoods in the city of Sanborn, Lin and collaborators used artificial intelligence techniques to extract it. Columbus was divided by a fast track in the 1960s. In his article, Lin and collaborators include an interactive visualization that allows us to go into these two neighborhoods, being able to see the buildings in great detail (https://bit.ly/3Dj3IgN). The visualization also shows the buildings that were demolished by the construction of the fast track. Lin and collaborators show us that it is possible to \u201crelive\u201d a neighborhood as it looked more mediated by the information contained in the Sanborn maps. Since this type of maps exist since the second half of the 19th century, it seems that the process of resurrection could extend even further into the past. In contrast, in our city, and since we only have little more than old photographs in black and white, it seems that we would have to settle for much less.",
    "https://upload.wikimedia.org/wikipedia/commons/8/8f/Iphone_4G-3_black_screen.png": "In 1854, Antonio Meucci, an Italian inventor who emigrated to the United States, put into operation a device that he baptized as a \u201ctelephone\u201d, to maintain communication with his wife who was suffering from rheumatism. The telephone connected the inventor\u2019s office on the ground floor of the building, with his wife\u2019s bedroom on the first floor, and is considered to be the precursor of modern phones. Unfortunately, due to economic problems Meucci could not patent his invention and only partially protected it. Alejandro Graham Bell was able to do so, which led to a demand from Meucci. Without success, he died without having been recognized as the inventor of the telephone and thus Graham Bell was recognized as the inventor. This was maintained until 2002, when the United States Congress approved a document that recognizes Meucci as the real inventor of the telephone. If he had been able to travel 150 years into the future, Meucci would have been delighted to know that justice had been done at last. To the point of making it unrecognizable. Not only because current phones can communicate by wireless means, but because, from its original function, phones have acquired a large number of additional functions. Thus, today, apart from using them to speak on the phone, we use smartphones to transmit texts and images, to watch movies and videos, to look for directions, to guide us to them, to take photographs and as geolocation devices, among many other applications. Thus, it is not surprising that a group of researchers led by Joseph Breda, from the University of Washington, have proposed a new function for smartphones: their use as thermometers to measure the temperature of the body. Breda and collaborators\u2019s proposal was published last March in the magazine \u201cProceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies\u201d. To fulfill this new function, Breda and collaborators make use of the termistors, which are devices that are inside mobile phones and serve to measure temperature at certain key points. They measure the battery temperature as a means of diagnosing their state of health. To implement this application, researchers developed the application \u201cFeverPhone\u201d, which estimates the body temperature from the temperature changes measured by the thermistors when the phone screen is pressed against the patient\u2019s forehead for 90 seconds. Being in front and screen contact establishes a heat flow that raises the temperature of the phone until a balance is reached. FeverPhone captures the temperature changes, interprets them and calculates the body temperature. Researchers tested their device with 37 volunteers, 16 of whom had had at least a mild fever. FeverPhone was able to determine the body temperature of patients with an average error of 0.23 degrees centigrade, error that is comparable with what is obtained with commercial thermometers.Breda and collaborators point out that they are not intended to replace body thermometers, which are specifically designed to measure temperatures, with a device designed for other purposes. They note, however, that often there is no hand thermometer in place in case of need. n, for example, a study carried out with 141 parents of children with convulsive fevers that required continuous monitoring of their body temperature. However, according to the study cited, only 15 percent of the parents had access to a thermometer. In such circumstances, FeverPhone would be of great use. That is, while in the world most people have a mobile phone, we cannot say the same for those with a body thermometer. Certainly, the device invented by Meucci 170 years ago has changed so much that it would be unrecognisable to him. To that extent it has changed, that continuing to call him \u201ctelephone\u201d is out of place. What could be a suitable name for a device that serves to speak on the phone, but also to send a written text? Or to take a photograph and upload it to a social network? Or to search for and find an address or information on Wikipedia? Or if FeverPhone finally consolidates, to measure body temperature?",
    "https://upload.wikimedia.org/wikipedia/commons/3/38/Groundwater_%28aquifer%2C_aquitard%2C_3_type_wells%29.PNG": "According to figures from the United States National Office of Oceanic and Atmospheric Administration, the average sea level at the global level has increased by approximately 20 centimeters since 1880, i.e. it has risen to an average speed of 1.5 millimetres per year in the last century and a half. According to the same source, in the period 2006-2015, the average sea level has more than doubled, reaching 3.6 millimetres per year. Experts explain to us that among the factors that cause sea level rise are the melting of polar ice in Greenland and Antarctica, and the expansion of ocean water as its temperature rises due to climate change. They are not, however, the only factors that contribute to sea level growth, and in this regard, an article appeared this week in the magazine \u201cGeophysical Research Letters\u201d, reports the results of a study carried out to determine the influence that the extraction of groundwater has on the rise of the ocean level. Seoul, South Korea. As we know, overexploitation of aquifers is one of the problems facing the world and leads to the depletion of groundwater deposits. Bringing groundwater to the surface, in addition, has the effect of increasing the level of surface water. Thus, Seo and collaborators point out that, through a climate model, it is estimated that between 1993 and 2010 enough water was extracted from the subsoil to increase the level of the oceans by 6.24 millimeters. Before starting their research, however, there was no direct evidence to corroborate this figure. In these conditions, the researchers decided to determine the effect that, on the sea level, groundwater brought to the surface. The method they followed to meet their objectives is, perhaps, surprising, since the researchers were based on the deviation suffered by the axis of rotation of the Earth between 1993 and 2010. Why does the extraction of groundwater influence the orientation of this axis? To understand this, let us think of the Earth as a giant trompo that revolves around an inclined axis, completing a turn within 24 hours. In turn, it rotates with a precession movement, completing a cycle in about 26,000 years, and carries out other movements that depend on the forces to which the planet is subject by other celestial bodies. Additionally, the orientation of the axis of rotation of the Earth is sensitive to a redistribution of mass on the planet, such as what can occur during a large magnitude earthquake. As well as the extraction to the surface of large quantities of groundwater, which is the case we are concerned with. As a result of its study, Seo and collaborators find that in order to explain the deviation of the axis of rotation of the Earth observed between 1993 and 2010, it is necessary to consider, apart from other factors, the volume of underground water extracted from the climate model.Only by this extraction, the axis of rotation would have moved about 80 centimeters.Although the experts rule out that the deviation of the axis of rotation of the Earth by the extraction of underground water can affect the climate of the planet, the conclusions of the work of Seo and collaborators are overwhelming: regardless of the enormous size of the Earth, we have managed to modify its axis of rotation in a record time. The problem, however, is that we have no other to lay hands on.",
    "https://upload.wikimedia.org/wikipedia/commons/3/36/International_congress_on_hail_shooting.jpg": "Since its invention more than a century ago, cinema has been an extremely attractive form of entertainment. For reasons, moreover, varied, given that cinema addresses virtually any subject and in various circumstances. The film \u201cCasablanca\u201d of 1942, for example, is considered by many as one of the best of all times, although when it was filmed it was not thought to be an exceptional film. As we know, the action of that film is situated in Casablanca, in French Morocco, during the Second World War, when France had been invaded by the Germans and the United States were about to enter the war. Casablanca is considered to have been part of the anti-Nazi American propaganda. At the same time, the film intertwines stories of intrigue, corruption, altruism and love, between Humphrey Bogart and Ingrid Bergman, which made it greatly attractive. This last, despite Bergman surpassing Bogart in height by five centimetres, which sometimes forced him to climb to a banquito when he appeared on his side in the film. In situations that have much or little to do with reality. Thus, a film allows us to travel to the Moon or Mars, or to the depths of the ocean, as well as to precise or distorted versions of the past, recent or remote. According to experts, this ability will be enhanced by the new artificial intelligence technologies to generate images. In this sense, in its latest issue, the magazine MIT Technology Review brings up the short film \u201cThe Frost\u201d \u2013\u201cThe Frost\u201d \u2013 which is the first composed of scenes \u201313 minutes in total \u2013 entirely produced by an artificial intelligence program from a libretto. A free version of \u201cThe Frost\u201d can be found on the Internet. The argument is simple: a bad manipulation of climate geoengineering led to the temperature of the Earth dropping drastically, to such a degree that only a small region of Antarctica remained habitable. In the initial scenes, in a frozen landscape, a group of people appears in an improvised camp warming around a fire and complaining of extreme cold. The scenes are strange, without movement. The movement of the lips in speaking does not seem natural to us either. Suddenly, the group of people receives what they interpret as the \u201csign\u201d that comes from the top of a mountain and feel compelled to go looking for it. On their ascent to the icy mountain, one of the members of the group slips and stays hanging from a rope, having to be sacrificed cutting the rope to prevent it from dragging other companions in its fall. Immediately, the group suffers the onslaught of a snow avalanche that buryes some. Later scenes show the survivors sitting in the snow recovering from the disaster and finally arriving at the place where the \u201csign\u201d originated. At that point, the film recedes five years, with the image of a scientist realizing that the planned intervention to change the Earth\u2019s climate will have disastrous effects. The film immediately changes to the UN compound, showing us a speaker who talks about the imminent launch of the mission to change the planet\u2019s climate. The launch took place without caring about the protests of the scientist who warned about the disastrous effects that it would have. This moment the film takes us to the mountain with the group of people who have reached the place where the \u201csign\u201d is broadcast, ending without explaining what happened next. The argument of \u201cThe Frost\u201d is very simple and the film is composed of groups of scenes that progress by leaps. Clearly, the film does not give us the sense of verisimilitude to which we are accustomed in the cinema. The scenes of \u201cThe Frost\u201d, however, are entirely elaborated using artificial intelligence technology. Thus, it would be expected that in the near future the sensation of verisimilitude of similar films will improve substantially. Otherwise, the experts go further and consider the possibilities of interaction of the viewer with the film. For example, the possibility that the viewer could manipulate the end of the film according to their preferences. Thus, if Casablanca had been filmed 80 years later, the viewer might have had the possibility to change the end of the film, so that Rick (Humphrey Bogart) and Ilsa (Ingrid Bergman) would have approached together I would take them out of Casablanca. Or even further, with the possibility that the viewer himself would be the protagonist of the film, replacing Rick or Ilsa, as the case may be.",
    "https://upload.wikimedia.org/wikipedia/commons/4/42/Broken_Hill_solar_plant_aerial.jpg": "As we know, the steam engine was one of the driving forces behind the industrial revolution of the 18th and 19th centuries. We also know that mineral coal was the fuel used by these machines and that this resulted in an energy transition in which coal replaced wood and other traditional biofuels. Later, with the advent of the electric industry and the automobile industry, oil was included in the energy mix, thus expanding the energy transition.It should be added that oil, in addition to being convenient, was a source of cheap energy.In fact, to those of us who lived in the 1960s of the last century, we know that the greatest concern of car designers was not precisely energy savings. Thus, we saw the movement of eight-cylinder automobiles through the streets that would run just five kilometres per litre of gasoline. Moreover, given that in Mexico a litre of gasoline costed around a weight, the car owners were not particularly concerned.The situation changed drastically in October 1973, when, with the so-called oil embargo, oil prices rose drastically to avoid returning to their weight. Since oil reserves were located in the Middle East, outside the industrialized countries, they began to develop substitutes for oil and thus reduce their dependence on political conflicts in the Middle East. The most obvious alternative energy source was perhaps solar energy, which is abundant and unlimited. One way to harness solar energy is by converting it into electric energy using solar cells. The first solar cell of silicon was developed in 1954 in the Bell laboratories of the American Telephone and Telegraph company and in 1958 the American satellite Vanguard was equipped with a silicon panel of 10 by 10 square centimeters to provide it with energy. In 1973, however, just 20 years after its invention, solar cells were in their infancy and were not an economically viable option to supply oil. That is, they could generate electricity, but at a prohibitively high price.Today, forty years after the oil crisis, the situation has been reversed, and we are facing a new energy transition. Thus, according to the latest report of the International Energy Agency, 2023 will be the first year in the oil crisis. As the World Economic Forum points out, solar energy is growing rapidly, to such an extent that in 2022 the growth of installed solar power generation capacity exceeded the combined capacity growth of all other energy sources, including wind power, natural gas, coal, hydropower and nuclear power, among others. It should be noted, however, that energy change occurs more sharply among industrialized countries than among developing countries, despite the fact that some of the latter, including ours, have large solar resources. An intrinsic feature of solar energy is that it is available only during the day. The problem of this intermittance can be mitigated by an electrical distribution network that transfers energy from an illuminated region to another region that at the time suffers a drop in solar intensity. Moreover, it is certainly necessary to develop massive energy storage systems. One example in this regard is the Snowy 2.0 project in the state of New South Wales in Australia, which aims to store energy in the form of solar intensity. The two dams are connected by a tunnel of 27 kilometers. To store energy, water is pumped through the tunnel from the lower dam to the upper dam by means of solar energy. The energy thus stored is recovered by returning the water to the lower dam by passing it through a turbine and an electricity generator. In view of the above, we are facing a new energy transition, in which fossil fuels will be replaced by alternate sources of energy. Among these sources, solar energy will be the dominant.",
    "https://upload.wikimedia.org/wikipedia/commons/7/75/AralSea1989_2014.jpg": "As one of the biggest ecological disasters that our time has witnessed, the Aral Sea, once the fourth largest saltwater lake on the planet, has been gradually drying out to become two separate bodies of water and a toxic sand desert. The collapse of the Aral Sea, located between Kazakhstan and Uzbekistan, was produced by the diversion of the Sir Darya and Daryia rivers that fed it, to irrigate cotton plantations. These rivers were diverted when Kazakhstan and Uzbekistan were part of the Soviet Union. Currently, the surface of the Aral Sea is only 10 per cent of the original surface, which amounted to 65,000 square kilometres, approximately the surface of the state of San Luis Potosi. The Aral Sea is certainly an extreme case of environmental disaster produced by human intervention that we would expect not to repeat; at least, not on a scale of such dimensions. An article appeared this week in the magazine \u201cScience\u201d, however, concludes that the volume of water stored in more than half of the lakes and responds As pointed out by Yao and collaborators, the volume of water stored in natural lakes and reservoirs fluctuates following changes in rainfall and discharges from rivers, as well as human factors such as dam construction and water consumption. To determine how all these factors have influenced the volume of water stored in natural and artificial bodies of water, Yao and collaborators carried out a study with satellite images of 1972 bodies of water, representing 95 per cent of the volume of water stored globally. Of these bodies of water, 1052 are natural lakes with surface areas between 100 and 377,000 square kilometers, while 921 are artificial lakes with surfaces between 4 and 67,000 square kilometers. With their study, Yao and collaborators not only sought to determine how the volume of water stored globally has evolved in recent decades, but also to identify the factors, natural or human, that have determined such evolution. Using 250,000 satellite photographs collected between 1992 and 2020, researchers determined that in 53 percent of the water reservoirs globally the volume of water stored is decreasing. In the case of natural lakes, the main factors responsible for this decrease are climate change and human consumption, while sedimentation is the main factor in the degradation of the volume of water stored in dams. Based on their study, researchers conclude that 2,000 million people live in areas where there is a significant trend of decrease in the volume of water stored and that these people will be the most affected by the lack of water in the future. Yao and collaborators also comment that their study revealed a decreasing trend in the volume of water stored in lakes such as Lago Salton in southern California and Lake Mar Chiquita in Argentina, which is the largest salt lake in South America. With respect to the latter, however, the digital daily Infobae collects from statements by Eduardo Pioviano, a researcher at the Conicet in Argentina, who denies that the Chiquita Sea is desicca We hope that the future will not give us disasters like that of the Aral Sea, with its strange and shocking images of fishing boats resting in the midst of an immense sea of sand contaminated by the waste of pesticides used in cotton fields. We hope that the consequences of the water shortage in the future will not reach such dramatic levels. But we must not fail to worry.",
    "https://upload.wikimedia.org/wikipedia/commons/a/ad/Beondegi.jpg": "When available, space tourism trips to the Moon and beyond will undoubtedly be fascinating experiences. Not everything will be so, however, at least with the same degree. It is possible, for example, that the food that is served to us in a restaurant on the Moon does not have the same quality as the food that we can enjoy in an ordinary restaurant, here on Earth. An idea of the food that we could expect to eat during an interplanetary pleasure trip is given to us by the winning projects of the \u201cDeep Space Food Challenge\u201d competition organized by NASA. According to the US space agency: \u201cThe aim of this contest was to generate new technologies or food production systems that require minimal resources and produce minimal waste, while providing safe, nutritious and tasty food for long-term human exploration missions.\u201d In this sense, since space missions have to embark with all the necessary food for the trip and that these expire in a year and a half, for long-term missions, it is necessary to develop techniques to produce them on board the ship. Food Challenge, which consists of three phases, was published by NASA in January 2021. About 200 participants were registered, and of these, five American companies and three foreign companies survived phase 2 and are competing in phase 3. This last was announced by NASA on 19 May. According to NASA statements collected by an article published this week in the magazine \u201cMIT Technology Review\u201d: \u201cPhase 2 was a kind of demonstration at the kitchen level, while phase 3 seeks to challenge participants to scale up their technologies.\u201d Among the participants in phase 3 is the company \u201cAir Company\u201d, based in New York. According to its website, this company focuses on the use of carbon dioxide in the atmosphere to produce alcohol and fuels. Air Company\u2019s products include aviation fuels, perfumes and Vodka. In relation to the NASA contest, Air Company proposes to use carbon dioxide accelerated by astronauts when breathing to generate alcohol, and from it to produce food. According to Air Company statements appearing in \u201cMIT Technology Company\u201d. Review: \u201cThe process produces alcohol that can then be fed to yeast, producing something that is edible. Essentially, a protein shake similar to a vegan meat substitute.\u201d A similar project is proposed by the Finnish company \u201cSolar Foods\u201d, which produces \u201cSolein\u201d, a kind of flour obtained from carbon dioxide. The space project of \u201cSolar Foods\u201d involves the production of \u201cSolein\u201d from carbon dioxide exhaled by astronauts and hydrogen produced during the generation of oxygen by the decomposition of water. Another finalist company in phase 3 of the contest is \u201cInterstellar Lab\u201d, based in Florida, which proposes the use of \u201cNUCLEUS\u201d for food production in space. NUCLEUS consists of nine modules, each with its own control system of temperature, humidity and irrigation. Modules can be used to grow vegetables, fungi and insects at the same time. As explains \u201cInterstellar Lab\u201d in a video on YouTube: \u201cIn space, astronauts will use fungi, insects and vegetables to grow at the same time. For example, they could use mushrooms to create a tasty soup. They could grind insects and get a protein-rich powder that will improve the taste of any food. Using plants, insects and mushrooms, astronauts will create a tasty and nutritious menu.\u201d The Swedish company Mycorena is another finalists. To produce food in space, this company proposes the use of a protein produced from the fermentation of a fungus. In statements from the head of Mycorena research collected by \u201cMIT Technology Review\u201d: \u201cThis protein itself does not have much flavor, but adding flavoring it is possible to obtain different foods, including burgers and nuggets.\u201d Also, using a 3D printer, \u201cfrom a screen you could choose and print a chicken steak.\u201d We would have to agree that, based on proposals to produce food in deep space, the options that we would have as space tourists would not be very flattering for most of us. Still, the shocking space environment in which we would be immersed, surely we would have forgotten any bad experience that we would have had with an artificial chicken fillet printed on it. 3D, bathed in a black fly sauce.",
    "https://upload.wikimedia.org/wikipedia/commons/9/96/Clothes.jpg": "As we recall, in September 1991 two climbers discovered Otzi\u2019s frozen body. The discovery occurred in a glacier in the Alps near the border between Austria and Italy. The extraordinary thing about the case is that Otzi died about 5,300 years ago and that his mummified body was preserved by the extreme cold to which it was exposed since his death. The state of preservation in which it was found allows us to know, according to Wikipedia, that Otzi\u2019s clothing at death consisted of a layer of vegetable fiber, a bear\u2019s cap, a goat\u2019s skin vest, leather caps and leather shoes. The discovery of the remains of a man in good preservation conditions is undoubtedly fascinating. In particular, it illustrates us about the type of clothing that was used 5,000 years ago, based on animal skins and other materials of plant origin with relatively little manipulation. Over time, as civilization advanced, the techniques of making clothes became more sophisticated with the invention of fabrics or textiles. The original function of clothing was to provide protection to the body against inclement weather. Today, thousands of years after its invention, textiles have acquired a new function with the invention of intelligent textiles. These textiles include elements that allow them to go beyond their traditional function. A garment made with intelligent textiles, for example, would have the ability to measure the ambient temperature and react accordingly to provide comfort to the user. They could also monitor the vital functions of the body and send an alarm signal to the doctor in case something goes wrong. An article appeared this week in the magazine \u201cScience Advances\u201d reports the manufacture of intelligent textiles using a procedure similar to that used to manufacture a common and ordinary textile. The article was published by an international group of researchers who carry as first author Sanghyo Lee of Cambridge University in the United Kingdom. Lee and collaborators describe the manufacture of a textile in which they mix. ordinary fibres with fibers in which they have been constructed devices that develop one of four functions, namely, light detection, energy storage, electronic processing and light emission. Thus, textile constitutes an electronic system capable of storing energy, capturing a signal, processing it electronically and sending a response signal. Functional fibre is manufactured by building on it the corresponding device. Thus, fibers specialized in storing energy, while others are manufactured light detectors or light-emitting LEDs. Also, fibers are responsible for processing the information received by detectors and providing it to emitters for retransmission. On the other hand, fibers and elements that make them functional should not be damaged by the rough handling to which a textile is normally subjected, and in this sense, Lee and collaborators show that their fibers pass the test. Intelligent textiles described by Lee and collaborators would be manufactured with functional fibers following the procedure normally used to manufacture an ordinary textile. Their functions, however, will be expanded radically, and not only cover the original function of protecting the user from the inclement of time, of a much more effective way than ordinary textiles, but they would include functions completely out of reach of an ordinary garment. An expansion of functions similar to that that happened with smartphones, which now serve us to communicate through social networks, to read the news, to guide us through GPS, to listen to music, and to take pictures and videos, among many other applications; including that of speaking on the phone. Taking back the story of Otzi, a study of his mummified remains found an arrowhead lodged in a lung, which would indicate that he probably died killed. However, we probably will never know for sure. Another would be the situation if instead of dressing in fur, Otzi would have worn a smart vest that would have transmitted the moments of his death. Unfortunately, Otzi lived and died 5,300 years from this possibility.",
    "https://upload.wikimedia.org/wikipedia/commons/b/b6/Arecibo_66.75261W_18.34607N.jpg": "As we are taught in primary school, the Earth revolves around the Sun, just like the other seven planets in the solar system. This was not always the case. That is, while the planets have always revolved around the Sun, there were times when it was thought that the Sun revolved around the Earth. In fact, this is what we find in the first instance when we observe that in the early hours of the morning the Sun emerges from the horizon, rises to a maximum height at noon and ends up disappearing from the west at sunset. An alternative explanation is that, regardless of who revolves around it, the Earth revolves around its axis in such a way that the face that exposes the Sun is continually changing. As we know - again as we are taught at school - this is the correct explanation. Naturally, this second explanation was not at the time the first choice because it took us out of a privileged position as the center of the Universe. This situation began to change in the 16th century with the advent of modern science that helped us to get rid of prejudices and convinced us that the world is easier to understand if we renounced to be the center. Once we accepted it, it became clear to us that the planets, including the Earth, revolve around the Sun, and the satellites around their respective planets. And with what we learned we were able to place artificial satellites around the Earth, and even around other planets in the solar system. Giordano Bruno was a character who lived the process that placed us outside the center of the Universe. With very little fortune, for he was executed at the stake in 1600 for holding opinions that the Catholic Church considered heretical. Among these opinions, Bruno believed in the multiplicity of worlds, according to which the stars that we see in the sky are worlds with planets similar to ours, inhabited by beings similar to us. We would not be alone in the Universe, so that, not only would we lose our position as the center of the Universe, but also our exclusivity as intelligent beings.The multiplicity of the worlds was not but a hypothesis that Bruno had no way to verify. However, given the immense number of stars in our galaxy and assuming that the appearance of life is a process that occurs at random, we can expect Bruno to have had reason. and that life, even intelligent, has indeed appeared on a multiplicity of worlds. With this in mind, over the past five decades, the SETI project has searched the sky for radio signals that could be interpreted as coming from an extraterrestrial civilization, without a conclusive result to date. Some experts have also considered the possibility that an extraterrestrial civilization might have already detected artificial signals that have escaped our planet and that would have revealed our presence in the Universe. This is analyzed in an article accepted for publication in the journal Monthly Notices of the Royal Astronomical Society, published by a group of researchers led by Ramiro Saide of the University of Mauritius, on Mauritius Island, located in front of the coast of Madagascar. In their research, Saide and collaborators calculated the intensity of the radio waves emitted by the communications antennas of cell phone networks.In this sense, it is necessary to consider that these networks have grown rapidly in recent decades, to the point that currently the number of cellular phones exceeds the number of inhabitants of the planet. Although such antennas are spread throughout the Earth's surface, their distribution is not homogeneous, so that the radiation that escapes into space in the direction of a point in the sky varies periodically with the rotation of the Earth. In this regard, the regions of the world that contribute the most to the radio waves emitted are Western Europe, the east coast of Asia and the west coast of the United States. They conclude, Saide and collaborators that, despite the dizzy growth that the cell phones have had, the radio waves that have escaped from our planet would not have been detected by a civilization that is within a radius of ten light years of our planet and that has a technological level equivalent to ours. It may not be the case, however, if it has a higher technological level.In any case, we will be able to be detected by our cell phones as the power of radio waves emitted grows, in the immediate future.",
    "https://upload.wikimedia.org/wikipedia/commons/3/3d/WNA_Heat_Wave_Temp_Anomaly.jpg": "As we recall, in the summer of 2021, the west coast of the United States and Canada was hit by an unprecedented heat wave. The effects of this extreme climate event are described in an article published last February 9 in Nature Communications magazine: \u201cMany places broke record highs of all time at more than 5 \u00b0C, and the Canadian national temperature record broke at 4.6 \u00b0C, with a new record temperature of 49.6 \u00b0C. The impacts of this event were catastrophic, including hundreds of deaths in the north-west of the Pacific, massive marine life mortality, reduced yields of crops and fruits, floods of rivers due to the rapid melting of snow and glaciers, and a substantial increase in forest fires, which caused landslides in the following months. These impacts provide examples of what we can learn and give us a vivid description of how climate change can be so devastating.\u201d In the future, as climate change progressed, more extreme events with similar catastrophic consequences are expected to occur; Even with worse consequences, of taking place in a developing country that would have fewer resources to face it. Can the occurrence of an extreme climate event be predicted and in that way be prepared to face it? Unfortunately, the planet\u2019s climate is such a complex system that it is not possible to predict extreme events. Something can be done, however, and in this sense an article appeared this week in the journal Nature Communications describes the results of a research carried out to determine where on our planet there is a greater risk of suffering an extreme climate event. This article was published by a group of researchers led by Vikki Thomson of the University of Bristol, in the United Kingdom. Thomson and collaborators focused their research on a climate indicator: the maximum temperature reached in a given place over a year. With this in mind, they consulted statistics of maximum temperature measurements accumulated over the last six decades. This allowed them, using a specialized mathematical technique, to calculate the likely time to pass in order to break, in a given place, the record of prevalescent high temperature. Based on their calculations, Thomson and collaborators determined the places on our planet that face the highest risks of suffering an extreme event of high temperature.Among these places are Afghanistan and the Central American region, which would be expected to break their high temperature record in less than 100 years.The case of Afghanistan is particularly serious due to its high population growth rate.Also, the odds point to the fact that, in less than 100 years, they will break their high temperature records Papua New Guinea, northwestern Argentina, parts of Central Europe, as well as parts of China and Australia.As Thomson and collaborators comment, the occurrence of an extreme climate event promotes in the country that suffers it the implementation of measures to alleviate a similar event in the future. Thus, a country that has not suffered in the recent past one of such events would have no incentive to implement preventive measures, which implies an additional risk.In addition to the above, Thomson and collaborators find that extreme heat waves have occurred that deviated from the statistics and that, if it had not taken place, would have been considered highly unlikely. s. This is the case of the heat wave that affected the United States and Canada in the summer of 2021. Even more serious, the researchers find that, in 31 percent of the regions examined, the maximum temperatures observed are exceptional and deviate greatly from the statistics, so it is not possible to estimate the time that would have to pass for the breaking of the record high temperature value. According to the data published by Thomson and collaborators, San Luis Potos\u00ed is in this case, so it is not possible to set a horizon of time for the occurrence of the next extreme climate event that would break the high temperature record. We would be in this way without information; so it would be in terms of probability. In such a situation, it might be prudent for us to cross our fingers. Or, we would touch wood.",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/2/21/Ganymede_-_Perijove_34_Composite.png/480px-Ganymede_-_Perijove_34_Composite.png": "Being the largest satellite in Jupiter and the solar system - greater even than the planet Mercury- Ganymede has a presence in literature. For example, the short story \u201cChristmas in Ganymede\u201d by science fiction writer Isaac Asimov, focuses on the company Productos Ganimedinos, which operates in Ganymede exploiting its mineral resources and its native labor. The native Ganimedin were baptized \u201castructes\u201d, because somehow they remember ostriches, but \u201cwith the shortest neck, the largest head and a plumage that seems to be coming from one moment to another.\u201d Also, they are provided with \u201ca pair of skinny and bony arms with three fingers.\u201d The natives of Ganymede are moderately intelligent and speak English, \u201cbut, when one hears them, they would prefer not to do so.\u201d Based on the above description, such that the Ganimedin would seem to be an ideal work force to explode. And, however, as Asimov relates, the mining company had problems when the In many difficulties, the company managed to simulate a visit to Santa Claus and with this its directors thought that they had solved the problem, because, given the lack of intelligence of the Ganimedines, they hoped that by the following year the memory of Santa Claus would have vanished. They had not taken into account, however, that in Ganymedes a year lasts just a little more than a week.As we know Ganymedes is part of the group of four Galilean satellites - the others are Callisto, Io and Europe - that can be observed as luminous points orbiting Jupiter; as Galileo could see in 1610 when he pointed his telescope towards that planet. The Galilean satellites were baptized by the German astronomer Simon Marius, contemporary of Galileo, and in this sense it would have to be remembered that Ganymedes, Callisto, Io and Europe, were lovers of Zeus, the Greek equivalent of the Roman Jupiter. Three of the Galilean satellites, Gani, Gani Medes, Calisto and Europe, will be studied by the European mission Juice, launched towards Jupiter on April 14 from French Guiana. The journey will be long, as it will not be until July 2031 when the mission will arrive in the vicinity of Jupiter. The path that will continue will be complex and will involve four orbits around the Sun, during which it will be assisted by the forces of gravitation of the Earth and Venus to reach the speed that drives it to Jupiter. Once there, the probe will fly over Ganymede, Calisto and Europe on 12, 21 and 2 occasions, respectively. At the end of the mission in 2035, Juice will be inserted into an orbit around Ganymede, in which it will be the first time that a probe is placed in orbit around a natural satellite, apart from the Moon. At the end of its life, Juice will lose speed and crash against the surface of Ganymede.Ganimede, Calisto and Europe are interesting because there are indications that the three contain oceans of liquid water below its icy surface. According to Planetary society, this satellite could house an ocean of 100 kilometers of depth, buried by a layer of ice of 150 kilometers thick. Could an ocean of underground water harbor some form of life? On our planet we know that life can be given at the bottom of the ocean around hydrothermal vents that provide the necessary nutrients. Are there hydrothermal vents at the bottom of the underground oceans of the Galilean satellites, around which life would have prospered? According to experts, although the Juice probe will not be able to detect life in Ganymede or Europe, it will provide us with a greater knowledge of the habitability conditions of those frozen worlds. Otherwise, if there were life in Ganymede presumably this would be primitive, far from the ass imagined by Asimov, with all and as stupid as it might have been.",
    "https://upload.wikimedia.org/wikipedia/commons/1/16/Spacecolony1.jpg": "As reported by the media, Space X achieved government approval in recent days for the test flight of its Starship rocket, the most powerful rocket ever built, capable of placing into orbit a 150-ton cargo. According to Elon Musk of Space X, the Starship ship will be the vehicle to carry manned missions to Mars as close as 2026. While experts consider it unlikely to reach Mars with a manned mission in 2026, this will surely happen in the near future. However, reaching Mars with a crew of a few astronauts is one thing, and another much more difficult is to establish there a permanent colony as sometimes proposed, as the environment on Mars is much more hostile than at first sight suggested by the photographs that from that planet have brought us the automatic probes placed on its surface. In this sense, we cannot extrapolate the difficulties that Europeans encountered, for example, to colonize the New World, with which explorers will face on Mars. Thus, if Magellanes and Elcano faced an immense ocean This will be nothing compared to what the future explorers of Mars will face, because, among other things, they will not have air to breathe. Colonizing Mars or other regions of space is extremely difficult for a very simple reason: settlers would face an environment markedly different from the terrestrial environment in which they evolved as a species. Thus, for example, on Earth we evolve under the influence of a fixed force of gravity, while in space this force does not exist. European colonizers faced difficult environmental conditions, but always within the world in which they had evolved. In an article published this week in the magazine \u201cFrontiers in Astronomy and Space Sciences\u201d, the difficulties to overcome to reproduce in space the environmental conditions of the Earth are analyzed as an indispensable requirement for the colonization of space. The article was published by Lee Irons and Morgan Irons, of Norfolk Institute and Cornell University, respectively. that creates differences in the pressure of the body fluids throughout the body and depending on the height \u2013 similar to how the pressure in a pool increases with depth. In the absence of gravity, the difference of pressures disappears and with this the physiology of the body that is tuned to that difference is affected. In space, it is possible to generate a force of gravity through a rotating structure of large dimensions \u2013 like the one that appears in the film \u201c2001 Odyssey of Space\u201d. As the authors mention, however, although this would simulate the force of gravity, it could not produce a difference of pressures in the body fluids. For this, the air inside the structure would also have to rotate, and for this to happen there would be a continuous supply of energy. A second factor is the oxygen atmosphere that on Earth is maintained in a natural and self-sustaining way. In space, such an atmosphere would have to be artificially maintained, which implies an energy expense. In addition, if a failure would not be a natural mechanism that would restore it and the colony collapse. The colony would depend on the amount of energy at its disposal, and to the extent that such a colony was further away from the Sun the energy would be scarcer. In this regard, as the authors say, if the present civilization were relocated to a place in space where there was less access to energy, human civilization would have a decline to a state compatible with the available energy. Thus, uncontrollably, supply chains will disappear, resources will be exhausted, social and government systems will faint or collapse, the population will decrease, as will genetic diversity, and human knowledge will be forgotten. Thus, sending a manned mission to Mars with a handful of travelers will undoubtedly be a reality in the near future, if not foreseeable.In the authors\u2019 vision, on the contrary, establishing a self-sustaining permanent colony will be quite more difficult to achieve.",
    "https://upload.wikimedia.org/wikipedia/commons/9/90/Ley_de_Moore.png": "We learned from the media that on March 24 Gordon Moore died at the age of 94. Although for a majority of people his name did not seem familiar, Gordon Moore had, and still has, a huge influence on the lives of all of us. Indeed, Moore is recognized as one of the main actors in the history of semiconductor chips, which have enabled the development of computers as we know them and of a myriad of gadgets, including mobile phones and the Internet network, which have so much changed our lifestyle. The story of the development of semiconductor chips is fascinating and in its early stages has many colorful episodes, particularly those in which William Schockley participated, one of the inventors of the transistor at the end of the 1940s. Schockley was at some point the head of Gordon Moore when the latter began his career, and while both were first-line actors in the development of chips, in many ways differed markedly from another. But let's go to the beginning of history. Semiconductor chips go back to the month of December 1947, when Walter Brattain and John Bardeen demonstrated the operation of the first transistor at the Bell laboratories of the ATT company in New Jersey. Shockley, who at that time was the head of Brattain and Bardeen, did not directly participate in the discovery, which upset him deeply. In his anger he tried to skim the merit of Bardeen and Brattain, which was unnecessary, as Schockley was an extremely brilliant physicist, with great merits that were key to the subsequent development of the transistor. At the same time that brilliant Schockley was a very complex person and with his attitude provoked the departure of Bardeen and Brattain from the Bell Laboratories. Over time, Schockley himself left the company and infiltrated towards the west coast of the United States to found the Shockley Semiconductor Laboratory company south of San Francisco, for the purpose of manufacturing silicon transistors. With this action, Schockley inaugurated what would later be known as the Valley. One of these was Gordon Moore, who was commissioned to develop ultra-pure silicon for the manufacture of transistors. Soon, however, Schockley\u2019s complex personality became a crisis and led to the departure of eight of his brightest researchers, Gordon Moore included. Schockley considered this output as a betrayal and baptized the researchers who renounced as the \u201ceight traitors.\u201d The \u201ceight traitors\u201d left Schockley\u2019s company for a well-defined purpose: to found the company Fairchild Semiconductors, dedicated to the manufacture of transistors and semiconductor chips, in which a certain number of transistors were integrated into a single silicon pill. Soon, this company flourished and earned money by selling chips, while the company of Schockley ended up disappearing. Years later, Gordon Moore and Rober Noyce - another of the \u201ctraitors\u201d- They left Fairchild to found the Intel Corporation company, which was dedicated to manufacturing semiconductor chips for computers and other applications. Moore first served as Vice President of Intel and later as Chairman, Executive Director, and finally Chairman of the Board of Directors. Moore, however, is mostly known for Moore\u2019s so-called law enunciated in 1965 and reformulated in 1975. which predicts that the computing power of semiconductor chips will double every two years. While Moore\u2019s law is not a physical law, it served over the years to guide the development of electronic companies. In particular, it led Intel to become one of the world\u2019s largest semiconductor chip manufacturers. More, with its business vision, it became a multimillionaire who donated $600 million to the California Institute of Technology and established an altruistic foundation with $5,000 million to boost scientific and environmental conservation projects. Shockley, for his part, received the Nobel Prize in Physics, together with Bardeen and Brattain, for his discovery of the transhis. But he never became the millionaire he pretended to be.",
    "https://upload.wikimedia.org/wikipedia/commons/6/6f/Beethoven.jpg": "On a day like today, 196 years ago, he died in Vienna Ludwig van Beethoven at the age of 56. As a cultural myth it is, his death has been dramatized since the beginning. Thus, according to the testimony of the Austrian composer Anselm Huttenbrenner, a friend of Beethoven and who accompanied him in his last moments: \u201cAfter Beethoven was unconscious in the wake of death from three o\u2019clock in the afternoon until after five o\u2019clock on March 25, 1827, there came a lightning accompanied by violent thunder, which flashed brightly into the mortuary chamber (the snow was in front of Beethoven\u2019s dwelling). After this unexpected phenomenon of nature, which overcame me a lot, Beethoven opened his eyes, raised his right hand and looked up for several seconds with a tight fist and a very serious and threatening expression as if he wanted to say: \u201cenemy potentials, I challenge you! The genius of the great master of tones fled from this world of deception to the realm of truth!\u201d concludes Huttenbrenner. Similarly, because of his status as a cultural myth, much has been speculated about the causes of Beethoven\u2019s death. We know that he was not in good health and suffered from a progressive deafness that began in his youth, as well as recurrent digestive problems and liver disease. Also, it is thought that he may have suffered from lead poisoning by drinking the Rhine wine he was addicted to, beyond what he would consider wise today. In this sense, it should be remembered that lead was added to the wine to give him a sweet taste. While two hundred years later it is not easy to accurately establish the causes of a person\u2019s death, an article appeared this week in Current Biology magazine tries to shed light on the death of Beethoven from the genetic study of hair remains that would have belonged to him. The article was published by a group of researchers headed by Tristan Begg of the University of Beethoven. In their research, Begg and collaborators had at their disposal eight hair samples that are attributed to Beethoven. As a first step, the researchers carried out a genetic study to determine the authenticity of those samples. They concluded that, in fact, five of them are authentic, while two definitely are not. One last sample did not show enough evidence to conclude in one sense or another. Thus, the researchers had at their disposal five samples of Beethoven's hair to determine if their health problems had a genetic origin.Unfortunately, the researchers could not determine whether their deafness and digestive problems had a genetic origin. They concluded, instead, that their death probably occurred due to a liver disease due to a genetic predisposition, aggravated by a combination of hepatitis B that they suffered in the last months before their death, and an excessive consumption of alcohol.Begg and collaborators also carried out a genetic investigation with living people with the same surname of Beethoven and that, based on genealogical records, have a common ancestro. , the researchers focused their study on genetic characteristics that are inherited only by way of father, father to son, as happens with the paternal surname. To their surprise, they found that there were not the expected genetic coincidences between Beethoven and his living descendants with the same surname. At the same time, the latter genetically coincide with a 16th-century Aert van Beethoven, of which he would also be a descendant Ludwig van Beethoven according to genealogical records. To explain these contradictions, Begg and collaborators argue that at some point between the generation of Aert van Beethoven and that of Ludwig van Beethoven, there was an extramarital episode in which the biological father of the son did not correspond to the father who appears in the genealogical register.The research by Begg and collaborators not only demonstrates the power of genetic methods to find out the possible diseases that led to death a person two hundred years ago and whose remains have come to us through time. Those involved would have preferred to keep it a secret. Otherwise, all this is of interest only in the case of truly exceptional people.",
    "https://upload.wikimedia.org/wikipedia/commons/5/5c/Microchips.jpg": "When we hear the word technology it is possible that companies like Google or applications like WhatsApp come to mind. Less often we would think of semiconductor chips or companies like Intel or TSMC, even though these are two of the biggest manufacturers of semiconductor chips without which neither Google nor social networks could exist. It should be noted, however, that as a result of the pandemic there has been a shortage of semiconductor chips - referred to in the press simply as semiconductors - that have taken them out of their relative darkness and made evident the fundamental role they play today. Indeed, as reported by the media, the automotive industry suffered in past years a shortage of semiconductors because, during the pandemic, the manufacturers of chips for the automotive industry redirected their production to semiconductor chips for computers and tablets, whose demand grew with isolation. This even forced stoppages in the production of automobiles. Semiconductor chips or microcircuitos consist of silicon flat tablets in which billions of transistors are monolithically integrated into a monolithic. The starting point for the manufacture of chips is a silicon wafer the size of a pizza, from which a large number of microcircuits will be obtained, with billions of elements each of them. For the manufacture of the chips all their electronic elements are recorded, including their electrical interconnections, using ultraviolet light, which implies an extreme difficulty, given the smallness of the elements to be recorded. This is done, the wafer is cut into tablets, each containing a microcircuit. As a final step, the microcircuits are encapsulated and their functioning tested. As is easy to understand, technologies are used to manufacture a microcircuit that are among the most complex that exist, and that include both the manufacture of the chip itself, and the manufacture of the equipment necessary to carry it out. In relation to the latter, it should be noted that there is only one manufacturer in the world that provides ultraviolet light machines to record microcircuits. Similarly, very few factories worldwide for chips are very few. In these circumstances, given the growing applications of the chips, the ability to manufacture semiconductors has become a strategic issue. Thus, the United States is concerned that China can develop the capacity to manufacture the most advanced semiconductor chips. In these circumstances, in July 2022 the United States Congress approved the \u201cChips and Science Act\u201d with $280 billion to strengthen innovation in semiconductor science and technology in that country. Likewise, this week we learned of Samsung\u2019s plans to establish in South Korea the largest semiconductor chip manufacturing center in the world, by investing in the next 20 years of $230 billion. This will consolidate the position of Samsung and South Korea as one of the world\u2019s largest chip manufacturers. We find semiconductor chips in computers, cell phones, game consoles, televisions, automobiles, medical equipment, and other devices. communication systems, bank tellers, microwave ovens, refrigerators and in general in domestic electrical accessories. And in what is one of their greatest impacts, by allowing the development of the Internet, semiconductor chips have drastically changed our way of life.At the same time, semiconductor chips, like other technologies of increasing sophistication, are widening the technological gap between the few countries that own their technology and those that are simply their users. And with the investments of hundreds of billions of dollars that those few countries are making to further increase the complexity of microcircuits, it would not seem that the situation will be reversed in the future.",
    "https://upload.wikimedia.org/wikipedia/commons/c/ce/Oil_well.jpg": "On August 27, 1859, Edwing Drake completed drilling for what would be the first commercially exploited oil well in the United States, near the town of Titusville in the state of Pennsylvania. Drake had been sent there, an area where oil sprouted to the ground, by the Seneca Oil Company to explore the potential of that area for large-scale oil production. Drake\u2019s success marked the beginning of the expansion of the use of oil, initially as a fuel for lighting lamps and then in the electric and automobile industries. Today, a century and a half after the energy revolution initiated by Edwing Drake, some specialists on the subject point to the possibility of a similar revolution, this time with hydrogen as the protagonist. As we know, hydrogen is a gas that can be used as a fuel to replace oil and natural gas, with the advantage that hydrogen combustion produces only water and does not contribute to the emission of greenhouse gases into the atmosphere. Thus, the energy revolution that would bring hydrogen would help us to mitigate the climate change that is experiencing. Hydrogen can be manufactured by decomposing water in hydrogen and oxygen using electric energy. If this energy is obtained from a clean source - for example, the Sun - to the hydrogen obtained is called \u201cgreen\u201d. If, on the contrary, to produce the electrical energy necessary to decompose the water, fossil fuels are used, the hydrogen obtained is adjective with colors that can reach the black, depending on the degree of atmospheric pollution that generates its production. Clearly, green hydrogen is the one that would have the greatest impact on the mitigation of climate change. Green hydrogen, however, is expensive to manufacture and, in fact, the global production of hydrogen is carried out almost entirely using fossil fuels. The latter could be exceeded if there were natural hydrogen deposits in such a way that we would not have to manufacture it but only take it from where it is found, and in this sense, the opinions of Viacheslav Zgonnik of the company Natural Hydrogen Energy LLC, expressed in an article published in February 2020 in the journal Earth-Science Reviews, are relevant. But, if this is the case, why have they gone unnoticed so far? After all, the land has been drilled countless times in search of oil for 150 years. Zgonnik offers us some answers. He points out that hydrogen tends to be located in geological strata different from the strata in which oil is found. Moreover, hydrogen is the lightest gas that exists quickly dissipates in the atmosphere when it reaches the surface making it difficult to detect it. Likewise, because of its small size, hydrogen is filtered through the rocks and it is difficult to confine it into a geological trap for long periods. But, above all, Zgonnik maintains that the invisibility of hydrogen has been due to prejudices of specialists who do not expect to find hydrogen and therefore do not seek it explicitly.In one way or another, the presence of hydrogen has been confirmed in a site in Mali and with this natural hydrogen has gained interest in the scientific community seeking to evaluate its potential to generate green hydrogen. In this sense, a presentation by Geofrey Ellis and Sarah Gelman of the US Geologi. cal Survey at a congress of The Geological Society of America last October concludes that natural hydrogen will most likely be able to cover at least 50 percent of the production of green hydrogen in 2100. If the potential of natural hydrogen to meet our energy needs were confirmed, there would be one element to counteract climate change, 150 years after an energy revolution contributed significantly to triggering it. We would thus have two energy revolutions, one against the other.",
    "https://upload.wikimedia.org/wikipedia/commons/f/fb/Aerial-SanAndreas-CarrizoPlain.jpg": "The 7.8 magnitude earthquake that struck Turkey on 6 February, and that has become the deadliest earthquake in the history of that country, asks us about the possibility of predicting an earthquake well in advance so that the population living in seismic areas can be saved. Unfortunately, as stated by an editorial in the journal Nature Computer Science of 17 February last, the forces that trigger the earthquakes are very complex and there is still not enough scientific knowledge to carry out this prediction.We know that earthquakes occur on the border between two tectonic plates that slide against each other.The earthquake of 19 September 1985 in Mexico, for example, was due to the movement of the cocos tectonic plate in the Pacific Ocean that glides below the continental plate of North America. Likewise, the earthquake that devastated the city of San Francisco, California, in 1906 was due to the horizontal landslide of the North American and Pacific plates, which move against the other one along the San Andr\u00e9s fault. The relative movement of two tectonic plates in contact, on the other hand, is resisted by the friction forces between these plates that try to prevent their sliding, in the same way as by pushing a heavy box to try to slide it along the floor, the friction forces between the floor and the surface of the box in contact with the floor are opposed to our efforts. Once the applied force reaches a minimum value, however, the box will be put into motion. As the tectonic plates will do once the friction force is exceeded and reached a breaking point. The accumulated energy will thus be released, generating seismic waves whose power will depend on the magnitude of the friction forces involved. Thus, the possibility of generating a large earthquake depends on the friction forces between the plates. If these are large, energy will accumulate over a longer or longer period, which can be released by generating an earthquake of large proportions. Yes, on the other hand, the friction forces were small, the ruptures will occur in shorter periods of time, without accumulating too much. This is the topic of an article that appeared last February 17 in Science magazine, which was published by a group of researchers led by Srishan Shreedharan from the University of Texas at Austin. In their article, Srishan and collaborators report the results of a study that led them to discover that after an earthquake the plates come together again after a certain period of time the friction forces are recovered - how they recover, to some extent, the friction forces between the floor and the box of our example once they are put into motion. The recovery time of friction forces between tectonic plates is crucial, because if this is long, the efforts that accumulate through the subsequent plate slide will tend to be eased in shorter periods without generating large earthquakes, which will be more likely to occur if friction forces recover quickly after the break. As part of their research, Srishan and collaborators conducted a laboratory study with materials extracted from the geological failure located 800 meters below the level of the friction forces quickly after the break. On the coast of New Zealand, finding very long times for the recovery of friction. From their results they were able to predict by means of a computer model that the accumulated tensions in the geological fault were relieved in short times, without generating earthquakes.This coincides with the history of the New Zealand failure, which is known to produce slow movements of plates without generating seismic waves of appreciable magnitude.Serishan and collaborators conclude that, while their results will not lead to a method to predict earthquakes, if they provide new scientific information about the mechanisms that generate earthquakes.On the other hand, as we develop capacity to predict earthquakes, we can reduce the number of people who die in one of these events taken the appropriate measures.And in this sense, the more than 50,000 deaths in the earthquake in Turkey are certainly too many.",
    "https://upload.wikimedia.org/wikipedia/commons/c/c0/Apollo_CSM_lunar_orbit.jpg": "At the end of the Pacific Ocean after turning to the southern end of the American continent, the expedition of Fernando de Magallanes met with an ocean whose immensity he did not expect. Thus, without foreseeing the enormous distance that would travel before taking land, Magallanes did not make enough food supplies and suffered the consequences. In the words of the Italian Antonio Pigafetta, who served as a chronicler of the expedition, \u201cWe sailed for three months and twenty days without trying even a fresh food. The cake we ate was no longer bread, but a powder mixed with worms that had devoured all its substance, and that also had an unbearable stench for being impregnated with rat orines. The water that we were forced to drink was equally rotten and stinking. To avoid dying of hunger we were still forced to eat pieces of cow\u2019s hide and we were often reduced to feeding us from sawdust and even rats.\u201d We know that the sailors of the expedition suffered from scurvy, which is a disease due to a deficiency in vitamin C intake, and that their misfortunes were ultimately due to a diet that did not include fresh fruits and vegetables. The expeditionaries, however, could not know that it was only until the 18th century that the Scottish physician James Lind discovered that scurvy patients improved with the intake of oranges and lemons. Thus, Magellan\u2019s expedition, due to ignorance and circumstances of the journey, was subject to a diet to which our body is not adapted. This last comment is valid with regard to the spatial exploration, which has taken new brioches and which has in its sights the conduct of trip missions that it will expose. In particular, space explorers will be subject to microgravity conditions, i.e. lack of weight, which are alien to Earth's inhabitants who have evolved into a serious environment. How does prolonged exposure to microgravity affect the body? An article published this week in Small magazine attempts to shed light on this issue, in particular, on how microgravity affects brain connections. The article was published by a group of researchers headed by Steven Jillings from the University of Antwerp, Belgium. Jillings and collaborators conducted an investigation with 14 astronauts, who were subjected to studies to determine whether their brain connections were modified after a six-month stay in the international space station. For this purpose, astronauts were subjected to three magnetic resonance studies, prior to the mission, immediately after completion, and eight months after this completion. Researchers find that there are some changes in the organization of the brain immediately after the end of the mission, and that after eight months some astronauts were subjected to magnetic resonance studies, immediately after the mission, and eight months after this completion. Of them, they remain, while others disappear, returning the brain to their original state. Researchers interpret that non-permanent changes correspond to adaptations of the brain to the conditions of microgravity - for example, to the loss of the sensation above-down- that revert once back to Earth. Permanent changes, on the other hand, would correspond to a process of learning the brain during the time it was subjected to new environmental conditions. Five hundred years ago, Magellan and his crew could have overcome the scurvy by consuming fresh fruits and vegetables. For this, however, they should have known something that was only more than two centuries later, besides having had refrigerators, even more distant in time. On the other hand, space explorers will face far more severe conditions than those faced by explorers of the past. Now, however, we know much more. For example, that the brain is modified in space. In addition to having the ability to build machines much more sophisticated.",
    "https://upload.wikimedia.org/wikipedia/commons/8/83/The_Sun_in_white_light.jpg": "We know that the climate change that the planet is suffering is caused by the burning of fossil fuels. Thus, the obvious way to solve the problem is to gradually stop consuming such fuels. This, unfortunately, has been easier said than done and the abandonment of fossil fuels is not taking place at the necessary speed. In these circumstances, several proposals have been made to reduce the amount of solar energy that is absorbed by the Earth and thus mitigate the increase in its temperature. According to its proponents, this alone would not solve the problem, but would help to achieve it together with other measures.The idea is very simple: to place a kind of umbrella that attenuates the solar radiation that receives the planet.On how to carry this out the proposals have been varied, from dispersing gases in the stratosphere that reflect the solar radiation, to placing a screen between the Earth and the Sun that hinders the passage of the solar rays.In an article appeared this week in the magazine Plos Climate is offered one more proposal.The article was published by a team of researchers headed by Benjamin Bromley of the University of Utah in the The proposal of Bromley and collaborators is to place a cloud of dust in the so-called L1 point of Lagrange, located approximately 1.5 million kilometers from the Earth along the line that binds the Sun and the Earth. At this point, the forces of attraction of the Earth and the Sun on an object are combined to make the rate of translation of that object around the Sun equal to the rate of translation of our planet. Thus, the cloud of dust would be permanently placed between the Earth and the Sun. As Bromley and collaborators argue, to mitigate 1.8 percent of the solar radiation the cloud will have to contain more than ten million tons of dust. They also anticipate that the cloud will tend to spread -among other things, by the collision with the rays of the Sun- so it will have to be continuously recomposed. Where would the dust necessary for this be taken? The authors of the article propose that it be from the Moon. They argue that carrying it from the Moon would involve a lower amount of energy in comparison with carrying it from Earth, given its lesser force. In addition, Bromley and collaborators find that the grains of lunar dust are the right size to disperse the Sun\u2019s radiation. Thus, to keep the solar shield in shape, the lunar dust would be periodically launched from the surface of the Moon to the point of Lagrange. Bromley\u2019s proposal and collaborators, however, is classified within the field of solar geoengineering that has many critics. In this sense, an open letter launched in January 2020 by 60 climate experts from all over the world and currently supported by more than 570 scientists, calls for the signing of an agreement not to use solar geoengineering. In the head of that letter we can read: \u201cWe call on governments, the United Nations and other actors to immediate political action to prevent the normalization of solar geoengineering as an option in climate policy. Governments and the United Nations must ensure effective political control, restricting the development of solar geoengineering technologies on a global scale. Specifically, we call for an International Agreement on Non-Use of Solar Geoengineering.\u201d In their open letter that attempts to change the temperature of the planet would cause changes in the global climate that scientists with the current knowledge cannot anticipate. The impacts \u201cwill vary according to regions, and there are uncertainties about the effects on climate patterns, agriculture and the provision of basic food and water needs.\u201d They also point out that the possibility of mitigating climate change through solar geoengineering could be used as an argument to delay policies to reduce fossil fuels. Thus, the attempt to artificially change the planet\u2019s climate could result in a remedy worse than disease. Apart from the fact that proposals to carry this out\u2014involving even worlds outside ours\u2014are in full bloom.",
    "https://upload.wikimedia.org/wikipedia/commons/a/a4/Air_pollution_by_industrial_chimneys.jpg": "What is the relationship between chess and air pollution? At first glance it would not seem that there was any. Unless, for example, we consider that perhaps it is not advisable to play a chess game in some garden when there is a severe episode of air pollution. An article published online on 26 January in the magazine \u201cManagement Science\u201d, however, finds that there is a relationship, more permanent than contingent, between chess and pollution. This article was published by a group of researchers headed by Steffen Khunn of the University of Maastrichst in the Netherlands. In its article, Khunn and collaborators report the results of a research project carried out to find out to what extent air pollution in an interior space affects the performance of a professional chess player. It is known that such pollution negatively affects a person\u2019s cognitive abilities and that chess is an exercise in which players precisely deploy such skills. Thus, researchers hoped to find a relationship between air pollution and the strategic decision that a chess player would make when making a move to win the game later. In their research, Khunn and collaborators analyzed more than 30,000 moves made by 121 players in 607 games, held in three official chess tournaments in Germany in the years 2017-2019. Tournaments had a duration of 8 weeks, which gave enough time to evaluate the performance of players in changing conditions of air pollution. Researchers focused their study on particulate contamination with sizes less than 2.5 micrometers. These particles, considered to be the greatest environmental risk to human health, are generated by multiple sources, including internal combustion engines, forest fires and agricultural waste, and inefficient burning of fuels. During their study Khunn and collaborators installed a pollutant particle detector to measure their concentration in the enclosure where the tournament was held and evaluated the performance of players under different concentrations of pollutants. Players\u2019 chess movements were analyzed with an artificial intelligence algorithm that determined that they were so close to or far away from optimal movement. As a result, researchers report: \u201cIn general, our findings show that concentrations in indoor spaces of polluting particles worsens. n significantly the ability of the subjects to select the optimal movement.\u201d Thus, a relatively small increase in the concentration of particles increases by more than 25 percent the probability of a player making a mistake. On the other hand, it should be remembered that players in a tournament play with a time limit, which forces them to make the first 40 moves in a fixed time. If they do not lose the game, which puts them under pressure as the time limit approaches. In their study, researchers find that the extent to which this limit approaches, the effect of pollution on the performance of the players is amplified. Thus, pollution has a negative influence on the decision-making of a chess player, especially if it is under pressure. That said, it should be noted that the interest of Kuhnn and collaborators is not for chess itself. Far from this, through the study of the decisions that chess players made under changing conditions of air pollution, they sought to determine to what extent such pollution affects the cognitive abilities of a worker in a company, and therefore their process of strategic decisions According to Khunn and collaborators, its results \u201chighlight the benefits of investing in infrastructure to protect workers from external hazards and to improve the quality of the air inside buildings.\u201d It would result that air pollution, beyond driving climate change and affecting our health, could also stun us and hinder our ability to make decisions, especially if we are under pressure.",
    "https://upload.wikimedia.org/wikipedia/commons/5/57/Paul_F%C3%BCrst%2C_Der_Doctor_Schnabel_von_Rom_%28Holl%C3%A4nder_version%29.png": "The Covid pandemic has reminded us of something that our generation had somehow forgotten: that there are lethal pathogens that from time to time produce epidemics of great proportions that can put us in danger of death. Certainly, we knew of epidemics and deadly diseases like Ebola. These, however, were not perceived as a widespread danger, as Covid has been. Fortunately, Covid made its appearance until the 21st century, when scientific knowledge about the origin of the disease has made possible the generation of vaccines in record time and has drastically attenuated its impact on the health of the population.In the past our ancestors did not have the same fate, and in this sense two of the three bubonic plague epidemics that have occurred in the last two thousand years constitute the most deadly example. The first of these epidemics occurred in the VI-VIII century AD. In the Roman Empire of the East and is known as the plague of Justinian, and that could have killed up to 25 percent of the population. It began with the so-called black death, during which half of the population of Europe would have died. A third epidemic of bubonic plague, currently underway, has spread over the last three centuries. In his historical novel \u201cDiary of the Year of the Plague\u201d, writer Daniel Defoe recounts the climate that London experienced in 1665 during the bubonic plague epidemic that struck the city and that it would have killed a quarter of its population. Defoe did not live these events personally, but it is assumed that he heard of them by a relative, who did witness them. Defoe\u2019s novel thus constitutes a credible account of London\u2019s misfortunes. London\u2019s plague, on the other hand, played an unexpected and crucial role in the development of physics and science in general. Indeed, as part of the social confinement decreed by the English king to mitigate the spread of the disease, Cambridge University had to close its facilities. This forced Isaac Newton, the most important physicist in history and the season at Cambridge University, to move to For two years Woolsthorpe, his place of birth. There, in forced isolation, Newton discovered the law of universal gravitation, which had a profound impact on the development of the scientific method. Being the bacterium \u201cYersinia pestis\u201d, the pathogen that caused bubonic plague, the one responsible for the two most deadly pandemics in history, many efforts have been made to understand its evolution since its first appearance 5,000 years ago. Unfortunately, as documented in an article published last week in the magazine \u201cCommunications Biology\u201d, the company has not been easy. The article was published by a group of researchers headed by Katherine Eaton of McMaster University, in Canada.In their research, Eaton and collaborators carried out an analysis of 600 genomic sequences of Yersinia pestis collected throughout the world. The samples studied correspond, both to the first appearances of the pathogen 5,000 years ago, and to all subsequent epidemics. Five populations of bacteria were able to distinguish researchers for which they were able to obtain information about their own. They come to the conclusion that the strains of the pathogen that originated at the beginning of an epidemic, such as black death, were not recent at the time, but were produced with an anticipation of tens or hundreds of years before the outbreak. Eaton and collaborators conclude that the evolution of Yersinia pestis throughout history is extremely complex and that in order to decipher it it it is necessary not only to take into account genetic evidence, but also to consider historical, ecological, social and cultural contexts.It is not surprising that it is difficult to clarify the course followed by the bubonic plague over five millennia.What is surprising is that, despite the distance in time, we can have information about this evolution, so it is incomplete. Otherwise, we should be fortunate that scientific knowledge and the availability of antibiotics have shielded us, to a large extent, from the horrors of the epidemics of the past. And that the bubonic plague pandemic has participated in the development of the scientific method that has fought it.",
    "https://upload.wikimedia.org/wikipedia/commons/f/f7/SPICE_SRM_overview.jpg": "In a joint statement dated the 13th of this month, the Semarnat and the Conacyt express their rejection of the realization in Mexican territory of experiments that seek to alter the climate of the planet. This, in response to the experiments carried out in Baja California, without the knowledge of the government of Mexico, by the company Make Sunsets, which launched balloons with sulphur dioxide to be dispersed in the stratosphere. According to this statement \u201c...the Semarnat will implement a strategy that prohibits these practices within the national territory, that serve to strengthen the first references worldwide.\u201d As we know, the gradual increase in the temperature of our planet by the emission of greenhouse gases is reaching alarming limits. To mitigate this increase, a series of strategies have been proposed. The most obvious is to reduce the consumption of fossil fuels. Another is to remove the greenhouse gases that have already accumulated in the atmosphere, or to prevent them from getting there, capturing them as they are generated. A third possibility is to reduce the amount of solar radiation that is absorbed by our planet. One way to do this is by placing an umbrella between the Earth and the Sun, which would have to be enormous in order to produce an appreciable effect. A more \u201cterrified\u201d proposal, classified within the field of geoengineering \u2013 that is, the engineering of the Earth \u2013 is that of dispersing sulphur dioxide along large areas in the stratosphere. We know that sulphur dioxide reflects solar radiation and thus has the effect of an umbrella. Dispersing sulphur dioxide at a height of 20 kilometers is what the company Make Sunsets in Mexico tried to do, raising two balloons containing helium and sulphur dioxide to explode and disperse its content. We do not know what the result of the experiment was, but if it had been successful it would not have had a appreciable effect on the Earth\u2019s climate, as it would have barely dispersed twenty grams of sulphur dioxide, enough, according to the company site, to compensate for the emission of twenty tons of carbon dioxide into the atmosphere for a year. On the other hand, what we do know is that Make Sunsets caused the rejection of Mexico, which led by the company\u2019s site, the company to suspend its experiments until \u201cfind the way to collaborate with the Mexican government.\u201d It would have to remember that geoengineering is a discipline with an incipient development and therefore its application is a matter of controversy. Thus, for example, while dispersing sulfur dioxide in the stratosphere is relatively simple and this could well have the desired cooling effect, experts are concerned about a possible impact on the ozone layer and a reduction in the volume of rains, which would be, in addition, more acidic. It is also anticipated that climate changes will not be the same throughout the Earth, which would generate geopolitical conflicts. Likewise, it is feared that the reduction of solar insolation will lead to a false sense of safety that would reduce efforts to reduce greenhouse gas emissions. In the previous context, Make Sunsets sells \u201ccooling credits\u201d to ten dollars each. Each credit implies the release in the stratosphere of a gram of sulphur dioxide, sufficient to compensate for the emission of a ton of dioxide of ten dollars each year. However, as the MIT Technology Review magazine points out in its latest issue, experts criticize Make Sunsets\u2019 rudimentary experiments, his attempt to market geoengineering, and his irresponsible behavior in carrying out his experiments in Mexico without the knowledge of the Mexican government. All this, they believe, can undermine serious attempts in the future to develop a technology that could contribute to mitigating climate change. Moreover, anyone interested in buying a cooling credit would have to wait. On the company\u2019s site we can read the following: \u201cKeep in mind that we don\u2019t currently have a future launch, so it will be a while before we can deliver their cooling credit. Its purchase is refundable at all times.\u201d",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/Rome-Pantheon-Interieur1.jpg/800px-Rome-Pantheon-Interieur1.jpg": "According to the ancient Greeks, the great pyramid of Giza and the hanging gardens of Babylon were part of the group of the seven wonders of the world. It is not surprising that the Greeks marveled at the pyramid of Giza, an immense stone mole of 140 meters high and 230 meters of side, whose existence could be verified by anyone who had the opportunity to travel to Egypt. In contrast, the existence of the hanging gardens of Babylon was more uncertain. In fact, even today, archaeologists have not managed to find remains of such gardens that proved that they existed at some time in history. Thus, they could be only a legend. Or perhaps the history was unfair to the gardens of Babylon, which might well have existed and their trace had existed in time. This, unlike the pyramid of Giza, which has survived thousands of years, both by its enormous volume, and by the great stone blocks with which it was built. The gardens of Babylon, in contrast, would have been built with bricks and would have resisted less the passage of the years. It serves to introduce the subject to deal today: the remarkable development by the Romans of concrete, in contrast, the ancient Greeks. as building material, with which they built roads, aqueducts and buildings that, without having the volume of an Egyptian pyramid, have lasted for two thousand years. This is the case of the Pantheon of Rome inaugurated in 128 A.D., which has the largest unreinforced concrete dome -43 meters in diameter- in the world. The durability of the concrete developed by the Romans has been attributed to the use in its manufacture of volcanic ash from the area of the Bay of Naples. An article appeared last week in the magazine \u201cScience Advances\u201d, however, points in another direction. This article was published by a group of researchers led by Linda Seymour of the Massachusetts Institute of Technology. As Seymour and collaborators point out in his article, in contrast to its modern counterparts, the concrete developed by the Romans in ancient times has remained stable in a variety of climates, in seismic areas, and even in contact with sea water. To investigate the origin of the longevity of the Roman concrete, researchers focused on small white deposits of ubicumetric size, which are ubicumetric. These deposits have been attributed to the careless manufacture of concrete by the Romans. Seymour and collaborators, however, find that they are formed of various forms of calcium carbonate and that, far from being the result of a careless manipulation, they are the product of the concrete manufacturing process employed by the Romans, in which live lime is mixed instead of off lime. On the other hand, and more importantly, Seymour and collaborators conclude that in the inclusions of calcium carbonate there is the secret of the longevity of the Roman concretes. That is, when concrete age and cracks form that weaken it, calcium carbonate reacts with water and fills such cracks preventing its propagation. Thus, a long-lived concrete with autosanation properties is obtained. In addition to that our descendants in the distant future find irrefutable proof that in our time we were able to build buildings capable of standing for thousands of years -living with the pyramid of Guiza, but without reaching its dimensions - what other benefit could derive from a It is known that the concrete manufacturing industry is highly polluting and that it contributes 8 percent of greenhouse gas emissions to the atmosphere, and in this sense, Seymour and collaborators maintain that to the extent that more durable concretes are manufactured, the longevity of constructions would be increased and the rate of greenhouse gas emissions to the atmosphere would be reduced. What is indispensable if we want someone to marvel at our constructions in the future.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d8/BiconvexLens.jpg": "As the end of the year approaches, it is customary to take stock of the scientific and technological advances developed throughout the year, as well as to make predictions about those that will be given in the new year.One of the scientific news of the year that ended yesterday was undoubtedly the launch of the James Webb space telescope of $10 billion. At this cost, we can take for granted that the telescope incorporates scientific instruments and light capture and imaging with the most advanced technology. In particular, it has a 6.5-meter-diameter mirror made up of 18 hexagonal segments, each of which can be independently oriented to keep the telescope in a precise approach. Beyond this sophistication, however, the telescope mirror is based on the same physical principles as the telescopes developed in the seventeenth century. Thus, the James Webb telescope constitutes a combination of technologies typical of the last half century, with a technology to capture light and form images that are 400 years old. And what happens with the space telescope also happens with other more terrestrial devices. For example, with smart phones that, apart from the This latter function is carried out with an amazing and growing ability, integrating technologies of microelectronics, computing, screen making and camera miniaturization. It should be noted, however, that for the latter technologies of different centuries are combined: the modern microelectronic sensors that convert light into an electrical signal, and the lens that captures the light of the subject photographed and focuses it on the sensor to form the image, and that it was conceived in first instance in the seventeenth century. On the other hand, if what is sought is to develop more and more of the thin phones - at the level of a credit card-, the factors that limit the advances in that direction are the battery of the phone and the lens of the camera, formed by the stacking of lenses necessary to reduce the distortions of the image. The latter would be to change by 2023, at least according to an article published in the newspaper The Washington Post on 30 December signed by Aaron Brown. That article refers to the so-called metallentes and the company Metal. In order to understand what metallents are, it is necessary to consider that a normal lens is an object made of glass or of some transparent material with curved surfaces, which changes the direction of the light passing through it in a controlled way according to the curvature of its surfaces. Thus, by necessity, a normal lens has a certain thickness dictated by such curvature. The surfaces of a metallent, in contrast, are flat and therefore its thickness is reduced to a minimum. In a smart phone, the stacking of lenses of the camera will be replaced by a single metallative and will not be the limiting factor of its thickness. Otherwise, the impact that the metallents would have would not be limited to reducing the thickness of the smart phones. Far from this, it should be pointed out that metallents work with a physical principle different from that of normal lenses and therefore provide additional information. Thus, the cameras equipped with metallents would constitute an expansion of our eyes and give us a different view of the world to which they will In this sense, we will mention that polarization is a property of the light to which our eyes are insensitive. In contrast, as Capasso explains, metal-equipped cameras can be sensitive to that property and see a world that is invisible to us. A normal camera can be sensitive to polarization, but it would be voluminous and would have to be equipped with special accessories. A metal-equipped camera, on the contrary, would have this capacity, a reduced cost and a compact size. If, as some predict, 2023 will be the year of the metallents, a technology originating 400 years ago would have been transcended, at the same time that we will have, not only thinner phones, but new eyes to see the world.",
    "https://upload.wikimedia.org/wikipedia/commons/0/03/Lise_Meitner_%281878-1968%29%2C_lecturing_at_Catholic_University%2C_Washington%2C_D.C.%2C_1946.jpg": "Having already begun the so-called Guadalupe-Reyes bridge, full of festivals and celebrations and in general of moments of leisure, it is illustrative to consider some scientific discoveries that were carried out precisely during the period of the decembrinas holidays and that due to its enormous impact have shaped the present society. These discoveries were made by scientists who decided not to participate in such parties; or that they decided to do so in a moderate way.We will begin by considering the sighting on December 25, 1758 of the Halley comet by amateur astronomer Georg Palitzsch, which had been predicted in 1705 by Edmund Halley. Halley suspected that the comets sighted in 1531, in 1607, and by himself in 1682, were in fact a same celestial body that visited our neighborhood periodically. To support his hypothesis, Halley used the then new laws of gravitation and the movement of Isaac Newton to calculate the orbit that would have that body on his journey around the Sun. Based on his calculations, Halley predicted that we would see the comet again in 1758, as it did. A second example is the discovery of the nuclear fission carried out during the December 1938 vacation by Lise Meitner and Otto Frisch. Meitner was a researcher of Jewish descent who, for this reason, had to abandon her job at the Kaiser Wilhelm Institute in Berlin - in a hasty manner and with only two small suitcases as luggage - and take refuge in Stockholm. In Berlin, Meitner, together with Otto Hahn and Fritz Strassmann, carried out experiments in which they bombarded uranium atoms with neutrons. With her flight to Sweden, Meitner interrupted her experiments in Berlin, but she continued in contact with Hahn, who, in a letter dated 19 December 1938, told her that by bombing uranium with neutrons, barium atoms were produced which is an element with a weight of approximately half the weight of uranium. Hahn had no clear idea of how the barium and Meitner was generated. This discovery, in the first instance, gave rise to the nuclear bombs that destroyed Hiroshima and Nagasaki at the end of the Second World War, and subsequently to the still more powerful atomic fusion bomb that had the world over the so-called cold war. The discovery of Meitner and Frisch also led to the development of nuclear reactors for the generation of electric power. A third example is the demonstration of the transistor carried out on 23 December 1947 by John Bardeen and Walter Brattain at Bell Laboratories in New Jersey, United States. Immediately after this demonstration, as told by Michel Riordan and Lillian Hodeson in their book Crystal Fire, William Shockley, also of Bell Laboratories, was locked in a hotel room to develop transistor theory of operation that is still in force. . As we know, the invention of the transistor has produced a radical change in our civilization and over time has led to the development of computers and the Internet, as well as a whole range of electronic devices. The above are just a few examples of scientific discoveries that have been of great significance and that have been carried out during the holidays of December. We cannot, however, think that December is a special month in this regard, so that, assuming that scientists are more interested in their work than in the decembrian holidays, important discoveries must be shared equally throughout the twelve months of the year. Moreover, apart from carrying out an investigation to determine the veracity of this latter statement, we venture to suggest that the Guadalupe-Reyes bridge is not precisely a promoter of the scientific progress of the country.",
    "https://assets.entrepreneur.com/content/3x2/2000/1659463551-the-line.jpg?auto=webp&quality=95&crop=16:9&width=675": "An article published last Friday in the magazine MIT Technology Review confirms that the Saudi Arabia project known as The Line is in full construction. This project, announced by the Crown Prince of Saudi Arabia in 2021, contemplates the construction of two skyscrapers of 500 meters in height in the middle of the desert. Since in the world there are at least ten buildings that exceed this height, by boat soon such a project would not seem anything from the other world. It should be noted, however, that The Line will have characteristics that place it beyond any other project built up to now. Indeed, The Line is intended to be a megacity in the Saudi desert for 9 million inhabitants with a very unique design: two buildings of 500 meters in height separated by 200 meters, which extend along 170 kilometers. The structure forms a kind of narrow canyon of 500 meters in height and 170 kilometers in length. In addition, with the walls of the buildings that see towards the desert covered with mirrors. The inhabitants of the city, which will lack streets and automobiles, will move in the space between the two buildings and will be able to reach any service walking in five minutes. . For longer distances they will have air taxis and an underground train that will allow them to travel the total length of the city in 20 minutes, at a speed of more than 500 kilometers per hour. The Line will thus constitute a linear and vertical city in which its inhabitants will live with all the comforts in a strip of land of 200 meters wide and 170 kilometers long, isolated from the desert by two buildings of 500 meters high. It would accommodate 9 million inhabitants in an area of 34 square kilometers -a square area of approximately 6 kilometers per side. For its operation, The Line will need to rely heavily on technologies such as robotics and artificial intelligence, as well as on technologies to desalinate water, produce rain and generate renewable energies, which are intended to fully cover the energy needs of the city. Investment in the megacity would reach 500.000 million dollars. Given the magnitude of the project and the technologies necessary for its realization, it was doubted that it could one day be carried out. The Line construction, however, would have started in April of this year and the article of MIT Technology Review mentioned above confirms it in a full way. . This, based on the analysis of high-resolution satellite photographs carried out by the Soar Earth company, which shows that \u201cabout 26 million cubic metres of earth and rocks have been excavated\u201478 times the world\u2019s tallest building volume, the Burj Khalifa.\u201d From its photographic analysis, Soar Earth also finds 425 vehicles on the site where the buildings and 650 vehicles will be located at a construction base close to the site, which serves as accommodation for the project workers. That base, five square kilometres of surface, has its own installation of solar cells, as well as several swimming pools and various football and cricket fields. Construction activity was observed around half the total length of the project. The Line has been presented by its creators as a \u201crevolution in civilization\u201d that will transcend \u201cdisruptible and contaminated cities, which ignore nature\u201d and where \u201chumanity has lived for a long time.\u201d The project, however, has been a source of criticism by the experts. line of architecture \u201cdezeen\u201d mentions some of them. It is argued, for example, that there is a lot of physical and environmental phenomena that will need to be controlled for the operation of the city, which will be difficult to carry out over a period of time. Likewise, the operation of the city will depend on technologies that in some cases are not fully developed. On the other hand, would it be attractive to live in a space of 200 meters wide that some find claustrophobic? There will certainly be different opinions about it. These and other criticisms have expressed the skeptics of the project The Line, which, however, advances to full steam in the Saudi desert according to MIT Technology Review. Certainly, driven by the abundance of resources.",
    "https://upload.wikimedia.org/wikipedia/commons/b/b6/Bronzebeile.JPG": "Today, some materials such as lithium or the so-called rare earths are highly appreciated for their numerous applications, including renewable energy generation, telecommunications and computer memory. Similarly, 3,500 years ago tin was a material of great importance for established civilizations, from East Asia to the Mediterranean Sea. Indeed, we know that some 5,000 years ago it was discovered that adding 10 per cent of tin to copper obtained an alloy that is tougher than its two constituents. This led to the manufacture of weapons for war and tools and tools for daily life, and at the beginning of the so-called Bronze Age that lasted until the end of the second millennium BC. On the other hand, we know that deposits of lithium and rare earth are not distributed uniformly throughout the surface of the planet and therefore constitute materials of strategic importance. The same was true of tin during the Bronze Age, whose mineral deposits were far from urban centres. Thus, as today industrialized countries are concerned to ensure the flow of strategic materials that they need. For the operation of their economy, the civilizations of the ancient world had to secure the flow of tin that they required. The discovery of a shipwreck of the Bronze Age on the south coast of Turkey with a cargo of 10 tons of copper and a ton of tin provided an opportunity to find out the origins, and the routes that followed the tin from the extraction site to that of its consumption.The experts, however, had not managed to agree on these points, until a study carried out by a group of researchers led by Wayne Powell, from Brooklyn College in New York, revealed the provenance and intricate route that would have followed the tin.The results of that study were published this week in Science Advances magazine.To unravel the mystery, Powell and collaborators carried out an analysis of the compositions of tin isotopes and lead of 108 tin ingots from the shipwreck and compared them with the corresponding compositions of known tin deposits - as we know, the chemical elements may exist as different isotopes that differed from each other in terms of their weight. In this way, the coincidence of the isotopic composition of a bullion with that of a field would indicate the origin of the bullion. Following this method, the researchers found that one third of the bullion came from mines in Uzbekistan, while the remaining two thirds came from mines in Turkey. With the results of their research, Powell and collaborators discovered a trading network with an age of 3,500 years, whereby the tin mined in Central Asia by small mining communities was sent, through more than 3,000 kilometres, to the Mediterranean Sea, where it was combined with tin mined in Turkey under the control of a central government. According to the researchers, the shipment of copper and tin from the evil ship would have been enough to produce swords for an army of 5,000 soldiers. Thus, the tin trade network, in addition to being sophisticated, was organized with disparate elements. In addition to the answer that might eventually be given to these questions, two things are surprising to us. First, that in the Bronze Age they would have been able to organize a trade route with the proven complexity, and second, that secrets could have been unravelled after 3,500 years. Although, thinking again, perhaps we should not be surprised that our predecessors have organized a complex trade route thousands of years ago. After all, by then they had already invented the metallurgy of bronze, which is more complicated. As perhaps we should not be surprised by the ability of the scientific method to explore the past, of which so many tests have given us.",
    "https://upload.wikimedia.org/wikipedia/commons/2/24/Aureus_Sponsianus_Bl%C3%A4tter_fuer_Muenzfreunde_1923_fig_10.jpg": "After 1,500 years of remaining in the dark, the existence of a Roman emperor of the Esponsian name would have been revealed two centuries ago when Roman gold coins were discovered with his effigy. While we must point out that the authenticity of those coins has been questioned and therefore the existence of Esponsian has also been, an article published this week in the magazine PLOS ONE provides proof that these coins are authentic. The article was published by a group of researchers headed by Paul Pearson of University College London. According to Pearson and collaborators, a handwritten note in 1713 by Carl Gustav Heraeus, who was Inspector of Medals of the Imperial Collection in Vienna, documents the acquisition of eight gold coins from five different designs, one of which showed the effigy of Esponsiano. These coins were part of a batch of coins that would have been discovered in 1713 in Transilvania, in present Romania. Heraeus acquired only part of the lot; the rest was dispersed among different buyers. are and collaborators report the results of a study carried out with four coins that would have been part of the lot discovered in Transylvania and that are currently part of the collection of the Museum The Hunterian of the University of Glasgow. One of these coins shows the effigy of Esponsiano, while the other three show well-known Roman emperors, one of them Gordian III and the other two Philip I or Philip II. According to the researchers, the design of four coins share many characteristics that make them think they were made by the same person. In particular, the coins portray emperors with prominent mentons and jumping eyes. The similarity between the coins can be appreciated in the quoted article, free consultation on the Internet. At first, it was thought that the coins discovered in Transylvania were authentic, although crude imitations of Roman coins made \u201cbeyond the limits of the empire.\u201d Likewise, it was considered that Esponsiano was a local usurper, who would have used the prevailing disorder during the so-called crisis of the Roman Empire in the third century. In 1868, however, as Pearson and collaborators point out, the most prominent expert on the subject stated that the coins were \u201cmistaken and ridiculously conceived falsifications.\u201d To date, the matter had not been clarified, and in these circumstances, the researchers proposed to study the four coins of The Hunterian\u2019s collection with modern analytical techniques to have more elements of judgment. Pearson and collaborators took images of the coins using visible, infrared and ultraviolet lights. They also observed the coins with an electronic microscope that allowed them to make a chemical analysis of their surface. They concluded that the coins showed scratches that showed natural wear during the time they were in circulation, and not an artificial wear that would have been caused by an attempt to counterfeit. Likewise, they found mineral deposits on the surface of the coins that showed that they were buried for a long time. Based on their results, Pearson and collaborators came to the conclusion that the coins found in Transylvania were very likely authentic and that Esponsiano should be historically reevaluated. researchers that Esponsiano would have been a military commander in Dacia -present-day Transylvania-, which was a province at the extremes of the Roman Empire, and that he would have taken power during the crisis of the third century, during which there was a constant change of emperors coming to power by military means. We would thus have that Esponsiano is an emperor who has come to history by the back door, to put it in some way, and that without modern techniques of analysis he might not have gone from being a fictional character invented by a counterfeiter of coins. On the other hand, it should also be noted that, as scientific techniques are developed to find out the past, the back door could become the front door.",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/b/be/Cruise_Automation_Bolt_EV_third_generation_in_San_Francisco.jpg/640px-Cruise_Automation_Bolt_EV_third_generation_in_San_Francisco.jpg": "On October 9th, the match between the Guadalajara and Puebla teams was held in the city of Puebla to enter the quarterfinals of the first division football tournament. During the execution of the penaltytis round at the end of the game -which was necessary since the match ended tied in the regulatory time - the goalkeeper of the Guadalajara team complained that an amateur in the grandstand was pointing to his eyes with a green laser at the time of facing the shooter, in order to obstruct his vision and make it fail. The incident has not been unique and has occurred in different circumstances, made possible by the easy and free acquisition of lasers with appreciable powers. Lasers are light sources with unique characteristics; among these, that of producing a beam of light that travels in a straight line and that is what in the first instance allows attacks like the one that took place in the Guadalajara-Puebla party. Moreover, blinding the goalkeeper is not the only malicious use that we can conceive for a laser. In this sense, an article written by a group of researchers headed by Yulong Cao of the This article is still in the review phase by other experts for its formal publication, but it is possible to consult it at the arXiv site maintained by Cornell University. In their article, Cao and collaborators evaluated the use of an infrared light laser to deceive the Lidar system that guides some cars without a driver. This system is based on an infrared laser and infrared radiation detectors placed on the roof of the car. The laser rotates quickly sending light pulses in all directions, so that, if one of these pulses finds an obstacle, it will be reflected producing an echo that will be captured by the car detectors. From the echo, the Lidar system will be able to determine the position of the obstacle, as well as the distance to which it is located. The latter measuring the time it takes for the laser pulse to travel back and forth to the obstacle. Thus, the Lidar system will have information about the conditions of the road; that is, if it is free to move forward or if there are obstacles to be avoided. Unfortunately, the above is easier to say than to make it a reality, as Lidar detectors capture multiple echoes produced by objects intercepted by the laser beam in their trajectory, which have to be analyzed by the system for its correct interpretation. For this, Lidar prioritizes the most intense signals discarding weaker ones. Taking advantage of this feature, Cao and collaborators managed to confuse the Lidar system by directing the car an infrared laser that pretended to be an intense echo signal, which eclipsed the true signal coming from a pedestrian, making it ignored. That is, by means of its false signal, the researchers generated a blind spot in the Lidar vision system, which ignored the presence of a pedestrian in the car's trajectory. Thus, as a person armed with a laser could block the vision of a doorman who tries to stop a criminal shooting, another person with worse intentions could generate a blind spot in the Lidar system that would not detect the presence of a pedestrian on his way. The consequences in the two cases, of course, would be very different. In one case blindness could result when much in the unfair defeat of a team, which could be recovered in the following year, while in the other there could be no possible recovery. On the other hand, it should be noted that the Lidar is only one of the two systems by which an autonomous car can \u201csee\u201d the way and that there is a second system, based on video cameras, that makes it competition. Both systems have advantages and disadvantages and some experts believe that the autonomous cars of the future could have, both a Lidar and video cameras, to have the best of both worlds. In which case, the possibility that a malicious actor could blind an autonomous car would be less worrying.",
    "https://upload.wikimedia.org/wikipedia/commons/c/c1/Telstar.jpg": "A European chronicle of the Middle Ages speaks of the appearance in 774 of a \u201cred cross\u201d in the sky after sunset. A contemporary Chinese chronicle notes the occurrence of a similar phenomenon in the year 775. Although it is not clear what caused these phenomena, some experts venture that they could be about glows caused by the entry of high energy particles from space into the Earth\u2019s atmosphere. This is supported by studies that measured the concentrations of carbon-14 in millennial trees that indicate that in the year 775 there was a sudden increase in the intensity of high energy radiations that entered the earth\u2019s atmosphere. With regard to the latter, it should be remembered that our planet is continuously bombarded by high energy radiations from the Sun and sources outside the solar system. Such radiations are absorbed in the high parts of the atmosphere and, among other secondary products, generate carbon-14 isotopes that are eventually incorporated into the biosphere and are absorbed by plants. Thus, the concentration of these isotopes in the growth rings of a tree - In this sense, the most widespread hypothesis is that it has been due to sudden increases in the amount of radiation that is known to grow annually and whose study is the objective of dendrochronology-, it will indicate the intensity of the high energy radiations that arrived to our planet from space throughout the tree life. Thus, by measuring the concentration of carbon-14 in Japanese cedar trees it was possible to determine that in the years 774-775 there occurred a sudden increase of 1.2 percent in the levels of high energy radiation that arrived to our planet, which is the largest one that has occurred in the last 11,000 years. In addition, there have been similar events, although of lesser magnitude. All these events are known as Miyake events, by the researcher who discovered them. Given that an event such as that occurred in 774-775 would have a catastrophic effect on our planet's communication systems, it is of great interest to try to understand the causes of sudden increases in the radiation levels coming from space to try to anticipate them. However, it has also been considered that they were due to increases in cosmic ray levels generated beyond the solar system. An article published in the journal Processings of the Royal Society A seeks to shed light on this issue. This article was published by a group of researchers and leads as first author to Quingyuan Zhan, University of Queensland, Australia. In their research Quingyuan and researchers modeled the carbon cycle over a period of 10,000 years and incorporated published dendrochronological data about six Miyake events occurring in the last 9,000 years, including the event of the years 774-775. They do not find a correlation between such events and the solar activity cycles that support the most accepted hypothesis and leave open the possibility that they are related to sudden increases in the intensity of cosmic rays. In fact, they consider that more research is necessary to reach a solid conclusion.When the Europeans of the High Middle Ages observed in the sky what seemed to be a red cross, they were far from understanding the nature of the phenomenon. It should be remembered that in 774 -just four years after Charlemagne, the so-called Father of medieval Europe, became king of the Franks - Europe was still far from the scientific revolution of the 16th and 17th centuries led by Galileo Galilei and Isaac Newton. And even further away from the 19th and 20th centuries that saw the light of modern communications systems that would be devastated by another Miyake event. Thus, if in 774 the increase in cosmic radiation did not appear to have greater consequences for the world - God would have protected innocence - today I would put it, paradoxically, head down. because of our absolute dependence on Internet networks, communications satellites and power transmission power lines. Product of our loss of innocence.",
    "https://upload.wikimedia.org/wikipedia/commons/f/fb/The_Sun_and_TRAPPIST-1.jpg": "If for some reason or reasons the emission of greenhouse gases to the atmosphere is not controlled and extreme weather events, such as droughts, hurricanes, and heat and cold waves increase in number and intensity, to the point of making the planet increasingly uninhabitable, we would have to look for options to move to another planet. What options would we have? Our first choice might be the Moon, which is, say, a stone\u2019s throw away. The Moon, however, is an inhospitable, dry and atmosphereless place, which would make it impossible to establish settlers in appreciable numbers. Thus, we would have to think of some other places further away and in this sense, we could consider Venus and Mars, which are the planets closest to the Earth. We exclude Venus, however, who has a dense atmosphere of greenhouse gases that cause the temperature on its surface to exceed 400 degrees Celsius. As for Mars, while its environmental conditions are less inhospitable, it has a faint atmosphere of carbon dioxide that would not allow us to breathe. The planets and their satellites are very cold. It is, for example, the case of Titan, the largest satellite of Saturn, whose surface temperature is less than 180 degrees Celsius. Thus, we would have to look for options to move some planet outside our solar system. At the moment we have no knowledge of any one that meets the conditions of habitability that are required, but the experts are in their search. For this, they have the help of the James Webb space telescope, recently put into operation. A planet that is in the lens of the James Webb is the TRAPPIST-1e, which orbits the star TRAPPIST-1 located 40 light years from the Earth -a light year is the distance that travels through the light in a year-. TRAPPIST-1 is a relatively cold star that has seven rocky planets orbiting around it. TRAPPIST-1e is the fourth planet closest to the star and is located within the area where liquid water can exist, so it is a candidate for life. Given this expectation, that planet will be the subject of a study by the James Webb telescope of the NASA in the hope of determining its real conditions to sustain life. As NASA carried out its studies to characterize the environmental conditions of TRAPPIST-1e, an international group of experts led by Assaf Hochman of the Hebrew University of Jerusalem, was given the task of determining the climatic variability that could prevail on that planet, which is key to sustaining life. Although for the time being there is no detailed knowledge of the environmental conditions prevailing in TRAPPIST-1e - knowledge that is expected to be expanded by the observations of the NASA telescope-, Hochman and collaborators decided to advance and predict the possible climate variability of that planet. The results of their research are reported in an article published this week in The Astrophysical Journal. In their study, researchers were interested in determining the climate variability of TRAPPIST-1e in the face of changes in the concentration of greenhouse gases in the atmosphere and find that, in comparison with the Earth, the climate of TRAPPIST-1e is more vulnerable to such changes. , consider that their study establishes a platform to determine the conditions of habitability of a planet and its climate stability in the face of changes in the concentration of greenhouse gases in the atmosphere. Thus, if its results were confirmed, we would have to remove TRAPPIST-1e from the list of candidate planets for a move in case the climatic conditions of our planet worsen. Otherwise, we would better look after the climate of our planet without looking for three feet to the cat, and limit the emission of greenhouse gases. Well, apart from how far away the possible substitute planets are, it could turn out that once there, we would find a place with greater climate variability. With what we would have left guatemala to enter guatepeor.",
    "https://upload.wikimedia.org/wikipedia/commons/b/b4/Vincent_Willem_van_Gogh_128.jpg": "As we can see in videos available on the Internet, filmed in the past days at the National Gallery in London, two young activists of the \u201cStop Oil\u201d group stood in front of the painting \u201cThe Sunflowers\u201d, by the Dutch painter Vincent van Gogh, with cans of tomato soup in their hand whose contents they threw on the painting. This was done, the activists covered the palm of the left hand with glue and pressed it against the wall. So, stuck to the wall, they launched an environmental discourse asking for the suspension of the use of fossil fuels, before the museum security guard removed them from the place. If van Gogh, by means of a time machine, had moved up to our days and had witnessed the scene, it would probably have missed him greatly. With a little more time remaining in the future, however, he would have probably learned that the planet is going through a process of climate change that threatens to overflow and reach a point of no return. And he would have also learned that, in parallel, a process of biodiversity loss is occurring that climate change is threatening to overflowing. is not foreign, at least according to the Planeta Vivo Report 2022, released this week by the conservationist society World Wildlife Fund. Indeed, according to that report, although at present the change in land use is the main threat to nature, if we fail to limit to 1.5 degrees Celsius the increase in the temperature of the planet with respect to its pre-industrial value, climate change will probably be the first cause of the loss of biodiversity in the coming decades.In addition to future events, even now the speed with which biodiversity is being lost is worrying. According to the Planeta Vivo Report 2022, between 1970 and 2018 an average reduction of 69 percent in the wild populations monitored. Moreover, such reduction, in which only vertebrate animal species are considered, is not uniform throughout the planet, and in this sense, Latin America occupies the first place with 94 percent reduction, compared to 55 percent in the Asia-Pacific region and 20 percent in North America. These figures, especially those referring to Latin America, sound, In this sense, the website Our World in Data provides us with a simple example to understand, from the variation of rhinoceros populations in Tanzania and Botswana between the 1980s and 2017. According to that site, in 1980, the population of rhinoceros in Tanzania and Botswana was 3795 and 30, respectively. In 2017, the corresponding numbers were 160 and 50. Thus, in Tanzania, there was a 96 percent reduction in the rhinoceros population, while in Botswana the rhinoceros population increased by 67 percent. Thus, adding both populations, there was a 95 percent reduction in the total rhinoceros. The Planeta Vivo Report 2022, in contrast, takes the average reduction observed in Tanzanian with growth in Botswana and reports a reduction of only 15 percent. This is misleading because it does not tell us that in Tanzania the rhinoceros are on the roads of Tanzanian rhinoceros. While in Botswana they have managed to increase the number of rhinoceros. Thus, we must take care of the figures on the reduction of the populations of wild animals reported in the Planeta Vivo Report 2022. However, the fact that the numbers reported are negative causes the alarm signals of the experts. In particular, the difference in figures between Latin America and other parts of the world is shocking.In conclusion, van Gogh would certainly have to be excused for the attack of the activists. And to argue that, in any case, it would have been more appropriate, by symbolic means, to attack some painting of Paul Gauguin - friend of van Gogh- made during his stay in the paradise of Tahiti in which he sought refuge, and that he is now threatened with flooding due to climate change.",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Cole_Thomas_The_Course_of_Empire_Destruction_1836.jpg/800px-Cole_Thomas_The_Course_of_Empire_Destruction_1836.jpg": "As we know, during the 8th and 9th centuries of the Christian era, the Mayan civilization of the southern lowlands of the Yucatan peninsula went into decline and eventually collapsed. The causes that led to this collapse have not been fully clarified. It has been speculated, however, that it could have been caused by a climate change that would have caused a mega drought and an agricultural disaster. It has also been speculated that a change in the climate would have been a factor for the collapse of the Western Roman empire, and in this regard it is known that a series of volcanic eruptions caused a decline in environmental temperature in the 6th century after Christ that lasted for 150 years. Given past experiences could climate change that is currently going through the planet have any consequence for contemporary civilization? An opinion article published this week in the journal Proceedings of the National Academy of Sciences expresses some points of view in this regard. This article was published by a group of researchers headed by Daniel Steel of British Columbia University in Canada. In its article, Steel and collaborators define the collapse of a civilization as the loss of social capacity to maintain the In a first scenario, social collapse due to climate change occurs in isolated and vulnerable localities, while other places have been able to adapt to the climate impact. In this scenario, social collapse occurs at a local level. In a second scenario, the collapse occurs in more widespread areas, even at the national level, but there will be large urban areas and national governments that will suffer the effects of climate change but survive it. The authors refer to this scenario as a \u201cbroken world.\u201d Finally, in a third scenario, there will be a global collapse of civilization. As Steel and collaborators mention, the impact of climate change on civilization can be direct, leading to droughts, floods, extreme heat and other climatic events that endanger agriculture and water reserves, as well as other essential elements for civilization. The impact may also be indirect, in which case climate change generates negative social effects. A drought could severely affect food production and thus generate famine and social instability. An indirect impact also occurs when internal, direct or indirect climate impacts generate vulnerability to external threats; threats of war or epidemic, for example. How real is a collapse of civilization as a result of climate change? As Steel and collaborators argue, while some experts are skeptical about it, it is not possible to rule it out. Thus, for example, the fusion of permafrost by global warming would exacerbate climate change and increase the chances of social collapse. It should be noted that permafrost is a layer of the subsoil, mainly in cold regions of the northern hemisphere, which is permanently frozen and its possible fusion alarm to experts, as it would release large amounts of greenhouse gases.In any case, they consider Steel and collaborators that the probability of a collapse of civilization by climate change has not been assessed with sufficient extent and depth using scientific methods. And if that were the case, once the causes that have led civilizations to collapse were understood, we could make use of the acquired knowledge to prevent the collapse of ours. And as an extra bonus, perhaps we can understand what led to the collapse of the Mayans of southern Yucatan.",
    "https://upload.wikimedia.org/wikipedia/commons/1/15/Gorilla.jpg": "By being well known, we would not be surprised to see a gorilla standing on two legs and repeatedly hitting his chest with both fists. As it does, for example, King Kong at the top of the Empire State building in New York, or as wild gorillas do that we can see in videos on the Internet. In contrast, we might be surprised to see a chimpanzee do the same thing. And yet, chimpanzees have been observed beating his chest by imitating a gorilla. This is mentioned in an article published in the latest issue of iScience magazine by a group of researchers headed by Crikette Sans from Washington University in Saint Louis, in the United States. But let\u2019s go in parts. In their article, Sans and collaborators report the results of an investigation carried out to study in depth the known social interaction that occurs between groups of gorillas and chimpanzees wild in areas shared by both species in Central Africa. What do gorillas and chimpanzees claim with this interaction? As for the first possibility, both gorillas and chimpanzees would respond to alarm signals given by a member of either species in the sight of a predator. Likewise, small groups of relatively unarmed gorillas or chimpanzees would be associated with groups of the other species in search of protection. Sans and collaborators find that, in fact, both species respond to alarm signals issued by a member of the other species. At the same time, however, they also find that groups that include chimpanzees and gorillas are larger than groups formed only by chimpanzees, which contradicts that the motivation for the association of chimpanzees with gorillas is to seek protection against predators.In contrast, researchers found evidence that support the association between gorillas and chimpanzees is largely motivated by the greater opportunity it represents to locate new sources of food. Thus, they find that 34 percent of the researchers found evidence that support the association between gorillas and chimpanzees is largely motivated by the greater opportunity it represents of locating new sources of food. In addition to the above, the social interaction between chimpanzees and gorillas, which can be both affective and aggressive, provides opportunities for the development of social, physical and cognitive skills. In this sense, Sans and collaborators witnessed games between chimpanzees and gorillas that involve body-to-body struggles, bites and blows. Interaction, in addition, creates opportunities for the transmission of knowledge between species. The observation of a chimpanzee giving himself blows in the chest to the style of gorillas mentioned at the beginning of this article, is an example in this regard. Sans and collaborators write: \u201cWe also observe gestures between species to initiate social interactions. Curiously, chimpanzees hit their chest, a characteristic behavior of gorillas.\u201d As Sans and collaborators point out, an interaction between species such as chimpanzees gives between chimpanzees. s and gorillas could have been present among human species in the remote past. Today, for about 40,000 years when Neanderthals disappeared, we are alone as a human species on the face of the planet. If Neanderthals had survived to this day it is interesting to ask ourselves - in an idle way - would we live with them as they do today chimpanzees and gorillas? Could a child, for example, play \u201cfights\u201d with his Neanderthal friend? There is no way to know, but in such case ours would certainly be a rare world.",
    "https://upload.wikimedia.org/wikipedia/commons/0/0d/Great_Wave_off_Kanagawa2.jpg": "On September 19, an unusual event occurred in Mexico: a 7.1 earthquake on the Richter scale with an epicenter off the coast of Michoac\u00e1n. Certainly, such a tremor would not be particularly noticeable if it had not been the third one that has occurred in Mexico with a magnitude greater than 7 on the Richter scale on a September 19th. There is, of course, no reason to assume that September 19th is a special date for tremors, so we have to conclude that the occurrence of three large earthquakes on the same day of September was pure coincidence. Without going any further soon, because unfortunately there is still not enough scientific knowledge to explain how earthquakes occur. In relation to the latter, an article appeared on September 5th in the magazine \u201cGeology\u201d describes the results of a project carried out off the coast of Japan by an international group of scientists led by Harold Tobin of the University of Washington. The project was carried out in the area of Nankai failure, off the Japanese coast of the Pacific Ocean. One of these was the earthquake that occurred in 1498 that generated a tsunami that destroyed the building that housed the large Kamakura Buddha of more than thirteen meters high, and that has since been exposed to the weather. More recently, in 1946, an earthquake occurred with a magnitude of more than 8 on the Richter scale that generated a tsunami with waves of five meters high that destroyed tens of thousands of houses and caused thousands of deaths.The objective of the project by Tobin and collaborators was to investigate the state of tension in which the rock below the sea bottom is found in the Nankai fault area, due to the interaction between the Eurasian and Filipino tectonic plates.As we know, the movement of one tectonic plate with respect to the other generates tensions and accumulates energy that eventually is released generating an earthquake. Researchers expected to find evidence of an upcoming earthquake of great magnitude, given that Nankai's failure is known to produce an earthquake of great magnitude approximately every hundred years ago and the last one generated by such failure has already occurred. In order to carry out their study, the researchers drilled the seabed to a depth of three kilometers using the Japanese research vessel \u201cChikyu\u201d, and determined the tension to which the rock was attached from the deformation of the well walls. They failed, however, to reach the Nankai fault that is two kilometers deeper. To their surprise, they found a state of tension almost zero, without an indication of the imminence of an earthquake, for which they have no explanation. One possibility, they speculate, is that the tension is accumulated to a greater depth, near the tectonic fault to which they did not arrive; or that the failure needs to accumulate less energy than expected before generating an earthquake. Another possibility is that the tension will be generated quickly in the future before its release. They trust researchers, however, that studies such as the one they have reported will lead to greater knowledge of the geological processes that give rise to earthquakes and eventually to the ability to predict them well in advance. On the generation of earthquakes, we cannot fail to be surprised at the technical capabilities deployed by the research group that drilled a three-kilometre deep well and managed to determine the state of tension of the rock down there, measuring the deformations of the well walls. And in that state of mind, we cannot fail to trust that in the near future the experts will reach a level of knowledge such as to allow them to predict earthquakes well in advance so that we can all get a good hold of ourselves. And so perhaps we could also understand the incredible coincidence that three major earthquakes occurred in Mexico on the same day of September.",
    "https://upload.wikimedia.org/wikipedia/commons/5/55/Hieronymus_Bosch_053_detail.jpg": "A comment published in October of last year in the Pan African Medical Journal, signed by Sylvain Diop, brought a story that was certainly fascinating. This story was told in the magazine \u201cEdinburg Medical Journal\u201d in 1884 by Robert Felkin, and took place in 1879 west of present-day Uganda. Felkin, who was at that time a medical student, was in the Bunyoro kingdom, where he witnessed a cesarean operation performed on a young Bunyoro. Felkin told: \u201cThe patient was a healthy and well-looking young woman, about twenty years old. It was her first pregnancy.... She had been supplied with abundant banana wine and was in a state of semi-toxification...The operator stood up as soon as I entered the cabin, holding her knife high with his right hand and murmuring a spell. After this, she washed her hands and washed the patient\u2019s abdomen with banana alcohol and then with water.\u201d In fact, it was until the middle of the 19th century that it was shown that, by means of the simple procedure of washing the hands before operating, the surgeon diminished the patient's ability to remove the baby quickly, cauterizing the bleeding points with a white red metal and closing the wound with iron needles.\u201d All this was done with such skill that an hour after the operation the patient looked without apparent discomfort. The operation also proved to be a success, with the baby's survival and the mother's wounds completely closed in eleven days. According to Felkin's description, Bunyoro's surgeons had a sophisticated knowledge that led them to overcome the problems presented by surgeries: pain, bleeding, and infections. Thus, Bunyoro surgeons drunk the patient to mitigate pain, cauterized the wounds with a hot metal, and combated the infections by means of alcohol.All of the above is surprising if we take into account that surgery at the time in Europe had little time to make use of anesthetics and aseptic practices. Before this, surgeons would certainly wash their hands after the operation, but not necessarily before it. Although the knowledge of surgeons of the Bunyoro kingdom, developed in isolation, is certainly surprising, possibly more surprising are the conclusions reached by an article published on September 7 in the journal \u201cNature\u201d by a group of researchers led by Tim Ryan Maloney of Griffith University in Australia. In that article, evidence of surgical amputation of a foot 31,000 years ago is reported, much earlier than would have been believed possible. Maloney and collaborators base their conclusions on the discovery, made in a cave in Borneo, of the bone remains of a child whose left foot was amputated. Such amputation was not due to an accident but to a carefully performed operation, as demonstrated by the clean and oblique cutting of the leg bones to separate the foot. The amputated child would have survived from six to nine years after amputation. The discovery of Maloney and collaborators, the oldest surgical amputation that was reported would have occurred 7,000 years ago. Now we know that, 31,000 years ago, there was already enough knowledge about anatomy, physiology and surgical practices that allowed the amputation, repair and disinfection of a child\u2019s foot, with such a success that he managed to survive the operation for several years before being buried. In light of this discovery, the case of Bunyoro surgeons is undoubtedly more understandable. At the same time it makes us wonder why the surgery in Europe progressed at a relatively slow start. Although it has now reached an impressive level.",
    "https://upload.wikimedia.org/wikipedia/commons/0/05/PIA24201-MarsPerseveranceRover-MoxieTwin-2021019.jpg": "As Bernal D\u00edaz del Castillo recounts in his \u201cTrue History of the Conquest of New Spain\u201d, during the march of the Spanish conquerors towards Tenochtitl\u00e1n, Diego de Ord\u00e1s would have obtained Cortes\u2019 permission to climb the Popocat\u00e9petl volcano, apparently only to find out what was up there. Diego de Ord\u00e1s set himself on the way to the top of the mountain accompanied by two soldiers and, according to D\u00edaz del Castillo, \u201c...when he went up the volcano he began to throw large flames of fire and medium-burned and light stones and a lot of ash, and he trembled all that mountain and mountain where the volcano is, and that they were left without giving way until then at an hour, they felt that he had passed that flame and did not cast so much ash and smoke, and that they went up to the mouth, which was very round and wide, and that there would be in the width a quarter of league.\u201d In these circumstances, Cort\u00e9s would have sent an expedition to the top of the Popocat\u00e9petl to collect sulfur, which he knew existed in the volcano. The expedition would have been successful since, already after the fall of Tenochtitlan, Cort\u00e9s commissioned a second expedition to the same volcano to bring more sulfur, according to Francisco Cervantes de Salazar in his \u201cCr\u00f3nica de la Nueva Espa\u00f1a\u201d. The expeditions of Cort\u00e9s to the Popocat\u00e9petl to obtain sulfur constitute a terrestrial example of what, in the context of space exploration, is known as \u201cUtilization of resources in situ\u201d, in reference to the use of extraterrestrial materials that would otherwise have to be transported from Earth. The possibility of collecting and processing extraterrestrial materials instead of transporting them from our planet to another planet or satellite is an essential point for space exploration, given the high costs of fuel needed to bring materials to space overcoming the gravity of our planet. In this sense, on 31 August an article appeared in the magazine \u201cS\u201d Cience Advances\u201d describing the results of the \u201cMOXIE\u201d project that seeks to establish the possibility of producing oxygen on Mars using the carbon dioxide of the Martian atmosphere. According to that article, MOXIE is part of the explorer \u201cPerseverance\u201d of NASA that is on the surface of Mars since February 2021 and that has managed to produce oxygen on seven occasions, from February 2021 to the end of that year, under varied atmospheric conditions. Each time MOXIE managed to produce six grams of oxygen every hour, equivalent to that produced by a tree on Earth. This amount is modest, but demonstrates the feasibility of generating oxygen on Mars using Martian materials and opens the possibility of making fuel for rockets, necessary to take off from the Martian surface back to Earth. A second article, published last July in the journal \u201cInternational Journal of Applied Ceramic Technology\u201d by a group of researchers from Washington State University, reports the development of materials from titanium alloys blends with Martian materials. Since we do not have any Martian materials to experiment, the researchers employed land substitutes that resemble them.In their study, researchers find that adding to titanium alloys five percent of Martian materials obtain materials with greater hardness, which points, for example, to the possibility of making parts of rockets using local materials on Mars.We can conclude that, just as Hern\u00e1n Cort\u00e9s helped himself with American sulfur to defeat the Mexica, the world will witness in the near future space expeditions that would be aided by extraterrestrial materials. No fatal consequences - hopefully - equivalent to those suffered by Native Americans. And without the dangers - let us also hope - of looking at an active volcano.",
    "https://upload.wikimedia.org/wikipedia/commons/f/f8/BFR_at_stage_separation_2-2018.jpg": "The \u201cSaturn V\u201d rocket that took Neil Armstrong and Buzz Aldrin to the surface of the Moon had a weight of close to 3,000 tons. We know that the rocket did not reach the Moon completely. In fact, only the modules, lunar, service and command modules - on which the astronauts were travelling - arrived, which added a minimal part of the total mass of the rocket. This is what is expected in a space mission, since, in order to drive a satellite or a spaceship to an Earth orbit and beyond, it is necessary to use enormous quantities of fuel to overcome the Earth\u2019s gravitational force. Such fuel is stored at each stage of the rocket body, which must be released and discarded once its fuel is exhausted. Thus, in the case of the \u201cApollo XI\u201d mission, the initial weight of 3,000 tons was reduced to less than 50 tons once the mission entered a lunar orbit. The cost of putting a satellite into orbit then reflects both the fuel used for the ascent and the investment in the rockets of waste. For example, according to an article published last August in the magazine \u201cScience\u201d, the cost of placing in Earth orbit a mass of one kilogram by means of the NASA space shuttle was $65,000, while the corresponding costs of the \u201cSaturn V\u201d and the new NASA rocket are $5,400 and $58,000, respectively. Unlike the space exploration of the early times that was driven with public money, there is currently considerable space activity by private companies, including \u201cSpace X\u201d by Elon Musk. This company has sought to reduce the costs of putting satellites into orbit. For this purpose, it has developed the technology necessary to recover and reuse the rockets used for this purpose. In this sense, it is possible to find on the Internet spectacular footage in which we see a rocket landing gently in a vertical position, on land or on a marine platform, supported by its engines. By means of the giant rocket \u201cStarship\u201d - 120 meters high - and using rocket recovery technology, \u201cSce X \u201cit expects to reduce the cost of placing a satellite in orbit to $10 per kilogram, which, according to experts, would radically change the space industry. In particular, it would substantially increase the number of satellites in orbit and with this and all the applications that derive from them, including a more detailed observation of the Earth\u2019s surface. In fact, in order to achieve such a drastic reduction in the cost of placing a cargo in orbit, a substantial increase in the number of launches into space would be necessary. Thus, according to Elon Musk, a single \u201cStarship\u201d rocket could make three weekly trips to space and thus put into orbit 15,000 tons, which would be almost equivalent to all the cargo that has been put into orbit throughout space history. Not all the experts, however, agree that such a drastic reduction in costs is possible to place satellites in orbit. In this sense, it has been noted that, despite the fact that \u201cSpace X\u201d has the technology to recover rockets, this has not impacted the bulk of what the company charges to its customers, which is $2,600 per kilogram using its rocket technology. \u201cFalcon 9\u201d rocket. It is not clear, however, if this reflects a commercial strategy of the company to maintain the cost of its services, which are the lowest in the market. Moreover, regardless of the factor by which \u201cSpace X\u201d manages to reduce its rates, the entry of private companies into the space industry has placed it in a new dynamic that will soon make us perceive the spectacular achievements of the decade of the sixties of the last century \u2013 which led us to the Moon \u2013 as something distant and, now, of the last century.",
    "https://upload.wikimedia.org/wikipedia/commons/b/bc/Frankenstein.1831.inside-cover.jpg": "During the summer of 1816, writer Mary Shelly and her husband coincided with the British poet Lord Byron and her personal doctor John Polidori, in a village near Lake Geneva in Switzerland. Due to the bad weather prevailing -1816 was a particularly cold year, even known as the \u201cYear without Summer\u201d - the occupants of the village were forced to stay for three days without being able to go for a walk. To kill the boredom, according to the anecdote, Lord Byron challenged the Shelly and Polidori, to write a story of terror. It was a good idea for Lord Bayron, since the only one who finished the story was Polidori, Mary Shelly conceived during her imprisonment the novel \u201cFrankenstein or the modern Prometheus\u201d that would make her famous. As we know, in her novel Shelly recounts the story of Victor Frankenstein, a medical student at the University of Ingolstadt, who became interested in the chemistry and physiology of the human body and who became obsessed in discovering the secret of life. For this purpose, Frankenstein Shelly did not provide details of the manufacture of this \u201cgendro\u201d. In particular, we do not know whether Shelly used electricity to give life to it as shown in Boris Karloff\u2019s 1931 film, but we felt that this was something highly novel at the time. In one way or another, aside from the resources Shelly would have imagined to create his \u201cgendro\u201d, the reanimation of dead matter was far from the possibilities of technology 200 years ago. Indeed, it is still so now, although it seems that specialists have taken important steps in that direction, as an article published at the beginning of August in the magazine \u201cNature\u201d by a group of researchers led by David Andrijevich of the Yale School of Medicine in the United States shows. Indeed, the article reports on the results of experiments during which a cardiac arrest was induced by a group of pigs, to later seek to revive them. As explained by Andrijevich and collaborators: \u201cAfter the flow of blood or equivalent ischemic exposures ceases, a harmful cascade of molecular processes begins in mammalian cells that eventually lead to their death.\u201d However, in the present case and against natural deterioration, after an hour of cessation of heart beats, researchers were able to reactivate in six hours the functioning of some of the animal organs, such as the brain and heart, which even showed some electrical and contractional activity. To achieve this, they used the \u201cOrganEx\u201d technology patented by Yale\u2019s group, whereby pigs were given a cocktail consisting of their own blood and 13 other substances, including anticoagulants and suppressors of the immune system. Andrijevich\u2019s results and collaborators do not imply that the pigs returned to life after being killed for an hour. In fact, it was not possible to detect a brain activity indicating that the animals had regained consciousness. However, such results could point to another type of consequences. For example, an increase could be anticipated. At the same time, on the other hand, if it turns out that the deterioration of organic tissues can be reversed even after death as we now understand it, the distinction between life and death becomes diffuse, which also introduces another type of considerations. Thus, for example, it would have to be redefined which means an irreversible state of brain death and the criteria for declaring a person dead and if, in any case, it is a candidate to donate its organs. In conclusion, two centuries after Mary Shelly on a cold summer day conceived a \u201cgendro\u201d of more than two meters high - which was later baptized with the name of its creator - we still do not have the technology necessary to make it a reality and is nothing more than a character of films and fiction. Thus, \u201cFrankenstein or the modern Prometheus\u201d would soon remain the first science fiction novel, as it is sometimes qualified. How long would it still be? The date is uncertain but possibly not too far away.",
    "https://upload.wikimedia.org/wikipedia/commons/3/3e/Aedes_aegypti_feeding.jpg": "Suppose you are trying to fall asleep, when suddenly a mosquito starts to buzz around your ear with intentions of feeding yourself at your expense. In those difficult moments - unless you are a fan of the wonders of the animal kingdom - you may not have the ability to reflect and thank nature that has manufactured a mosquito sucks blood with so many abilities, including the ability to anticipate a swig and fly quickly to get safe, as well as the ability to detect from the distance to a confined prey in your room.At less uncomfortable moments, we would expect, perhaps we could be in a better mood to admire the skills of mosquitoes. Particularly their acute sense of smell that is the one that guides them to our room, attracted by the carbon dioxide that we exhale when breathing and by the odors that we fire by the skin. On the negative side, mosquitoes, in addition to annoying, are transmitters of a number of diseases, including Dengue, Zika and Chikungunya, and in this sense it is important to understand in detail their olf mechanisms. Our sense of smell is based on neurons with olfactory receptors placed in the mucosa of the nasal cavity. Each neuron responds to the presence of an odor molecule and transmits the information to a reception center located in the olfactory bulb by means of an extension that passes through the bone, through small perforations, located in the upper part of the nasal cavity. One relevant aspect is that each receptor responds to a particular type of odor, so that if the receptors of one type were disabled, the sensitivity to the corresponding odor would be lost. Could a strategy of defense against mosquitoes be developed by focusing our batteries against their receptors sensitive to human body odors? Unfortunately, such that there would be certain difficulties. At least according to an article appeared this week in the magazine \u201cCell\u201d, published by an international group of researchers headed by Margaret Herre of Rockefeller University in New York. According to the results, there would be some difficulties. The mosquitoes are still able to find their way to their food source. To the surprise of the researchers, the mosquito olfactory system is more malleable than expected, and this would be related to the difficulty we encounter in getting rid of mosquitoes. That is, they would have several ways to get to Rome, so that, if one or more fail, they will always have other practicable ones. So, despite their size, it would seem that mosquitoes are more sophisticated rivals than we would have thought in the first instance, that they have developed a strategy of redundant receivers that assures them to find the way to their food. At the same time, however, we would not expect that in the long run, they would leave the researchers' attacks, which have already been able to find some of them. This is not encouraging for mosquitoes, as it will facilitate the development of sophisticated techniques to combat them. As soon as these techniques make their appearance, it is better for us to use more traditional procedures against mosquitoes. For example, to close doors and windows when we anticipate that they can invade us. It is a pity to spend the night at night at night.",
    "https://upload.wikimedia.org/wikipedia/commons/1/1a/Janus_particles_that_follow_a_predefined_path.jpg": "Except in certain cases, for example, when we apply an ointment to cure some burns or apply drops to irritated eyes, to name a few, the medicines or drugs that we use to cure diseases do not apply directly to the affected place, but are introduced to the body by some means, with the intention that they will spread and eventually reach their destination. Seen in this way, the procedure seems inefficient and with the disadvantage that not only the sick part is exposed to the action of the drug, but also other healthy parts of the body, with potential side effects.To address this problem, researchers are developing tiny robots that can be introduced into the body loaded with microscopic quantities of highly concentrated drugs. Once inside, robots would advance to the sick area where they would deposit their drug load.The disease could then be attacked locally and more efficiently, minimizing the affectation to other parts of the body.The above certainly seems to be science fiction and in some way it is.Never, numerous research groups around the world are advancing in construction. In this sense and by way of example, in the issue of June 15 of the scientific journal \u201cScientific American\u201d is described a micro robot the size of a hycharus, which constitutes a robot advance to administer drugs inside the body. This robot was created by researchers from Stanford University in California. It is inspired by paper origami art and can be deformed just like the origami figures do. The robot can be guided along its way by a magnetic field and for this it is added a tiny magnet at one of its ends. The interaction of this magnet with the magnetic field provides the robot with the necessary force to move. A second magnet placed at the opposite end of the robot, allows it to compress or extend as an accordion. Thus, by means of an expansion the robot would be loaded with the medication, which, after being transported to the place of application, would be released by means of a compression. Experts, however, in addition to trying to build tiny robots capable of moving inside the body guided by For this purpose, the robot has to be endowed with a certain degree of intelligence that would allow it to choose the best way to reach the pre-established goal. It must also avoid unexpected obstacles in a changing environment. In this direction, an article published online last June in the magazine \u201cCommunications Physics\u201d reports the development of an intelligent micro robot model with the ability to move autonomously within the body through body fluids. The article was published by a group of researchers headed by Zonghao Zou, of the University of Santa Clara in California. It should be noted that Zou and collaborators did not physically build a micro robot, but the artificial intelligence algorithms that provided it with the ability to learn, on their own, to move to a certain point, in a real fluid and following the laws of physics. For this, researchers idealized the micro robot as three spheres of the same radio, an artificial intelligence algorithm that provided it with the ability to learn, on its own, to move to a certain point, in a real fluid and following the laws of physics. The robot could deform, change or rotate the length of the bars that united the spheres, and with this move forward, stop or rotate. It could also assess the situation in which it was in and, if necessary, change course to reach the goal, even in changing situations involving unprogrammed obstacles. The robot, moreover, adapted to the environment and its unexpected obstacles without external help; that is, it learned to swim by itself. While micro robots medicine dispensers are certainly not around the corner, the intense activity that is taking place around the world to develop them tells us that they are not too far either. And they could be not only \u201cfoolish\u201d robots that have to be held hand in hand to do their task, but intelligent robots that fix them without external help.",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/NesjavellirPowerPlant_edit2.jpg/800px-NesjavellirPowerPlant_edit2.jpg": "What did King Henry VIII of England have to do with climate change?Since the reign of Henry VIII - known to no small extent for decapitating two of his six wives - and climate change are separated in time for almost five hundred years, it is difficult to find a direct connection between the two events.However, there is a certain connection as discussed below.As we know, following his divorce from Catherine of Aragon to marry Ana Bolena, Henry VIII broke with the Catholic Church and this breakup led him to confiscate the property of the monasteries. This released lands with coal deposits that could thus be exploited more efficiently. As a result, the availability of coal, coupled with the scarcity of wood as fuel, led to the gradual replacement of wood by the former. Two centuries later, as we also know, an industrial revolution developed in England that was based on coal as a source of energy. Thus, in a delayed manner, Henry VIII contributed to the boom of coal burning, which you have even risen today, and which has contributed substantially to atmospheric pollution and climate change.Hab The wind, which has been used in the past and above all in the present as a source of energy, is also, ultimately, the product of solar activity, through photosynthesis, but also fossil fuels, a product of plants buried hundreds of millions of years ago. The wind, which has been used in the past and above all in the present as a source of energy, is also, in the final analysis, the result of solar activity. It is also the gravitational energy contained in a dam that is used to generate electricity in a hydroelectric plant and the energy that produces a solar panel. This is the case of nuclear energy, which is obtained by the controlled disintegration of certain chemical elements. It is also the case of geothermal energy that takes advantage of the heat inside the Earth to generate electrical energy or energy in the form of heat. In this sense, it should be remembered that the temperature of the subsoil increases with depth. A geothermal electricity plant can take advantage of high temperature fluids that naturally emerge from the depths of the Earth. In the absence of this, engineers and scientists are developing techniques to inject water into the subsoil through a well until it reaches a level of hot rock, and then extract it as high temperature water from a second well. If the temperature of the water extracted is high enough - greater than 100 degrees centigrade-, the steam generated can be used to move a turbine and an electricity generator. All this, of course, assuming that the water injected by the first well is channeled by the second well to the surface, which is not guaranteed because it could leak from undetected cracks. In an article published this July in the news section of the magazine \u201cS. A $218 million project funded by the U.S. Department of Energy, which aims to develop techniques to inject water into the subsoil and extract it with a high enough temperature to generate electricity, is described by Warren Cornwall. The project is taking place in the Utah Desert, and if it is successful, it will take a big step towards the development of a renewable source of energy, practically inexhaustible, non-polluting, and of great magnitude. In this regard, researchers estimate that under the subsoil of the United States there is enough hot rock to generate five times the electricity consumed by this country. In addition, unlike solar and wind energy, the geothermal source would be independent of the Sun, of the characteristic intermittances of these energies, and without the potential contamination of a nuclear plant. All this said, it would be indulgent with Henry VIII for his contribution to contaminating the planet, which had, after all, a positive aspect, and which we trust is in the way of mitigation.",
    "https://upload.wikimedia.org/wikipedia/commons/a/a6/The_Rim_Fire_in_the_Stanislaus_National_Forest_near_in_California_began_on_Aug._17%2C_2013-0004.jpg": "In January 2019, in the middle of the polar vortex that hit the U.S. Midwest, then President Trump recommended that citizens be careful and try to stay where possible inside their homes. According to Trump, \u201cA large part of the country is suffering with a tremendous amount of snow and an almost record cold. It\u2019s amazing how big this system is.\u201d To these claims, hardly rebatable, the former president added: \u201cIt would not be wrong to have a little of that good global warming out of fashion.\u201d With regard to the latter, it should be mentioned that, while those who suffer the rigors of winter 2019 surely would not have dropped anything bad a bit of heat, the truth is that, unfortunately, global warming is not out of fashion, and in fact, it is very present and there is no need to invoke its presence. For example, according to experts, it is present in the current heat wave that is affecting Europe and other parts of the world, which was very likely triggered by climate change. And the same can be said of the heat wave that the world suffered last summer, and We doubt for a moment the specialists - as Trump does - and affirm that climate change is not real and that experts lie for some reason. We could do so, but remember that we tend to trust experts even against our own perceptions. We accept, for example, that the Earth is round, despite the evidence obtained from our eyes that would lead us to conclude that it is flat. We trust, however, the experts who have come to the conclusion that it is round from distant times. More than two thousand years ago, for example, Eratostenes even managed to determine the radius of the Earth by measuring the length of the shadow that projected a stake of the same length placed in Aswan and Alexandria, in Egypt, the same day of summer solstice. Today, beyond Eratostenes, we have overwhelming evidence that the Earth is round, which we admit. As a truth, even though such evidence usually comes to us only from hearsay and not from direct experience, we should ask ourselves whether the experts have sufficient evidence that climate change is real and, if so, whether such change is associated with our activities.First, we should remember that climate scientists relate global warming to the increase in the concentration of greenhouse gases in the atmosphere, particularly carbon dioxide.This concentration has been monitored continuously since 1958 at the Mauna Loa Observatory in Hawaii.The measurements show a continuous annual increase in the content of carbon dioxide in the atmosphere, which has grown by 33 percent between 1958 and 2021.The experts also find that this increase is linked to the emission of greenhouse gases, mainly by burning fossil fuels.It is known, on the other hand, that the temperature of the Earth's surface depends on a balance between the energy it receives from the Sun and the heat it is radiated by that surface back into space.The carbon dioxide in the atmosphere absorbs this heat and partially returns it back from the surface of the Sun. So, the definitive proof that the burning of fossil fuels is one of the key factors that is driving climate change is the measurements of the temperature of the earth's surface, which, although it has positive or negative variations from year to year, on average has a growing trend. Thus, in the last two centuries this temperature has increased by approximately a degree centigrade.According to the experts, while it is not understood in detail how global warming triggers extreme events, there is no doubt that there is a relationship between the two phenomena, which will be clarified insofar as climate models become more sophisticated.Furthermore, there is sufficient evidence to believe that global warming is real, and while many of these evidences are technical in nature and difficult to understand for non-specialists - as at the time were the experiments of Eratostenes - global warming will surely be universally accepted in the near future. duck, walks like duck and behaves like duck, then possibly a duck.",
    "https://upload.wikimedia.org/wikipedia/commons/b/bf/Webb%27s_First_Deep_Field.jpg": "For many of us who live in the city, going to the countryside on a starry night is an experience due to the enormous number of stars that shine in the sky and that in the city are covered by artificial lights. Certainly, in the city we can clearly observe stars, as well as planets like Mars or Jupiter. The interference of night lights, however, makes it difficult for us to appreciate the sky in all its splendor and complexity. In the past the nights were noticeably darker - the electric light was invented recently, just over a century ago - and we had greater contact with stars and planets. In fact, the sky has been observed with detail for thousands of years and its visible characteristics have been precisely determined. For example, for a long time we have known that stars have a rotational movement around us, while the movement that distinguishes planets is significantly more complicated.However, even in a starry night in complete darkness, the limitations of our eyes as light detectors impose barriers to appreciate the firmament in all its complexity. We know, for example, that when Galileo Galilei pointed out his telescope towards Jupiter, he discovered four small luminous points around him that change their position daily. Galileo correctly interpreted that these were satellites orbiting around Jupiter - now known as Galilean satellites - similar to how planets orbit around the Sun. This supported the position of the Sun as the center around which planets rotated, which considerably simplified our view of the world.All of this comes to light by the publication this week of the first photographs, in full color, of the new NASA James Webb telescope that are spectacular. In this sense, and to be fair, it would have to be remembered that such a telescope was designed to work with infrared radiation and that, with the exception of red, the telescope camera is blind to colors such as green and blue. The photographs presented, therefore, are in false color. That said, it should be reiterated that the images are undoubtedly spectacular, with a resolution that far exceeds that of green and blue. In particular, we can see the superiority of the new telescope over the NASA Hubble telescope - which is its predecessor - in Internet publications where images obtained with one and the other telescope from the same space region are compared. Indeed, it is clear that the images of the James Webb telescope are sharper and show details that are difficult to distinguish in Hubble images. One of the factors determining the superiority of the new telescope over its predecessor is its size. Thus, while the Hubble telescope\u2019s primary mirror has a diameter of 2.4 metres, the corresponding mirror of the James Webb is composed of a set of 18 hexagonal segments that make a diameter of 6.5 metres. Under these conditions, the James Webb telescope intercepts six times more radiation than the Hubble and is thus able to detect objects further away. Additionally, the Hubble telescope is specialized to operate with visible and ultraviolet radiation, while the James Webb was designed to operate primarily with infrared radiation, which can penetrate clouds of cosmic dust that otherwise obscure what is. Thus, the new NASA telescope promises substantial advances in the knowledge of the Universe, including details of its birth more than 13 billion years ago, and the possibilities of some extrasolar planets to harbor life.All this in parallel with a public relations effort by NASA to publicize the achievements of a project that cost the friolera of 10 billion dollars.And with regard to the latter, it should be recognized that the images of the new telescope given to advertising could not have been more fortunate.On the other hand, the images of the new telescope, with everything and its false colors, provide us with visions of the universe, which would have been impossible to conceive looking at the sky with bare eyes without the help of instruments that expand its capabilities.Not to mention the regression that we have had in the last century of electric light, which has made us lose contact with the firmament.",
    "https://upload.wikimedia.org/wikipedia/commons/d/dc/Child_pushing_grandmother_on_plastic_tricycle.jpg": "As is well known, during his five-year journey around the world in the HMS Beagle brigantine, Charles Darwin carried out a series of observations of the fauna and flora of the places visited, which served as the basis for writing and publishing in 1859 the Origin of Species, a controversial and very influential work. The journey began in Plymouth, England, in December 1831, touching several points of South America, penetrating both from the east coast and from the west coast, after crossing through the Strait of Magellan. In particular, in the Galapagos Islands of Ecuador, Darwin observed finches, clearly related to pinches of the American continent, with peaks of different forms that adapted by means of mutations to the specific type of food they consumed. To explain the mechanism of adaptation of a species to the environment in which it inhabits, Darwin devised the theory of natural selection. According to this theory, an organism when its traits were reproduced to its descendants. For this to happen, however, it must survive until reproductive age, which is contingent to the good or poorly adapted. If it has a good adaptation it will be able to reproduce and perpetuate its features; otherwise, those traits will be lost. Thus, with the passing of generations the traits of the best adapted individuals will prevail to the detriment of those with less adaptation. Thus, if the food source for the finches of the Galapagos Islands were hard seeds, natural selection will develop individuals with short and strong peaks, to the detriment of finches with long and thin peaks, more suitable, perhaps, for an insect-based diet. In these conditions, natural selection suppresses mutations dangerous for survival and develops individuals with traits adapted to their environment that allow them to reach reproductive age. In contrast, for natural selection it would not be relevant the fate that such individuals could suffer once they exceed this age. Thus, we could expect that the end of an individual's life would coincide with the end of reproductive age, from which he would be the victim of dangerous mutations for which he did not have defense. to be depressing; that is, from the point of view of the evolution of our species, beyond the reproductive age we would have no more tasks to perform in this world. Thinking twice, however, we note that, in contrast to other species - even with chimpanzees, the closest to us - women\u2019s lives extend well beyond their reproductive age. And since this is not only because of the medical advances that have extended it considerably, one may wonder why we live so long \u201cextra\u201d without an apparent evolutionary advantage. We find a response in an article published this week in the magazine \u201cProceedings of the National Academy of Sciences\u201d of the United States, published by Raziel Davison and Michael Gruven of the University of California in Santa Barbara. In that article, Davison and Gruven consider the intergenerational influence that grandparents have on the reproduction of daughters and therefore on the transfer of their own traits to grandchildren. They considered the research societies of hunters recollectors in which older adults contribute to the generation of resources for the support and care of their grandchildren. In this sense, children are dependent on humans for an unusually long period before they start generating their own resources. Davison and Gruven conclude, on the other hand, that older adults from an age of about 70 years lower their productivity and consume more resources than they generate. Even in this situation, however, older adults can exercise an intergenerational, pedagogical or information transfer evolutionary force, teaching grandchildren skills to achieve greater productivity. According to Davison and Gruven, grandparents and older adults have an influence on the evolution and adaptation of our species to the environment, not direct, as is the case of parents, but indirect through the intergenerational transfer of resources and knowledge. And as such, they carry out a task in the world. Even after reproductive age.",
    "https://upload.wikimedia.org/wikipedia/commons/8/8f/PSM_V10_D029_Ancient_fire_making_methods.jpg": "Suppose that, on board a time machine, a traveler retreats a million years into the past by landing in the middle of a forest with a cold that hits the bones. At a distance he reaches to see an individual of the species \u201cHomo erectus\u201d given to the task of lighting a fire to warm up -and possibly also to prepare the food. The individual in question takes two pieces of wood that quickly rubs against each other, until, with the heat generated, he manages to set fire to a pile of straw and with it to a pyra of firewood. Beyond the impossibility of traveling to the past, how feasible is it that the time traveler could witness a scene, a million years ago, in which a primitive human lights a fire? Anyone who has tried to start a fire without matches or without a lighter will possibly agree that it is not a simple task, even though on the Internet we find video recordings that we want to convince us that, with enough practice and with an expert who teaches us, we could achieve it relatively quickly. The article was published by an international group of researchers headed by Zane Stepka of the Weizmann Institute of Sciences of Israel.The technique of learning to light a fire from scratch, and that in doing so they showed a great imaginative capacity and considerable efforts of trial and error - without demonstrative videos and without anyone to guide them.When was it learned how to handle the fire? According to experts, there is ample evidence of the use of fire for some 200,000 years. Beyond 500,000 years before the present, in contrast, the evidence is scarce.This could mean that the use of fire developed until a few hundred thousand years ago, or that analytical techniques to study such remote times are not sensitive enough.In relation to the latter, an article published this week in the magazine \u201cProceedings of the National Academy of Sciences\u201d of the United States, which reports the development of a technique to determine whether a particular rock was subject to a warming of hundreds of degrees centigrade by exposure to fire. The technique is sensitive even if the material under study does not show visible features of the action of fire that may have faded away by the passage of time. That is, it reveals what is hidden by the naked eye.The researchers applied their technique to materials from the archaeological site Evron Quarry in Israel, which is dated between 800,000 years and a million years before the present.This site includes fossils of different animals and stone objects. Stepka and collaborators applied their technique to 26 stone tools that show no visual signs of having suffered an exposure to fire, finding that they had been exposed to a temperature above 600 degrees Celsius.Further, an analysis of 87 animal remains using infrared light revealed that an elephant tusk also presented evidence of having been subjected to a high temperature. Stepka and collaborators recognized that, on the basis of their discoveries, they cannot categorically conclude that primitive humans made use of it. A million years ago, because exposure to high temperatures could be due to natural causes, since Evron Quarry is an open-air archaeological site. However, the fact that stone tools and animal remains that were subjected to high temperatures have been found in the same site constitutes a non-conclusive indication of the use of fire in very early times, within the time range of the \u201cHomo erectus\u201d. In any case, Stepka and collaborators point out that the technique developed by them could help date with solid evidence the beginning of the use of fire, an event that some consider was key to the appearance of our species. Thus, until further notice, we would have to be cautious before ensuring that, if we went back a million years in time, we could meet a member of the species \u201cHomo erectus\u201d in the act of lighting up a fire. What we could be sure of is the cognitive capacity of primitive humans. Hundreds of thousands and possibly a million years ago.",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/d/d0/Northwest_passage.jpg/800px-Northwest_passage.jpg": "Once the Europeans convinced themselves that America was not Asia and that to get from Europe to Catay, sailing southwards, they had to surround the new continent by the Strait of Magellan, Spanish and English eagerly sought a passage through the north, the famous Northwest Pass, which constituted a shorter route. During the sixteenth and seventeenth centuries it was believed in the existence of the Strait of Anian, a channel in the north of the American continent that would connect to the Atlantic and Pacific oceans. Explorers like Juan de Fuca at the end of the sixteenth century, for example, claimed to have seen it. Today we know that the Strait of Anian reported by Fuca is only a channel that surrounds the island of Vancouver. It was soon made clear, however, that there was no Northwest Pass through the American continent and that this possibly was located north of it, through the arctic ices. Thus, in the nineteenth century expeditions were organized to find it, some of which proved tragic. It is the case of the expedition of 1845 commanded by John Franklin which was trapped in the ice. The Norwegian Roald Amundsen, who in 1906 led the first sailboat that managed to cross from the Atlantic Ocean to the Pacific Ocean through the Canadian Arctic, had better luck. Today, travelling through the Northwest Pass has been simplified thanks to the naval technology available to us, far superior to that of the pioneer explorers of the Arctic Ocean. But not only because of that, but also because of a circumstance that is both unfortunate and fortunate: the climate change that is producing a decrease in the volume of Arctic ice. Thus, the Northwest Pass is increasingly practicable, as is the maritime route through the Russian Arctic that also connects the Atlantic and Pacific Oceans. The decline of Arctic ice is opening new possibilities for maritime navigation. In this sense, it should be noted that the route between Yokohama and Rotterdam through the Northwest Pass is 37 percent shorter than the corresponding route through the Suez Canal, and the same happens with other routes between Asia and Europe. , which would be practicable at some point, would represent even greater distance savings. Thus, a substantial increase in activity in the Arctic Ocean is expected. And in this context, an article appeared this week in the magazine \u201cProceedings of the National Academy of Sciences\u201d of the United States, alerts about the implications that this increase will have. The article was published by a group of researchers led by Amanda Lynch of Brown University, in Providence, Rhode Island. As Lynch and collaborators point out, Arctic routes are not as active as might be expected. This is due, among other factors, to the fact that they are still risky due to the variability of climatic conditions, and to the fact that they have limited satellite coverage and ice forecasting capacity. Additionally, Arctic routes are expensive due to Russia\u2019s regulations for navigation on their Arctic routes. In this connection, Lynch and collaborators note that Russia imposes strong restrictions on maritime navigation along its Arctic coast, which greatly hampers maritime traffic. The United Nations on the Law of the Sea of 1982, according to which the countries with coasts near the marine routes have the ability to regulate the marine traffic of the route, provided that the area remains covered with ice most of the year, which will be increasingly rare. Thus, the decrease of the volume of ice in the Arctic will lead to an increase in the sea traffic, both by the unblocking of routes and by the loss of control of that traffic that Russia will experience as the volume of Arctic ice decreases and the marine routes are removed from their Arctic coast. In these conditions, Lynch and collaborators warn about the legal, environmental and geopolitical implications that will have the disappearance of the Arctic ice, and the need to regulate the increase in activity in the Arctic that will be inevitable in the years to come. And not only by the greater volume of goods transported, but also by an increase in tourism and the exploitation of the mining resources and fossil fuels of the region.So, about 500 years later, the Northwest Pass will be in full activity.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d8/Stradshp.jpg": "The only harp built by Antonio Stradivari dates back to 1681, and is currently part of the museum collection of the San Pietro a Majella Conservatory of Naples. It is a small harp, with a sound box of 75 centimetres in length and a 93 centimetres column bearing the inscription: \u201cAnt: Stradivarius Cremonen. F. 1681\u201d. At its top, the harp is adorned with two sculpted figures of sirens, one of them with a cupid mounted behind its back, and with a mask at the base of the column. Although said harp as a musical instrument is not particularly remarkable, according to an article published last May in the magazine \u201cDendrochronologia\u201d, it provides evidence indicating that Antonio Stradivari learned the technique of stringing instruments in the workshop of Nicolo Amati. The article was published by a group of researchers headed by Bernabei Mauro, of the CNR-IBE National Research Council, in Trento Italy.As we know, Nicolo Amati was a member of a famous group of researchers headed by Bernabei Mauro, of the CNR-IBE National Research Council, Trento Italia. family - third generation- of violin builders in the 16th and 17th centuries established in the city of Cremona, in northern Italy. Amati was about 40 years older than Stradivari, and since the latter was also originally from Cremona, it is natural to conclude that it was his apprentice. There is, however, no reliable documentary evidence in this sense and the only evidence in this regard is the inscription: \u201cAntonius Stradivarius Cremonensis Alumnus Nicolaij Amati, Faciebat Year 1666\u201d, recorded in one of the first violins manufactured by Stradivari. Was Stradivari apprentice from Amati? In order to answer this question, Mauro and collaborators carried out a dendrochronological analysis of the reference harp. In reference to this type of analysis, it should be remembered that the cross-section of a tree can show concentric rings, with light and dark alternate colors, and that in these rings is written the history of tree growth. That is to say, the variation of colour and thickness of the rings reflects the climatic changes to the In this way, the age of the tree can be estimated by counting the number of rings of its trunk. To carry out their analysis, Mauro and collaborators photographed the harp sound board, made of fir wood, with a high resolution chamber and determined its ring pattern over 150 years. A first conclusion they arrived at was that, except for a small area in a lower corner, the plate was made from a single piece of wood.A search was made in a dendrochronological database of string instruments, Mauro and collaborators found that the Stradivari harp ring pattern, made in 1681, coincides with the corresponding pattern of a violonchelo made by Nicolo Amati two years earlier. The conclusion is that both instruments were made from the same piece of wood.From this result two possibilities are presented. One of them is that, both the harp and the cello would have been manufactured in Ama's workshop. In this sense, given that both Amati and Stradivari lived in the same city, it is not crazy to think that they bought their materials from the same wooden merchant. Thus, with their research Mauro and collaborators contribute data that support the idea that Stradivari was apprentice to Amati. The results, however, are not conclusive and additional work is required to corroborate it. How important is it to know the details of Stradivari\u2019s training in the art of making violins? As we know, Antonio Stradivari is the most famous violin builder that has existed and some of his instruments can today reach prices of many millions of dollars. We also know that Stradivarius violins keep manufacturing secrets that have not been deciphered. In these circumstances, it is the case that it would have been possible to do so. important -and interesting- to find out how Antonio Stradivari reached such a level of perfection in his art. After all, the Antonio Stradivari do not occur in pot.",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/a/ab/Oil_platform_P-51_%28Brazil%29.jpg/800px-Oil_platform_P-51_%28Brazil%29.jpg": "The development of mobile phones, which include taking photographs and recording audio videos, have made public - through the Internet - events that were assumed to be private, or that had occurred on the public road, but in the presence of a small number of witnesses. Mobile phones, combined with other image and sound recording devices, are thus a kind of eye and ear with the ability to make known everything they hear and see millions of people. This article is quoted by an article published this week in the magazine \u201cEnviromental Science and Technology Letters\u201d, which reports the detection of a giant methane leak on the oil platform Zaap-C of Pemex parked on the Campeche probe. This article was published by a group of researchers headed by Itziar Irakulis-Loitxate of the Polytechnic University of Valencia, Spain. But let's go in parts. It would first be remembered that, after carbon dioxide, methane is the most important greenhouse gas. Indeed, it has a time of residence in Valencia, Spain. It is estimated that methane is a greenhouse gas 25 times more powerful than carbon dioxide in a period of 20 years. It is also estimated that methane is responsible for 20 percent of the global warming that the planet is suffering. On the other hand, it should also be remembered that in the oil fields there is the practice of burning the natural gas -mostly methane - that is released during the extraction of oil. This practice is highly criticized for leading to a loss of energy resources, in addition to generating carbon dioxide that is emitted into the atmosphere. It is nevertheless maintained for economic reasons. Moreover, it is estimated that the oil and gas industry is responsible for about 30 percent of the methane emissions into the atmosphere and in this sense the specialists are concerned about the so-called ultra-emission events, during which large amounts of this gas are released. These events occur sporadically, by accident or intentionally for reasons of maintenance of the facilities. In this scenario, experts consider that monitoring of the oil fields is indispensable. One of them uses satellite photographs. How can a satellite image indicate the presence of methane emissions? To understand this, it would first be necessary to consider that the images to be used are not taken using visible light, but with infrared \u201clight\u201d, which is invisible to us. It would also be necessary to take into account that methane absorbs mostly infrared light with certain \u201ccolours that are its own distinctive footprint. Taking all this into account, by means of photographs taken using infrared light with the \u201ccolors\u201d for which methane is absorbent, it is possible to deduce the presence of a methane column for its silhouette printed in the photograph. Irakulis-Loitxate and collaborators used infrared photographs taken by two satellites using infrared sunlight reflected by the surface of the sea, from which they were able to detect that there were three ultra giant methane emissions on the Zaap-C platform on 8, 18 and 24 December 2021. In December, the burning of natural gas associated with oil, which is a common practice on that platform, was suspended most of the time. They found a temporary coincidence between the suspension of gas burning and the occurrence of ultra-methane emissions, which leads them to conclude that both events are related and that \u201c...this ultra-emission event \u2013which is probably related to abnormal conditions of the process on the site, for example, malfunctions or problems with the equipment, and which has resulted in a substantial amount of gas ventilated through the column \u2013 is a unique incident and with the longest duration since the activity of gas burning began on this platform.\u201d On our part, we may conclude that the existence of cameras has not only stolen privacy - in a broad sense of the term - but is also capable of giving wide diffusion to events that would otherwise have been less known. Of course, photographic cameras that have our mobile phones are considerably simpler than satellite infrared cameras. However, they play a similar role in terms of loss of privacy. .",
    "https://upload.wikimedia.org/wikipedia/commons/3/3b/American-cockroach.jpg": "Gregorio Samsa, the protagonist of Franz Kafka\u2019s novel \u201cThe Metamorphosis\u201d, woke up one morning after an uneasy dream, \u201cturned into a monstrous insect.\u201d Kafka does not specify what kind of insect, but he speculates that it might have been a beetle, or a cockroach as a second possibility. Although, thinking about it, it could have been neither of the two insects if we were to stick to the laws of physics that would make the existence of an insect of one metre high highly unlikely, capable of spinning with the jaws the doorknip of a door as described by Kafka, who also enjoys walking through walls and ceilings. The laws of physics, of course, pass to the second plane in Kafka\u2019s impressive novel in which the protagonist undergoes a transformation that causes repulsion. In this sense, Gregorio transforms into something like a beetle or a cockroach, and not, for example, into a rabbit or a dog, animals that are less likely to turn out. We may agree that cockroaches are particularly repulsive and not, for example, in a rabbits. This is why we are trying to put an end to them. As much as this is particularly difficult, because they and their predecessors have been present on the planet for 350 million years. This is an introduction to the issue we would like to address today: the unusual and rapid evolution that home-made cockroaches are having because of the use of insecticides used to combat them. This evolution is reported in an article published last May in the magazine \u201cCommunications Biology\u201d by a group of researchers headed by Ayako Wasa-Katsumata of the State University of North Carolina in Raleigh. According to Wasa-Katsumata and collaborators, the substances used to control cockroache pests contain insecticides mixed with glucose, which has developed cockroaches with an aversion to glucose as a means of defense. They also note that recently it has been observed that male cockroaches are less successful when trying to mate with females with glucose aversion than with females without this aversion. For this purpose, they carried out a series of experiments on the mating of cockroaches, both with aversion to glucose and without it. It should be noted that, during the courtship prior to mating, the male offers the female secretions rich in different sugars and keeps them busy enjoying the delicacy, which gives him time to overcome their resistance and carry out mating. Researchers, however, found that, in contrast to the females without aversion to glucose, the females with such aversion did not find pleasant the consumption of the sugars contained in the male secretions, since their saliva decomposed them by producing glucose. In these conditions, the female tended to react negatively and separate herself from the male without giving her time to complete mating. The mating strategies of the male cockroaches, developed for females without aversion to glucose, are then less efficient with females who have developed such aversion. In addition, the researchers found that the male cockroaches that have developed aversion to glucose produce nuptial secretions with sugars that are more difficult to produce glucose when mixing with the saliva of females, compared to those males who have not developed such aversion. Thus, they have more success in their matings with females equally with aversion to glucose. According to Wasa-Katsumata and collaborators, their results show \u201c...as an adaptive taste feature can emerge quickly under a \u201cnatural selection\u201d imposed by humans, and that this emerging trait creates mismatches in sexual communication.\u201d We can conclude that fighting cockroaches, which have inhabited the planet for hundreds of millions of years, is certainly a difficult task, and that their adaptability is illustrated by the results of Wasa-Katsumata and collaborators. On the other hand. if cockroaches are repulsive to us, it is not entirely clear the reason for it to be so, as they are relatively harmless compared to other insects. And thus, the fact that Gregorio Samsa has become an insect monster, which may well have been a giant cockroache, is not quite clear. Maybe a point less than unfair to the species.",
    "https://upload.wikimedia.org/wikipedia/commons/b/bc/Pompeii_Garden_of_the_Fugitives_02.jpg": "Last Thursday, a group of researchers led by Gabriele Scorrano of the University of Rome, published an article in the journal Scientific Reports in which the genomic sequence of a victim of the eruption of the volcano Vesuvius is reported for the first time. As we know, in the year 79 A.D. the Vesuvius erupted burying the cities of Pompeii and Herculaneum, located on the shores of the Gulf of Naples, and killing about two thousand of its inhabitants. Since the eighteenth century, when the excavations of Pompeii and Herculanus began, both cities have been fascinating, as they were suddenly buried by meters of ashes and volcanic rocks, frozen in time, providing a first-hand stamp of life in that part of the world in almost two thousand years ago. A written testimony of what happened that day gives Plinio the Younger, nephew and adoptive son of Plinio the Old. At the time of the eruption of Vesuvius, Plinio the Old Man commanded the Roman fleet in Miseno, a town located at one end of the Gulf. Or from Naples. Pliny the Young, who was also in Miseno, writes in reference to his uncle, a sage with encyclopedic knowledge on a large number of subjects: \u201cOn 24 August, at about one o\u2019clock in the afternoon, my mother asked him to observe a cloud that appeared of a very unusual size and form (which was later discovered came from Vesuvius).... This phenomenon seemed to a man of such knowledge and research as my uncle, extraordinary and worthy of deepening. He had prepared a light boat and gave me permission, if he wanted to, to accompany him. I said that he preferred to continue with my work.\u201d It turned out that Pliny the Younger\u2019s decision would have been more than his uncle\u2019s, for he, in his eagerness to deepen his knowledge of the cloud, ended up dead, poisoned by it. According to Pliny the Younger, his uncle: \u201cInstantaneously fell dead; suffocated, according to conjectured, by some thick and noxious steam, having always had a weak throat, which was often inflached.\u201d Young man, we know that a good part of the inhabitants of Pompeii and Herculano died suffocated or burned by the flow of volcanic gases and materials that advanced at great speed and with temperatures of hundreds of degrees Celsius, sweeping the cities suddenly. Given the exposure of the bodies to high temperatures, that the same happened in the open air that inside the buildings, the scientists doubted that useful genetic material could be recovered from the body remains. Scorrano and collaborators, however, demonstrated that it is possible to recover genetic material that provides valuable information. The research was based on two skeletons found in what would have been the dining room of the so-called \u201cCasa del Artesano\u201d in Pompeii. One of the skeletons was found lying on the remains of a triclinium, a species of divan that the Romans used in the dining room -they had the habit of eating lying-, with the arm and left leg resting on the floor, and the right arm and leg on the divan. The position in which they were found indicates that they were both surprised by the flow of volcanic gases and that they did not attempt to flee. The researchers determined that the skeleton found on the triclinium belonged to a male person, aged between 35 and 40 years, while that found on the ground corresponds to a woman aged over 50 years. Although the remains of the woman did not provide sufficient information for a complete genetic analysis, it was possible to determine that the man had a genetic profile consistent with the population of central Italy in Roman times, and that his ancestors probably arrived from Asia minor during the Neolithic age. Further, an analysis of the male skeleton showed evidence that he suffered from spinal tuberculosis, which is supported by the fact that the researchers found DNA from the tuberculosis pathogen in that skeleton. Scorrano and collaborators concluded that, while the high temperatures to which the bodies found in Pompeii were subjected could have destroyed their genetic material, at the same time, the fact that they had been buried in my ashes. The deterioration of this material by contact with the oxygen of the air. Thus, there is hope that Pompeii will provide us with an ever more accurate photograph of a city two millennia ago and of the catastrophe that ended it. Beyond the limited information that gives us the only account that we have.",
    "https://upload.wikimedia.org/wikipedia/commons/5/5b/Redox_Flow_Battery.jpg": "To the extent that we become increasingly dependent on solar and wind energy to combat the climate crisis, its intermittent nature becomes more noticeable. And with this, the need to develop methods to store it in large quantities for hours without sun or wind. There are different possibilities to store energy. We can, for example, use the energy of the sun to raise a volume of water to a certain height and store energy using the gravitational force. During the night we can use the stored energy to power a turbine and with this an electricity generator, as it is done in a hydroelectric plant. We can also store energy in compressed air, that is, in air that has been subjected to pressure by means of a compressor powered by solar or wind energy. We can also do so in flyers set to rotate at high speeds. Or by non-mechanical methods, in a fluid heated to a high temperature by means of solar radiation, for example.Certainably, there are many methods and devices that can be used to store energy. It should be noted that lithium batteries are also used for mass energy storage. It is the case of the Moss Landing lithium battery bank in San Francisco, California, the largest in the world, which is sufficient to provide power to 50,000-10,000 homes for four hours. On the other hand, according to specialists, although lithium batteries are the best choice for relatively small installations, for massive energy storage there are better possibilities. Specifically, flow batteries would be more suitable for this application. To understand the difference between lithium batteries and flow batteries, it should be remembered that the former generate electricity from a chemical reaction occurring in an electrochemical cell, and that all the elements and chemicals needed for their operation are housed in a single sealed container. In the flow batteries, in contrast, while also dependent on chemical reactions occurring in an electrolyte cell, the energy is stored in liquids that are housed in external containers, and that circulate into the electroly-lithic cell, in contrast, while also depending on chemical reactions occurring in an electroly-sensitive cell, the energy is stored in liquids that are stored in external containers, and that are moved into a cell. It is clear that with these characteristics a flow cell is not suitable for, for example, a mobile phone, which requires a compact and sealed battery. On the other hand, for applications where large amounts of energy are sought to be stored, the space occupied by storage batteries plays a smaller role. In fact, for these applications the flow batteries have some advantages over those of lithium. In fact, while to increase by a certain factor the power of a lithium battery bank it is necessary to increase the number of batteries by the same factor, in order to have a similar increase of power in a flow battery bank, only the volume of liquids in which energy is stored, without changing the size of the electrolytic cell, need to be increased. Flow batteries would also have an additional advantage over lithium batteries, in the sense that in their construction could be used materials more abundant than lithium and with a low environmental pollution. The North American company ESS, for example, manufactures flow batteries in which it uses iron, salt and water for the liquid that stores the energy. technology can produce batteries with low environmental impact, with non-toxic elements and without danger of explosion, as is the case with lithium batteries. Likewise, the company claims that its batteries have a life time of 25 years and that they can operate beyond the four continuous hours characteristics of lithium batteries. From all of the above, it seems that flow batteries, particularly those that use iron salt and water, will be the solution to store the energy of the Sun and the wind. Of course, it would be necessary to wait to see if this prediction is fulfilled. Soon, batteries that work with iron, salt and water, are certainly a showy option.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d0/LSD_structural_formulae_v.1.png": "Hallucinogenic drugs and the space race, two characteristic elements of the 1960s, are returning for their own sake. As we recall, the space race took place in the context of the conflict known as the Cold War, which took place between the United States and the Soviet Union at the end of World War II. At the beginning, the Soviet Union advanced the United States by becoming the first country to place an artificial satellite in Earth orbit in 1957, as well as in carrying out the first manned orbital flight in 1961. The United States, however, eventually surpassed the Soviet Union by becoming the first country - unique to date - to bring an astronaut to the surface of the Moon in 1969. We recall, on the other hand, that the 1960s saw a boom in the recreational use of hallucinogenic, natural and synthetic drugs, as part of the so-called counter-cultural movement. One of these drugs is the LSD, which was synthesized by the Swiss chemist Albert Hofmann in 1938. Hallucinogenic drugs, for example, are present in The Beatles\u2019 music from their 1966 album Revolver. Likewise, it has been said - although Lennon denied it - that the initial lyrics of the title of the song \u201cLucy in the Sky with Diamons\u201d correspond to the acronym LSD. Timothy Leary is one of the leading figures in the 1960s around LSD consumption. Leary was a professor at Harvard University where he developed his interest in the use of LSD to treat psychiatric problems. Leary, however, was not a conventional scholar and his interests went beyond those merely characteristic of the academy. In this sense, an article appeared on May 6 in the newspaper \u201cThe New York Times\u201d under the signature of Nina Burleigh makes remembrances of Leary and her psychedelic summers, carried out in Zihuatanejo in 1962 and 1963. Leary, created the International Federation of Internal Freedom that organized summer retreats at the Catalina Hotel in Zihuatanejo. In those retreats, groups of about 50 Americans, experienced According to Burleigh, in the information given to the participants, one could read: \u201cThe objective of the transpersonative community is to free the members of their networks so that they can fly, at will, through the infinite space of their consciousness or through the infinite time/space of the energy fields that surround them.\u201d It is not surprising that in these circumstances Harvard had dispensed with the services of Leary, who, to make matters worse, did not attend to impart his courses. Moreover, the psychedelic training center of Zihuatanejo did not last beyond the summer of 1963 because of restrictions by the Mexican government. Later, in 1965, Leary was arrested in the United States for possession of marijuana, receiving a sentence of 30 years in prison. He did not go to prison, because he was released on parole. In 1970, however, he was again convicted for possession of marijuana and is now sent to prison. Being imprisoned, Leary wrote the book \u201cStarseed\u201d in which he made connection with another of the characteristic elements of the time: the alien space. It is about the construction of a spaceship capable of transporting 5,000 people to travel through space to make contact with extraterrestrial civilizations and thus advance in our evolution as a species. Thus, Leary had interest in two types of journeys, into the interior of the mind, through hallucinogenic drugs, and into outer space by means of spaceships. Today it is clear to us that the space race and the use of hallucinogenic drugs that flourished half a century ago, diminished over time. Certainly, the exploration of space has not been suspended in all these years, but certainly lost the momentum of the decade of the sixties. The LSD, for its part, was declared an illegal substance. The situation is changing, however. Thus, we have that the space race has acquired a new impetus with the entrance to the space business, both from private companies, as well as from countries such as China that maintains robots explorers on Mars and on the dark face of the Moon. Likewise, the interest in the use of hallucinogenic drugs has been reactivated for the treatment of psychiatric problems. With a new impulse, two elements characterized by the 1960s. 50 years ago Leary conceived a decoctuous project to travel into space in conjunction with journeys to the interior with hallucinogenic substances. Today, we could ask ourselves whether such substances could be useful in a different way than that imagined by Leary: to alleviate the psychological problems that will afflict space travelers of the future, who will remain isolated for a long time.",
    "https://upload.wikimedia.org/wikipedia/commons/c/cb/Impact_event.jpg": "On April 15, the BBC released its documentary \u201cDinosaurs: The Final Day\u201d, which deals with the extinction of dinosaurs due to the impact of an asteroid. The documentary, which will be broadcast on American public television on May 11 with the title \u201cDinosaur Apocalypse\u201d, is excellent and presents the subject in a very attractive way, although some points of view expressed in it have been a matter of scientific controversy. To understand this controversy, it should be remembered that some 66 million years ago an asteroid the size of Mount Everest, with a speed possibly higher than 30,000 kilometers per hour, impacted our planet near the current Yucatan coast. As a result, an amount of energy of such magnitude was released that it changed to Earth forever. Thus, the fall of the asteroid marked the end of the Cretaceous period and the beginning of the Paleogeneous period, the so-called KPg border. This border meant the extinction of dinosaurs and the take-off of mammals on Earth. The impact of the asteroid is well documented. same as the effects that it would have had on our planet, including the destruction of all living species within a radius of 1,500 kilometers around the impact site, as well as the emission of gases and particles into the atmosphere that would have dispersed throughout the planet, and that would have blocked for years the sunlight interrupting the photosynthesis process. As a result, 75 percent of the species on Earth would have been extinguished. It should be noted that the BBC documentary focuses on fossils dating from the KPg border, discovered by the American paleontologist Robert DePalma in a site named Tanis, located in the North American state of North Dakota. According to DePalma, these fossils correspond to animals that were direct victims of the fall of the asteroid and in that sense the conclusion is extraordinary. Specifically, in the BBC documentary the fossilized foot of a tescelosaur -a dinosaur with a size of 2.4-4 meters, according to Wikipedia-, with the skin clearly visible, a baby pterosaur about to come out of the egg, a turtle is shown through the At the same time, the material ejected up at great speed from the impact of the asteroid, or escaped from the Earth's gravitational attraction, either by a stake, or by fish with tectites - small glass spheres - lodged in the gills and dead in unusual positions. It should be noted that at the KPg border, the center of the North American territory was crossed by an inland sea that communicated with the Gulf of Mexico, and that the fossils dug up in Tanis corresponded to both terrestrial and aquatic animals. According to DePalma, the fossils of Tanis show evidence of animals that were suddenly killed, the same day that struck the asteroid. To explain how an event that occurred 3,000 kilometers away could act so quickly, DePalma argues that when the meteorite fell, it generated a earthquake of great magnitude that in turn generated a sudden rise in the sea level near Tanis, which caused the water to penetrate at great speed into the land by dragging marine animals and burying them in mud together with the terrestrial animals that it found in its path. , or it returned to the surface reaching a high temperature by friction with the atmosphere. Thus, the material would have melted forming the tectites that were found in the gills of the fish that would have died suffocated. And all this, the water wave and the tectite rain would have occurred shortly after the impact of the meteorite.There are experts, however, who are skeptical of DePalma's conclusions, and before accepting them they prefer to wait for it to publish their findings formally in a scientific journal, after they are critically reviewed by other experts. This is the normal procedure for a scientific result to reach broad acceptance. DePalma, however, is not given to follow usual practices and in the first instance makes public its findings by non-formal means, as is the case of the BBC documentary. And as is also the case of an article published in 2019 in the magazine \u201cThe New Yorker\u201d on the same subject. To whom we are lay in the matter, the results presented in the BBC documentary seem impressive and convincing arguments. But is it really possible that we can know. With an accuracy of hours what happened 66 million years ago, and that we can learn of victims of such a remote catastrophe? That is, victims who were born in the Cretaceous and died in the Paleogene. One way or another, we should recognize that the possibility is fascinating.",
    "https://upload.wikimedia.org/wikipedia/commons/4/4d/Andasol_Guadix_4.jpg": "The Sun is one of the main actors in the energy transition process we are going through, which is natural, because it is the Sun, ultimately, the source of energy on which the higher life of the planet depends. Learning to make use of the energy of the Sun for a definite purpose, however, has not been a simple task. One of the first examples in this sense took place at the site of Syracuse by the Romans, in the year 212 before the Christian era. We remember that, on that occasion, Archimedes actively participated in the defense of the city, creating all sorts of defensive devices. One of these devices was a set of mirrors that were used to direct the solar radiation towards the Roman ships for the purpose of setting them on fire. It is not clear, however, if the defenders of Syracuse would have managed to destroy Roman ships by this technique, or if it was a mere legend.In any case, it is interesting to note that Archimedes's ideas to destroy Roman ships have points of contact with a technique that is used today to take advantage of the energy of the Sun. This technique consists of directing solar radiation through a set of mirrors to a reservoir containing a fluid. As a result, the fluid reaches a high temperature and can be used to move a turbine that in turn drives an electrical energy generator. This way of harnessing the energy of the sun, however, is not the most widespread. The most common way to do so is by means of solar panels, also known as photovoltaic panels, which directly convert solar energy into electrical energy without intermediate steps. This means of taking advantage of solar radiation is advancing at accelerated pace. In this sense, during the week that ends today we learn by the media that the company Sun Power, based in Singapore, had submitted to the corresponding authority an environmental impact statement by the planned construction in Australia of what will be the largest plant of photovoltaic panels in the world. That plant will have a power of up to 20 gigawatts and will be located in the Northern Territory, approximately half way between the city of Alice Springs in the center of Australia and the city of Darwin on its northern coast. To appreciate the size of the projected solar plant , it should be mentioned that it will extend over an area of 12,000 hectares, will include 28 million solar panels and storage batteries so that the energy flow will not be interrupted during the night and will have a cost of 22,000 million dollars.It will be about twenty times bigger than the Villanueva solar plant, in the state of Coahuila, which is among the 10 largest in the world.The Villanueva plant covers an area of 2,600 hectares and has 2.3 million solar panels.On the other hand, given that the solar plant will be located in the middle of nowhere - the Northern Territory has an area of almost one and a half square kilometers and a population that does not reach 250,000 inhabitants - the energy produced will be sent by a transmission line to a point on the north coast of Australia distant 800 kilometers.A part of the energy generated will be consumed in the Northern Territory, while the other, majority, will be exported to Singapore from the north coast of Australia by means of submarine cables of 4,200 kilometers in length.It is anticipated that the year 2028 such energy will cover 15 percent of the electricity needs of electricity. In addition to its enormous size, the Australian solar plant in project contemplates battery banks to provide continuous energy. This overcomes a weakness of the photovoltaic energy that occurs only to the extent that the Sun shines. Returning to the site of Syracuse, now, more than two thousand years away, it is clear to us that Archimedes would have easily carried out his purposes of burning with solar radiation the Roman ships that besieged them with elements of modern technology, such as concave mirrors of glass coated with aluminum and mechanical mounts oriented towards a fixed point by means of a computer - he has, of course, realized that the Romans would not have also counted on modern technologies and would have manufactured their ships with steel and equipped them with modern weaponry that would have easily been swept away with the mirrors of Archimedes. He would have, of course, not exist and has no sense to imagine things that did not happen. What is real, we now know, is that the Sun is a powerful source of energy that can be exploited and that is economically profitable. As the Australian project demonstrates.",
    "https://upload.wikimedia.org/wikipedia/commons/0/0d/Laproscopic_Surgery_Robot.jpg": "According to the consulting firm PwC, about 30 percent of jobs in 29 countries, mostly industrialised, will have been lost in the middle of the next decade because of automation. This is not unusual, as the loss of jobs due to the advent of a new technology has already occurred before. Thus, the steam engine replaced human force in the nineteenth century and eliminated manual sources of work. Similarly, the appearance of personal computer and word processors in the last decades of the twentieth century radically changed the skills required for office work and marginalized people without these skills. On the other hand, while they have eliminated jobs, new technologies have created new employment opportunities with different skills than traditional ones. The introduction of electricity in the last decades of the twentieth century, for example, gave rise to jobs that required the skills of the then new technology. Likewise, automation, while eliminating jobs, is expected to generate new ones according to the new circumstances. In the last 250 years in three revolutions, the outgoing features of which are, in their respective form, the steam engine, electricity and computers.A fourth industrial revolution driven by technologies such as the Internet, artificial intelligence and robotics is currently underway, which, like the previous revolutions, is expected to destroy jobs and generate new ones.On this occasion, however, it is anticipated that the changes will occur with such speed that there will be professions that will become obsolete in the course of a generation. That is to say, there is the possibility that a worker will have to retrain professionally in order to preserve his job, and in these circumstances a guide would be useful to him to choose a professional retraining.In the same way, a young man seeking a first professional training would find useful information on the future stability of such or which job.With this in mind, a group of researchers headed by Antonio Paolillo, from the Federal Polytechnic School of Lausanne, Switzerland, decided to carry out an investigation to determine the risk of the disappearance of jobs by automation, determined both by the development of the The results of the research were published on 13 April in the journal \u201cScience Robotics\u201d. In their article, Paolillo and collaborators create an index for the risk of automation that measures the probability that a certain job will be occupied by a robot with artificial intelligence. This, based on the skills that that position requires, and on the present and future possibilities of robotics and artificial intelligence to cover those skills. Researchers also developed a second index that gives us the measure to which the skills of a certain job, destined to disappear, can be used in a retraining for a job that has a higher probability of survival. Paolillo and collaborators calculate the risk of automation of about a thousand occupations and find that physicists are at the lowest risk of being replaced by a machine (place 1 on the list), while meat balers are the most at risk (place 967). In the middle of these extremes are robotic engineers, economists and electrical technicians, who occupy 122 places. , 203 and 458, respectively. As for the index that can be used as a guide for changing professions, Paolillo and collaborators created an Internet site (Resilience To Robots \u2013 EPFL) that allows us to evaluate the best option to change professions. However, it should be noted that, although in some cases the advice that gives us the site is certainly useful, in others the answers are disconcerting.For example, the first option offered by the site for the profession of physicist is that of surgeon, which clearly implies a professional re-training almost total.This is impractical, besides that there would be a loss in the value of the risk index.In addition, even if the site could be improved, the article by Paolillo and collaborators shows us the urgency of adapting the study plans of the professional schools to the changing conditions of the labor market of the future, which will be determined by the fourth industrial revolution.",
    "https://upload.wikimedia.org/wikipedia/commons/2/26/Electrical_and_Mechanical_Services_Department_Headquarters_Photovoltaics.jpg": "This energy is a virtually inexhaustible source, but 50 years ago, when the oil crisis occurred, there were no technologies to compete economically with fossil energy sources. To be precise, in 1973 there were solar cells that directly converted the energy of the sun into electric energy, but their high cost did not make them competitive. Over the last fifty years, solar cell technology has developed to such an extent that today it competes economically with other sources of energy generation, as well as its operation does not generate atmospheric pollutants, as is the case with fossil sources. One measure of the success that the solar cells are having is perhaps the protests that are generating in some of the communities of the United States for the installation of the so-called solar farms, made up of large areas covered by solar panels. The criticisms made of these farms are that they occupy large areas that result from ecological damage, including soil erosion and pollution with herbicides used to prevent the growth of weedness. The solar cells are particularly competitive for the electrification of rural areas or places away from the electricity distribution network. For this type of applications, however, their greatest limitation is made more noticeable: they generate energy during the day, but not during the night. Thus, a storage medium is required -typically a battery system - that captures the energy generated during the day to be used during the night. The batteries, however, add complexity to the power generation system, which limits its attractiveness. In this sense, an article appeared this week in the magazine \u201cApplied Physics Letters\u201d reports the development of a solar cell that produces energy, not only during the day, but also during the night. The article was published by a group of researchers headed by Sid Assawaworrarit from Stanford University, California.The development of Assawaworrarit and collaborators part of a conventional silicon solar cell that was adapted to a thermoelectric plate. The silicon cell produces energy during the day from the radiation it receives from the sun, while the thermoelectric plate does so during the night. For the latter to happen, it is necessary to establish a temperature difference between the top face and the lower face of the thermoelectric plate. To understand how the thermoelectric generator can produce energy during the night, when there is no solar radiation, let us consider the following. First, it should be mentioned that all objects emit a certain amount of heat that tends to cool them. However, if the object is, for example, inside a room, it will absorb the heat emitted by walls or other objects in the room and compensate for the lost heat. If, on the contrary, it is exposed to weather on a starry night, it will emit radiation to the sky that will be lost irremediably and will not have a way to be compensated. Thus, the object will cool down from the ambient temperature - such as a plant cools and can even freeze on a clear night. The solar cell is connected to the thermoelectric plate, with the cell placed on the top looking at the sun. During the day the arrangement operates as a typical cell. During the night, heat is cooled to the firmament through the cell, which produces a temperature difference of a few degrees centigrade between the two sides of the thermoelectric plate, and the consequent electrical energy. The energy generated during the night -which is certainly much lower than that generated during the day- could be used for lighting. For this purpose, an area of 20 square meters of cells would be sufficient for a 1 watt lamp, according to the authors of the reference article. Assawaworrarit and collaborators note, the elements used to build their cell were not specifically designed for the application and there would be much space to optimize the arrangement. In these conditions, they consider that their results demonstrate a viable option to build devices to generate energy from solar radiation, both day and night. And with this they advance in the substitution of the fossil sources of energy generation. solar cell lines.",
    "https://upload.wikimedia.org/wikipedia/en/4/45/The-Martian-Chronicles.jpg": "In his novel \u201cMartian Chronicles\u201d published in 1950, American writer Ray Bradbury makes a compilation of short stories published over several years in which the colonization of the planet Mars is told. The novel begins with the story \u201cThe Summer of the Rocket\u201d, in which Bradbury recounts the take-off, on a cold winter day in 1999, of a rocket heading to Mars with the first two explorers on board. The rocket departed from a space port in the U.S. state of Ohio, generating such intense heat that, for a moment, the winter cold turned into summer heat. The take-off of the first rocket to Mars was successful, but not the conclusion of the mission, as its members were completed upon reaching Martian soil. After several voyages of exploration, however, the terrestrials arrived in large quantities to Mars, colonizing a planet that was very different from their place of origin, but not to such an extent that it prevented them from adapting. \u201cMartian Chronicles\u201d is, of course, a splendid book of fiction that does not purport to reflect the real environmental conditions of Mars. In fact, we know that these In this way, Mars is different from Earth in many respects, some as contrasting as its lack of atmosphere with oxygen and its extreme temperatures. Mars is also different in more subtle aspects. One of these is revealed by an article published this week in the journal \u201cNature\u201d by an international group of researchers headed by Sylvester Maurice of the Institute for Research in Astrophysics and Planetology of Toulouse, France. In their article, Maurice and collaborators report the result of an investigation carried out to determine the speed of sound in the Martian atmosphere, which they anticipated would be different to the corresponding speed on Earth. This, due to three factors: In order to carry out their study, Maurice and collaborators made use of the Perseverance explorer, who arrived at the surface of Mars in February 2021. This explorer has the SuperCam microphone, housed in the explorer\u2019s mast, at a height of 2.1 meters above the ground. The microphone is part of an analysis instrument that uses a laser to heat and evaporate rocks from the Martian soil, and was primarily designed to record the sounds produced by that laser during the process. As a secondary application, the researchers used the SuperCam to measure the time it takes to the sound produced by the laser to reach the microphone \u2013 after traveling 2.1 meters \u2013 and with this time calculate the speed of the sound. Researchers find that the sound on Mars travels at a speed 30 percent slower than on Earth. Furthermore, while on our planet the severe and sharp sounds travel at the same speed, on Mars the acute sounds travel faster than the severe ones. To be more accurate, if we listen, a sound coming from a distant source about 30 meters, the serious sounds will arrive two tenths of a second later than the sharp ones. Thus we would have problems to, for example, listen to a concert performed by an orchestra. Of course, it would have to be recognized that, given their extreme environmental conditions, it is unlikely that we would have the opportunity to attend a concert hall on Mars. And if that were the case, we would have to come in an astronaut suit, just as the members of the orchestra would have to do, which seems difficult. The remarks about the peculiarities of the propagation of sound in the Martian atmosphere do not have a great practical importance for future colonizers of Mars, although they are significant from the scientific point of view and contribute to the knowledge of a planet that, supposedly, we will colonize in a future not yet determined.And as for \u201cMartian Chronicles\u201d, although it is a novel that relates a planet that does not correspond to reality - without wanting to do so-, it is a fantastic book, highly recommended.",
    "https://upload.wikimedia.org/wikipedia/commons/9/97/444226main_exoplanet20100414-a-full.jpg": "The Roman writer and soldier Plino the Elder, who died during the eruption of the volcano Vesuvius in 79 C.E., left us a description of the monopods, a race of men who lived in India and who had very peculiar characteristics. According to Plinio the Elder, the monopods, as their name indicates, had only one leg and one foot, although this last one of enormous proportions. Far from constituting a hindrance, the huge foot allowed them to move by leaps at great speed, besides that they used it to protect themselves from the sun, lying back and raising their feet until their shadow covered them completely. The monopods, on the other hand, were not the only monsters that in ancient and medieval times were believed to be living in distant lands of difficult access, and in that sense it would be necessary to remember the blemies, beings without heads and face in the torso that inhabited Ethiopia. Now that practically the whole planet has been explored, it is difficult to argue in favor of the existence of exotic beings. We can mention, for example, that in August 1924, when the planet Mars had a maximum approach to Earth, the government of the United States established the \u201cNational Radio Silence Day\u201d, which set the suspension of radio transmissions for five minutes every hour over a period of 36 hours. This, in order to listen to hypothetical radio transmissions that the Martians would have broadcast to communicate with us, taking advantage of the proximity of the two planets. Unfortunately, the efforts were not successful. Today, we know that there are no Martians on Mars \u2013 although there could be microbial life \u2013 as there are probably no intelligent beings anywhere else in the solar system outside the Earth, so we have had to move our efforts to find intelligent life to more distant places. Thus, throughout the second half of the last century and so far, we have searched the sky with the hope of detecting radio signals issued by a civilization. Unfortunately, as in the case of the National Radio Silence Day, the initiatives have not been successful so far. Alongside the search for extraterrestrial intelligent life, initiatives are being carried out to discover the presence of some form of life on extrasolar planets, known as exoplanets. Far from the impact that it would have to detect a message sent by an extraterrestrial civilization, to discover life in an exoplanet, even if it were not intelligent, it would have a huge scientific importance. According to NASA, some exoplanets have been discovered, some with characteristics similar to those of the Earth, and one might wonder if some of them were to host life. To try to find out, it is necessary to search them in search for biosignals that indicate the presence of living organisms. A gas associated with biological activity is methane. Thus, the presence of methane in the atmosphere of an exoplanet could indicate that such a planet hosts life. It should be noted that there are also other gases, such as oxygen, which are also associated with biological activity. that is easily detectable by NASA\u2019s new James Webb space telescope. We have, on the other hand, that the mere presence of atmospheric methane does not allow to ensure the presence of life, as this gas can also be generated by non-biological processes. Thus, to determine the probability that an exoplanet given to life, based on the measurement of atmospheric methane, is necessary to take into account the global conditions of that planet. In an article published this week in the magazine \u201cProceedings of the National Academy of Sciences\u201d, a research group headed by Maggie Thomson, from the University of California in Santa Cruz, reports the results of a study in which it is concluded that on a planet similar to Earth, non-biological processes cannot easily maintain a concentration of atmospheric methane, and that the detection of such gas in the atmosphere of an exoplanet would be a strong indication of the presence of life. Based on all of the above, we could expect that in the coming years we receive news about the discovery of life on a planet around a distant star. Discovery that will be carried out with the James Webb telescope, We will not discover beings without a head or with one foot, of which we are fascinated, but without a doubt the news will be more than relevant.",
    "https://upload.wikimedia.org/wikipedia/commons/e/e3/Kheops-Pyramid.jpg": "From the pyramids of the Giza complex, in Egypt, the pyramid of Keops is of the highest proportions: 230 meters per side and 140 meters of height. It is also the one that has a more complex internal structure, which includes an underground chamber, and two chambers in the body of the pyramid: the queen\u2019s chamber and the king\u2019s chamber. It is possible to access these chambers through a tunnel that starts from the north side of the pyramid at an altitude of 18 meters from the base of the pyramid. At the end of its ascending section, the tunnel is forked in a horizontal tunnel, leading to the queen\u2019s chamber, and in a narrow and ascending tunnel of 47 meters in length and 8 meters in height leading to the king\u2019s chamber, which is known as \u201cGreat Gallery\u201d. The king\u2019s chamber has an area of approximately 10 by 5 meters and a height of six meters. There is also a tunnel to access the underground chamber. In addition to its large dimensions and internal complexity, the pyramid of Keops is attractive because of the secrets it containss. Indeed, we know that at present the king\u2019s chamber houses only one s s sarco This, on the one hand, is not something extraordinary, for it is known that the tombs of the Pharaoh Keops were usually the victims of thieves. However, as noted in an article signed by Mike Dash and published in the \u201cSmithsonian Magazine\u201d in 2011, while it is known that the tunnel leading to the underground chamber was known since ancient times, there is no equally solid evidence that the upper chambers have been the knowledge of Greeks and Romans. In fact, it would have been until 820 C.E. that, at the initiative of the Caliph Al-Mam\u00fan, the tomb of Keops had once again penetrated after thousands of years of isolation. For this, a new tunnel was drilled into the wall of the pyramid.For the rest, the pyramid of Keops not only keeps secrets about its history in the last 4,500 years, but also as far as its internal structure, which apparently is more complex than what it is. In this sense, a team of researchers from the University of Nagoya, Japan, discovered in 2017 a hole inside the pyramid that had remained hidden. This hole, revealed using a cosmic ray technique, has a length of 40 meters, almost equal to the Grand Gallery that gives access to the king\u2019s chamber. To deepen our knowledge of the pyramid of Keops, a group of specialists headed by Alan Bross, from the National Accelerator Laboratory, United States, has in place a project to investigate its internal structure using cosmic ray techniques as well. These projects are described as in an article submitted on 17 February to the site \u201carXiv\u201d, which houses research manuscripts that have not yet passed the peer review process. It should be mentioned that, rather than cosmic rays as such, the technique of Brosss and collaborators employ muons produced by these rays. As we know, cosmic rays are particles of very high energy coming from space, which, upon penetrating into the atmosphere of our planet, produce cascades of secondary particles. These particles are weakly absorbed by penetrating a material and are therefore ideal for determining its internal structure. In the case of the pyramid to be studied, if the material through which the muon beam passes is solid rock, it will suffer a certain absorption that can be determined by measuring the amount of muons emerging from the pyramid. If, on the other hand, the muons in its path find a hole, they will suffer a minor absorption that can be determined by leaving the pyramid. Thus, the presence of holes inside the pyramid, and even changes in the composition of the solid materials that make it, can be detected. Furthermore, by carrying out measurements from various angles around the pyramid, researchers will be able to locate the position of the holes inside the pyramid, just as a tomograph takes three-dimensional images inside the body. Thus, with certainty, we will soon have news about the secrets kept inside the pyramid of Keops, which will be revealed using techniques that only a century ago would have looked like science fiction. reveal the secrets of its history in the last 4,500 years.",
    "https://upload.wikimedia.org/wikipedia/commons/2/20/Oumuamua_orbit_at_perihelion.png": "On August 25, 2012, NASA\u2019s \u201cVoyager 1\u201d space probe abandoned the solar system and thus became the first human object to penetrate interstellar space. It is currently more than 23 billion kilometers away from us \u2014 some 150 times the distance between the Sun and Earth \u2014 moving away at a speed of more than 60,000 kilometers per hour. In tens or hundreds of thousands of years it will reach the vicinity of solar systems neighbouring ours, and while it is unlikely that it will come into contact with alien civilizations, Voyager 1 carries on board a time capsule with images and sounds of the Earth, as well as information on the position in the space of our planet. Voyager 2, on its side, became in 2018 the second artificial object to leave the solar system, and it is expected that in the future it will be done by three more NASA probes, the Pioneer 10 and 11 and the New Horizons. Thus, we have already opened the time of interstellar voyages, just as other alien civilizations have surely done so. With regard to the latter, in October 2017, the visit of an unusual object, which crossed through our solar system with a speed and trajectory such as to indicate an origin outside the solar system. This object, the first of extrasolar origin detected in our planetary system, was baptized as \u201cOumuamua\u201d, which in Hawaiian means \u201cmessenger from afar that comes first\u201d. Since its discovery, Oumuamua has been a source of controversy among specialists for its unique characteristics. In particular, because during its approach to the Sun it experienced an acceleration in its speed beyond that it would have experienced by the mere gravitational attraction of the Sun. This would indicate that Oumuamua has the nature of a comet. Indeed, a comet is constituted by materials that vaporize as it approaches the Sun, forming the comet's coma and tail. This vaporization generates a force that prints the comet an additional acceleration during its approach to the Sun. Thus, the acceleration in excess observed during the approach of Oumuamua could be explained if we assume that the comet's The conclusion that Oumuamua has the nature of a comet has been disputed by Shmuel Bilay and Abraham Loeb of Harvard University, who claim in an article published in the November 2018 issue of the magazine \u201cThe Astrophysical Journal Letters\u201d, that the force that produced the increase in the acceleration of Oumuamua was in fact due to the pressure of the Sun\u2019s radiation. In this regard, we know that the radiation of the Sun exerts a force on an object by affecting its surface. This force, of course, is very small and does not most affect objects here on the surface of the Earth, it can, however, produce great effects if it acts for a long time on objects that present a large surface to solar radiation. In fact, it is solar radiation that drives the space probes equipped with solar sails, in the same way that the wind drives sailboats.To support its conclusions, Bilay and Loeb calculates To determine the form that Oumuamua should have to experience the acceleration observed during its approach to the Sun. They find that it should have the form of a thin sheet with a thickness less than a millimeter; just what would be expected of a solar candle. In these conditions, Bilay and Loeb speculate that Oumuamua could constitute the remains of an interstellar ship, already out of operation, built by an alien civilization. It is not difficult to imagine that the speculation of Bilay and Loeb has been strongly contested by specialists who argue a natural origin for Oumuamua, with everything and its strange behavior. Loeb, however, has sustained its original conclusions. Thus, in an article to be published in April of this year in the magazine \u201cNew Astronomy\u201d, together with another author criticizes the conclusions of an article in which it is argued that Oumuamua has a natural origin and is actually a piece of frozen nitrogen, which was vaporized as it approached the Sun generating an increase in its acceleration.Unfortunately, Oumuamua is already beyond the reach of our telescopes and it is not possible to study it with In this situation, we would have to be alert if another similar object crosses our solar system. After all, from our own experience, we know that a technological civilization can send probes to other stars.",
    "https://upload.wikimedia.org/wikipedia/commons/f/f0/Spent_nuclear_fuel_hanford.jpg": "If we were to go back 100,000 years into the past on board a time machine we would find a European continent populated by Neanderthals, as well as by mammoths, rhinoceros and bears, among other great mammals. Modern men would still take a few tens of thousands of years to get there after their departure from Africa. 100,000 years ago the development of agriculture was still far away, which allowed the settlement of hunter-gatherers groups and over time the development of civilizations. Undoubtedly, 100,000 years ago the world was very different from today. If, using our time machine, we were now moving 100,000 years into the future, what would we find? It is difficult to anticipate it given the rapid and surprising changes that civilization has undergone in the last two hundred years, driven by the scientific study of nature. However, we can perhaps anticipate that we would find ourselves with traces of our passage around the world, just as we now have traces of our predecessors tens of thousands of years ago. We can reasonably be sure of this last at least one of our past. Our activities: the operation of nuclear reactors for the generation of energy that produce waste that will be radioactive for up to hundreds of thousands of years. Indeed, as we know, following the discovery of the possibility of disintegrating some atoms by bombarding them with neutrons, it was possible to develop nuclear reactors to produce energy. Currently, according to data from Wikipedia, there are 435 reactors in operation in the world that produce about 10 percent of the electricity consumed by the world. The use of electricity of nuclear origin, however, varies widely between countries. In France, for example, 70 percent of the electricity has nuclear origin. Nuclear energy is classified as \u201cclean\u201d, in the sense that it does not produce greenhouse gases and is therefore considered as an appropriate source of energy to combat climate change. Nuclear energy is, however, far from being clean in a broader sense, as it produces radioactive waste, in the form of nuclear fuel used, which can be highly hazardous for tens of thousands of years. four meters long, filled with uranium dioxide tablets. When removed from the reactor, the fuel is hot and highly radioactive, so it must be reprocessed, or submerged in a water pool for several years to cool it down and then transferred to a steel container sealed and stored in a concrete silo. Currently, more than a quarter of a million tons of highly radioactive nuclear waste are stored in the vicinity of nuclear reactors and nuclear weapons manufacturing plants on a global level. It is considered, however, that this storage is only temporary, as long as the problem is solved definitively. In this sense, Finland is one of the countries that has made the most progress by building an underground storage site on the island of Olikiluoto on the west coast of the country. A description of the site appeared this week in the magazine \u201cScience\u201d, in an article signed by Seeder El Showk. The radioactive tubes discarded by the Finnish reactors will be placed in sealed iron containers of six meters high, and these at the same time in containers sealed. In the space between the two containers argon gas will be injected to avoid corrosion. Containers with radioactive waste will be buried in about a hundred tunnels at 430 meters deep. The site is being built in the rocky subsoil, between two parallel geological faults, separated by 800 meters. With all these precautions, Finns expect that the radioactive materials placed in the containment -thousands of containers - will be kept in total isolation for a space of 100,000 years, at the end of which they will have lost their dangerousness. Thus, if everything goes well, hypothetical archaeologists of the future could discover in Olikiluoto a warehouse of nuclear waste -fortunately already harmless - product of a technology that will surely seem obsolete.And with this discovery, they may be asked for the reason that I bring the primitive inhabitants of the Earth to manufacture highly dangerous materials that they later had to bury, using great efforts and care, at great depth.",
    "https://upload.wikimedia.org/wikipedia/commons/f/f7/Homo_sapiens_neanderthalensis-Mr._N.jpg": "Certainly, we have no news that an orangutan in the jungle has been spotted making a stone tool and using it, for example, to open a fruit that he intends to eat. We have not witnessed it perhaps because his teeth are sufficient for this purpose. Or, because the orangutans are not smart enough to conceive, manufacture and use tools. Although this is what is likely to come to our mind in the first instance, an article published this week in the magazine Plos One casts doubts about it. Indeed, in that article the results of experiments carried out with five orangutans that live in zoos in Norway and the United Kingdom, which show that these animals, without any training, are able to use a sharp stone tool to open a box. They are, moreover, able to learn by imitation the process of making a stone tool. Evoluciously, our species and that of the orangutans are very separate and we would have to go back thirteen million years into the past to find a common ancestor. As a species, there is no doubt that we are superior to the orangutans, as we are to any other living species on earth.The latter, however, is only a circumstance of the time we had to live and the situation would have been very different forty thousand years ago, when our species lived together in Europe with the Neanderthals.As we know, the Neanderthals inhabited the European continent for hundreds of thousands of years before being extinct some forty thousand years ago, coinciding with the arrival of our species to that continent. By this coincidence, it has been speculated that Neanderthals suddenly became extinct before the attack of the cognitively superior homo sapiens.Such, however, it seems, that such speculation is too optimistic with regard to our supposed superiority over Neanderthals.In this sense, the conclusions of an article appeared on the 9th of a cognitively superior homo sapiens appear. In his article, Silmak and collaborators report the discovery of dental remains and stone instruments in the Mandrin cave in the south of France, which demonstrate the presence in this cave of modern humans about 55,000 years ago. That is, the homo sapiens would have arrived in Europe about 10,000 years earlier than was thought. Even more, the findings indicate that Mandrin cave was alternately occupied by modern humans and Neanderthals. Indeed, the researchers find evidence of occupation by Neanderthals 60,000 years ago and of the subsequent occupation by modern humans, followed by occupation by Neanderthals and finally by modern humans. Thus, the process of extinction of Neanderthals was more complex than was believed and would not have occurred suddenly by the onslaught of an evolutionaryly superior species. On the contrary, at least as far as the Mandrin cave was concerned, the process of extinction of Neanderthals was given a more complex than was believed and would not have occurred suddenly by an evolutionaryly superior species. And so, if we had lived in Europe 50,000 years ago, we would have lived with a species with a truly distinctive appearance - with a more robust body and prominent ciliary arches, among other characteristics - but not too different from our own. And with an intelligence not too far from ours, as demonstrated by the sophisticated techniques they developed to make stone tools. Even now, it is clear that a cross between Neanderthals and modern humans, whose genetic material is a legacy of the former, whose legacy of the former, has been in fact 50,000 years ago, we had no exclusivity on the planet as the only species with a superior intelligence. Thus, our ancestors would have had to have been accustomed to not having exclusivity in this sense. On the other hand, if any of us, in a time machine, had moved 50,000 years into the past, we would have encountered a different population in many respects - with regard to their species - but the same in others, including intelligence. What, without a doubt, would have been an entire experience. any case, of a different nature than what we loosely experience with the orangutans.",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/1346-1353_spread_of_the_Black_Death_in_Europe_map.svg/880px-1346-1353_spread_of_the_Black_Death_in_Europe_map.svg.png": "According to data from Johns Hopkins University, the Covid 19 virus has infected more than 400 million people and led to death nearly six million people around the world; this, in just a couple of years since its appearance in Wuhan, China, in January 2020. The Omicron variant of the virus has been particularly rapid in its spread, producing record numbers of new infected ones and replacing the Delta variant in just a few months. Fortunately, it has also been less virulent.With everything and the traumatic that has resulted in the last two years of pandemic, we may feel fortunate to live in a time of medical advances and public hygiene. Centuries ago, our ancestors did not have the same luck. In this sense, history tells us of pandemics that terrorized populations without the means to defend themselves for being totally ignorant of the causes of the disease. One of the most cited examples in this regard is the black plague that struck Europe in the 14th century and that would have ended between 30 percent and 50 percent of the population in the course of a few years. It is possible, however, that the devastation caused by the black plague has been exaggerated. To this conclusion comes an article published this week in the journal \u201cNature Ecology and Evolution\u201d, which was published by an international group of researchers led by Adam Izdebski, of the \u201cMax Planck Institute for Science of Human History\u201d in Jena, Germany. In their article, Izdebski and collaborators maintain that, although there were areas of Europe highly devastated by the pandemic \u2013 according to historical evidence \u2013 this was not widespread throughout the continent. They come to this conclusion by means of a paleoecological study, using the procedure described below. Izdebski and collaborators point out that from 75 percent to 90 percent of Europe\u2019s population in the 14th century was rural, and that the death of a large percentage of this population would have left large tracts of land uncultivated. With this, the plants cultivated on the agricultural surfaces would have been replaced by pastizales or by the vegetation proper of the place. If there were a change in the vegetation of the agricultural lands, there would be evidence of the population collapse produced by the plague pandemic. But how could Izdebski and collaborators find out if there was an invasion of the agricultural surface by other plants in this or that place? They did so by studying the pollen grains that, dragged by the wind, ended up trapped in a layer of land and rocks at the bottom of lakes and wetlands, which are thus witnesses of the plant past of the vicinity. The information provided by the pollen will be older in the greater depth than it is in the layer of land at the bottom of the lake. To carry out their study, the researchers took 1, 634 samples of the fund of 261 lakes and wetlands in 19 countries of Europe and focused on studying the changes in the pollen caught at intervals of one hundred years, before and after the year 1.350, around which the pandemic began. They found, although there were places where a population collapse occurred, among which are areas of central Italy and France, as well as southern part of the peninsula. In some areas there is even an increase in the cultivated area.This is the case of a region in the centre of the Iberian peninsula, and of large areas in Poland and Russia.The results of Izdebski and collaborators show that very possibly the collapse of the population of Europe by the black plague has been exaggerated.Truely, according to historical texts, there were highly devastated regions - which is corroborated by the study - but this was not a widespread phenomenon.In one way or another, the Europeans survived the black plague, just as we have survived many other pandemics caused by various pathogens throughout history.And this gives us hope that, as soon as possible, we will be able to get out of the pandemic that we had to live.After all, we have to defend ourselves with infinitely superior means in comparison with those of our ancestors in medieval Europe, who attributed the disease to the most disparate causes, since the corruption of the pandemic. air to the astronomical phenomena, which, of course, didn't take them anywhere.",
    "https://upload.wikimedia.org/wikipedia/commons/2/29/Atahuallpa%2C_Inca_XIIII_From_Berlin_Ethnologisches_Museum%2C_Staatliche_Museen%2C_Berlin%2C_Germany.png": "One of the key episodes in the conquest of Peru by Francisco Pizarro was the capture in Cajamarca, after a cellada, of Atahualpa, the last Inca emperor free. As a rescue to achieve his liberation, Atahualpa offered to deliver to Pizarro gold and silver objects in sufficient quantities to fill the room in which he was imprisoned to reach his raised hand. Pizarro thus accumulated tons of gold and silver, despite which in the end he condemned Atahualpa to die at the stake. As we know, greed for gold and silver was something common among Spanish conquerors, and this is what possibly explains the archaeological finding -and macabre- reported in an article published this week in the magazine \u201cAntiquity.\u201d This article was published by an international group of researchers headed by Jacob Bongers of East Anglia University in the United Kingdom. In his article, Bongers and collaborators report the results of an investigation carried out with human remains discovered in the Chincha valley, in the Peruvian coast, approximately 200 km south. This valley was dominated by the Chincha people between the 1000s and 1400s of our era, but it was integrated into the Inca empire upon the arrival of the Spanish conquerors. Specifically, the researchers studied 79 copies of what they called \u201cpost vertebrae\u201d, consisting of groups of human vertebrae stuck in canes. These specimens were recovered in 20 mortuor sites known as chulllpas. By means of dating by coal radio, the researchers estimate that the vertebrae correspond to people who died between the 1520s and 1550s of our era, while the canes in which they were tied would have been cultivated between the 1550s and 1590s. Thus, the vertebrae would have been assembled and returned to bury in their graves, tens of years after the death of the people they belonged to. It should be noted that the first period coincides with the arrival of the Spaniards to Peru, as well as with the epidemics and famines known to have occurred in this country at the beginnings of Lima. They consider Bongers and collaborators that the time lag between the death of a person and the use of his bones to assemble a \u201cpost vertebrae\u201d arrangement, possibly indicates that the original tombs were looted by European colonizers with the intention of stealing the gold and silver objects that they might contain. In fact, as the researchers point out, it is known that the looting of graves was an extended practice in the Chincha region. On the other hand, the rape of graves and the dispersion of the mortuary remains that it brings as a result would have contrasted with the attitude of the Chincha people, which gave great value to the integrity of the human body. Thus, assembling vertebrae in cane was a way of gathering again the human remains dispersed by European avid colonizers of gold and silver. As Bolgers and collaborators comment, the high value that Andean peoples gave to the integrity of the human body can be appreciated by the fact that, in the ritual sacrifices of infants carried out by the Incas, death was produced by methods \u201c In the same direction, it is stated that, when facing his death sentence, tied to a pole and in front of a pile of wood, Atahualpa was given two options: to die burned, or to convert to Christianity and to die by strangulation. Atahualpa chose this last option, apparently because if he died on the bonfire his body would lose all its integrity by becoming ash. Atahualpa was baptized with the name of Francis - in honor of Pizarro- after which he died strangled; with the whole body, however. All this reveals to us how much the world has changed in five hundred years. Yes, perhaps not so much in terms of appreciation for gold.",
    "https://upload.wikimedia.org/wikipedia/commons/9/99/Gas_stove.jpg": "Over the past hundred years, the world\u2019s population has grown rapidly to nearly 8 billion human beings today. Concurrently, population growth has required an increase in food and energy production, which, among other effects, has led to an accelerated increase in greenhouse gas emissions to the atmosphere. Of these gases, the most pernicious is carbon dioxide, produced by the burning of fossil fuels, followed by methane, which is the majority component of natural gas. Carbon dioxide is a gas that remains in the atmosphere for hundreds of years once it is dispersed, while the lifetime of methane in the atmosphere is only 10-15 years. The power of methane as a greenhouse gas, however, is about eighty times greater than that of carbon dioxide when its effects are averaged in the first 20 years. In this sense, it is estimated that 25 percent of the global warming that the Earth has experienced in the last two centuries is due to methane emissions. Methane in the atmosphere originates, both in natural processes and in human activities, including production and use of methane in the past two centuries. A source of methane is the leaks that occur during the transport of natural gas in gas pipelines. Surprisingly, another significant source of methane emissions into the atmosphere is domestic stoves. The latter, according to an article published this week in the magazine \u201cEnvironmental Science and Technology\u201d, published by a group of researchers led by Eric Lebel, Stanford University, California. In that article, Lebel and collaborators report the results of a study carried out with the stoves of 53 homes in California, with the aim of quantifying the levels of methane emitted to the atmosphere during their operation. In this sense, methane emissions can occur, both during the process of burning burners of the stove - when opening the gas key and before combustion starts - and because of the incomplete combustion of the gas. Additionally, and surprisingly, the emission of methane into the atmosphere also occurs when the stove is not in operation and has its gas keys closed. Indeed, Lebel and collaborators find that 75 percent of the methane emission occurs when the stove is not in operation. The second source of methane emission is the furnaces of the stoves, followed by the incomplete combustion of the gas. Gas that escapes at the beginning of the burning of the burners has a significantly smaller contribution, equivalent to the emission by incomplete combustion in a burner lit for 10 minutes. Thus, domestic natural gas stoves are a source of greenhouse gas, not only of carbon dioxide that occurs during the combustion of the gas, but also of methane. But how significant is this source? In this regard, Lebel and collaborators estimate that the methane emitted by domestic stoves in the United States is equivalent to the greenhouse gas generated by half a million gasoline cars. It is estimated that the population in the world about 10,000 years ago, at the beginning of agriculture, was of some millions of human beings. Over the course of time this population increased slowly: up to a few hundred million at the beginning of our era, to 1,000 million in 1800, and to 2,000 million in 1930. In the second half of the century the annual growth of the world population rose considerably above its historical rates, reaching a level of 1,000 million in 1800, and 2,000 million in 1930. As a result of this evolution, despite the reduction in the annual growth of the last 50 years, we reached the current population of 8 billion people and with this we put the planet in trouble, which has not proved to be large enough. To such an extent we have pressured the planet, that even the mere act of cooking our food can contribute to global warming.",
    "https://upload.wikimedia.org/wikipedia/commons/3/34/Surgical_face_mask.jpg": "With the declaration of health emergency issued by the World Health Organization on January 30, 2020, the use of the mouth covers increased rapidly as a means of limiting the transmission of the coronavirus. At the same time, however, the discarded mouth covers were constituted as a source of contamination by plastic materials whose effects could transcend those of the pandemic. In that sense, an article published last December in the magazine \u201cNature Sustainability\u201d documents the increase in the number of discarded mouth covers as garbage in public places over a period of 14 months, between September 2019 - before the outbreak of the pandemic - and October 2020. The research was carried out in 11 countries on three continents, including Australia, Germany and the United States, and showed that in the period of study the number of mouth covers-bassura increased more than 80 times. The environmental problem represented by the use of mouth covers can be put into perspective if we consider that the staggering number of more than one hundred thousand million mouth covers, according to one article, is discarded monthly. published in March 2021 in the magazine \u201cFrontiers of Enviromental Sciences and Engineering\u201d. That is to say, about three million mouth covers are discarded every minute, which add to the acute problem of environmental pollution by plastics that the planet suffers. With regard to the latter, the experts distinguish between contamination by macroplastics, microplastics - plastic fragments with dimensions between 5 millimetres and one millimetre- and nanoplastics, with dimensions less than one millimetre. Likewise, scientists know that macroplastics are continuously degraded into smaller fragments by the action of the environment, particularly by the ultraviolet component of solar radiation. Nanoplastics are of particular concern to specialists because it is thought that, because of their small size, they could be more toxic and could be more widely dispersed in the environment. This last, unfortunately, has just been verified, as reported by an article published this week in the magazine \u201cEnvironmental Research\u201d, signed by a group of researchers headed by Dusan Materic of the University of Usan Materic. In fact, as documented in their article Materic et al., studies carried out in Greenland and Antarctica found the presence of nanoplastics in both latitudes. In Greenland they found nanoplastics along a 14-metre-long ice column, which corresponds to ice deposited since 1965 to the date, demonstrating that the dispersion of nanoplastics into the Arctic region is not a new phenomenon, but has occurred over the last fifty years. In Antarctica, at the other end of the world, Materic and collaborators found in the ocean ice concentrations of nanoplastics four times larger than those found in Greenland. One may wonder about the origin of nanoplastics found in the polar regions. In this regard, researchers find that, both in Greenland and Antarctica, about fifty percent of nanoplastics are made of polyethylene, which is used in plastic bags and packaging. In Greenland, the second and third components of nanoplastics are rim powders -approximately 25 percent- and PET -20 In Antarctica, in contrast, no rim powder was found and about 30 percent of nanoplastics are made of polypropylene, which is a plastic with a wide range of applications. Materic\u2019s results and collaborators confirm that nowhere on our planet, however far from urban centers, is free of plastic contamination. In particular, these researchers demonstrate for the first time that nanoplastics have reached the most remote regions of the world. What are the consequences of nanoplastic contamination for our health? In this regard, Materic and collaborators do not offer conclusive information, but comment that nanoplastics can have \u201ca toxic effect on marine organisms, affecting their growth, inducing a delay in their growth, generating malformations and subcellular changes.\u201d In this context, it is clear that, while the mouth covers have been a basic tool to deal with the coronavirus pandemic, at the same time they have been constituted as a source of environmental contamination by macroplastics, microplastics, microplastics, and microplastics. and nanoplastics, capable of invading the whole planet. Which is, of course, a manifestation more than nothing is free and that everything has a cost.",
    "https://upload.wikimedia.org/wikipedia/commons/c/c4/ALH84001.jpg": "On December 27, 1984, a group of meteorite hunters sponsored by the National Science Foundation of the United States discovered in an ice field in Antarctica a meteorite of just under two kilograms named ALH84001. Although at the time the origin of the meteorite was not correctly identified, subsequent studies regarding its composition of oxygen isotopes made it clear that it formed on planet Mars some 4,000 million years ago, when liquid water would have existed on the Martian surface. The meteorite ALH84001 was ejected from the surface of Mars by the impact of a celestial body, and after traveling in space for about 16 million years, it finally landed on Antarctica some 13,000 years ago. The meteorite ALH84001 reached great notoriety in 1996, when NASA announced that it had found organic remains that pointed to the existence of life on Mars in a remote past. This evidence was detailed in an article published in the magazine \u201cScience\u201d on August 16, 1996, by a group of researchers headed by David McKay of NASA\u2019s \u201cLyndon B. Johnson Space Center\u201d in Houston, Texas. In his article, McKay and collaborators support his findings in a series of observations, which include images obtained by means of an electronic microscope of what would be the fossilized remains of Martian microbes, as well as organic and magnetic compounds that attribute to biological activity. McKay and collaborators are certainly cautious and admit that, taken separately, his observations do not constitute strong evidence of the biological origin of materials and structures observed in the meteorite. He states, however, that the observations as a whole support his conclusions. NASA\u2019s announcement of McKay\u2019s findings and collaborators even prompted a press release from President Clinton in which he expressed: \u201cToday, rock 84001 speaks to us through all these billions of years and millions of miles. It speaks of the possibility of life. If this discovery is confirmed, it will surely be one of the most surprising visions of our universe that science has ever revealed. Its implications are as far-reaching and impressive as one can imagine. . Although it promises answers to some of our oldest questions, it raises even more fundamental ones.\u201d On the other hand, the famous scientific divulgator Carl Sagan, after describing the discovery as \u201cglory\u201d, said: \u201cThe possibility of arriving independently at the same type of life on two independent planets is very small. This is one of the great emotions: to see how its evolutionary history proceeds on two different planets.\u201d McKay\u2019s conclusions and collaborators, however, have been very controversial and it is possible that at present there is sufficient evidence that they are not true. The last arguments in this regard appeared this week in the magazine \u201cScience\u201d, in an article published by a group of researchers headed by Andrew Steele of \u201cCarnegie Institution for Science\u201d in Washington, D.C. According to Steele and collaborators, the organic compounds found in the meteorite ALH84001 are the result of the interaction of water with martian rocks and do not have a biological origin \u2013 in fact, they point out, the same non-biological interaction is also observed on our planet-. They come to this conclusion after applying sophisticated analytical techniques to the study. Thus, it does not seem that the meteorite ALH84001 brings us news about the evolution of life on our neighboring planet, which would undoubtedly constitute the scientific news of the century. This is disappointing for us and for NASA, which justifies much of its planetary exploration projects in the search for extraterrestrial life. So, for the time being, we will have to keep waiting for solid evidence of the existence of extraterrestrial life. In this sense, while the meteorite ALH84001 does not provide them immediately, it does show us that, as Steele comments: \u201cOn Mars, non-biological chemical reactions occur that give rise to a set of organic compounds from which life may have developed, and which represent a background that must be taken into account for the search for life in the past on that planet.\u201d Surely, it is only a matter of having a little patience.",
    "https://upload.wikimedia.org/wikipedia/commons/1/1a/Rosca-de-reyes-mex.jpg": "Now that we have passed the Guadeloupe-Reyes bridge, they will not miss, those with feelings of guilt for the extra kilos acquired during the decembrina parties that have included among their purposes for the new year the one to reduce weight. For this they will have at their disposal a great variety of diets to lose weight; some more supported than others, by movie stars even. However, and besides the characteristics of these diets and the famous of its proponents, the physical chemistry of the body is imposed: to lower the extra kilos we will have to eliminate the chemical energy accumulated in the body by having ingested more than strictly needed to function. That is, the excess of body fat has to be combined with the oxygen we breathe, releasing the energy required and leaving carbon dioxide and water as residues. These residues will have to be removed from the body by some way to make effective the weight loss and in this sense arises the question: What is the most important way to expel them? An article published in December 2014 -but of great relevance in these moments of trouble - offers us an answer. \u201cBritish Medical Journal\u201d by Ruben Meerman and Andrew Brown of the University of New South Wales in Australia. According to Meerman and Brown, to oxidize 10 kilograms of body fat 29 kilograms of oxygen provided by the air we breathe are used. They calculated that oxidation generates as residues 28 kilograms of carbon dioxide and 11 kilograms of water that must be discarded by the body. Researchers also calculated the percentages of body fat that are eliminated, such as carbon dioxide through the lungs, and as water. They found that by means of the lungs 84 percent of the residues are eliminated, while only 14 percent of them are discarded as water. The latter, by means of urine, feces, sweat and other body fluids. Breathing is then the main way to lose weight by exhaling carbon dioxide, which does not stop being surprising. In fact, Meerman and Brown include in their article a table in which they write opinions from different specialists that are missing in their majority. Thus, to the question of when someone loses weight. Where are you going?, more than 60 percent of family doctors and dietologists answered that it is transformed into heat \u2013 violating mass conservation \u2013 while less than 5 percent answered correctly.Based on their results, Meerman and Brown offer us examples of practical interest. Thus, they estimate that a person of 70 kilograms of weight, resting and developing light activities every eight hours, exhales about 203 grams of carbon per day. If this same person runs for an hour, increases his or her carbon exhalation by about 39 grams, raising his or her total daily emission to about 240 grams of carbon. By comparison, 500 grams of sugar contain 210 grams of carbon, at the same time as a 100 grams panqu\u00e9 equals 20 percent of a person's daily energy requirements. Merman and Brown conclude that efforts to lose weight through physical activity can easily be exceeded by relatively small amounts of excess food. So, in a certain way and if we are to maintain the line, the speed with which the lungs work would have to follow at the speed with the physical activity. To judge by the epidemic of overweight and obesity that plagues the world, however, it seems that it is easier to get tired of the lungs to get tired of the stomach. Thus and given that at the level of the population in general there is no knowledge of the direct relationship between breathing and weight loss -which reinforces the idea of \"eating less and moving more\" - Meerman and Brown recommend that: \"all these concepts should be included in the educational programs of secondary schools and the courses of biochemistry in universities, and thus correct the misconceptions that are held about weight loss\".For the time being, if this were the case and since it is not God's way, as the purpose of the new year we should be subjected to a diet and physical exercise to lose -via breathing - the kilos of more cattle in the last bridge of the year.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d2/Gaumont1902.jpg": "As the end of each year approaches, it is customary to take stock of the main scientific and technological advances and discoveries that have taken place over the past twelve months. On this occasion, for example, the \u201cSmithsonian Magazine\u201d highlights some space activities, including the three missions sent to Mars by the United States, China and the United Arab Emirates, the new NASA space telescope and the take-off of space tourism. It also highlights the development of pills to deal with Covid, the discovery in China of what could be a new archaic human species, and the negative effects that climate change is having on coral banks. Scientific technological advances have been accumulating for four centuries, increasing our knowledge of nature, which has made possible the development of technologies that have radically changed, and in record time, our way of life. In this context, it is interesting to move one hundred years into the past, until the end of 1921, and to ask ourselves about outstanding scientific or technological developments that took place in that year. Since 1869. Thus, by going through \u201cNature\u201d, we find in the issue of 27 October 1921 an article with the title \u201cSpeaking films\u201d published by Alexander Rankine of \u201cImperial College London\u201d in which he describes a technique for making sound films. As we know, in the decade of the twentieth century cinema was a consolidated industry based on silent films, whose projection was accompanied by music or other recorded sounds. However, and despite the success of silent cinema, there were attempts to add sound synchronized \u2013 in particular, dialogues \u2013 with the projected scenes. The main problem to make a sound film was the synchronization of the image with sound. Without this synchronization the projection was not credible or even laughable. Thus, if the image and sound were recorded in different media, it was necessary that both began to reproduce simultaneously, which did not necessarily occur \u2013 depending on the operator\u2019s ability. Moreover, if, for some reason, the film tape was to be repaired by removing some stage and returned from the film. On the other hand, the problem of synchronization with the soundtrack increased considerably. Alternatively, the synchronization of the image and the sound could be achieved automatically by recording them in the same film roll. The latter, discussed in Rankine\u2019s article, was the solution that finally adopted the film industry. Such a solution required technological developments that, although not yet mature enough in 1921, did not have to wait long to see them crystallize in the 1930s. A hundred years ago, however, there were those who doubted that the sound cinema had some future. For example, a comment to the article published by Rankine, appeared on October 10, 2021 in \u201cNature\u201d signed by Lough Pendred, puts it this way: \u201cWhile the mechanical problem of synchronization could be solved, there is a more serious difficulty that could last and that could be better described as psychological. It must be remembered that, both by the images and by the sound, a film seeks to deceive the human senses. In the eye it is deceived to believe that it sees real people in motion. If the film fails to deceive the sense of sight, it also fails to achieve the psychological effect. Likewise, the sound of the film tries to deceive the sense of the ear. Unless we really believe that we are hearing Enrico Caruso, the pleasure and the effect will only be partial.\u201d And Prended continues: \u201cNow, my own experience is that you can deceive one sense, but not two at the same time. You can fool the eye with the images or the ear with the sound, but if you try to deceive them both simultaneously it will fail and both deceptions will be destroyed.\u201d Pendred supports his arguments with a personal experience: a sound film in which a person appeared dancing to the rhythm of a banjo, which did not seem credible to him at all. To last bull, a hundred years later, we know that Prended was wrong to take it out and that the cinema is able to deceive our eyes and ears and transport us to an imaginary world. Otherwise, the story of the cinematographer \u2013 with just a hundred years of life \u2013 shows us how much it can change the lifestyle of so many people. All thanks to the science and technology that results from it.",
    "https://upload.wikimedia.org/wikipedia/commons/6/6a/JWST_spacecraft_model_2.png": "We woke up last Christmas day with a good new one: at 6 am and 20 minutes in the morning it took off successfully in the European space port in French Guiana, a European Space Agency rocket with NASA\u2019s new space telescope on board. The launch of that telescope, called \u201cJames Webb Space Telescope\u201d, culminated in a 25-year effort during which the project suffered from administrative obstacles and successive budget increases that led it to reach a surprising final cost, close to $10 billion. James Webb telescope has great ambitions. It tries, for example, to detect infrared radiation that was generated 13.5 billion years ago - that is, radiation generated in such a distant place, that it took 13.5 billion years to reach us - and with this, to study the Universe at an early stage since its formation. It also tries to study the atmosphere of planets outside our solar system. What advantages does a space telescope have with respect to another located on the Earth\u2019s surface? We know that the atmosphere hinders the observation of the firmament in various ways. It can, for example, absorb some of the radiation that comes from space making it difficult or impossible to detect from the surface of our planet. This is particularly true of infrared radiation, which is invisible to us, but which is of great interest to astronomers. In fact, the new space telescope is intended to obtain infrared images of the Universe. Thus, it is crucial to place it in space, above the atmosphere.The James Webb telescope has a 6.5-meter-diameter mirror made up of 18 hexagonal segments covered with a thin gold film. It will be placed at a distance of 1.5 million kilometers from our planet \u2013 about four times the distance between Earth and the Moon \u2013 at a point where it will follow Earth in its orbit around the Sun. It is designed to work at a temperature of less than 230 degrees Celsius. To achieve this low temperature, the telescope has a five-layer \u201cshape\u201d of a material called kapton, which protects it from the radiation of the Sun. With this protection, the telescope can reach its operating temperature by emitting radiation to space. What is the reason why? The reason is simple to understand, even though it may not be apparent at first sight. Indeed, we know that all objects, depending on their temperature, emit radiation. This is obvious to the naked eye if, for example, we heat a metal object to about 500 degrees Celsius, a point where the object will be able to be red-hot and will emit a red-colored radiation. If we now cool it to about 200 degrees Celsius, the object apparently stops issuing. This, however, is incorrect, as the emission will continue to exist only now in the form of infrared radiation that we cannot see - we could see it by approaching the hand to the object, without touching it. Thus, no matter how low its temperature, an object will emit infrared radiation to some degree.Let us now put it in the place of space telescope designers who try to detect infrared radiation that reaches Earth emitted by very distant objects. It is not difficult to understand that the new space telescope is an extremely sophisticated instrument, which will operate at a temperature of less than 230 degrees Celsius, at a distance of 1.5 million kilometers from the Earth, obtaining images of what the Universe was like 13.5 billion years ago. An instrument that will surely allow us to advance in understanding the Universe. Although at the surprising cost of 10 billion dollars.",
    "https://upload.wikimedia.org/wikipedia/commons/2/24/Yucatan_chix_crater.jpg": "On November 23, NASA launched a spaceship with the mission of colliding with Dimorphos asteroid. NASA\u2019s goal is to find out to what extent it is possible to divert the trajectory of an asteroid in order to develop strategies to defend ourselves from the impact of asteroids on a collision route with Earth. Certainly, it is not the case of Dimorphs, who in their closest approach to our planet will be at a distance ten times greater than the distance between Earth and the Moon. However, even with a very low probability, we cannot rule out that in the future we faced a large asteroid with disastrous results for the planet. The extreme example in this sense is the well-known 10 km diameter asteroid that caused the extinction of dinosaurs at the end of the Cretaceous period 66 million years ago. As we know, the impact of this asteroid occurred near the village of Chicxulub, on the north coast of the Yucatan peninsula, generating a 200-kilometre-dia crater that produced gigantic earthquakes and tsunamis. The impact launched huge amounts of dust and particles that blocked into the atmosphere. For years, solar light, preventing the photosynthesis process and leading to the third great extinction of species in the history of the Earth. With regard to species extinction, specialists consider it essential to determine the time of the year when the fall of the asteroid occurred, since many biological functions, such as reproduction patterns and feeding strategies, depend on the seasons of the year. In this sense, the question arises: is it possible to determine the time of the year when an event occurred, certainly catastrophic but extremely remote? Surprisingly, an article appeared this week in the magazine Scientific Reports gives us an affirmative answer. This article was published by an international group of researchers, led by Robert DePalma of Manchester University, in the United Kingdom. In its article, DePalma and collaborators conclude that the beginning of the end of dinosaurs occurred on a spring-summer day approximately 66 million years ago. They base their conclusions on multiple evidence collected over several years at a site called Tanis, in North Dakota. that to point out that 66 million years ago the central part of the current territory of the United States was covered from north to south by an inland sea that connected with the Gulf of Mexico. The site in which DePalma and collaborators collected their evidence would have been located near the coast of that inland sea. According to the reference article, from the 13 minutes of the impact of the asteroid and over the next two hours, there was a rain of particles over the Tanis area, which was later buried with the flora and fauna of the place by the tsunami that followed it, together with the marine species dragged by it. From this mixture of animals and plants, terrestrial and marine, and preserved by sediments, was where DePalma and collaborators found the materials to carry out their research. They studied, for example, the bones of fish that showed that the characteristic bands that indicate the rate of growth of bones year by year, and even from season to season, were abruptly interrupted, suggesting that the death of the fish occurred during the spring and summer months. In addition, by means of a study of the pattern of carbon isotopes of fossil bones, which is related to food intake, the researchers concluded that the pattern of isotopes corresponds to the period of higher food intake, that is, the spring-summer months. The age of the youngest fossil fish found, and since spawning months are known, also indicates that their death occurred during spring-summer. Thus, it seems that dinosaurs found their destination on a spring-summer day 66 million years ago. We do not have the exact date of such an unfortunate event, but it is possibly irrelevant. More relevant is to know that it occurred during spring, given the dependence on many biological functions with the time of year and the consequences that a future event such as Chicxulub might have on life on Earth. Otherwise, it would have to be recognized that: 1) the event was unfortunate for dinosaurs, but not for us, because Chicxulub marked the beginning of the era of mammals, to which we belong, and 2) that it is not too much to maintain Watched our neighborhood looking for threatening asteroids.",
    "https://upload.wikimedia.org/wikipedia/commons/b/b8/Photovoltaik_Dachanlage_Hannover_-_Schwarze_Heide_-_1_MW.jpg": "Our energy future is undoubtedly centered on the Sun, which not only radiates the surface of our planet with a quantity of energy that is several thousand times more intense than we need for all our activities, but also constitutes a virtually inexhaustible and, in principle, non-polluting source of energy from the environment. Despite all its positive qualities, however, solar radiation has not been the source of energy that the world used to carry out the industrial revolution of the last two centuries which, as we know, has been primarily based on fossil fuels, first coal and then oil and natural gas. A fundamental reason for this to have happened is more or less obvious: it is easier to set fire to a fuel than to build a device to convert the energy of the sun into another more convenient form of energy. Of course, at the time it was not easy to build a machine that would use the heat produced by the combustion of coal to generate water vapor and move a mechanical piston that would boost industrial activity. More difficult, however, it was to devise and build a solar panel that would capture solar light and convert it into energy. This required sophisticated physical theories and the development of equally sophisticated technologies for the purification, treatment and handling of materials, which were not available until the middle of the last century. Moreover, apart from their positive qualities, solar energy has negative points. One of them is its dilution. That is, while the amount of energy that affects the entire surface of the Earth is enormous, the amount that affects a square meter of land is scarcely enough to light a medium-sized television - when the sun shines, of course. Thus, it is necessary to cover with solar panels a relatively large area for almost any practical application. In contrast, the energy contained in a fossil fuel is highly concentrated - it can even explode, as we know - and is easily transportable, in addition to being available at all times of the day. For all the above, it is not surprising that fossil fuels have taken the lead to solar energy. However, since the oil crisis of 1973 and given the growing problem of environmental pollution, solar energy has taken such an increasingly relevant role, to such a degree that In this regard, a report released on December 1 by the International Energy Agency (IEA) predicts that this year will end with an increase of 290 gigawatts in the global capacity for generating electricity by renewable sources, of which 160 gigawatts will correspond to solar energy. The increase in the capacity for generating electricity by solar energy in 2021 - 17 percent - would be unprecedented, and would be equivalent to 100 nuclear power plants such as Laguna Verde in the state of Veracruz. In the medium term, the IEA expects that in 2026 the capacity for generating renewable electricity will increase by 60 percent compared to its level in 2020 and reach a level equivalent to the current combined level of electricity generation by fossil fuels and nuclear energy. The increase in the installed capacity of renewable energy will be in spite of the increase in the costs of key inputs for the manufacture of solar panels and wind turbines, aided by the rise in the costs of fossil fuels. However, the AIE predicts that if the high costs of raw materials continue throughout 2022, the reductions in solar energy costs that have accumulated over the past three years could disappear.In one way or another, and despite their initial lag, solar energy has become a clean energy generation technology that will be key to combating climate change in the decades to come. However, the AIE warns that, even with the impressive speed at which it is growing, renewable energies would have to double their growth rate if the zero emission target of pollutants set for the middle of this century is to be achieved. Some efforts would therefore remain to be made.",
    "https://upload.wikimedia.org/wikipedia/commons/9/92/Plaguet03.jpg": "Trapped by the Covid 19 pandemic and in view of the prospect of a fourth wave of contagion by the omicron variant, which is announced will be more deadly than the previous ones, it may be necessary to remember, in a sad way, that epidemics of great proportions have been a constant in history. Let us think, for example, of the bubonic plague epidemic that decimated the population of Europe in the 14th century or, more recently, the so-called Spanish flu that produced a century ago between 20 and 50 million dead. Otherwise, the current pandemic has brought about changes that are expected to be permanent, just as it has accelerated others that were already underway. It is hoped, for example, that the so-called work at home will become more common, as would the virtual meetings of work and online purchases. It would also come less obvious changes. Namely, and by way of example, there would be a tendency for the model of air transport based on hubs -air ports of large proportions that concentrate air traffic and distribute it to smaller airports - to be replaced by a model of air transport based on hubs. traffic from point to point - not through a \u201chub\u201d - in order to limit the concentration of large crowds of people and avoid contagion. We would expect, of course, that an epidemic that ends with a substantial percentage of the population will lead to irreversible changes. In that sense, it is considered that the medieval epidemic of bubonic plague in Europe contributed to the end of the feudal regime and to the advent of the Modern Age. Taking into account all of the above, it is topical to comment on an article published this week in the magazine \u201cPast and Present\u201d, published by Peter Sarris of Cambridge University in the United Kingdom. In that article, Sarris refutes Merle Eisenberg of Princeton University and Lee Mordechai of the University of Maryland, who consider that the impact and significance of the epidemic known as Plague de Justiniano has been exaggerated by historians and that this epidemic was in fact \u201csimilar to one of our influenza outbreaks\u201d. It should be remembered that the Plague de Justiniano was a pandemic of bubonic plague that was detected for the first time in the port of Pelusio in the Nile River Delta in the summer of 541 C.E., and in less than a year it spread to Constantinople -today Istanbul-, from where it spread to the Middle East, Europe and North Africa. It should also be remembered that at that time Constantinople was the capital of the Roman Empire of the East, governed by Justinian I. As Sarris mentions in his article, a first-hand witness to the situation caused by the Plague of Justinian was the historian Procopius, who was present in Constantinople when he arrived at the epidemic. Procopius wrote his impressions in the work \u201cHistory of Wars\u201d, which was intended to relate the wars waged by Justinian. According to Procopio and other historians, at its most high stage, the epidemic claimed more than 10,000 victims per day, in a city of half a million inhabitants, half of whom had perhaps already succumbed by the disease. The same Emperor Justinian would have been sick, although he was able to recover. In addition to the accounts of first-hand witnesses, there are other evidences In this sense, Sarris mentions that, in a law of 544, Justiniano tried to impose limits on the wages of artisans and agricultural workers who \u201ctryed to take advantage of the shortage of labour due to the pandemic to obtain higher wages, or higher prices for the goods and services they offered.\u201d In another law of 544, \u201cJustiniano tried to prevent tenants of the Church\u2019s lands from negotiating lower incomes, while at the same time allowing the Church to rent land in perpetuity to promote the continuous cultivation of the land.\u201d Thus, according to Sarris\u2019 arguments, the Plague of Justiniano was far from being an intra-scendent flu and had a significant social and economic impact. As for our own pandemic, and aside from the changes that will inevitably leave us as an inheritance, we are considerably better equipped \u2013 in resources and knowledge \u2013 to defend ourselves; this, compared to those who suffered pandemics centuries ago. In that sense, we have advantages. to the maximum.",
    "https://upload.wikimedia.org/wikipedia/commons/6/6d/Telerobotics_image1_large.jpg": "On 2 September 2004, the exploration submarine Alvin plunged to a depth of 2,200 metres at the limit of the Juan de Fuca tectonic plate in the Pacific Ocean, opposite the coast of the North American state of Washington. As part of its activities, the submarine collected samples of marine fauna from the bottom of the ocean and brought them to the surface. To the surprise of the researchers who examined them, the samples included 38 specimens of molluscs of the species \u201cL. gordensis\u201d, which is characteristic of a site located at the limit of the Gorda plate, more than 600 kilometers south and 2,700 meters deep. The discovery was indeed surprising, since the site on the Juan de Fuca plate where the molluscs \u201cL. gordensis\u201d were found does not have the proper environmental conditions for its development. Indeed, it is known that this species thrives on the Gorda plate, in a place where there are so-called hydrothermal chimneys that provide the nutrients needed for its development. At the site where the 38 specimens of \u201cL. gordensis\u201d were collected, in contrast, The mystery was soon revealed: the specimens found in the Juan de Fuca plaque were not really typical of that place, but were taken there by Alvin that two days earlier made a dive into the Gorda plate, where it also collected samples of local fauna. It was then an oversight of the one who was in charge of cleaning Alvin\u2019s device to collect samples and left traces of the previous operation. Otherwise, in unloading the culprit, it should be added that no one thought that an organism could be taken to the surface from a depth of 2,700 meters, to be immediately submerged to 2,200 meters and finally brought back to the surface, and that it did not die in the process. The molluscs \u201cL. gordensis\u201d, however, were able to overcome all this abuse, apparently without harm, and travel between two isolated points in the bottom of the sea bearing extreme environmental conditions. The above serves as a starting point for us to comment on an article that appeared is week in the magazine \u201cBioScience\u201d where the possibility of interplanetary contamination is discussed, now that the This article was published by an international group of researchers led by Anthony Ricciardi of McGill University in Canada. The environmental conditions for an interplanetary journey are extreme and, indeed, humans and other higher organisms could not bear it unless they were heavily sheltered in an artificial environment within a spaceship. Although \u201cL. gordensis\u201d molluscs would not survive an interplanetary journey without adequate protection, their example shows us that there are organisms that can withstand amazing extreme conditions. And in that sense, it should be remembered that a study carried out in 2018 by Japanese scientists demonstrated the survival of a certain type of bacteria exposed for three years to space conditions outside the international space station. As Ricciardi and collaborators point out, \u201cThis result shows that it is feasible to transport living cells between Earth and Mars.\u201d Even if the probability of an interplanetary contamination was small, if it could have great consequences. In this regard, Ricciardi and collaborators comment that \u201cthe situation is similar to that of disasters\u201d. extremes, natural or technological - for example, an earthquake of large dimensions or the fusion of the nucleus of a nuclear reactor - which, although typically rare, have potentially unacceptable consequences that deserve unique safeguards.\"In any case, for specialists the invasion of a planet by foreign organisms would have consequences difficult to anticipate and the same could mean a major catastrophe. It would have caused us to worry if the invasion were to take place on a planet hundreds of millions of kilometers away. More we would have to worry if such an invasion occurred on our own planet, as the flow of microorganisms could occur on two tracks: from Earth to other planets, and from other planets to Earth; the latter to the extent that the return of spaceships sent to explore other bodies of the solar system is intensified. Thus, our best allies will be the harsh conditions of space that impose barriers to the flow of microorganisms. Barriers that we expect are high enough.",
    "https://upload.wikimedia.org/wikipedia/en/c/ce/Communion_book_cover.jpg": "Given the enormous number of planets with Earth-like conditions orbiting around stars in the vicinity of our solar system, many specialists consider that the development of intelligent life on extraterrestrial worlds must be something common. Indeed, over many years efforts have been made to detect radio signals sent by a technological civilization outside the solar system in order to alert us of its presence; without success so far, in an unfortunate way. What could be the physical aspect of the possible intelligent beings of other worlds? There are no elements on which we could base ourselves to venture a hypothesis about it. Certainly, there are not, for example, to support the diversity of physical aspects that we can appreciate among the parishioners of the interstellar canteen that appears in the film \u201cThe War of Galaxies.\u201d Among these we can see characters with large heads, without hair and with almond eyes, as well as others with heads that recall that of a reptile, or with a skull topped with a kind of double horns pointing upward. The pretension of \u201cThe War of Galaxies\u201d, of course, is only to serve. as entertainment and in no way present possibilities, with some scientific support, for the physical appearance that the hypothetical inhabitants of other worlds would have. In fact, almost all the parishioners of the canteen have a humanoid aspect, with two legs and two arms, besides maintaining an upright position, all characteristics that we cannot assure would have the natives of other solar systems, for which evolution could have taken a different path. Indeed, as the zoologist Arik Kershenbaum of the University of Cambridge in the United Kingdom comments in an interview appeared in the online publication \u201cQuanta Magazine\u201d last March: \u201cWe have four limbs only because we descend from a fish with four fins that came out of the water almost 400 million years ago. We could easily have had six limbs, or even eight, if the evolutionary history had been different.\u201d For the rest, while it is fascinating and fun to imagine the aspect that our interstellar neighbors would have in the assumption that they existed, the exercise does not cease to be simply a speculation. And it will not cease to be so until we have convincing information about it. In terms of interstellar news, however, not everything is negative - although not as spectacular as it is for extraterrestrials - if we are to consider an article published this week in the journal \u201cNature Communications\u201d by astronomer Siyi Xu of the NORILab research center of the National Science Foundation of the United States and geologist Keith Putirka of the State University of California. In that article, Putirka and Xu report the results of an investigation carried out to find out the chemical composition of planets in our interstellar environment. The planets that were the subject of the study no longer actually exist, but were at some point swallowed by their respective stars, disintegrating into their atmosphere. Thus, the chemical elements that made up a given planet were diluted in the atmosphere of the star that captured it, which thus became a \u201ccontaminated star\u201d with chemical elements other than hydrogen and helium that are his own. And in that sense, after studying the atmospheres of 23 contaminated stars, located within a radius of 650 light years around the sun, Putirka and Xu find some planets with chemical compositions similar to those of the rocky planets of our solar system. The composition of most of the rocky planets studied, however, is exotic and alien to our planetary environment. In fact, researchers had to create names to classify the unusual compounds they found. The stars around us can then host strange worlds: rocky planets different from those we find in our solar system. It is missing to find out if these worlds also harbor exotic forms of life, including intelligent life. Not necessarily with two legs and two arms.",
    "https://upload.wikimedia.org/wikipedia/commons/1/1b/Pizza_%284738720687%29.jpg": "According to the World Health Organization, while in 1980 108 million people in the world suffered from diabetes, in 2014 this number had quadrupled, reaching 422 million; that is, 8.5 percent of the world\u2019s adult population. In subsequent years the increasing trend continued and in 2019 the number of people with diabetes reached 463 million, representing 9.3 percent of the adult population. According to experts, the trend will continue in the future and it is expected that in 2045 almost 11 percent of adults will suffer from diabetes. Given the situation, diabetes is already a major public health problem and could become the biggest epidemic of the twenty-first century. As specialists explain, the increase in diabetes cases in the last half century is largely associated with changes in our diet, which has led us to higher consumption of so-called junk food, with the consequent increase in our rates of overweight and obesity. The prevalence of diabetes, on the other hand, is not uniform throughout the world and affects some countries more than others. It is interesting to mention the article published in 2017 by Paul Zimmet of Monash University in Australia in the journal \u201cClinical Diabetes and Endocrinology\u201d in which he mentions a diabetes prevalence study carried out in Mauritius in the Indian Ocean, in which they rose every five years between 1987 and 2015: They found that the prevalence of diabetes rose from 14.6 percent in 1987 to 23.6 percent in 2009, an increase of 60 percent in two decades. An interesting point that Zimmet notes, is that the trend in the growth of the disease was the same for the three majority ethnic groups in Mauritius: Chinese, South Africans and Indians in India, which would indicate that the trends observed in Mauritius could spread to China and India, which combine a good part of the world population.We would therefore be faced with an epidemic of global scope.In fact, as Zimmet says, both in China and India, the diabetes epidemic has grown rapidly. The prevalence of the disease has risen from one percent in 1980 to almost 10 percent in 2009. In line with this increase, Zimmet notes that McDonalds' restaurant in Tiananmen Square in Beijing, China, is one of the most active in the chain worldwide. An evidence that the consumption of junk food is one of the major causes of the diabetes epidemic is provided by the article published this week in the magazine \u201cJAMA Network\u201d, by a group of researchers headed by Rania Kanchi, from the University of New York. In their article, Kanchi and collaborators report the results of a study carried out in order to find out whether the availability of fast food restaurants in a given neighborhood has any influence on the probability that the inhabitants of the same one develop diabetes. For this purpose, they included a group of more than four million veterans of the U.S. Army scattered throughout the U.S. territory, not suffering from diabetes, and followed it throughout the period 2008 to 2016. This, to find out if they developed the disease, died or remained healthy throughout the study period. researchers found that a higher density of fast food restaurants in a given neighborhood leads to a modest increase in the risk of developing diabetes. In contrast, a higher density of supermarkets is associated with a lower risk of developing the disease in suburban and rural neighborhoods. The latter, presumably because a supermarket offers options to buy food that can be cooked at home for a healthier diet. Thus, either the density of fast food restaurants in the United States would have to be limited, or they would have to offer low options in fat, salt and sugar. Otherwise, regardless of the measures taken, and unlike other calamities that plague the world, we can individually take action to protect ourselves. And as a guide, we might perhaps remember what were the foods that were consumed half a century ago, and move back to the chatarrization of food.",
    "https://upload.wikimedia.org/wikipedia/en/f/fa/IPCC_Special_Report_on_Global_Warming_of_1.5_%C2%BAC.jpg": "Forced by climate change, the world has undertaken an energy change. Not with sufficient decision, however, according to the International Energy Agency (IEA). Indeed, in its \u201cEnergy Outlook 2001\u201d, the IEA considers that, with current energy policies, the increase in the temperature of the planet with respect to its pre-industrial value could reach 2.6 degrees Celsius at the end of this century. This value is well above 1.5 degrees Celsius, value that experts consider to be the maximum permissible to prevent a climate disaster.In addition, even with the cuts in greenhouse gas emissions promised by the countries of the world, it will be possible to limit global warming to 1.5 degrees Celsius.In these conditions, the IEA considers that it is necessary to implement more aggressive policies with a view to achieving a balance in 2050 between the volume of greenhouse gases emitted into the atmosphere and the volume of greenhouse gases removed from it, which would allow limiting the global temperature increase to acceptable levels. This includes the replacement of vehicles with internal combustion engines by electric vehicles, which we know is a process that is already underway. Indeed, there are car manufacturers that have set a date to stop producing vehicles with gasoline engines. On the other hand, mass electrification makes sense if the electric energy to be consumed is generated with a low atmospheric impact, without burning fossil fuels as it happens in a thermoelectric power plant. In this sense, the IEA considers that, among other measures, it is necessary to install two times more solar panels and wind turbines than those currently contemplated in the most ambitious plans. A second aspect considered by the IEA is the increase in energy efficiency; that is, to use less energy to do the same thing. In this sense, electrification contributes positively, as there are electrical devices that are more efficient than its counterparts that use fossil fuels. This is the case, for example, of electric cars, which - according to the IEA - use 70 percent less energy per kilometer travel than gasoline cars. The importance of this measure can be seen if we remember that methane is a greenhouse gas eighty times more powerful than carbon dioxide, although it has a shorter lifespan in the atmosphere. Finally, the IEA considers that innovation in clean energy generation technologies should be promoted in the present decade, even if the impact of this innovation only has an impact until the next few decades. All the technologies needed to achieve the emission reduction targets by 2030 are already available. It is not the case with the 2050 targets, for which technologies are currently in the development phase in order to achieve them in their entirety. For example, at night in the case of solar energy. The market for lithium batteries will then be enormous. In fact, in the projections of the IEA that market will have a growth in the coming decades several times bigger than the growth of other clean technologies, including those of solar panels and wind turbines. Thus, the world has entered a phase of energy change, that although it would not be happening at the desired speed, it would leave far away that time of energy waste - in the middle of the last century - in which we were not fully aware that, over time, with our waste, we would endanger the Earth\u2019s climate.",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Carbon_sequestration-2009-10-07.svg/530px-Carbon_sequestration-2009-10-07.svg.png": "As we know, the planet Earth is experiencing global warming as a result of the sustained increase in the concentration of greenhouse gases in the atmosphere. With regard to its pre-industrial revolution of two centuries ago, the temperature of the planet has risen by 1.1 degrees Celsius and experts predict that it will reach catastrophically higher values if corrective measures are not taken. Experts also predict that the increase in Earth\u2019s temperature will cause extreme weather events, which will be more frequent and intense as the global temperature is higher. And this year, with its wary of heat waves, droughts, hurricanes and torrential rains, has given them the reason. The Paris climate convention of 2015 established measures to reduce the emission of greenhouse gases into the atmosphere and limit the increase in global temperature to less than 2 degrees Celsius with respect to pre-industrial levels, at the same time that it would be sought that such an increase would not exceed 1.5 degrees Celsius. In follow-up to the Paris convention, and with the aim of accelerating actions to achieve the agreed goals, next month will take place in November. In Glasgow, Scotland, the United Nations Climate Change Conference (COP26). Like every year, the International Energy Agency (IEA) - founded in 1974 in the wake of the oil crisis and of which Mexico has been a member since 2018 - published its World Energy Outlook 2021, in which it reflects its prospects for the development of the global energy sector for the remainder of the century. On this occasion, the IEA advanced its annual publication as a contribution to the COP26 meeting. As the Executive Director of the IEA writes in the preface to the reference document: \u201cThis year\u2019s edition of the World Energy Outlook has been designed, exceptionally, as a guide for COP26. It clearly explains what is at stake: what the promises of reducing emissions made by governments so far mean for the energy sector and climate. And it makes clear how far these announced commitments should be extended so that we have a good chance of limiting global warming to 1.5\u00b0C and avoiding the worst effects of climate change.\u201d IE that the countries as a whole have made sufficient commitments to tackle global warming and that greater commitments and actions are necessary for this purpose. In its \u201cWorld Energy Outlook\u201d, the IEA considers three possibilities or scenarios for the development of the energy sector and its impact on the global climate in the remainder of the century. A first scenario assumes that the energy policies of the countries of the world will remain in their current state, which would lead to an increase in temperature of 2 degrees Celsius in 2050 and 2.6 degrees Celsius in 2100. In a second scenario, these policies will be modified in accordance with the commitments made by the countries, and with this the increases in temperature in 2050 and 2100 will be 1.8 degrees Celsius and 2.1 degrees Celsius, respectively. Finally, in a third scenario, greenhouse gas emissions will be reduced gradually until a balance is reached between greenhouse gases emitted and removed from the atmosphere in 2050. In this latter scenario, the increase in global temperature would reach a maximum value of 1.5 degrees Celsius in 2030, which would be maintained approximately In this way, even with the current commitments to reduce greenhouse gases, the increase in the global temperature of 1.5 degrees Celsius would not be limited with respect to the pre-industrial level - besides, of course, that these commitments are not binding and in this regard it would be necessary to remember that the United States withdrew from the Paris agreements at the initiative of the previous US administration. Thus, according to the World Energy Outlook 2021, in order to maintain the increase in temperature to a maximum of 1.5 degrees Celsius with respect to its pre-industrial value, a target of zero net greenhouse gas emissions would have to be set in 2050. And to achieve zero net emissions, since eliminating fossil fuels completely is not possible, it will be necessary to develop means to remove greenhouse gases from the atmosphere and thus balance those that will inevitably be emitted.",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Dszpics1.jpg/640px-Dszpics1.jpg": "Let us hope that the extreme weather events of last summer have convinced the skeptics that global warming is something real - otherwise there is probably no hope that they will one day come to be convinced. As we know, in the past months the planet suffered numerous extreme weather events of such magnitude that experts consider to be an unequivocal manifestation of global warming. These events included: a heat wave with record temperatures that caused the death of more than 500 people in British Columbia and in the north-west of the United States, torrential rains in Western Europe and China that resulted in more than 200 deaths in Belgium and Germany and more than 300 deaths in the Chinese province of Henan, and huge forest fires in the west of the United States and Canada, where the people of Lytton in British Columbia were destroyed in 90 percent by fire. Last summer\u2019s weather events also included huge fires in Yakutia, a region of northern Siberia, which would have destroyed six million hectares of forests. Yakutia\u2019s fires reached such a magnitude that smoke would have reached the north pole, about three of them. More recently, last September, the city of New York was flooded by the effect of Hurricane Ida. We know that global warming is being caused by the sustained increase in the concentration of greenhouse gases in the atmosphere since the beginning of the industrial revolution at the end of the 18th century. The most relevant greenhouse gas is carbon dioxide, a product of burning fossil fuels. This gas, however, is not the only one we can blame for global warming and in this sense methane occupies the second place. Indeed, while the concentration of methane in the atmosphere is about two hundred times smaller than that of carbon dioxide, as greenhouse gas methane is about 80 times more powerful. Thus, experts estimate that 30 percent of the increase in global temperature since the industrial revolution is due to the increase of methane in the atmosphere. In addition to the above, compared to carbon dioxide, it is estimated that the concentration of methane in the atmosphere is growing at a faster rate and that since the beginning of the industrial revolution has risen about 2.5 times. half of the methane emissions to the atmosphere originate in human activities, mainly activities related to agriculture and food production, waste management, and fossil fuel extraction. In these conditions, given the growth of the world population and its standard of living, some specialists consider that it will be problematic in the future to stop growth in methane emissions to the atmosphere. Given this situation, mitigating the greenhouse effect of methane would require it to be removed from the atmosphere in order to reduce its concentration in the atmosphere. An article published this week in the magazine \u201cPhilosophical Transactions A\u201d discusses the benefits that such extraction would have for the planet\u2019s climate. The article was published by a group of researchers from the United States and the United Kingdom, headed by Sam Abernethy from Stanford University. According to the study by Abernethy and collaborators, reducing by 40 percent the methane in the atmosphere would reduce global warming by 0.5 degrees Celsius in 2050. To appreciate this last, it should be remembered that today the temperature of the planet is about 1.2 degrees above. This, of course, in the case of efficient methods to carry out such extraction, which for the time being does not seem to be true. Thus, at least for the next few years, we will probably have to get used to extreme weather events.",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/a/ac/Photos-photos_1088103921_Floating.jpg/640px-Photos-photos_1088103921_Floating.jpg": "As we know, the seeds of some plants are designed to travel large distances carried by the wind, which makes it possible for a sedentary plant to reproduce in places far from the place where it is immobilized. Somehow, such seeds can be conceived as biological devices optimized for travelling in the air, which were developed by nature through the natural selection mechanism. Given the great engineering experience of nature, it is natural to try to copy their designs to build artificial devices with specific functions. For example, there are initiatives to build computing devices based on the organization and functioning of the human brain, which is a highly complex and efficient \u201cdevice\u201d that nature has managed to develop over millions of years of evolution. An article appeared this week in the magazine \u201cNature\u201d gives us another example in this regard: the development of tiny devices that can remain suspended in the air for long periods and travel large distances. The reference article was published by a large group of researchers attached to institutions in South Korea, the United States, China and the United Kingdom, headed by Bong Hoon Kim. , from Soongsil University in South Korea. The design of the devices reported by Kim and collaborators, in terms of their traveling ability, is inspired by the aerodynamic design of the flying seeds of sedentary plants. Unlike these, however, their purpose is not to transport genetic material, but to perform a series of functions, from measuring atmospheric pollution to controlling the spread of diseases. Specifically, Kim\u2019s devices and collaborators, some with the size of a grain of sand, are largely based on the seeds of the plant \u201ctristellateia\u201d, which are star-shaped and have the ability to keep floating in the air for a long time, slowly descending with a rotation movement in the form of the blades of a helicopter. Imitating to the natural seeds, the flying chips are shaped like a three-point star, carefully designed so that they can remain in the air for a long time in a stable way. In the center of the chip can be placed various microcomponents, including an electronic microcontroller, an electronic memory for Kim and collaborators imagine swarms of flying chips thrown from an airplane at high altitudes that descend slowly with a movement stabilized by their rotation, which would allow them to disperse into large areas of the ground by performing functions such as measuring air pollution, studying the dispersion of pathogens, or performing surveillance observations.All this at a reduced cost compared to traditional methods.Dispersing large quantities of flying chips into the atmosphere, of course, would mean generating a source of pollution that would increase the pressure on our already grounded environment.In this regard, Kim and collaborators recognize the problem and mention in their article that they are working to develop chips that can degrade over time and integrate into the environment.This, however, would still be to be seen.Kim and collaborators, on the other hand, mention that, as far as their ability to keep flying, their chips have surpassed the designs of nature, while they were able to build flying chips with smaller sizes than seeds.Kim and collaborators, on the other hand, mention that, as far as their ability to keep flying, their chips have surpassed the designs of nature, at the same time that they were able to build flying chips with smaller sizes of seeds. All this despite the fact that it took nature hundreds of millions of years to develop them. Thus we have an irrefutable demonstration that science works. As often as it is questioned.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d0/ActionStoriesVol16No1.jpg": "In the popular culture cavemen are often represented grunts and with a grown beard, sometimes armed with a stone axe -like Trucut\u00fa in the comic strips of the fifties of the last century-, others with a stick on their shoulder, but always dressed in animal skins. On the other hand, in the recreation of life in prehistory, periods often overlap that are actually separated by tens of millions of years, at best. For example, in the film \u201cThe Caveman\u201d, released in 1981, we can see Ringo Starr and his companions running disheartened to be safe from the attack of a cardboard dinosaur. The film presents us this scene no matter how much dinosaurs have disappeared when our species still lacked more than sixty million years to be present on the surface of the planet. Otherwise, while it would be expected that cavemen, given their troubled life, will always show themselves grunted and bearded, it is not clear when it is present on the surface of the planet. This article was published by a group of researchers headed by Emily Hallett of the Max Planck Institute in Jena, Germany. In their article, Hallett and collaborators described the finding of bone tools in the \u201cCave of the Smugglers\u201d, an archaeological site located about 250 meters from the Atlantic coast of Morocco. Researchers explored this cave with the aim of finding out what was the diet of its primitive inhabitants 90,000-120,000 years ago. For this purpose, they collected bones of animals found inside to determine which species they corresponded to and whether they had been used as food. In their research, Hallett and collaborators found bones of animals that effectively showed signs of having been part of feeding the inhabitants of the cave. At the same time, however, they found bones that had been carefully carved with the clear purpose of making tools. Researchers speculate that these tools, in the form of a spatula with rounded ends, began to dress with animal skins. This conclusion is reinforced by the fact that in the cave bones were found with marks that did not correspond to the typical marks found in the bones of animals slaughtered for food purposes. And yes, on the contrary, consistent with the purpose of removing in a single piece the skin of the animal. Thus, Hallett and collaborators found evidence that 100,000 years ago our ancestors already used clothing, and in this sense the question arises: what was it that prompted the inhabitants of the Cave of the smugglers to cover their body? Certainly, given the thinness of human skin, an animal skin cover would have provided protection against low temperatures. However, the experts point out, this is valid for the cold climate of northern Europe, it is less so in Morocco, where the temperature was more moderate.In these conditions, a second question arises: would the inhabitants of the Cave of the smugglers have dressed simply for the taste of doing so and walking well presented? This is, of course, a fascinating question for which a second question arises: Unfortunately at the moment we have no answer. Experts note, however, that the introduction of the dress into prehistory coincides with the appearance of personal ornaments with seashells, which clearly do not have a practical purpose. It is therefore open the question of whether the fashion in the dress is older than we would have imagined, and if it has an age of at least 100,000 years. Hallett\u2019s results and collaborators, on the other hand, support the popular image of the caveman dressed in skins. This, at least with regard to the cavemen who lived for some 100,000 years to date. There is no support, on the contrary, for scenes of cavemen fighting or fleeing from more or less real dinosaurs. With the exception, for other reasons, of the film \u201cThe Caveman\u201d, which is very funny.",
    "https://upload.wikimedia.org/wikipedia/commons/8/8c/PompeiiStreet.jpg": "The morning of August 24, 79 C.E. - although, according to other versions, it could have been a couple of months later - the life of the Roman cities of Pompeii and Herculano reached an abrupt end. As we know, that day the Vesuvius erupted burying the two cities under a thick layer of volcanic material. At the event an undetermined number of its inhabitants intoxicated with poisonous gases died. And those who did not die had to flee without the possibility of returning. Having an abrupt end, buried by volcanic material, Pompeii and Herculano were frozen in time, and in that sense it was a fortunate event, as it provided us with a \u201cphotograph\u201d of the way of life in Roman cities two thousand years ago. Of course, the inhabitants of Pompeii and Herculano would not agree that the eruption of Vesuvius and the abrupt end of their cities had been fortunate, even though, in some way, they had been immortalized. In time and trying to mitigate the catastrophe of Pompeii and Herculano with our knowledge of vulcanology, we must get the most out of the lucky/unfortunate event.In this spirit, an article appeared last August 25 in the magazine \u201cScience Advances\u201d provides us with detailed information about the food consumed by the inhabitants of Herculano during the time of the catastrophe. The article was published by an international group of researchers led by Silvia Soncin of the University of New York. The study was carried out with 17 skeletons of inhabitants of Herculano, 11 men and 6 women, which constitute a sample of 340 skeletons that were found in nine stone warehouses lined up in front of the beach. The victims would have come so far to protect themselves from the pyroclastic flow of the volcano. As Soncin and collaborators argue, \u201cThis remarkable group of victims of a natural catastrophe is not only of great public interest, but also offers an opportunity to advance substantially in our knowledge of Roman society by applying bioarchaeological approaches. Instead, the skeletons of Herculano provide an \u2018instantane\u2019 of an ancient population that is rarely offered in archaeology.\u201dSoncin and collaborators proposed to find out the diet of the inhabitants of Herculano from an analysis of carbon and nitrogen isotopes in the collagen of the victims\u2019 bones. Interestingly, researchers find clear differences between diets followed by men and women. Thus, compared to men, Soncin and collaborators find that women in Herculano obtained less percentage of proteins that consumed cereals and seafood, and relatively more from animals and land products, including meat, eggs and dairy products. What is the reason for the differentiation of diet between men and women? Soncin and collaborators do not offer a definitive explanation in this regard, but as regards the increased consumption of seafood by men, they note that they had greater contact with the sea - as fishermen - than the fishers - than the fishers. Also, researchers point out, men generally occupied more socially privileged positions compared to women, and were released from slavery at a younger age than women. All this would have provided men with greater opportunities to obtain higher-priced food. Pending a more solid explanation, Herculano\u2019s \u201cinstantane\u201d provided by Vesuvius clearly shows an asymmetry in the feeding of men and women. And while at present this might prove to some extent surprising, it should be noted that in Roman society, where slavery was practised, such asymmetry would not have been noticed. What is highly surprising is that, even taking into account the help of Vesuvius, such detailed information about the dietary customs of a Roman city that disappeared two thousand years ago has been obtained.",
    "https://upload.wikimedia.org/wikipedia/commons/5/5e/Protonshower.jpg": "An article that appeared this week in the magazine \u201cSpace Weather\u201d discusses possibilities to turn around one of the multiple obstacles that astronauts would face from a hypothetical mission to the planet Mars: high-energy radiations that permeate space. This article was published by an international group of researchers led by Mikhail Dobynde of the Skolkovo Institute of Science and Technology, in Moscow, Russia. On Earth we are protected from radiation from space by the Earth\u2019s magnetic field. In contrast, in the course of a trip to Mars astronauts would not have this protection. An exposure of the traveler to such radiations beyond a certain limit could cause cancer and eventually death. It is known that astronauts from a future manned mission to Mars would face two types of high-energy radiations: cosmic rays from interstellar space and radiations generated by the activity of the Sun, whose intensity varies periodically following a cycle of eleven years. In the past, the duration of missions to the Moon of the Apollo program was measured in days, and the risk that the astronauts ran by the Sun, whose intensity varied periodically following a cycle of eleven years. By contrast, the duration of a mission to Mars is measured in years, which substantially increases the risk of radiation from space. The ship that would transport the crew members of a hypothetical mission to Mars would then have to be adequately protected against the radiations of space. How to protect themselves from these radiations is the topic addressed by Dobynde and collaborators in the above-mentioned article. As Dobynde and collaborators point out, the solar radiations to which astronauts would be exposed on their journey to Mars would grow and decrease in accordance with the maximum and minimum of solar activity. On the contrary, the intensity of cosmic radiation that they would experience would decrease as the activity of the Sun increased and increased when it decreased; this, by the effect of the solar wind. Cosmic radiation, on the other hand, contains higher numbers of particles of very high energy compared to solar radiation that is composed mostly of particles of lower energy.Based on everything above, and taking into account that it is more difficult to protect themselves from particles of higher energy - since it would more easily penetrate the shielding of solar radiation. Dobynde and collaborators determine, from computer calculations, the best moments to carry out the trip to Mars. Thus, such a trip must begin during a maximum of solar activity, when the intensity of cosmic radiation is less. Moreover, according to the calculations of the researchers, even with these precautions, the total duration of the journey to and from Mars should not exceed four years. They also establish that the next two dates to undertake a manned trip to Mars are the years 2030 and 2050. Dobynde and collaborators also calculate what the thickness of the aluminium shielding of the spacecraft would be. We might think that the greater the thickness, the greater the protection. This, however, is not entirely true, because absorbing in the shielding the radiation of high energy would produce a secondary radiation that would penetrate inside the ship, increasing the radiation absorbed by the astronauts. Thus, the thickness of the shielding should be large enough to protect the interior of the ship from the Sun's radiations, without exceeding, however, a certain value to minimize Dobynde and collaborators offer recommendations to minimize the exposure to high-energy radiation of the crew members of a future mission to Mars. They conclude that, while space radiation imposes strict limitations and presents technical difficulties, a manned mission to Mars is still viable. Otherwise, we might conclude that plans - which are occasionally publicized - about an imminent manned trip to Mars are only publicity tricks or public relations; and that if such a trip is made, it will not take place in the near future. After all, space radiation is completely alien to our natural habitat.",
    "https://upload.wikimedia.org/wikipedia/commons/7/70/Student_during_Coronavirus_in_Mexico_%28cropped%29.jpg": "Should children return to face-to-face classes on 30 August or if they fail to continue their education remotely? As we know, this is something that has been discussed intensely in recent days. On the one hand, it is argued that without face-to-face classes children are deprived of contact with other children and other people, with negative consequences for their education and psychological development. On the other hand, those who oppose face-to-face classes point out that this would endanger their physical health, given the wave of contagions caused by the new strain of coronavirus. It should be recognized that critics of the return to school do not lack the reason, if we take into account that the vaccination programme in our country has not progressed at the speed we would have desired. Thus, according to data from Johns Hopkins University, only 22.5 percent of the population in Mexico is completely vaccinated. On the other hand, leaving aside the obvious negative consequences that would have for the education of children to not return to face-to-face classes, it is necessary to ask that so much reason to those who claim that the lack of social contact in Mexico is completely vaccinated. This article, in which the development of cognitive abilities of children in the early years of their lives is being studied, but which has not yet been through a peer review process, was published by a group of researchers from American institutions headed by Sean Deoni from Brown University in Rhode Island. Deoni and collaborators report the results of a study carried out to determine to what extent the social isolation forced by the coronavirus pandemic has affected the cognitive development of children. They write in this regard: \u201cThe human brain is unique in its line of time of prolonged development. Babies are born with relatively immature brains which, like them, are both competent and vulnerable. Babies are inherently competent in their ability to initiate relationships, explore, seek meaning and learn; but they are vulnerable and depend entirely on caregivers for their survival, emotional security, behavioural modeling and the nature and rules of the physical and socio-cultural world in which they inhabit. , the infant brain is born with an immense capacity to learn, remodel and adapt, but is sensitive and vulnerable to abandonment and environmental exposures that begin even before birth. The adaptive plasticity of the brain, however, is a double-edged sword. While positive and enriching environments can promote healthy brain development, neglecting insecurity, stress and lack of stimulation can damage mature brain systems and alter cognitive and behavioral outcomes.\u201d The Deoni et al. study was carried out as part of a 2011 program that aims to study the development of cognitive abilities of children during their early years of life. This allowed them to compare the development of children born during the pandemic with the development of children of the same age born before it. They considered 672 children from the Rhode Island state area, predominantly Caucasian. They found that those born during the pandemic months showed motor skills and verbal and nonverbal communication that were significantly lower than those born before the pandemic. They attributed this result to the lack of encouragement to children, both because of isolation. They find, moreover, that children with lower economic levels are more affected by the greater degree of stress to which their parents are subjected. If Deoni and collaborators are right \u2013 one should remember that his article still has to go through a peer review \u2013 the pandemic, even without infecting them, can affect the cognitive development of children in their early years of life. And he will tend to do so more in the lower their socio-economic level. One more example of the inequity of the world. In other words, the leanest dog is burdened with fleas.",
    "https://upload.wikimedia.org/wikipedia/commons/e/e6/Fuelcell.jpg": "The Sun is, without doubt, the natural source of energy that we should use to move the world: it is practically inexhaustible and more than sufficient to fully satisfy our energy needs, in addition to being, in principle, to our entire availability. It was not, however, the first source of energy that our ancestors used and, in fact, we have only begun to take advantage of it until very recent times. To be precise, this latter is not strictly true, since the predecessors of our species learned to control fire hundreds of thousands of years ago, they made use of plant fuels that ultimately had a solar origin \u2013 through the photosynthesis process. Likewise, the coal that drove the Industrial Revolution two centuries ago, and subsequently the oil and natural gas, had a plant origin, and ultimately solar. However, if we do not consider applications such as the one that Archimedes supposedly carried out more than two thousand years ago in Syracusa, destroying enemy ships by means of a giant mirror that concentrated the sunlight, the systematic use of the Sun's energy has only been given in the last half century. In the past, there were no technologies needed to efficiently harness this energy, perhaps beyond its use to heat living spaces. At present, solar energy can be used by concentrating it - in Archimedes' way - on a fluid to reach temperatures of hundreds of degrees Celsius. The hot fluid is subsequently directed to a turbine, which in turn moves to an electricity generator. Thus, it is possible to convert, in two steps, solar energy into electric energy. Alternatively, solar energy can be converted directly into electrical energy by means of photovoltaic panels; application that, as we know, is becoming increasingly popular. Despite all its virtues, however, the Sun's energy is marked by an original sin: it is intermittent, following the cycle of day and night. This makes it necessary to have a means of storing energy generated throughout the day to use it at night, which has been one of the weaknesses of solar energy, for which there are increasingly competitive generation devices, but storage means with comparatively less development. It is the hydrogen that, as we know, is a fuel gas that reacts chemically with oxygen generating water. There is currently an interest in developing hydrogen production technologies using solar energy, which would allow the excess energy present during the day to be used to generate hydrogen for consumption in hours of the night. Since hydrogen combustion does not involve carbon, greenhouse gases are not generated, which is beneficial for the environment. It would thus have a system to generate and store energy, which would be environmentally friendly. On the other hand, a system with these characteristics would have to be economically competitive and its manufacture would not be easy. In this context, an article appeared this week in the journal \u201cNature Communications\u201d in which advances are described in the development of a cell to obtain hydrogen and oxygen from water. The article was published by a group of researchers from the United States and China headed by Soonil Lee from the University of Texas. We know that the water molecule is made up of two hydrogen atoms and one of oxygen and the device Lee and collaborators has the An interesting aspect is that the materials used in Lee\u2019s cell and collaborators have been developed by the electronics industries and solar cells, in particular silicon, which is the basis of more than 90 percent of solar panels. The structure of Lee\u2019s cell and collaborators, in addition, reminds us of that of a solar cell. On the other hand, the technology they employ is relatively simple and potentially low cost. A device such as that they seek to develop Lee and collaborators then points in the direction of a non-polluting solar energy, available during the day and night, and economically competitive with other forms of energy generation. And with these perspectives, for the sake of the planet, let us hope that these are not too good to be true. Otherwise, what we can be sure about is that the Sun\u2019s energy is inexhaustible and that its original sin is \u201cminute fish\u201d.",
    "https://upload.wikimedia.org/wikipedia/en/1/11/2001_A_Space_Odyssey_%281968%29.png": "If you have an adventurous spirit and you like strong emotions, and you also have 17,500 euros to overtake, you might be interested in the offers of flights to the stratosphere promoted by the agency Mig-Flug - easily reachable on the Internet. For this amount, Mig-Flug offers flights in a MiG-29, a Russian-made fighter capable of travelling at a speed 1.7 times the speed of sound. During the flight, the plane will reach a maximum altitude of 17-22 kilometers, from which you will be able to verify that the Earth is indeed round. You will also be able to verify that the space is black, although covered with stars, even during the day. To make it more attractive, you will experience during the flight accelerations equivalent to 8 times the acceleration of gravity, and the maneuvers and pirouetas of a fighter plane. For the most daring, it is possible that a flight that only reaches a height of 20 kilometers is not sufficiently exciting, in which case you could consider the suborbital flights of the companies \u201cVirgin Galactic\u201d and \u201cBlue Origin\u201d. an obstacle to making use of these opportunities: the cost of the ticket, which is about $250,000 in the case of Virgin Galactic. In the case of Blue Origin, the cost of the flight, eleven minutes in total, would appear to be tens of millions of dollars. So, unless we are multimillionaires, we would have to stay with the desire to travel to space. Virgin Galactic and Blue Origin are two companies interested in developing space tourism and suborbital trips of the last weeks were widely publicized for this purpose. There are also companies interested in tourism at the orbital level and even beyond. For example, the company \u201cOrbital Assembly Corporation\u201d intends to build a hotel in a terrestrial orbit, which has been called \u201cVoyager Station\u201d, and which would be completed in the year 2027. The Voyager Station hotel, whose project can be consulted on the Internet, will consist of two concentric rings, the largest with a diameter of 200 meters, joined by tubes in the form of bicycle wheel rays. It will have 11,600 square meters of living space, which includes individual suites. The facilities also include a gymnasium, a bar and a restaurant. The structure will be maintained in rotation - such as the double ring structure that appears in the 2001 film Space Odyssey directed by Stanley Kubrick-, in order to generate a gravity of one sixth of the land, so that a person weighing 72 kilograms would weigh only 12 kilograms in the hotel. The hotel will also have a zero-gravity area - in the center of the structure - so that guests can experience weightlessness. With all these amenities, it is not difficult to conclude that the Voyager Station hotel will be one of super luxury, which will be at the disposal of an extremely small number of inhabitants of planet Earth. For this last reason, as well as other considerations, spatial tourism development projects are subject to much criticism. For example, in an online article published on the site \u201cThe Conversation\u201d, Eloise Marais, of the \u201cUniversity College London\u201d, notes that the burning of the fuels used for space tourism. To encourage space vehicles to pollute, both the lower layers of the atmosphere and the stratosphere. Blue Origin uses as hydrogen fuels and liquid oxygen, which in reacting produce water vapor, which negatively affects the Earth\u2019s climate, while Virgin Galactic uses fuels that generate carbon dioxide, nitrogen oxides and carbon particles. According to Marais, the effect that all of these pollutants have on the Earth\u2019s climate is uncertain and more studies are necessary to clarify it. However, Marais points out, we know that two thirds of the combustion gases are expelled at heights between 12 and 85 kilometers, where they contribute to destroying the ozone layer that protects us from ultraviolet radiation. We also know that the gases expelled by space vehicles are atmospheric pollutants that contribute to global warming. The same re-entry of spaceships into the atmosphere that produces high temperatures causes the nitrogen of the air to combine with the oxygen to generate nitrogen oxides. Thus, subject to a detailed study of the effect of space tourism trips on the planet\u2019s climate, it does not seem to lack the reason for those who think that that the interest of the owners of space companies, and of the few billionaires with the ability to make tourism, should not prevail over the interest of the vast majority of inhabitants of this planet. Although the rich have to conform to more emotions of this world.",
    "https://upload.wikimedia.org/wikipedia/commons/7/78/Polar_Bears_Fight_Climate_Poverty_2.jpg": "While in the area of environmental pollution no one is entirely blameless, and in that sense we are all equal, it is also true that, recalling George Orwell, some are more equal than others. Indeed, we have to, speaking in terms of territorial extension, 90 per cent of greenhouse gases, which are responsible for global warming, are generated in less than 8 per cent of the Earth\u2019s surface; to a large extent in industrialized countries. Thus, as polluters, some are indeed more guilty than others. On the other hand, although greenhouse gas emissions are concentrated in certain places - large urban centres, industrial areas and oil extraction areas, among others - their influence extends throughout the planet. In these conditions, there are regions of the world that suffer air pollution despite having done little to generate it. To what extent does the emission of greenhouse gases in localized regions of the world affect the rest of the planet? An article appeared this week in the magazine \u201cScience Advances\u201d illustrates us in this regard. This article was published by a group of researchers headed by Kyle Van Houtan of Monterey Bay Aqua. A positive index indicates that the increase in temperature in the site considered is greater than would be expected given its local generation of greenhouse gases, while a negative index indicates what is expected in California. Van Houtan et al. carried out a study to determine the relationship between the generation of greenhouse gases in a specific place on the planet, and the resulting increase in temperature. Between atmospheric pollutants they considered carbon dioxide, methane, nitrogen oxide, and carbon particles, the main greenhouse gases. It should be noted that the emission of these pollutants is concentrated in the northern hemisphere, mainly in Western and Central Europe, China, Japan, Korea, northern India, and the northeastern United States. To carry out their study, Van Houtan et al. constructed an index that reflects the disparity, at a given location, between the emission of greenhouse gases and the average increase in temperature expected over a period of 50 years. The results obtained by Van Houtan and collaborators are interesting. They find, for example, that in the period between 2050-2099, 99 percent of the planet's surface will have positive disparities. This will be particularly high in the Arctic regions and in northern countries such as Canada, Russia and Finland. But also in countries of Central Asia, northern Mexico, Bolivia, Peru and the Amazon region. They will also have positive indices in countries of northern and southern Africa, and much of Australia. In contrast, the industrialized regions of Europe, Asia and North America will have negative disparities, mainly due to their high levels of pollutant emissions. Van Houtan's study and collaborators show us fine details of something that we already knew from the start: while greenhouse gases are generated mainly by the industrialized world, their effects extend to the whole planet, affecting non-industrial countries. It is clear that a given increase in temperature in a country with few resources will have an amplified effect, compared to the same increase in an industrialized country. Thus, anywhere we see it, global warming will have a higher cost for countries with less resources. By paying in this way just for sinners. Or what is the same, the leanest dog will be charged fleas.",
    "https://upload.wikimedia.org/wikipedia/commons/f/f2/Change_in_Average_Temperature.png": "Was it the heat wave that hit the northwest of the United States and southwest of Canada last week and that produced hundreds of deaths as a result of global warming? Perhaps we would be tempted to assume that this was the case, given that all the record high temperatures in that region of the world, including Washington and Oregon states in the United States and British Columbia in Canada, were broken \u2013 and by far \u2013 the extreme case in this regard was the people of Lytton in British Columbia, which recorded a temperature of 49.6 degrees Celsius on 29 June, a record that set a record for the entire Canadian territory. Moreover, to the misfortune of its inhabitants - about 250-, the high temperatures combined with a dry environment caused a fire that broke with 90 percent of the town's constructions. It should be noted, however, that experts are cautious about associating a particular climate phenomenon to global warming. This can only be established, with some security \u2013 never absolute \u2013 after a rigorous analysis of the climate phenomenon in question. The WWA initiative is an international effort to analyse and communicate the possible influence that climate change has on extreme weather events, such as storms, extreme rains, heat waves, cold waves and droughts. The WWA initiative produces quick reports with scientific support, on extreme weather events and their relationship to climate change. This, in order to minimize their social, economic and environmental impact. As WWA states on its website, the analysis of an extreme climate event is done in an accelerated manner in order to provide quick answers to questions such as how likely a similar event is to occur in the near future, and thus to influence those who make decisions on future climate disaster mitigation measures.What are the conclusions of the WWA study on last week\u2019s climate event? Researchers venture that it may have been an extremely rare phenomenon, which only occurs when decisions are taken on future climate disaster mitigation measures? If that were the case, the inhabitants of Oregon, Washington, and British Columbia \u2013 and particularly those of Lytton \u2013 would have run with very bad luck. WWA\u2019s study, however, also concludes that global warming made it 150 times more likely that a climate event similar to last week would have occurred. That is, without climate change such an event would have occurred only once every 150,000 years. Or what is the same thing, would never have happened in practical terms. An extreme climate event that occurs once every 1,000 years may not be cause for concern about any more disasters that might occur. Unfortunately, with the growing pollution that is experiencing the atmosphere of our planet, the likelihood of a climate phenomenon like last week\u2019s occurrence is equally increasing. To be precise, as we know, the temperature of the planet has increased by approximately 1.2 degrees Celsius since the beginning of the industrial revolution by the emission of greenhouse gases into the atmosphere and it is expected that such an increase will rise to 2 degrees Celsius in 2040 when such an emission is not moderated. Once this temperature is reached, the study will be conducted once every 1,000 years. WWA estimates that a climate event similar to last week will occur every 5 to 10 years. In addition, the temperatures that would be reached would be 1 degree Celsius. Researchers conclude that their results are cause for alarm and that the rapid warming of the planet is leading us to an unknown territory, with significant consequences for our health, well-being and sustenance. Thus, the world will have to prepare to live a future that is possibly different from the present that we had to live.",
    "https://upload.wikimedia.org/wikipedia/commons/e/ee/Peking_Man_Skull_%28replica%29_presented_at_Paleozoological_Museum_of_China.jpg": "In September 1941, the fossils of the so-called Beijing Man were packaged in two boxes to be transported from China to the United States on board the American ship President Harrison. As we recall, the Beijing Man, with an age of 500,000-250,000 years, was discovered in the decade of the twenties of the last century. At the time, he enjoyed great celebrity as a \u201clost link\u201d that demonstrated Darwin\u2019s theory of evolution. The determination to send those fossils out of China was intended to save them from the hostilities of the Chinese-Japanese war, in progress since 1937. Fossils, however, never reached their destination and disappeared without leaving a trace. Were they stolen by the Japanese on the way to the port where they would be embarked on to the United States? Were they taken away by the American sailors who would have transported them to their final destination? Or, did the vehicle transporting them on Chinese territory have been assaulted and stolen by thieves without the slightest idea of the scientific importance of fossils and simply discarded them? To the extent that they are not finally located, there is no way to find a safe answer and the disappearance of the Beijing Man is immersed in the most absolute mystery, which could certainly give material for a film. To the previous story is added another, also of fossils discovered in Chinese territory, which could also provide material for cinema. This second story revolves around a fossil of the homo genus, a surprisingly well preserved skull and with an antiquity of hundreds of thousands of years, which is the subject of three articles published this week in the magazine \u201cThe Innovation\u201d, by researchers in institutions in China, Australia and the United Kingdom. This second fossil, indeed, has a peculiar story, which is related in one of the above mentioned articles: \u201cHarbin\u2019s skull reported in this document was allegedly discovered in 1933. A man (maintained in anonymity by his family), who worked for Japanese occupants as a construction contractor, discovered the skull when his team of workers was building a bridge for Japanese people near Harbin City in northeastern China. was clever and realized the potential value of the discovery, probably because the discovery of Beijing Man\u2019s first skull in 1929 had attracted great interest in China. Instead of passing his skull on to his Japanese boss, he buried it in an abandoned well, a traditional Chinese method to hide treasures. After the establishment of the modern Chinese republic, man returned to agriculture and did his best to hide his experience as a labor contractor for Japanese invaders. The skull remained unknown to the public and science for decades, but survived the Japanese invasion, civil war, the communist movement, the cultural revolution and the unbridled fossil trade in recent years. The third generation of the man\u2019s family learned of his secret discovery before his death and recovered the fossil in 2018.\u201d Thus, in contrast to Pekin\u2019s Man, Harbin\u2019s fossil was lucky and managed to circumvent the Chinese-Japanese war. Moreover, the original discoverer\u2019s relatives agreed to donate it to a Chinese research institution. s, since the Chinese contractor died without revealing the exact site where he discovered the fossil, which made it difficult for the researchers to determine its age. They were not prevented, however, and it was found that the fossil has a minimum age of 146,000 years. The photographs included in the articles published by the researchers show a skull, with almost perfect conservation, relatively elongated and low, and with a volume that could accommodate a brain of a size comparable to that of a modern human. In contrast, it has large ocular basins and large and protruding eyebrows, wide mouth and large teeth. According to the researchers, the morphological characteristics of the Harbin fossil make it different from other homo species. This, leads them to claim that it belongs to a new species, which would become our closest relative. Something in which, however, other specialists do not agree.In one way or another, whether the Harbin fossil belongs to a new or another already established species, it is fortunate that a specimen of that age and with that excellent state of conservation has managed to reach us, even in the midst of a war between Chinese and Japanese.",
    "https://upload.wikimedia.org/wikipedia/commons/3/39/Soft_Total_Artificial_Heart_sTAH.jpg": "Imagine that we have a problem with the pump that goes up the water from the reservoir to the storage tank on the roof of the house, which stopped working after firing black smoke and smelling to burn. In view of this situation, we most likely have to send the pump to a repair shop for its rewinding. The problem would have a relatively simple solution, however, since domestic water pumps are relatively simple devices, with an internal structure and operating principles that are within the reach of a medium-trained technician. Of course, the damage could be extensive and that the pump cannot be repaired. In such a case, we may have to buy a new pump. It serves as an introduction to the subject we want to deal with in this article: the manufacture of artificial organs for the human body as substitutes for defective organs. In this context, the human body is conceived as a machine, although rather more complex than those machines with which we are more familiar -even the most highly sophisticated such as mobile phones or digital computers. It is known that in the world there is a great shortage of organs donated for transplantation and that many patients die before having the opportunity to receive one. In these conditions there is a huge interest in the production of artificial organs to meet a growing demand. It is, however, the question: how feasible is it to manufacture an artificial organ that could be transplanted to replace a defective organ? The answer is that, while artificial organs are not yet available for transplantation, there are great advances in this direction.A technique used to manufacture artificial organs is similar to the 3D printing regularly used to manufacture three-dimensional objects with inanimate materials, such as plastics and metals. For this, a digital version of the object to be manufactured is developed first, which is fed to a 3D printer. Following the digital design, the 3D printer manufactures the layer-by-layer object, depositing material in a controlled way through a mobile injector head.The object is built from the bottom up, with the lower layers serving as support to the subsequent layers.The 3D printers are also used to manufacture organic tissue and, through a model, the object is built from the bottom up to the lower layers. It is not difficult to understand, however, that making a functional artificial organ is much more complicated than making an inanimate object. To build organic material, the printer manufactures a frame or scaffolding from a biodegradable material, on which functional cells are deposited. The frame allows the cells to be placed in the right place, giving shape to the organ to be built. At a later stage, the frame with the cells on its surface is placed in an incubator, so that the cells reproduce forming the organ.The pretense of the experts is that, once this point is reached, the artificial organ -heart, kidney, liver, etc. - can be transplanted to the patient who requires it.Unfortunately, although functional tissues, including cardiac tissue, have been manufactured, this claim has not been crystallized.One particularly difficult aspect is the development of the vascular network necessary to bring nutrients to the organic tissue.The interest in the development of artificial organs, however, is very large and many efforts are being made to make them come true.Six years ago, for example, NASA launched the contest \u201cVascular Tissue Challenge\u201d, which offered a prize of $500,000 that would be divided among the first three teams that \u201cfind success in creating a thick and metabolically functional vascularized human organic tissue, in a controlled laboratory environment.\u201d NASA\u2019s interest is to use functional organic tissues to study the effect that deep space \u2013 high-energy radiation, for example \u2013 would have on future astronauts. We could thus hope that in a future not yet specified, but that we hope it will not be too far away, we will have available artificial spare parts for parts or organs of the body with operating problems, just as the burned ambush of a water pump is replaced. Unfortunately, sometimes the damage will be such that it will not allow a repair. In such case, the replacement will be total, by a new model.",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/c/c6/2008-08_archeon_schnabelschuh.JPG/320px-2008-08_archeon_schnabelschuh.JPG": "If we went back 60 years in time to the city of London we would meet a generation of young people who are looking in many ways to break with the generation of their parents. We would find young people who, among other things, are looking for fashion as an element of identity. The climate of the city of London in this regard is portrayed satirically in the song \u201cDedicated follower of fashion\u201d by the British group \u201cThe Kinks\u201d \u2013 very popular in the UK in the 1960s, but little known in Mexico-, which in one of its stanzas says: \u201cAnd when it does its small rounds. Around the boutiques of the city of London. Looking eagerly for all the fashions and trends. Because he is a dedicated follower of fashion.\u201d It is not surprising that a generation of young people in the city of London just over half a century ago would have been so interested in walking to fashion to differentiate themselves from the previous generation. After all fashion remains an important element even today, although not necessarily for the same reasons that drove the young sesenteros. In fact, fashion has This is the case, for example, of the narrow shoes and high heels, which do not agree with the structure of the human feet, which is the result of millions of years of evolution. Moreover, the pretension to dress in fashion is not something that is characteristic of recent times, and in that sense an article is illustrative that is to be published in the magazine \u201cInternational Journal of Paleopathology\u201d, published by a group of researchers headed by Jenna Dittmar of the University of Cambridge in the United Kingdom. In that article it highlights the importance of fashion, particularly the fashion of footwear, in medieval Europe. And as happens today, even at the expense of the health of the feet. In their article, Dittmar and collaborators report the results of a study carried out with 177 human skeletons excavated from the British city of Cambridge. The skeletons, with antiques ranging from seven to ten centuries, were unearthed from four cemeteries. social classes, a cemetery of charity hospital containing remains of poor people who died there, the cemetery of an Augustinian monastery with remains of people with a high social level, and a rural cemetery with remains of peasants, both free and not free.The interest of the researchers was to determine whether the bones of the feet of skeletons show evidence of bunions, which could have resulted from the use of too narrow shoes.With regard to the latter, it is known throughout the fourteenth century in Europe a fashion of narrow and pointed shoes known as poulains developed.This can be seen in paintings of the time that show individuals wearing very narrow shoes and with such elongated tips that they are ridiculous.The length of these tips denoted the social position and could reach a length close to half a metre. It is not difficult to conclude that anyone wearing such exaggerated shoes would have had trouble walking, with the danger of stumbling and breaking a leg. Thus, to avoid this eventuality, the tips of the shoes were tied to the shins. Unfortunately, although this last resort solved a In fact, Dittmar and collaborators concluded that 18 percent of the individuals studied suffered in the life of juanetes. The problem was more pronounced among Augustinian monks -43 percent of the remains showed juanetes - than among those buried in the cemetery of the hospital -23 percent-, in the parish cemetery -10 percent- and in the rural cemetery -3 percent-. In addition, the juanetes were less frequent among those who died in the 11th-XIII centuries, than among those who died in the 14th and 15th centuries, after the poulains became fashionable. Thus, Dittmar and collaborators made a connection between the juanetes and the poulains, who, however, maintained their popularity despite the pain they caused. Over time, fashion disappeared for difficult reasons to anticipate. One of them was used by the church: the poulains made it difficult to kneel to pray. They are not, therefore, typical of our days, and are lost in the night of the times. Despite the problems that fashion may cause.",
    "https://upload.wikimedia.org/wikipedia/commons/1/1c/Pallet_of_scrap_lead-acid_automotive_batteries_%28wide_view%29.jpg": "Certainly, there is nothing free in this world and for everything we have to pay. And in this sense, the measures that are being implemented to mitigate climate change are no exception. Let us think, for example, of replacing gasoline cars with electric cars that will undoubtedly have a beneficial impact on the climate of our planet. At the same time, however, the batteries of electric cars at the end of their useful life will become polluting waste - in some cases toxic - that will have to be disposed of in some way, even if they accumulate in the environment. An idea of the imminence and magnitude of the problem that the world will face when this happens provides us with an article published in the magazine \u201cNature\u201d in November 2019, by a group of researchers headed by Gavin Harper of the University of Birmingham in the United Kingdom. Harper and collaborators note that in 2017 approximately a million electric vehicles were sold and that, assuming in a conservative way, that the battery bank of a car has an average weight of 250 kilograms, at the end of the useful life of these batteries -the manufacturers guarantee them by some of electric vehicles in 2017. The problem, moreover, will escalate rapidly in the years to come as car manufacturers reduce or stop the production of gasoline vehicles and replace them with electric cars. Thus, it is estimated that in 2030 more than one hundred million electric cars will be in circulation, with the consequent generation of polluting waste at the end of their useful life.What are the possibilities and associated problems for the handling of batteries already out of use? Harper and collaborators, as well as an article published in the magazine \u201cScience\u201d on May 20, signed by Ian Morse, offer us a panorama of this. These batteries would have basically three destinations: 1) their accumulation in a reservoir of polluting waste, 2) their recycling to recover the most valuable elements and 3) their reuse in applications other than that of electric cars. As we know, batteries used in electric cars use lithium metal for their operation, in addition to other elements such as cobalt and nickel. Recycling would involve the destruction of batteries and This is particularly important in the case of cobalt, whose global reserves are under pressure from the electric battery industry. According to Morse, however, battery manufacturers are trying to eliminate cobalt from their processes. In such a case, the economic incentive for the development of battery recycling techniques, which is based on cobalt recovery, would be lost, and recycling companies would be in the position of \u201ctrying to sell waste mountains.\u201d The ideal option, on the other hand, would be to reuse batteries through reconditioning. Reconditioned batteries would find application in the field of renewable energies, such as solar and wind, which require storage systems given their intermittance. This is partly because the structure and technology of the batteries differs according to the manufacturer. In fact, a battery bench is made up of a set of modules, whose number varies widely according to the manufacturer. Each module, in turn, is formed of cells whose number and geometry also depends on the manufacturer. Thus, there are cylindrical cells and cells in the form of rectangular prism. The cells, moreover, can be joined with a glue difficult to remove. All this, together with the lack of technical information about the structure and materials of the batteries, makes their disassembly difficult, with the consequent increase in the costs of refurbishment.From all the above we conclude that, indeed, everything in this life has a price, and while electric cars will contribute to mitigating the climate problem, the same will do to increase the problem of environmental pollution. There is therefore no perfect solution.",
    "https://upload.wikimedia.org/wikipedia/commons/c/c7/Mug%2C_Anasazi_%28Ancestral_Pueblo%29%2C_Johnson_Canyon%2C_Colorado%2C_c._1100-1300_AD%2C_ceramic_-_Native_American_collection_-_Peabody_Museum%2C_Harvard_University_-_DSC06067.jpg": "The obsolescence of certain professional skills as technology advances - and the consequent disappearance of associated jobs - is not, of course, new. During the industrial revolution of the 18th and 19th centuries, for example, manual work and craft skills were replaced by machines for industrial manufacturing. More recently, the appearance of personal computers and text editors have largely made obsolete the traditional skills of a secretary to take dictation and write texts. At the same time, however, new technologies have created new professional specializations and jobs to replace the lost. In the previous context, it is not surprising that, as robotics and artificial intelligence technologies advance, jobs are lost in industrial production lines and in the service sector and that at the same time new jobs based on these technologies are generated. An article appeared in the June edition of the journal \u201cJournal of Archeological Science\u201d gives us an illustrative example in this regard. This article was published by Leszek Pawlowicz and Christian Downum of the University of Northern Arizona. In their article, Pawlowicz and Downum report the results of an investigation that aimed to determine, by a novel method, the possibility of classifying ceramics manufactured by indigenous peoples of northern Arizona during the period that covers the years 825 and 1,300 of our era. These ceramics are known as Tusayan\u2019s white clay. As the authors explain, Tusayan\u2019s ceramic vases are painted with geometric motifs in black and dark coffee colors, and have traditionally been classified into seven main types, according to their style of decoration. However, Pawlowicz and Downum argue, despite their usefulness, this classification suffers from the same problems of typologies from other archaeological sites. Among other things, it was designed with subjective criteria and for purposes that are no longer considered valid. Given the above circumstances, Pawlowicz and Downum proposed to evaluate the use of an artificial intelligence algorithm to classify Tusayan\u2019s ceramics, which crudely emulates the process followed by the human brain to analyze visual information. To train the algorithm, the researchers fed it with thousands of photographs of fragments of this ceramic.Once trained, their ability to classify a set of ceramic fragments from Tusayan, which did not contain any of the fragments used in their training, was evaluated. To establish a comparison with their human counterparts, Pawlowicz and Downum asked four archaeologists, with extensive experience in Tusayan ceramics, to also classify the ceramic fragments provided to the algorithm.The experiment results were remarkable, as the algorithm learned to identify the ceramics in a relatively short time, with a precision that matched that of two of the volunteer experts and exceeded that of the other two. Additionally, it was able to explain what criteria it used to give its classification in each case, something that human experts have difficulty in specifying.To clarify the latter, suppose that we are presented with a photograph and we are told it is from someone we know well, but that it actually corresponds to another very similar person. It is possible that we recognize this fact instantly, but at the same time we have difficulty explaining why our security. , according to the results of Pawlowicz and Downum, computers and their artificial intelligence algorithms can do the work of analyzing and classifying archaeological objects with greater precision and speed than humans. They also have the virtue of not getting tired, which is certainly an advantage to carry out a work that is of their own long and tedious. Thus, at first glance, they would threaten to take the work away from archaeologists. It would not be the case, however, according to Pawlowicz and Downum, who do not think that computers and their algorithms can solve all, or even most, of the problems of classification of ceramics. But they are, potentially, powerful tools to improve objectivity, replicability, speed and efficiency in the classification of the design of ceramics. And in that sense, open new possibilities of specialization for archaeologists, threatened, like the whole world, with being left without work due to technological advancement.",
    "https://upload.wikimedia.org/wikipedia/commons/8/82/SARS-CoV-2_without_background.png": "According to the \u201cOur World in Data\u201d site, approximately 1.6 billion doses of Covid-19 vaccines have been administered globally to date. As a result, 9.5 percent of the world\u2019s population has received at least one vaccine, while an additional 5 percent is fully vaccinated. In the application of vaccines, the leadership has Israel, which has managed to immunize 59 percent of its population completely. The United States, on the other hand, is the country that has applied the most vaccines with a total of 282 million. With this, 38 percent of its population is fully vaccinated. Mexico does not stand out in terms of the percentage of its fully vaccinated population, even compared to other Latin American countries. Thus, just 8.8 percent of Mexico\u2019s population is fully vaccinated, in contrast to Chile and Uruguay, which have fully vaccinated 40 percent and 28 percent of its population, respectively. Moreover, while unevenly speaking, the world\u2019s countries are progressing in the vaccination process and we hope that the health emergency will soon be overcome. Some wonder about the direction that the coronavirus will take in the future and speculate about the possibility that it will become an endemic virus - without its current virulence -, as other common influenza viruses that appear seasonally. And this is a possibility that is explored in an article published on May 7 in the magazine \u201cVirus\u201d, published by a group of researchers from the University of Utah headed by Alexander Beams. Beams and collaborators point out that keys can be found on the future evolution of the coronavirus causing the current epidemic if other epidemics of the past are examined. They consider in particular the so-called \u201cRussian flu\u201d, which originated in Central Asia in 1889. From its point of origin, the epidemic reached St. Petersburg and from there it quickly expanded to Europe and the rest of the world. 25 million people were infected, of which one million died. Researchers note that there is genetic evidence that the Russian flu was due to a currently seasonal coronavirus. Such coronavirus would have thus lost its virulence, either because it suffered genetic changes, or because it died. Because the population developed immunological defenses. In this regard, Beams and collaborators bring up the case of a group of people who remained isolated for five months in a British base of Antarctica in the decade of the seventies of the last century, who became seriously ill by a common influenza virus. This, according to the researchers, was because the immune system seems to require frequent exposure to the virus to maintain its effectiveness. To explore the possible future evolution of Covid-19, Beams and collaborators developed a simplified mathematical model that assumed that the severity of the disease depends on the size of the virus dose to which the patient was exposed. They also assumed that serious patients expel more viruses than people with mild diseases, so that the former will tend to produce severe patients and the second mild patients. Likewise, they assumed that children tend to suffer mild infections and therefore are primarily generators of mild patients. Finally, they considered that, to the extent that the population generates partial immunity, cases of mild diseases could be generated, as happens with other common influenza coronavirus. , Beams and collaborators find that in the long term the population will be predisposed to developing mild diseases, leading to the disappearance of serious diseases in the course of a decade. This would be the result of an adaptation of our immune system - which was not prepared to combat the virus when it made its appearance-, rather than a genetic evolution of the coronavirus. In the future, those who would find the virus for the first time would be children, but they would tend only to develop mild diseases. If Beams and collaborators were right, in the future the coronavirus, which has caused us so many headaches over the last year, would be but a bad memory. Perhaps posterity will remind us with something like this: \u201cin the twenties of the 21st century a pandemic of coronavirus developed that led the world, just as the Spanish flu did a century earlier.\u201d In addition, of course, the bug will be a monserga every winter when we have to take care of another virus.",
    "https://upload.wikimedia.org/wikipedia/en/6/61/Himera480.PNG": "It is not surprising that the story of the Greek historian Herodotus about the battle of Himera is unconvincing to modern historians. After all, as we know, history is made by the victors, in addition to the fact that the battle of Himera occurred 2,500 years ago. We could not therefore expect Herodotus to have been strictly impartial in describing an event that led to the blunt defeat of the Carthaginians at the hands of the armies of Syracuse and Agrigento and saved Himera, on the north coast of Sicily, from the invasion of Carthage. He saved it until its fall and destruction 70 years later in the hands of the Carthaginians in a second battle of Himera, after which it was never rebuilt. According to Herodotus, when the Carthaginian \u201cbars\u201d attacked the Greek colony of Himera were defeated by a coalition of allies of Sicilian cities. An article published this week in the online magazine \u201cPLOS ONE\u201d, however, has other data. Indeed, the article suggests that the army that defeated the Carthaginians It was not exclusively composed of Greek soldiers, but included mercenaries from various places, not only from Sicily, but from other regions around the Mediterranean Sea and even beyond. The reference article was published by a group of researchers attached to American institutions, headed by Katherine Reinberger of the University of Georgia.How is it possible to reach a conclusion such as that offered by the researchers about an event that occurred 2,500 years ago? To understand it, it would first be necessary to mention that Reinberger and collaborators studied the remains of 62 soldiers of the Greek coalition killed in the battles of Himera found in 8 mass graves. The researchers were interested in determining the concentrations of two isotopes of the strontium element in the dental enamel of the victims. It is known that these isotopes are incorporated into the body through the intake of food and water, and that their concentrations in it are a reflection of the respective concentrations in the soils and rocks of the regions where the soldiers grew. Thus, by measuring the concentration of strontium isotopes in the teeth of the dead soldiers, Reinberger and collaborators were able to determine the geographical origins of the fighters in the battles of Himera. And, as for the first of these battles, fought in 480 B.C.E., what they found contradicts Herodotus. In fact, it does so in a frontal way, since two thirds of the army that defeated the Carthaginians in this first battle came from regions outside Sicily, from the Black Sea to the Iberian Peninsula. In contrast, the researchers find that in the second battle of Himera - 409 B.C.E. - three four of the dead were from Sicily. What Reinberger and collaborators found coincides with the historical accounts according to which in the first battle of Himera a coalition of Greek allies successfully confronted the Carthaginians, while in the second, the city of Himera faced them alone, with disastrous results. The coalition that defeated Cartago 2,500 years ago, however, would have been mostly formed by mercenary soldiers. In particular, the changing loyalties of mercenaries would have offended the ideals of citizenship and loyalty, and Herodotus, who wrote in the classical period, would have shared the attitudes against mercenaries. He would not have been surprised by his partiality in writing about the composition of the Greek army that defeated the Carthaginians in Himera.Parciality that he would have imagined would go unpunished in the years to come.It has not been, among other things, by a study -2,500 years later - that has revealed the necessity that there was at the time of incorporating mercenaries into the armies of classical Greece.A study that employed high sophistication laboratory techniques that would surely have seemed to Herodotus to be like the devil's own.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d3/Waymo_Chrysler_Pacifica_in_Los_Altos%2C_2017.jpg": "How much confidence do computers deserve? Or more precisely, how much do you trust the programs or algorithms that run on them? It is possible that the much or little confidence that inspires you depends on each particular application. For example - if that were the case - you very likely trust that the taxes that discount you from your monthly salary, which is surely calculated by a computer algorithm, have been correctly fixed. In contrast, you may be more cautious about the algorithm that guides autonomous cars, which, as we know, have been protagonists of fatal accidents. Likewise, there would be a certain probability that you would have wondered about the correctness of the medical diagnosis that a computer would have spread to you after you were told the symptoms of your illness. The truth is that in the future we will have to get used to the computers and their algorithms playing an increasingly important role in our lives. The algorithms that control the movement of cars without a driver, for example, will surely progress to such an extent that in the near future it will be safer to travel in one of these cars than in one driven by a human - While it should be recognized that in some cases such as our city, where traffic is highly disordered and the streets are full of potholes and ditches that take months to disappear, such algorithms will encounter important challenges. One way or another, however, we will get used to algorithms and become increasingly dependent on them. And in that sense we can ask ourselves about the degree of confidence that inspires us, he asks that he seeks to answer an article that appeared this week in the magazine \u201cScientific Reports\u201d and that has as authors a group of researchers from the University of Georgia led by Eric Bogert. In his article, Bogert and collaborators report the results of a study designed to determine the degree of confidence that inspires the algorithms in comparison with the opinion of a group of people. For this purpose they gathered a group of 1,500 volunteers in virtual form and asked them to count the number of people that appeared in a series of photographs that were divided into two groups. In addition to the photographs, volunteers were provided with the correct numbers of people in each image, with the note that They had been obtained by an algorithm trained with 5,000 images in a first group of photographs, and by a group of 5,000 people in the second. In no case were two numbers of people provided for the same photograph. Naturally, as the number of people in a photograph rose, the probability grew that the volunteers would not count them and instead base their estimates on the numbers that were provided to them. In these circumstances, Bogert and collaborators found that the volunteers tended to use more the suggestions provided by the algorithms -which are perceived as being particularly capable of manipulating numbers - than in the judgment of other people. We would not thus have reticence, of being Bogert and collaborators in the right way, in accepting the increasing meddling of the algorithms in our daily life. Intromission which, on the other hand, hardly begins. With regard to the latter, although according to the so-called Moravec paradox, what is easy for humans and which requires sensomotor skills - prunting a rosal, for example - is extremely difficult for an algorithm. We would be so far from being able to emulate a computer. However, in other activities that are difficult for humans - to demonstrate a mathematical theorem, to play chess, or to perform mathematical calculations with large numbers, for example-, computers will overtake us and do it more widely in the near future. Thus, professional skills that are valuable today will tend to be obsolete as their associated jobs are taken by assault by algorithms. It would be the case, for example, of professions focused on administrative activities. In contrast, paradoxically it would not be from professions such as gardening or those that demand sensomotor skills.",
    "https://upload.wikimedia.org/wikipedia/commons/b/b5/Farewell_to_home%2C_G%C3%B6teborg%2C_1905.jpg": "In a science-fiction scenario we could imagine that our planet reaches such a level of pollution by overexploitation of our natural resources that part of the world\u2019s population is forced to migrate to another planet. The migratory waves, of course, have occurred in the past and never under optimal conditions. We would agree, however, that changing our planet would be a little more traumatic. The most likely destination would be Mars, which is relatively close, although with unwelcome environmental conditions, because in addition to not having an atmosphere with oxygen to breathe, it is continuously bombarded by deadly high-energy radiation, among other drawbacks. Planetary emigration should not then be an option \u2013 unless we have no other choice \u2013 and more we should try to fix our environmental problems as soon as possible. These problems include the crises of atmospheric pollution, pollution of the oceans, pollution by plastic waste, pollution by radioactive waste, congestion of satellites into Earth orbits and, of course, global warming and climate change that could not have been slowed down. This problem is addressed by an article published this week in the journal \u201cScience\u201d by Scott Jasechsko and Debra Perrone of the University of California in Santa Barbara. In that article, Jasechsko and Perrone report the results of a study in which they made a compilation of 39 million wells in 40 countries, which produce half of the total water extracted from the subsoil at a global level. Researchers compared the level of water in each well with its depth and found that up to 20 percent of wells have depths not greater than 5 meters below their water level. Jasechsko and Perrone also examined the construction memories of each well and found that, while the more recently drilled wells tend to be deeper than the previous ones, this is not always the case, even if there is data that there is a decrease in water levels due to overexploitation. . The data compiled by Jasechsko and Perrone show that in a majority of countries, including the United States, the United Kingdom and Mexico, there was a tendency in the period 2000-2015 to drill deeper wells than shallower ones, to compensate for the fall in water levels. In some other countries, such as Argentina, Germany and Japan, the opposite trend occurred in the same period of time. In these conditions, Jasechsko and Perrone estimate that up to 20% of wells worldwide would be at risk of drying up if the water level decreased by a few meters, generating a crisis of large proportions. And this could happen both with old wells and with recently drilled wells. Despite this, as the authors point out, not all countries that studied have a water monitoring network. Consider Jasechsko and Perrone that well monitoring networks should be implemented that provide data on their depths and water levels, data that should be made public, in order to determine the depths to which the new wells should be drilled; In the light of predictions about the reduction of water levels in the future, we have the task of addressing and remedying the environmental problems that the planet is going through, including the overexploitation of aquifer mantles, if we are to be forced to migrate to another planet.However, in anticipation of this latter eventuality, it should be mentioned that the week that ends today NASA announced that its explorer \u201cPerseverance\u201d had managed to produce oxygen on Mars from the carbon dioxide of the Martian atmosphere. The amount produced was very small, about five grams, which is barely enough to allow one person to breathe for ten minutes. The result is, however, encouraging, because it involves the use of martian raw material to manufacture an element that is not only indispensable for future astronauts to survive on Mars, but is also essential for driving the rockets that would bring them back to Earth. In addition, combining it with hydrogen, it will be possible to obtain water, which is also indispensable for survival. An important step, without being small, to advance in the colonization of Mars.",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Pyramid_scheme.svg/1024px-Pyramid_scheme.svg.png": "One of the news of the week was the death of Bernard Lawrence Madoff, better known as Bernie Madoff, in a prison in the state of North Carolina. Madoff, who was 82 years old at the time of his death, received a 150-year prison sentence in 2009 for having scammed some $20,000 million to thousands of investors, who entrusted his capitals with the promise of earning top yields from those offered by the market.In the end it turned out that Madoff\u2019s scheme was fraudulent and that not only the supposed profits - about $40,000 million - were non-existent, but that the invested capitals were at risk of being lost.To swindle billions of dollars to thousands of unwary -which included film director Steven Spielberg, television presenter Larry King and the Metz baseball team in New York, among many other celebrities and organizations - it is necessary, of course, to be a test-free skill and to have a great capacity of simulation and conviction, qualities that Madoff possessed in his own degree. a round table held in New York City in October 2007, shortly before the discovery of their criminal activities, Madoff said: \u201cIt does not mean that there are no abuses, no doubt, but in general, in the current regulatory environment, it is practically impossible to violate the rules. This is something that the public does not really understand. If you read things in the newspaper and see that someone violates a rule, you say well, it is always doing this. But it is impossible for a violation to go unnoticed, and certainly not for a considerable period of time.\u201d And despite his statements \u2013 which are not convictions \u2013 Madoff was in violation of the rules of the United States financial system for several decades before he was finally discovered. This occurred during the economic crisis of 2008, which prevented him from continuing to maintain his simulation. Interestingly, while his victims were prominent characters and organizations, Madoff used to scam them a system that is not at all sophisticated: the so-called Ponzi scheme or pyramidal fraud. This scheme consists of collecting funds with the promise of high dividends. These, however, are not paid for the profits generated by the capital invested, As expected, but using the resources received from new investors, what is not self-sustaining It is not difficult to understand that a Ponzi scheme, by necessity, will collapse at some point. Indeed, this is the scheme that governs the so-called pyramids that appear from time to time. By way of example, let us consider a pyramid that is initiated by a person who invests a certain amount -1,000 pesos, for example - and, in the course of a month, has the obligation to incorporate two more people who will invest 1,000 pesos each of them. These two new people are asked to in turn incorporate two people each who in turn contribute 1,000 pesos to the common capital. The process of repeating continuously with the consequent growth of the size of the pyramid, both in number of members and in capital. At the same time, to make their incorporation into the pyramid attractive, each interested person is assured a return on their investment -10 percent, for example, after a month. If the flow of new members is continuous, the resources provided by the newcomers will always reach to pay the highs. Monthly returns of all members on the lower levels of the pyramid, which will gradually grow. The incorporation of new members, however, is too fast and there will soon be no more candidates. At that time, the agreed revenues will not be paid for and the entire scheme will collapse.The financial environment in which Madoff's Ponzi scheme developed is, of course, more complex than the example considered above. In the background, however, the same bases are available: the payment of attractive revenues using the money of others. Madoff probably knew that his fraudulent scheme would be detected at some point. During his trial, on March 12, 2009, he stated: \u201cWhen I started my Ponzi scheme, I thought it would end soon and I could free myself and my clients from the scheme. Over the years I realized that my arrest and this day would inevitably arrive.\u201d According to some, however, it took too long on that day, since there were more than enough indications that Madoff operated a Ponzi type fraud.",
    "https://upload.wikimedia.org/wikipedia/commons/3/35/Tesla_Semi_5.jpg": "If, as a point of reference, we consider that 28 per cent of the energy consumed by the United States is used by the transport industry, and that 53 per cent of this percentage corresponds to petrol vehicles, it is not difficult to conclude that internal combustion motors contribute significantly to air pollution causing climate change.In these conditions, the announcements of Volvo and General Motors are encouraging in the sense that they will cease the production of internal combustion motors from 2030 and 2035, respectively, to be replaced by electric vehicles.It would be expected, of course, that to the extent that internal combustion motors are replaced by fully electric vehicles, the emission of greenhouse gases would be limited to the atmosphere, since an electric motor does not emit this type of gases.However, this latter statement would have to be nuanced. Certainly, during the operation of an electric motor, greenhouse gases are not emitted. In order for the engine to function, however, the battery bank of the automobile had to be charged beforehand, and for this purpose, the electric power had to be transferred from a generating station through it. We can say that there is no car that does not generate pollution, and that everyone will do so to a certain extent.The above, the important thing is to compare the levels of pollution generated by both types of electricity from the power grid - the Villa de Reyes thermal power station, for example - we can ask how this station obtains the energy that it transfers to the battery bank: does it obtain it through a non-polluting energy source such as that of the Sun, or by a source that emits greenhouse gases burning fossil fuels? In the second case, we cannot say that electric cars are totally non-polluting.In fact, we cannot do so in the first case, because even if the car battery bank obtained its energy from a totally clean source, such as a solar panel bench, it would have been necessary to make such panels using industrial and mineral extraction processes that require energy that, with certainty, it was not generated by a clean source without greenhouse gas production. A document prepared for the Congress of the United States by Richard Lattanzio and Corrie Clark, specialists in environmental and energy policies, offers us this comparison. The document, dated June 16, 2020, can be consulted freely on the Internet. When Lattanzio and Clark compare greenhouse gas emission levels during the manufacture of motor vehicles - including those produced during the extraction and processing of raw materials - find that they are higher for electric vehicles than for internal combustion vehicles. They find that, during the production phase, greenhouse gas emissions for vehicles of the same size, electric motors emit between 1.3 and 2 times more greenhouse gases than internal combustion vehicles. The disproportion in the generation of pollutants between the two types of vehicles is also met in terms of the emission of other gases such as nitrogen oxides and sulphur dioxide. On the other hand, it should be noted that, according to Lattanzio and Clark, electric cars use 77 percent of the energy they receive from the electricity grid, while internal combustion cars use Only 12 to 30 percent of the energy stored in gasoline. In these circumstances, the increased production of greenhouse gases during the manufacture of electric cars compared to internal combustion cars is compensated in favor of the first ones during the lifetime of the vehicles, despite the fact that the batteries add an additional weight to them. From Lattanzio and Clark\u2019s analysis it appears that fully electric cars can have a positive impact on the mitigation of climate change. To what extent this mitigation will occur will depend, however, on the mixture of energy sources, pollutants and clean, from which the electricity grids are supplied. With the danger that if this mixture is not favorable, the remedy could even be worse than the disease. After all, it is not possible to create energy out of nothing and the one used by electric cars will have to be generated in some way. That we better try to make it nonpollutant.",
    "https://upload.wikimedia.org/wikipedia/commons/2/24/Huawei_P30_Pro_R%C3%BCckseite.jpg": "If Alexander Graham Bell, who is often credited as the inventor of the phone, had traveled in time to our day - through the H.G. Wells time machine, for example - he would hardly have recognized smartphones as the successors of his invention. This would certainly have been because smartphones, apart from serving to speak on the phone, are used in many other applications by any other dissymbols, from taking photographs and videos, and seeing photographs and videos that others send us over the Internet, to checking the state of the time for tomorrow and finding out the best way to travel by road between two points. On the other hand, it would have to be recognized that, if there were, Bell\u2019s confusion would actually be attributable to a problem of semantics, since we should probably not call \u201ctelephone\u201d a device that far transcends the functions of the phone as it was originally conceived. In fact, the evolution of smart phones has been linked to that of computers, which have likewise transcended their original function as machines to perform calculations with numbers and have become increasingly intelligent. As a result of advances in computer technology, their functions have multiplied and diversified, while gradually becoming more complex. Thus, it is appropriate to comment on an article that will be presented next week at the Conference on Health, Inference and Learning congress of the Association for Computing Machinery by a group of researchers headed by Xin Liu of the University of Washington in Seattle. In that article, Liu and collaborators describe the development of an application for smartphones that allow the determination of a person\u2019s heart rate and breathing frequency from an 18-second video. Through an analysis of subtle changes of light reflected by the face, which depend on variations in blood flow, the application is able to determine the heart and respiratory rhythms. As researchers explain, the coronavirus pandemic through which we have more frequent virtual medical consultations. The patient\u2019s information obtained by telephone sessions or by Zoom is, however, limited and under these conditions. the developed application would provide relevant information on their health conditions. On the other hand, the determination of the cardiac and respiratory rhythms from a video, as discussed by Liu and collaborators, requires that the application be adapted to different physical and physiological characteristics of the population, including the color of the skin that affects the amount of reflected light. The application should also be able to obtain information in changing environmental conditions -for example, of levels and shades of illumination-, different to those in which the training is carried out. Likewise, the application must take into account the sensitivity relative to the colors of each phone.To achieve all this, it can be trained to the application by artificial intelligence techniques, providing a large number of cardiac and respiratory data of the population in general, obtained by professional instruments. Train smart phones to monitor the heart and respiratory rhythms in this way, however, it would require time, effort and a great amount of resources. One way to turn it around these difficulties is by personalizing training, providing the telephone with the physical and physiological characteristics of its owner obtained by professional instruments. Liu and collaborators, the training would be done without the help of these instruments and with a small amount of physiological data. This would help to extend the use of the technique among the population. The application developed by Liu and collaborators is aimed at overcoming all these difficulties, and according to his article, surpasses other existing systems by an appreciable margin. The researchers recognize, however, that the application has difficulties with dark skin that reflects less light for its analysis. Thus we have a new application, if necessary, of smartphones. Same that we should probably stop calling phones - but yes extremely smart devices. And not thus confuse Alexander Graham Bell in his hypothetical journey from the past. After all, more than enough surprises would have to be carried away.",
    "https://upload.wikimedia.org/wikipedia/commons/c/ca/SalkatPitt.jpg": "According to statistics updated yesterday by the New York Times, the United States has applied nearly 137 million vaccines to its population against the coronavirus, making it the country that has most vaccines applied. In percentages, 27 percent of the American population has received at least one dose of the vaccine while 15 percent is fully vaccinated. At the current rate, the United States would vaccinate 70 percent of its population over the course of four months. In absolute numbers, the United States has been followed by China, India and the United Kingdom with 97 million, 58 million and 32 million vaccines applied, respectively. Not surprisingly, the countries that have applied the most vaccines tend to be those that have contributed the most to its development, and in that sense the United States that have channeled or committed more than 10 billion dollars of public money to private pharmaceutical companies to accelerate the development of vaccines, including Pfizer, Moderna and Johnson, which have produced the three vaccines authorized to date in the United States. In Mexico, for example, according to New York Times statistics, about 6.5 million vaccines have been applied, representing just 5.1 vaccines per 100 inhabitants. It is not difficult to understand that the United States, which has invested massively in the development of vaccines, has sought as a priority to ensure the sufficient number of vaccines to cover its population. Similarly, and in a predictable manner, rich countries, whether or not they have funded the development of vaccines, have sought to secure enough vaccines to protect their respective populations. As a result of all of the above, rich countries have negotiated contracts with pharmaceutical companies and seized available vaccines, to the detriment of countries with fewer resources that are of little interest to those companies. As noted last January 18, Tedros Adhanom Ghebreyesus, Director of the World Health Organization, \u201cMore than 39 million doses of vaccines have been administered in at least 49 high-income countries. Only 25 doses have been administered in one of the lowest-income countries. In this context, it is important to stress the need for the development of vaccines in order to improve the quality of the vaccines available to pharmaceutical companies in order to improve the quality and quality of the vaccines available to them, and to ensure that the quality of the vaccines available to them is respected. In this sense it is illustrative the case of the Brazilian city of Manaus, located in the middle of the Amazon jungle and which, despite being relatively isolated and practically without communications via land, has had two deadly waves of coronavirus and has even generated a new, more contagious strain that has already spread to other South American countries. Regardless of the good intentions of those who struggle for pharmaceutical companies to give up their profits as long as the pandemic passes, it is possible that they do not go beyond that, good intentions. AstraZeneca, for example, has stated that he will not fight with his vaccine until after the pandemic. Such seems, however, that he intends to declare it finished next July. I hope, but is to be doubted.",
    "https://upload.wikimedia.org/wikipedia/commons/c/c5/Tokyo_Shibuya_Scramble_Crossing_2018-10-09.jpg": "Shibuya\u2019s pedestrian passage in Tokyo is known to be the most crowded in the world. On the Internet it is not difficult to find videos where it is possible to observe a multitude of pedestrians waiting for traffic lights to allow them to cross across the street from across the world. Once this happens, and through five steps marked on the pavement with white lines, the pedestrians launch to reach their goal, intersecting without interfering with those who come in the opposite direction. Crowds crossing through the pedestrian passage of Shibuya \u2013 thousands of people at the same time, according to Wikipedia \u2013 reflect the high mobility of Tokyo\u2019s population and the fact that Shibuya is one of the main stations in this city\u2019s extensive network of urban and suburban trains. It should be mentioned that crowds in Shibuya are not unique in Tokyo \u2013 a city whose metropolitan area is in the world\u2019s first or second largest population \u2013 and constitute more the rule than the exception. The reference article was published by a group of researchers headed by Hisashi Murakami of the University of Tokyo, and it reports the results of a study carried out with two groups of 47 students each, who walk in opposite directions and enter and cross into a corridor of 3 meters wide and 10 meters long. The experiments were carried out under four conditions. In the first, three of the elements of one of the groups, randomly selected, were asked to make use of their mobile phones during the experiment and were placed in the three front positions when entering the group into the corridor. Specifically, they were asked to type a message and to keep the view fixed on their phone most of the time. In two other experiments, three people were randomly selected to use their mobile phones, but were placed in the middle part of the group in one case. Finally, in a fourth experiment no participant made use of his mobile phone. The experiments were filmed and the results can be freely consulted on the electronic page of \u201cScience Advances\u201d. According to Murakami and collaborators, when entering two contact groups, the people who lead them make decisions about the way forward to avoid collisions, based on an assessment of the movements of the person they have in front of them, while those who come behind simply follow them. Thus, in the video corresponding to the experiment in which mobile phones are not used, it is observed that when making contact the two groups are seamlessly divided into three rows that alternately intersect. In contrast, in the experiment in which the three participants to the head walk distracted with their cell phone and only see forward a fraction of the time, they find it difficult to evaluate the future movements of the person facing them and the interaction is much more disordered. This makes the group take longer to form rows and delay their exit from the corridor. It does not only happen with those who use their phones, but also with the leaders of the other group, who have difficulty evaluating the future movements of the distracted leaders and making decisions accordingly. In cases where the distracted ones are inserted in the middle and at the end of the group, the results are intermediate between the two previous cases. Thus, the results of Murakami and collaborators show us that there are times when walking sharing our attention with a mobile phone is not the most advisable thing. This is perhaps not surprising. As it is probably not surprising to find out that when walking distracted by typing a message we could also be inconvenienced for those with whom we interact, who might have difficulty predicting our immediate movements. There would be times to use our mobile phone to consult and send written messages, to find out the latest news, to know if it will rain the day of tomorrow, to take photographs, to record voice messages, to take class online and, of course, to speak on the phone. But maybe not to write a message when we cross a pedestrian pass in peak hours.",
    "https://upload.wikimedia.org/wikipedia/commons/6/66/NAMA_Machine_d%27Anticyth%C3%A8re_1.jpg": "In 1901, near the Greek island of Anticythera in the Aegean Sea, a group of divers who dived into the sea in search of sponges discovered among the remains of an ancient shipwreck an object that they did not at the moment identify, but that would ultimately be famous.This object, with an age of about two thousand years, is today known as the Anticythera Mechanism, a kind of computer used to describe the movement of the Moon, the Sun and the five planets known in ancient times.The Anticythera Mechanism is today found in the National Museum of Archaeology in Athens.As it is easy to understand, after two thousand years of remaining submerged in the sea, the state in which the Anticythera Mechanism is found is not the one we would have wanted and, in fact, is incomplete and divided into 82 fragments that constitute only one third of the total. This, however, does not prevent us from seeing that it is an object in whose construction techniques were used to manufacture mechanical parts that are desired to be advanced for the time. Although the Anticythera Mechanism has been the subject of study by several research groups, due to its state of deterioration it has not been able to unravel all the details of its construction and functioning. The results of the last effort in this regard were published the week that ends today in the journal Scientific Reports, by a group of researchers headed by Tony Freeth of University College London, in the United Kingdom. In that article a model is developed for the Anticythera Mechanism that the authors consider finally unveils the secrets it contains. According to the model of Claudius Tolomeo, accepted at the time the Anticythera Mechanism was built, the Earth is the center of the Universe, with the Moon, the Sun and the five planets then known orbiting around it. If this is true for the Moon and could pass as such for the Sun, it is far from being so for planets that, as we know, revolve around the Sun. Thus, the trajectories that follow the planets seen from Earth are quite more complicated than those of the Moon and the Sun. And if, as Ptolemy strives to put the Earth in the center of the Universe, we will have to assume that the planets move in a more complex path than a simple circular orbit around our planet.In these circumstances, Ptolemy devised the theory of the epicycles, according to which the planets move in circles around a point that in turn moves in a circular orbit around the Earth. Moreover, since the epicycles were not enough to explain the trajectories of the planets, Ptolemy was forced to assume that the orbits of the epicycles are eccentric, that is to say that they are not centered on the Earth but on another point of space. And since the latter was not sufficient either, Ptolemy without being discouraged postulated the existence of an additional point, the ecuante, from which the speed with which the center of the epicycles crossed the firmament was constant. So, as the images published by Freeth and collaborators -which can be freely consulted on the Internet on the Scientific Reports site - illustrate, the Anticythera Mechanism could have consisted of a complex assembly of gears on gears, some rotating on a common axis and others around fixed eccentric axes on the former. The design produced by Freeth and collaborators is undoubtedly fascinating and corresponding to the original design would also be surprising. Could the Greeks have produced an ingenuity with the level of sophistication shown in the developed model two thousand years ago? As Freeth and collaborators point out, the Anticythera Mechanism builders would have, among other things, built multiple hollow axes, embedded in one another as Russian dolls, without counting metal lathes.If Freeth and collaborators were correct, the Anticythera Mechanism -which would not have been in any single way- constituted a single work- constituted a movement of the Moon, the Sun and the planets. superlative design of engineering and technology. In contrast, the Ptolemy model implemented in this mechanism is too complicated. In addition to clearly wrong.",
    "https://upload.wikimedia.org/wikipedia/commons/e/e8/WWTP_Antwerpen-Zuid.jpg": "When were the rotifers discovered and who was their discoverer? There is no definitive agreement on this, but it is known that their existence was first revealed by the end of the 18th century, according to some by Englishman John Harris and according to others by Dutchman Antoni van Leeuwenhoek. According to Wikipedia, there are about 2,200 species of rotifers and these are common around us. Despite this, we delay in discovering them because of their small size. For the benefit of the reader, it may be worth mentioning that - again according to Wikipedia - the rotifers are organisms that are mostly microscopic in size, between a tenth of a millimeter and a half millimeter, and that they are found in ponds and ponds, as well as in humid places. Given their small size, to observe the rotifers in detail Harris and Leeuwenhoek had to resort to the use of microscopes, primitive, but with sufficient increases. In an article published in 1694 in the magazine \u201cPhilosophical Transactions\u201d of the Royal Society, Harris relates his observations: \u201cI examined a small drop of rainwater that had been in a clay container in my window for about two months...I saw there an animal like a great worm that could contract in a spherical figure and then stretch again; the tip of its tail appears as a forceps like that of a tijereta; I could see clearly that it opened and closed its mouth, from where air bubbles frequently came out.\u201d For the first fortunate ones who could see through a microscope a hidden world until then, the experience had to have been fascinating. Equivalent to the one that Galileo experienced when pointing his telescope towards Jupiter and discovered four bright spots - the Galilean satellites - orbiting around it. Today there are much more powerful microscopes than those who employed Harris and Leeuwenhoek that allow us to see the microworld, and even the nanoworld - a thousand times smaller - with luxury of details. An example of this is the article published this week in the journal \u201cInternational Journal of Molecular Sciences\u201d by a group of researchers led by Katarzyna Turnau of the University of Krakow in Poland. In that article, Turnau and collaborators reveal a theatre of war that takes place within a drop of water from a wastewater treatment plant, and in which a certain species of rotifers participate, on the one hand, and an alliance of microscopic fungi, bacteria and viruses, on the other. In this war, the rotifers are the attacked part: the aggressors are interested in them as cattle for their feeding and act accordingly. In fact, as we will see, instead of war we could talk about a massacre.Using optical microscopes and electronic microscopes, Turnau and collaborators were able to follow the details of the hostilities.As part of the joint strategy of attack, the fungi establish a network of filaments with which they manage to trap and immobilize the rotiferous with the help of adher bacteria. After this, the filaments penetrate the inside of the dam to absorb nutrients, while the bacteria attached to the external and internal walls of the filaments are thrown into the approach, also in search of nutrients. At the end, the fungus removes the filament from the inside of the rotifer, leaving only a shell with bacteria inside it. Throughout this process, Turnau and collaborators find a large amount of viruses during the process and although they consider that they have an active part in it, they do not have at the moment a clarity about it. Certainly, even several centuries away from the invention of the microscope there is ample space for amazement in our exploration of the microscopic world. In particular, the work of Turnau and collaborators shows us that there can be wars and alliances such as those occurring here above.",
    "https://upload.wikimedia.org/wikipedia/commons/9/92/Perseverance_Landing_Skycrane.jpg": "In his 1898 novel \u201cThe War of the Worlds\u201d, the British writer H.G. Wells imagines that the Earth is invaded by an army of Martians who make use of gigantic war machines and caloric ray cannons capable of incinerating everything they touch. The first signs, not understood at the time, of the danger that haunted our planet, was a series of glares that could be observed from the surface of Mars during 1894, and that they were nothing other than the shooting of huge-sized cannons used to launch into Earth the invading ships. Whoever has read the novel will know that it had a happy ending - within what is possible, because of the enormous destruction caused by the Martians - since the invaders were finally annihilated by the terrestrial microbes. Curiously, in the unlikely event that there were Martians on Mars, these could have recently testified to events similar to those described by Wells in his novel: three glows that occurred on the surface of our planet between 19 and 30 July last year, the meaning of which would not have been clear to them in At first, but which they would later have discovered were originated by the ignition of three rockets that took off from the surface of our planet bound for Mars. These rockets carried on board spaceships from NASA missions, the Chinese space agency and the space program of the United Arab Emirates. NASA\u2019s mission was to pose gently on the Martian surface to the explorer robot Perseverance. A similar objective was the Chinese mission, which has been given the name of Tianwen-1, and which also includes a spacecraft to orbit Mars. On its side, the mission of the United Arab Emirates includes only one orbiter. The scientific news of the week was undoubtedly the successful arrival of the explorer Perseverance to the surface of Mars on the last day 18. Perseverance has as its mission to identify places conducive to the development of microbial life and to explore them in search of signs of life. It will also carry out experiments for the manufacture of oxygen from the Martian atmosphere that is formed primarily by carbon dioxide. It will also collect samples of rocks. As an additional element, NASA\u2019s mission includes a small helicopter to explore the Martian surface from a novel perspective: above that surface, but not as far away as the orbiting satellites. All this at a cost: about $2.8 billion, which includes the development and construction of the Perseverance, its launch and operation costs, and $85 million to design, build and operate the helicopter. Tianwen-1, for its part, entered orbit around Mars on 10 February \u2013 one day after the Arab probe \u2013 with the explorer robot on board. It is expected that the explorer will try to pose gently on the Martian surface next May. There is thus a renewed activity in the exploration of Mars that now includes not only the United States and Russia, the countries that initiated space exploration \u2013 the last still Soviet Union \u2013 but also China, India, Japan, the United Kingdom, the Union In the same way there is a renewed activity in the exploration of the Moon and some asteroids and all of this somehow takes us back to the past, at the time when H.G. Wells wrote his novel The War of the Worlds, which some have understood as a criticism of the colonialism of the time by which some European countries took over virtually the entire African continent, as the Martians wanted to take over the Earth. Will we now be in a situation in some similar way in a race between countries to seize the resources of space? Of course, on Mars there are no Martians - as there were Africans in Africa in the 19th century - who were to steal the land from them and in that sense there should not be developed concepts such as the \u201clower races\u201d invented by Europeans to justify the dispossession, and which was even used by H.G. Wells himself at the beginning of his novel, with everything and his criticism of European colonialism. Otherwise, apart from hidden intentions, with certainty the Martian probes, they will send us, from the remote place where they are, news and images that will surely be fascinating.",
    "https://upload.wikimedia.org/wikipedia/commons/8/86/Luna-3_%28Memorial_Museum_of_Astronautics%29.JPG": "Our history takes place in Mexico City in December 1959, and in it Mexican spies, American spies and members of the Soviet KGB intervene. As we shall see, while history could serve as an argument for a James Bond film, it corresponds to true facts according to the version of several of its protagonists, and revolves around the theft by the Americans of the secrets of a space probe that the Soviet Union had on display in the National Auditorium. The story is told in an article published on 28 January in the magazine \u201cMIT Technology Review\u201d signed by Jeff Maysh. As we know, on 4 October 1957 the Soviet Union succeeded in putting into Earth orbit Sputnik 1, the first artificial satellite in history, followed two months later by Sputnik 2 with the bitch Laika on board. The United States, for its part, placed in orbit its first satellite, Explorer 1, on 31 January 1958. The space race between the United States and the Soviet Union began in this way. This difference soon became clearer when the Soviet Union managed to send the Moon 2 and Moon 3 probes, the second of which was able to photograph the hidden face of our natural satellite in October 1959. With this, the Americans panicked as they considered that Soviet space superiority reflected their ability to manufacture nuclear missiles - the true interest of the space race - that they could make white on their territory. Thus, the Soviet Union organized a travelling exhibition to exhibit their technological development, in which the lunar probe occupied the central place. The exhibition opened on November 21, 1959 in Mexico City and lasted until the end of December. Taking advantage of the occasion, the Americans decided to try to find out the secrets of Russian space superiority by surreptitiously examining the lunar probe. Given that it was heavily guarded by Soviet agents, this was not possible during the exhibition, so they devised a plan to hijack it for a few hours during its transfer from the National Auditorium to the train station on In order to carry out their plan, U.S. spies counted on the help of Mexican spies commanded by a member of the Presidential General Staff, according to Maysh, who, taking advantage of the transit chaos characteristic of Mexico City, managed to separate the truck in which it was being transported to the probe, from the vehicle in which Soviet agents were transporting it to their care. Thus, Mexican agents took the lunar probe to a previously chosen place where the U.S. spies opened the box where it was being transported and completely disarmed to photograph it. After this, they rearmed it carefully so that the Soviets would not notice the violation. Before re-arming it, however, they removed all the removable parts from its interior. Particularly, they were interested in obtaining samples of the fuel used by the Soviets, which they considered to be one of the factors that made it superior to Russian space technology. All of the above was achieved during the night in space a few hours, so that before dawn the lunar probe arrived at the railway station in Mexico City. All this demonstrates the high degree of empowerment of the American spies, one of whom was part of a group of thieves and intruders known affectionately as \u201csecond-floor men\u201d for their ability to enter buildings across the second floor. It should also be said that, according to Maysh, the squadron that carried out the latrocinium had the valuable help of a person from the American embassy, who asked them to forget about the enchiladas and daisies and to only consume oats and water, since once inside the box where the probe was transported, the space would be tremendously reduced and a bad gas would be at the cost of the entire operation. The information provided by the abduction of the Soviet probe would have been of great help for the Americans to finally win the race to the moon and with this the story had a happy ending.",
    "https://upload.wikimedia.org/wikipedia/commons/f/ff/Opera%C3%A7%C3%A3o_Hymenaea%2C_Julho-2016_%2829399454651%29.jpg": "As estimated by the International Energy Agency (IEA), due to the economic slowdown due to the coronavirus pandemic, global energy demand during 2020 declined by approximately 5 percent. Concurrently, carbon dioxide emissions into the atmosphere decreased by 7 percent, palliating the growing global warming problem, while energy investment declined by 18 percent. Once the pandemic has been overcome, however, the economy will be reactivated and energy consumption will be increased, thereby increasing the emission of greenhouse gases. In these conditions, one wonders how energy consumption and global warming will be affected in the years to come. In this sense, the IEA considers two possible scenarios. The first assumes that the measures and policies implemented by the different countries to combat global warming will be the same as before the pandemic, and that this will be put under control during 2021. Given these conditions, global energy consumption will return in 2022 to the level it had in 2019 and from there it will resume its pre-pandemian growth rate. The IEA assumes that the crisis due to the pandemic will continue and it will only be until 2025 that energy demand will recover its pre-pandemy level. In this context, the economy will suffer a higher level of damage and the pandemic will mark the beginning of a decade with the growth in energy demand lower since 1930. According to the projections of the IEA, in the second scenario carbon dioxide emissions will stabilize in the next ten years, while in the first scenario they will continue to grow, albeit at a slower pace than before the pandemic. In both scenarios the levels of carbon dioxide emissions will be substantially lower than those that would have occurred if the pandemic had not occurred, especially for the second scenario in which the world takes longer to overcome it. In all scenarios considered by the IEA, a decline in the use of coal is predicted, which, as we know, was the most important fuel during the industrial revolution. This decline was already present before the pandemic, but its fall will accelerate in the years to come. On the contrary, natural gas will continue to rise, While the demand for oil, if the second scenario is met, will reach a limit in the 2030s. On the other hand, renewable energy, including solar, wind and hydroelectric, will play a central role in the future energy of the planet. And among all of these, photovoltaic solar energy \u2013 which uses solar modules to convert the sun\u2019s energy into electric energy \u2013 will take the lion\u2019s share in electricity generation. This, due to the spectacular reduction by a factor of 100 in the price that solar modules have in the last four decades. The current coronavirus pandemic will have repercussions on global energy demand, even after it is exceeded. This at least according to the AIE, which projected before the pandemic a 12 percent increase in energy demand between 2019 and 2020. Now, projections in the same period are 9 percent in the first scenario and only 4 percent in the second. The post-pandemian world course is then dependent on the time it takes the world to overcome the health crisis. And in this context, it is worth noting that some rich countries, notably the The United States and Britain have taken up much of the world\u2019s vaccine production and would be in a position to overcome the crisis this year. Moreover, due to their technological development, the industrialized countries will have tools \u2013 as they had to manufacture vaccines \u2013 to develop the sustainable energy schemes that the world of the future demands. In Mexico we are in a very different situation. On the one hand, we have a number of vaccines that is insufficient, at least for the moment, to overcome the pandemic before it goes on its natural course. And, on the other hand, given our technological limitations, how are we going to overcome the climate crisis in the decades to come?",
    "https://upload.wikimedia.org/wikipedia/commons/e/e7/Hydrogen_Density_Plots.png": "One characteristic of our time is the dizzying advance of scientific knowledge and with this of technologies based on such knowledge. That such progress is truly dizzying is exemplified by the development, in less than a year, of several vaccines to curb the advance of the coronavirus pandemic. Given the great speed with which scientific and technological knowledge advances, universities and vocational education centers must renew their curricula at the same speed, even if they are quickly obsolete. In this regard, it is interesting to comment on an article published last October in the journal \u201cPhysical Review Physics Education Research\u201d, by a group of researchers led by Michael Fox, of the Institute of Standards and Technology, and of the University of Colorado in Boulder. In the reference article, entitled: \u201cPreparing for the Quantum Revolution: What is the Role of Higher Education?\u201d Fox and collaborators make an analysis of the changes that must be carried out by the universities of the United States to train the engineers and high-skilled technicians that need the companies involved with the quantum information field. Because the term \u201cquantum revolution\u201d might be unfamiliar, it is worth mentioning that this revolution is based on \u201cquantum mechanics\u201d, a discipline developed in Europe in the first decades of the last century by an exceptionally brilliant generation of physicists. Quantum mechanics is a theory that explains the functioning of nature on an atomic scale, in radically different terms from the physics applied to objects of ordinary size. In fact, quantum mechanics predicts phenomena that are surprising to us, such as an object that can be in two places at a time. Despite the unexpected of its predictions, quantum mechanics has proved extremely useful. It was crucial, for example, for the development in 1947 of the transistor and in 1960 of the laser, which are angular stones on which the Internet is supported. Today, a century after its invention, quantum mechanics has given rise to the field of quantum information, which still promises technological advances in the field of quantum information. In this context, the term \u201csecond quantum revolution\u201d has been coined, and according to it, Fox and collaborators carried out a survey among companies related to quantum computing to find out their needs of engineers and researchers. Based on the answers obtained, the researchers determined that the activities of companies in the quantum industry are grouped into: quantum detectors, quantum communications, and quantum computing, including hardware and software. For these areas the American quantum industry will need a workforce of engineers, theoretical and laboratory scientists, and highly specialized technicians. Part of this workforce will have to have formal training in the field of quantum information, while the rest would have to have credited one or two semesters of introductory courses in this field.The importance of all of the above for Mexico may be questioned. As a technologically underdeveloped country, we will undoubtedly go to the saga of the rich countries in terms of quantum industry development. Given the globalization process, however, it is possible that at some point in time, jobs will open up. in Mexico in this industry and therefore we should advance events and contemplate the conductive adjustments in our curricula. At the same time as we promote scientific research in the area of quantum information, which is a prerequisite for the implementation of solid educational programs that remain permanently up to date. Otherwise, by not doing so we would be admitting that we have no more ambition than to be an eternally dependent country.",
    "https://upload.wikimedia.org/wikipedia/commons/4/4d/Rust_screw.jpg": "As we know, the current coronavirus pandemic has led to an economic slowdown at a global level. This, in turn, according to the organization Global Carbon Project, has led in 2020 to a seven percent reduction in greenhouse gas emissions to the atmosphere, compared to 2019 emissions. This reduction is the largest observed since records have been kept. At the same time, as a result of this pandemic, activities such as work at home, teleconferences and the consumption of entertainment videos via the Internet, which in turn generate greenhouse gases. Indeed, all these activities require electricity, part of which is generated in thermoelectric power plants that consume fossil fuels. And even electrical energy generated from the sun or wind, requires burning fossil fuels to make the necessary solar panels or windmills, as the case may be. The Internet also relies on giant computers and memory banks to store data that requires fossil fuel production. In fact, although it is a little surprising, experts estimate that the Internet contributes about 3.7 percent of global emissions. This article appeared this week in the magazine \u201cResources, Conservation and Recycling\u201d gives us a perspective on the impact of greenhouse gas emissions on the different activities of the Internet. This article was published by a group of researchers headed by Renee Obringer, of the University of Maryland, in the United States, using data from 13 countries distributed throughout the world, including Mexico. Obringer and collaborators also consider the use of water and soil by the Internet, which, they argue, should be considered in conjunction with the generation of greenhouse gases to assess their environmental impact. They note, for example, that for the processing and transmission of data by the Internet, Brazil generates 68 percent less greenhouse gases than the world average, but it is 210 percent higher than the average for the use of water. This is because Brazil obtains 70 percent of its electricity from hydroelectric power plants. Thus, depending on the origin of its electricity, other countries will have numbers above the average. On the other hand, beyond statistics and numbers, it would be very useful to know what possibilities we have, as users of the network, to contribute to mitigating their environmental impact. And on this Obringer and collaborators offer us some guides. For example, if we receive ultra high definition videos for four hours a day, we will generate in one month 53 kilograms of carbon dioxide \u2013 the most abundant of greenhouse gases. If, on the contrary, we decrease the quality of the video to standard we will reduce that generation to 2.5 kilograms, saving the equivalent of carbon dioxide produced during a journey of 150 kilometers by car. Obringer and collaborators note that if this is multiplied by 70 million users, the savings will be substantial. As for the use of water, if 100,000 users reduced the quality of the videos they receive would save enough liquid to grow 185 tons of potato. Thus, according to Obringer and collaborators, some simple actions can help mitigate the environmental impact of the Internet. Among these actions mention: turning off the video in a virtual meeting, reducing the quality of the videos of entertainment, reducing the time of games, limiting time on social media, erasing emails and files stored in the cloud \u2013 given that this requires memory banks \u2013 and opting out of email groups.Of course, all of this is easier said than making it happen with the current costs of transmitting data over the Internet.If these costs were high enough, we might think twice before deciding whether we really want to send this or that image or video. Or if for the movie we want to see a standard resolution is enough. Otherwise, as long as the costs remain low, we might consider that, according to NASA, last 2020 is, together with 2016, the year that has experienced on average the highest temperature since records are kept.",
    "https://upload.wikimedia.org/wikipedia/commons/7/77/Nuages.gif": "For a country with so many shortcomings like ours, is it worth investing in science? Especially because to the extent that the tools and instruments for scientific research have become increasingly sophisticated, their cost has increased simultaneously. For those of us who dedicate ourselves to this type of activity the answer is obvious: the investment that we can make to develop science in Mexico will be highly profitable in the future. In relation to the latter we can argue what follows.The objective of scientific research is to determine the causes of natural phenomena.This has practical consequences, since understanding what causes a phenomenon allows us to exercise a certain degree of control over it.For example, we know that in the starry nights the ambient temperature tends to drop compared to the cloudy nights and with this a plant can freeze.This phenomenon explains it the physics taking into account that the plant emits toward the sky in a continuous way energy by radiation, which tends to decrease its temperature until possibly freezing.In a cloudy night, however, such radiation is reflected by the clouds and this allows it to be reabsorbed by With this program, the government granted funds for billions of dollars to five pharmaceutical companies for research, development and production of vaccines. However, support was given, with the help of the plant, to limit its temperature reduction; much the opposite of what happens in a cloudless night, when radiation is lost to space. Given this knowledge, we could design a procedure \u2013 or technology \u2013 to prevent frost by placing a cloth on the plant that simulates a cloud and obstructs the view of the sky. Thus, scientific knowledge allows us to develop technologies \u2013 some of them very sophisticated \u2013 to solve problems of all kinds, and a dramatic example in this regard is given by the current coronavirus pandemic. As we know, last December, a vaccination campaign against COVID-19 was launched in several countries, using vaccines developed over a record time using huge amounts of money and sophisticated scientific knowledge. One condition: that the United States have priority access to vaccines. As a result, the United States now has 200 times the number of vaccines available to Mexico, and the situation would not seem to be very different in the future. In these conditions, there is a danger that the coronavirus pandemic will disappear naturally before the total population of the country will be immunized. We would thus have to have invested considerably greater resources during the development of vaccines in order to ensure higher numbers. Or, that we would have had the scientific and technological infrastructure to develop our own vaccines. This would have required long-term investments that we are unfortunately not used to. The coronavirus pandemic shows us the advantages of investing in science, with all the considerable resources that it demands, given that current technology relies heavily on scientific knowledge. A country without science is a country without technology, and is also a country forced to import it, with all the disadvantages that this could represent at any given time.And what we can mention for Mexico with regard to the development of vaccines against coronavirus, is a country that is a country without technology, and that is a country obliged to import it, with all the disadvantages that it is a country, with all the advantages that this could represent. equally valid for other scientific and technological fields of central importance to the country. After all, Mexico is the 15th economy of the world.",
    "https://upload.wikimedia.org/wikipedia/commons/5/50/Colores_violetas.png": "Like the magazine \u201cScience\u201d in retrospect, it made an analysis of the scientific advances of the year that has just ended, in its last issue it also gives us its predictions about what it considers to be the main scientific advances of the year that has just begun. And among these advances, in an unsurprising way, the magazine includes two aspects related to the coronavirus pandemic. On the one hand, it considers \u201cScience\u201d that the team of ten scientists sponsored by the World Health Organization that will visit China several times throughout this year, will succeed in unraveling the mystery regarding the origin of the coronavirus pandemic, which will certainly be of great importance to prevent other pandemics in the future. On the other hand, it anticipates \u201cScience\u201d that another scientific discovery of first importance in 2021 will be the development of specific drugs for the treatment of Covid-19, which will be essential given that in the future the virus will be endemic. At present, antivirals that have been developed for the treatment of other diseases with limited results are used to attack this disease. It is possible to decontinue virus surfaces by means of ultraviolet light. As we know, this light -invisible to us - is a form of electromagnetic radiation that is beyond the violet of the rainbow, as well as infrared light, at the other end of the rainbow, is beyond the red color. Ultraviolet light is more energetic than visible light and by irradiation can damage different components of the coronavirus and inactivate it. Disinfection by means of ultraviolet light is not something new and has already been practiced by means of ultraviolet light. Ultraviolet light is more energetic than visible light and by irradiation can damage different components of the coronavirus and inactivate it. Disinfection by means of ultraviolet light is not something new and has already been practiced. For several decades. Today, however, there are new sources of ultraviolet light that, according to an article published this week in the magazine \u201cPhotochemistry and Photobiology\u201d, would be particularly suitable for disinfecting surfaces contaminated by coronavirus. The article was published by a group of researchers led by Yoram Gerchman of Haifa University in Israel, and in it they report the results of a study carried out to evaluate the use of LED sources of ultraviolet light to inactivate the Covid-19 coronavirus. It should be mentioned that the first sources of LED light appeared in the decade of the 60s of the last century, first, as sources of infrared light and then of red and green light. Subsequently, in the nineties of that century, blue LEDs were developed and with these white LEDs that started a revolution in the field of lighting. An extension of the technology of blue LEDs has led to the development of ultraviolet LEDs that now Gerchman and collaborators claim can be used to disinfect surfaces quickly and efficiently; for example, for In addition, in their study, researchers find that 99.9 per cent of the viruses can be destroyed in half a minute by irradiation with ultraviolet LEDs. At their own cost, LEDs compete favourably with conventional ultraviolet light sources. Gerchman and collaborators, on the other hand, note that ultraviolet light is dangerous and that its handling must be careful. It would not be appropriate, for example, to disinfect the dining table or the door knob by a non-expert person in its handling \u2013 as it would not be to disinfect the inside of the body, as the president of the United States once suggested. If with the appearance of vaccines we can see a light at the end of the tunnel, we would have to recognize that the solution to our problems is not imminent. And in that sense, Gerchman and collaborators offer us a technological resource to help us alleviate the crisis. Resource that, after the nightmare ends, will help us to prevent the next one.",
    "https://upload.wikimedia.org/wikipedia/commons/9/97/Mural_-_Birth_of_Christ.jpg": "A look at the Earth from space allows us to corroborate what we well know: that during the end-of-year holidays we show a massive display of multicolored lights that raise the nightly luminosity of the Earth above normal. Indeed, in the NASA document entitled \u201cThe Earth at night\u201d - which is possible to find on the website of the North American space agency-, nightly images of the Earth are included in which the nightly luminosity of our planet is compared during the months of December 2012 and 2013, with the average luminosity of the years 2012-2014. NASA concludes that during the Christmas season this luminosity increases between 20% and 50%; in the urban centers this increase is 20-30%, while in the suburbs it is 30-50%.In addition to explanations for our enthusiasm for the Christmas electric lights, it should be said that these originated towards the end of the nineteenth century during the first years of the electricity industry. Edison, who, as we know, played a central role, as an inventor and entrepreneur, in the development of that industry, decorated on the eve of the 19th century. In 1882, Edward Johnson, vice president of Edison\u2019s company, decorated a three-coloured Christmas tree with lights and then rotated it. This was done, as an article published in December 2016 by the \u201cSmithsonian Magazine\u201d relates, and Johnson invited a reporter from Detroit\u2019s \u201cPost and Tribune\u201d newspaper to see its creation. He wrote: \u201cIn the back of the beautiful halls, there was a large Christmas tree that had a very picturesque and strange appearance. It was brilliantly lit with eighty lights in total enclosed in these delicate glass eggs, and divided almost equally between white, red and blue. One can hardly imagine something more beautiful.\u201d By his invention, Johnson is recognized as the father of the Christmas tree illuminated with electric light. A decade after his invention, in 1895, the Christmas tree with electric lights arrived at the White House. That year, President Grover Cleveland ordered that the tree of the residence be decorated with hundreds of multicoloured lights, which constituted a decade after his invention, In 1903, the company General Electric commercialized the first miniature lamps for the decoration of Christmas trees. In the same way, in 1919 General Electric introduced the decorative lamps in the form of a flame, while in 1946 the company NOMA commercialized the bubble lamps that generate an upward flow of gas bubbles when they are lit. Today the Christmas incandescent lamps are being replaced by the LED lamps, which have many advantages, including that of being considerably more efficient, durable and resistant to impact, which undoubtedly contributes to the growth of Christmas lighting.It has been almost a century and a half since Edward Johnson came to decorate the Christmas tree with the newly invented electric lamps. He did not invent, of course, the Christmas tree, which is before the electric light.Before Johnson, however, the Christmas tree was illuminated by candles, which, in addition to the danger of causing a fire, did not have the spectacularity of electric light. In its early days, when the electric light was started. As soon as the population became accustomed to the new technology, however, the Christmas lights quickly advanced, covering trees, poles, fences, ceilings, and all kinds of surfaces on which a guide of light can be fixed. To the extent that today Christmas lighting can be easily detected from space.",
    "https://upload.wikimedia.org/wikipedia/commons/9/94/Nic%C3%A9phore_Ni%C3%A9pce_-_Mus%C3%A9e_Nic%C3%A9phore_Ni%C3%A9pce_-_DSC06022.JPG": "A photograph is a window that allows us to take a look into the past, immediate or relatively distant. How far away is it? Not beyond 1826, the year in which Joseph Nic\u00e9phore Ni\u00e9pce took a natural landscape in France, from the window of his office, what is recognized is the first photograph of history in which a natural landscape is captured - and preserved for the future. Regardless of its relevance as the first photograph of which we have news, this one is of poor quality and hardly appreciated details of the captured landscape. More interesting, without a doubt, is the photograph Louis Daguerre of 1838 in which the Boulevard du Temple of Paris is shown with great detail, with the image of a man standing and with a raised leg, apparently polishing his boots. And even more interesting is what is the first photograph \u201cselfie\u201d of the history, dating from 1839. In this photograph we can see the image of the amateur chemist Robert Cornellius looking at the camera. Photography is of a remarkable quality, given the early time in which it was taken and the few resources of the photographer. We have, of course, paintings and sculptures of people who lived hundreds and even thousands of years ago, but in which the artist printed his views, which could make them reflect a distorted reality. On the other hand, while there are no photographs of people more than two centuries old, the analytical techniques developed by modern science allow us in some cases to obtain information from people who have died much longer. Perhaps not to such a degree as to obtain reliable images of how they looked in life, but of other circumstances that marked their passage through this world. It is the case of people who after death were mummified, as was a common practice in ancient Egypt for more than two millennia. During the mummification process, the moisture of organic tissues was removed to avoid putrefaction and wrapped up in bandages impregnated with resins. human remains that would otherwise have been disintegrated a long time ago have come through the centuries. Thus, while such remains only give us a limited picture of the appearance that the person had in life, at the same time they allow us to investigate the circumstances that he went through throughout his existence. Egyptian mummies have been studied by means of X-ray techniques, using non-invasive methods. A notable example was published this week in the magazine \u201cInterface\u201d, by a group of researchers headed by Stuart Stock of the Northwest University in the North American State of Illinois. The Stock and Collaborators study was carried out with a 1,900-year-old mummy, discovered in Hawara, Egypt, in 1911, and is notable for the use of a large-scale research facility: the Advanced Source of Photones, from the National Argonne Laboratory of the United States Department of Energy. Employing a powerful X-ray beam generated by the source of photons, the researchers searched inside the mummy through its coating of bandages and resins. , helped by a previous computerized tomography study, by which they obtained an image of the inside of the mummy. They concluded that it was very likely a girl who showed traumatic signs and therefore had had a natural death. They also determined that she was buried with a calcite beetle amulet, which was intended to protect her during her transit to life after death. And all this information was obtained without destroying the mummy. It is very difficult that we could ever recover the image that the girl of Hawara had in life. To begin with, the photograph was not invented until about 1,800 years after she died. Furthermore, the light that at the time reflected the girl and with which she could form an image, at best she left our planet about two millennia ago and it is unthinkable that with the techniques that we can recover it. We will have to limit ourselves to the information that we can obtain with techniques such as those employed by Stock and collaborators. At least for the moment.",
    "https://upload.wikimedia.org/wikipedia/commons/b/bf/Macho_cabr%C3%ADo.jpg": "In December 2016, German archaeologists discovered in Sch\u00f6ningen, northern Germany, an interesting object: a wooden rod about 64 centimetres long, slightly curved and finished at both ends, and with a cross section that is approximately circular in its middle part and flattens to the extremes.The archaeologists concluded that this object was a hunting weapon used to kill or stun animals and that it could have been thrown to a distance of about a hundred meters.According to their discoverers, the object found in Sch\u00f6ningen is the oldest hunting weapon of which is known, manufactured and used by the foregone species of the Neanderthal some 300,000 years ago.For hundreds of thousands of years, in a hunter-gatherer stage, our genus used to hunt animals to make food.With the passing of time, however, livestock was developed - some ten thousand years ago - and there was no longer a need to hunt wild animals.In its place, some species were domesticated and kept in captivity, sacrificing, however, and there was no need to hunt wild animals. These numbers, moreover, are increasing rapidly, because while in the last fifty years the world\u2019s population has doubled daily, meat consumption has tripled. Moreover, in the future we might change again the way we obtain meat to feed ourselves, which would not come from the sacrifice of living species but from cultivation processes, analogous to how we grow plants in an agricultural field. As an indication that this is no longer a topic of science fiction but something feasible, the week that ends today we find out by means of the media that the US company \u201cEat Just\u201d got the Singapore food agency to approve for sale farmed chicken meat, obtained without the slaughter of live animals. This is the first time that a government agency approves the consumption of farmed meat. To manufacture its product, called \u201cchicken bits\u201d, \u201cEat Just\u201d combines farmed meat in a 1,200-litre bioreactor with components of live animals. This is the first time that a government agency approves the consumption of farmed meat. The cells needed to start the cultivation process are obtained from live animals, without sacrificing the donor. The nutrients needed for cell growth are of plant origin. All of this is certainly impressive, but one wonders whether the \u201cchicken bits\u201d grown are different than those obtained by more traditional means? According to the British newspaper \u201cThe Guardian\u201d, the answer of \u201cEat Just\u201d is: \u201cOf course they know different. But we hope that through transparent communication with consumers about what the product is and how it compares with conventional meat, we will be able to win. But there is no security.\u201d From the company that markets the \u201cchicken bits\u201d we would expect, of course, a positive opinion about their product. To have more evidence, however, we would have to consider more points of view. One of these is found in an article published last Thursday in \u201cThe Guardian\u201d, signed by Jenny Kleeman, who would have tried the \u201cchicken bits\u201d a couple of years ago. Although Kleeman\u2019s testimony is not recent and the product could have improved in two years, According to Kleeman, the chicken of \u201cEat Just\u201d: \u201cYes, it tasted like chicken: it had the unmistakable smell of chicken on my tongue and on my nose. It had some of the juicyness of the animal meat you expect when you eat chicken: that sticky sensation on your teeth when you bite a piece of meat. But it had the consistency of processed meat of lower imaginable quality. This was not a piece of chicken, a cut of meat, but a mass of chicken cells, bulging and pressed in the form of nutget. I had been told that this was the future of the food. But it was hard to swallow it.\u201d We would have to admit that with Kleeman\u2019s testimony our \u201cimpressive\u201d label to the product of \u201cEat Just\u201d is perhaps a little exaggerated, unless in the last two years the \u201cchicken bits\u201d have improved substantially. Soon, however, we have no further evidence about it, and it is difficult to predict if we enter in the short term in a third stage as meat consumers, different. which has prevailed in the last 10,000 years.",
    "https://upload.wikimedia.org/wikipedia/commons/1/11/Vancouver_Montage_2020.jpg": "What are the most appropriate measures to combat the spread of the coronavirus epidemic? Over the past few months we have received a wealth of information about it; contradictory in some cases, however. At the beginning of the pandemic, for example, some did not advise the use of the mouth cover because they felt that it could give a false sense of safety and cause the person using it to lower the guard. The mouth cover would thus be counterproductive. Over time, however, it has been extended, and has even become mandatory in some circumstances. In contrast, maintaining a minimum distance between people is a widely accepted measure, although it is not clear what this distance should be. The latter, given that contagion can occur through saliva drops, which fall to the floor after travelling relatively small distances, or by aerosols that are kept in the air for longer and travel longer distances. Moreover, the optimal measures to mitigate the spread of the coronavirus depend on the particular situation involved, as concluded by a group of researchers from Canada and the United Kingdom, in an article published on 19 November in the magazine \u201c The research group is headed by Paul Tupper of Simon Fraser University in Vancouver, Canada. Tupper and collaborators set out to determine the most appropriate measures to minimize the number of new infected people and make recommendations for organizing events. As a first step, they developed a simple mathematical model to calculate the number of people infected by a COVID 19 patient according to four parameters: intensity of transmission, duration of exposure, proximity of people, and, if applicable, the degree to which the different subgroups that make up a particular gathering of people are mixed. Researchers obtained values of these parameters from reports of different events including parties, restaurants, night clubs and meetings in general. They included, for example, the event in Washington State where 52 people from a 60-member choir were infected during a trial. They also included the case, which occurred in China, where 5 passengers from a bus, out of 39, were infected during a two-hour trip by a sick person who did not use bobo-covering. At the same time that, during the 50-minute sub-sequent journey of the same person, but now with mouth covers, none of the 14 passengers were infected.By means of their model, the researchers say, it is possible to determine which are the most effective measures to minimize the contagion in a given event.For example, reduce the transmission speed using mouth covers, increase the physical distance by decreasing the number of participants, or create bubbles that include a small number of participants without there being mixtures between them.Tupper and collaborators consider two extreme cases: a long-term meeting and many participants, in which the probability of being infected is large, and a second case in which this probability is small.The researchers find \u2013in an unsurprising way \u2013 that in all cases physical distancing is an effective measure to prevent the spread of the virus. However, the same thing does not happen, with the mouth covers, which is effective when the probability of infection is low, but it is to a lesser extent when a state of saturation of infections has been achieved. In the coming months, we will have to consider all the options to limit its spread, based on studies such as Tupper and collaborators. Although, like any scientific study, it has limitations and there is room for it to be imprecise. Although never as much as the versions that pointed out at the beginning of the pandemic that the mouth covers, far from being effective, were counterproductive.",
    "https://upload.wikimedia.org/wikipedia/commons/1/17/Ciclodelh20.jpg": "According to climate scientists, the rise in the temperature of the oceans by global warming is increasing the intensity of tropical cyclones. In the north of the Atlantic Ocean, cyclones - which in that region are called hurricanes - originate in the warm waters of the ocean off the coast of Africa. That is where there are adequate conditions of humidity and temperature necessary for the birth and development of these natural phenomena. As the experts explain, hurricanes thrive with the humidity that collects atmospheric air in contact with ocean water. In fact, such humidity is the fuel that generates and keeps a hurricane. Indeed, by absorbing moisture, the air becomes lighter and rises above the surface of the ocean, to heights where it finds lower temperatures that cause humidity to condense into clouds. With this condensation, the energy that keeps the hurricane in motion is released.The maximum amount of humidity that can contain the air, on the other hand, depends on its temperature; and at the same time, the higher the temperature of the water, the more easily it can transfer moisture into the air. as they move over the warm waters of the ocean. On reaching the coast, in contrast, they lose the energy source that keeps them moving and eventually extinguish. This is fortunate because only one strip along the coast of arrival is the one that suffers from hurricane strikes. This strip, however, is widening due to the effect of climate change. This, at least, according to an article published last November 11 in the magazine \u201cNature\u201d by Lin Li and Pinaki Chakraborty of the Institute of Science and Technology of Okinawa, Japan. According to Li and Chakraborty, as the temperature of the oceans is increased by climate change, there is a greater incorporation of moisture into the atmosphere, and therefore hurricanes tend to appear with higher loads of moisture and higher intensities. This increases the penetration distance of hurricanes land in the coast once they touch the coast, given that, with a higher humidity load, hurricanes have more reserves to survive active for longer periods, even on firm ground. Li and Chakraborty arrived at This conclusion, by means of a study of the hurricanes that hit land in the last 50 years, has increased in line with the rise in ocean temperature. Thus, while at the end of the 1960s a typical hurricane lost 75 percent of its intensity after the first day of landfall, at present this loss is only 50 percent. In addition, by computer simulations, Li and Chakraborty have shown that the increase in the duration of hurricanes on land is indeed linked to a higher humidity burden. The results of Li and Chakraborty indicate that even if the intensity of hurricanes remained the same, their destructive power is increasing by virtue of their greater penetration on land. In relation to this, researchers point out that the inland populations are less prepared to withstand the onslaughts of hurricanes than the coastal populations, and therefore are more vulnerable. Given that the planet's climate is extremely complicated, Li and Chakraborty's results would have been the result of Li and Chakraborty. With certainty, in the near future, to the extent that the effects of climate change are studied in detail, results will be found that will not be called to surprise, but that will not be apparent at first sight. After all, the temperature of the planet had not been so high in the last six thousand years.",
    "https://upload.wikimedia.org/wikipedia/commons/5/53/Simplified_world_mining_map_2.png": "After the Apollo project that brought Americans to the surface of the Moon came to an end, the space race entered a period of relative calm. Space activity did not cease completely, of course, and in the last half century we witnessed numerous spatial events, including the birth and death of space shuttles, and the sending of probes to explore the planets of the solar system with spectacular results.In the present century, in contrast to the period of relative calm, we are witnessing a renewed interest in space, not only from the original protagonists, the United States and now Russia, but also from the European Union, Japan, China, India, and even Israel.The interest in space, moreover, has spread to the private capital, which sees the possibility of doing business beyond our planetary borders.This, with NASA's complacency, propitiated the birth of private space companies by suspending the space shuttle program, which eliminated its ability to place astronauts in orbit. Space activity is thus in full swing, with plans to establish lunar bases and travel to the planet Mars. In order to extend our presence beyond the confines of the planet. For this expansion, however, space missions would need material resources, including metals and water, which could not carry with them from Earth because of the onerous amount of energy that would result \u2013 taking a bottle of water into space, for example, could cost tens of thousands of dollars. The high cost of sending materials into space is associated with the need to overcome the gravity of our planet, which requires a large amount of energy. Space missions would thus have to be made of resources in space. Asteroids, located between the orbits of Mars and Jupiter, would be candidates for obtaining materials in space, given their small mass and also small gravity. Asteroid mining, however, would require heavy machinery to be carried from Earth. In these circumstances, NASA has proposed as an alternative the use of biomining techniques. Biomining uses bacteria to extract valuable materials, for example, copper or gold, from mineral deposits. Since it does not involve the use of heavy machinery, biomining would then, in principle, be appropriate. In order to assess this operation, an international group of researchers led by Charles Cokell of the University of Edinburgh, Scotland, carried out a microgravity biomining study at the International Space Station. The results of this study were published this week in the journal Nature Communications. Specifically, Cokell and collaborators studied the extraction of materials known as rare earths, basaltic rocks using microorganisms. They found that such micro-organisms were not affected in their performance by the microgravity conditions prevailing at the International Space Station, concluding that biomining is possible in space. In fact, Cokell's results and collaborators go beyond their implications merely for spatial exploration and demonstrate that rare earth biomining is technically possible in space. And that said, it should be noted that rare lands are material of great technological importance, which we can find in numerous devices, including memories, including memories of rare earths being technically possible in space. And that, moreover, it is proposed that the demand for rare earths will soon exceed the supply. Thus, in this context, asteroid mining is presented as an option to obtain rare earths, which, according to experts, would be economically viable in the near future. Will we see in the years to come an expansion of our species to other confines of the solar system as augurs for the present boiling of space activity? And if this expansion were to occur, who would own the resources that would be obtained from the probable mining, by microorganisms or by other means, of asteroids? It is perhaps not out of the question to conclude that they will be owned by the first one that reaches them. Even if, in principle, it is assumed, they are the property of all mankind.",
    "https://upload.wikimedia.org/wikipedia/commons/6/62/Roihuvuori_water_tower_-_Helsinki_Finland.jpg": "One recommendation that foreign tourists who visit our country very commonly receive is that they be careful with the water they drink, if they feel compelled to spend a substantial part of their time getting to know hotel and restaurant baths, instead of enjoying the many tourist attractions that Mexico offers them. On the other hand, the problem with contaminated water is not, of course, exclusive to our country. In fact, according to the World Health Organization, 485,000 people die annually throughout the world as a result of diarrhea caused by drinking contaminated water. Given this figure, we are surprised to learn that 2,000 years ago, in the city that we now know as Tikal, in northern Guatemala, there were facilities to purify water that used techniques that are used today for this purpose. This, at least according to an article that appeared last October 22 in the journal Scientific Reports, published by a group of researchers headed by Kenneth Barnett Tankersley of the University of Cincinati.As Tankersley and collaborators explain, in contrast to Tenochtitlan, which had abundant natural sources of drinking water, Tikal was located In a territory in which the drought periods were common and therefore water had to be stored for human consumption.Since the stored water is susceptible to bacterial contamination and toxic materials, this would imply that the inhabitants of the city would have developed means to purify it.This is the conclusion reached by Tankersley and collaborators based on a field study carried out in Tikal, during which they discovered what was a water tank, with a capacity of about 58 million liters, which showed less levels of contamination than other deposits around it. At the bottom of the reservoir, in addition, they found sediments with quartz particles the size of a grain of sand and materials known as zeolites, which are today used in water purification systems. Zeolites are highly porous materials, which contain an intricate network of microscopic pores that penetrate into their interior and branch out. So dense and intricate is this network that, adding the area of all pores, a zeolite gram can add an area of 500 to 500 to 800 square meters. It is this high porosity that allows to trap contaminants in the water filtration and purification systems used today. Zeolites found in Tikal are not typical of the place where the water tank is located, but they would have been taken there from a distant place about 30 kilometers, presumably for the purpose of building a water purification system. There is no certainty of what the structure of this system would have been, but Tankersley and collaborators speculate that the water filter was placed at the point of entry of the water to the reservoir. There, the quartz and zeolite materials were placed between two solid side walls and two palm petates that allowed the water to enter and exit through the filter. From time to time, water avenues caused by tropical cyclones dragged the filter materials into the water tank forming layers in the sediment of the same. Thus, the filter would have to have been reconstructed after each avenue of water. In the case of the zeolite material, formed by particles of less size than quartz, there was transport of water. material towards the reservoir, even during the normal operation of the filter. It is undoubtedly remarkable that the Maya of Tikal have developed two millennia ago a system of water purification using principles that are valid today. And even more remarkable is that Tikal\u2019s is the oldest system of water purification in the world, using Zeolites, of which there is news. In fact, according to Tankersley and collaborators, Zeolite was not used again to purify water until the beginning of the 20th century. Thus, the Maya of Tikal advanced in this matter a couple of thousands of years to the rest of the world. In time Maya civilization declined and with this the technology of water purification was lost by means of Zeolites and we can do nothing about it. It is, however, in some interesting sense, to ask ourselves whether, if we had survived the Mayan civilization, would we have a higher quality water in Mexico? Which, of course, does not go beyond an idle exercise.",
    "https://upload.wikimedia.org/wikipedia/commons/c/cb/WW2Montage.PNG": "As we know, a person\u2019s body temperature is an indicator of his or her state of health, which would worsen the more he or she differs from his or her normal temperature. It is therefore essential to know the latter. According to 19th-century German physician Carl Reinhold August Wunderlich, the normal body temperature is 37 degrees Celsius on average. Wunderlich came to this conclusion after carrying out millions of body temperature measurements with 25,000 people. Such, however, it seems that Wunderlich\u2019s figures are not necessarily valid on the current days. This is the case, for example, of the population of the United States whose average body temperature has been decreasing in the last 200 years at a rate of 0.03 degrees Celsius every ten years, according to an article published in January of this year in the eLife magazine by a group of researchers headed by Myroslava Protsiv of Stanford University. Thus, the authors of that article conclude, the body temperature of the U.S. population - the same as in other developed countries - is currently approximately half a centigrade degree lower than the measure of measure. According to Protsiv et al., the decrease in body temperature is likely to be associated with the appearance of antibiotics and the economic development of industrialized countries, which has raised living standards, improved hygiene conditions and reduced infections by tuberculosis and malaria, all of which have decreased levels of chronic inflammation since the 19th century. An additional factor for this decrease, Prostiv and collaborators argue, could be associated with the use of heating and air conditioning systems, which limit environmental temperature variations, thus the body spends less energy to adapt to these variations. An article published this week in the magazine \u201cScience Advances\u201d gives us one more example of a decrease in body temperature. This time, in addition, not in a developed country, but in one in development. The article was published by an international group of researchers, headed by Michael Gurven of the University of California in Santa Barbara.Gurven and collaborators report the results of a study conducted with a representative group of the indigenous Tsiman\u00e9 population in Bolivian Amazon. . The results of the study are relevant because, according to the researchers, tsimane are an indigenous group with a subsistence lifestyle, which does not have running water and is highly exposed to different pathogens. They are thus far from the conditions prevailing in an industrialized country and it could be predicted that their body temperature would be closer to that measured by Wunderlich in the nineteenth century. Far from this, tsinam\u00e9 have experienced a decrease in body temperature equivalent to that observed in industrialized countries. This decrease has also occurred in the last two decades \u2013 the years corresponding to the presidency of Evo Morales \u2013 when tsinam\u00e9 enjoyed an improvement in their public health infrastructure and medical services, as well as vaccination campaigns and access to medicines. In industrialized countries, the decrease in body temperature has been in line with an increase in life expectancy that doubled in the years since the industrial revolution. Tsinam\u00e9, for their part, increased their life expectancy from 43 to 53 years in the second half of the twentieth century, although In addition, given that some Tsinam\u00e9 villages do not have electricity, it is obvious that the use of heating and air conditioning systems is not something common, and in this regard the energy used in the thermoregulation of the body does not seem to be a factor that determines body temperature. Moreover, there are certainly great differences in the conditions experienced by populations in North American cities compared to the Tsinam\u00e9 populations in Bolivian Amazonia. And despite this, as Gurven and collaborators point out, both populations have experienced a decrease in their body temperature coinciding with an improvement in their epidemiological and socio-economic conditions. And while the explanations for this phenomenon are still unclear, they argue that body temperature could be an indicator of the health of the population, as is life expectancy.",
    "https://upload.wikimedia.org/wikipedia/commons/c/cb/RBG-LED.jpg": "At present, with almost eight billion inhabitants in the world, approximately half of the world\u2019s habitable land is used to produce food. Moreover, it would be expected that in the next few decades, as the population of the planet increases \u2013 which is expected to reach almost ten billion people by 2050 \u2013 the area used in food production should increase. On the other hand, the challenges to increase food production in terms of the increase in its population will not be the same for all countries of the world and an article published this week in the magazine \u201cMIT Technology Review\u201d, signed by Megan Tatum, provides us with a dramatic example in this regard. The article of marras is entitled \u201cWithin Singapore\u2019s great commitment to vertical agriculture\u201d and refers to the production of indoor vegetable food that Singapore is carrying out, which, as we know, is a city-state with an area of 697 square kilometers \u2013 equivalent to a square area of just over 25 kilometres on the side \u2013 and a population of more than six million inhabitants. in the world. As a city-state, with a dense urban profile of high-rise buildings, Singapore devotes just 1 percent of its surface to food production and has to import 90 percent of the food it consumes. According to Tatum, this put Singapore in a situation of vulnerability in the months leading up to the crisis of 2008, when there was a worldwide increase in food prices. In this context, private companies in Singapore have developed vertical farms for the cultivation of vegetables in enclosed spaces using hydroponic techniques. In its article, Tatum describes the facilities of VertiVegies, one of these companies dedicated to the production of vegetables. Tatum writes: \u201cIn the interior of the installation, uneven plastic trays were carefully stacked on metal shelves, extending from the concrete floor to the corrugated steel ceiling. In each tray there were small green plants of different species and sizes, all with their roots bathed with the same watery solution, their leaves curving towards the same pink glow of the LED bar lights that buzzed slightly above. Plants are thus cultivated in sheltered facilities that are insensitive to external climatic conditions, and with artificial LED lighting and not through sunlight. With regard to the latter, it should be noted that when using LEDs as a source of illumination it is possible to combine the red and blue colors \u2013 and not the green color-, which are the ones that optimize the growth of plants. On the other hand, one aspect of central importance for Singapore is the vertical structure of the farm that optimizes space in its densely populated urban area. Vertical farms such as Verti Vegies could be a solution to Singapore's problems of vulnerability with regard to its dependence on food with the outside. With regard to this, Tatum cites Paul Teng, from Nanyang Technological University, who estimates that through vertical farms Singapore will be able to produce in ten years 30 percent of the vegetables it consumes. Criticisms to vertical farms such as Verti Vegies focus, understandably, on the high costs of installation \u2013 due to the high value of the urban land \u2013 even for vertical installations, as well as the costs of production of plants. that involve the use of artificial LED light \u2013 whose cost, however, has been significantly reduced in the last ten years.In one way or another, whether or not the use of vertical farms is extended in the decades to come, we would have to grant that the installations of VertiVegegies make us glimpse a future that until very few years ago was only typical of science-fiction. A future in which food is produced in closed facilities highly technified, more efficient and less polluting of the environment compared to traditional agriculture. And, moreover, that they are insensitive to the external climatic conditions. This latter is a point not to dismiss in the context of global warming that produces increasingly frequent extreme weather events.",
    "https://upload.wikimedia.org/wikipedia/commons/9/93/OOo-2.0-Base-ca.png": "Last January, the London police announced the installation in the city of a facial recognition system that would assist in the arrest of persons wanted by the police. For this purpose, the system will capture and analyze images of the face of people in public places, and will look for matches with the characteristics of faces included in a data bank of suspects of having committed a crime. In the event that the system has pointed out a suspect, the police will approach him and ask him to identify himself and arrest him in case he confirms that he is the person he is looking for.The facial recognition systems have become reality thanks to the advances experienced by artificial intelligence technology and massive facial imaging banks that have accumulated in recent decades.The London police measure, on the other hand, has been a source of criticism, because of the apparent inefficiency of the system for the identification of suspects. Thus, while the London police argue that the system generates only a false alert for every 1,000 cases, a study by the University of Essex finds that of 42 cases studied, only in 5 were successful. Of course, the reason for the great difference between what was reported by the University of Essex and the London police would be substantial differences in the efficiency of the facial recognition system depending on the facial images that it has to analyze. Thus, this efficiency would be greater with images obtained on purpose, well illuminated and resolved, than with blurred images obtained in a public place. Otherwise, although the case of London is not unique \u2013 Moscow, for example, shortly after the announcement of London, made known the deployment of an extensive facial recognition system \u2013 other cities, such as San Francisco and Boston, have banned its use by the police or government agencies because they consider it a technology that is not yet sufficiently developed. It is pointed out, for example, that technology produces biased results against minorities, which accuse a greater percentage of false positives compared to the white majority population.The cause of bias does not lie, of course, in the nature of facial recognition systems, but in the information that was supplied to them, in the form of facial images, during their training. , facial recognition systems are exposed to a greater number of images of white people than of other minorities, and as a result there is a bias in the number of their mistakes. One case that has become visible in recent days and that also involves a bias of facial recognition systems \u2013 this time towards the younger ones \u2013 is that of the city of Buenos Aires, Argentina. As commented in an article published this week in the magazine \u201cMIT Technology Review\u201d under the signature of Karen Hao, the city of Buenos Aires has installed a facial recognition system for the capture of persons wanted by the police. This system is linked to a database known as the National Consultation of Rebeldies and Captures, or CONARC, in which data are concentrated of persons suspected of crimes.The Buenos Aires system has shown numerous faults of identification of suspects.In one case, for example, a man was arrested for 6 days, being transferred to a maximum security prison before being released. In another case, the victim was warned that he could suffer more arrests in the future and to avoid them, a pass was given to him. In addition, according to a \u201cHuman Right Watch\u201d investigation, CONARC contains information about minors, most of whom are aged 16 and 17, but also some who are considerably younger, even up to a year old. Although it has not been documented that infants would have been the subject of an arrest, older young people if they are exposed to this contingency. In fact, they are more likely than adults, given that facial recognition systems cause more mistakes in the case of younger ones, because they were trained to recognize older people. We may conclude that facial recognition systems as they advance technologically will undoubtedly have positive aspects. But in so far as this happens, both their positive and negative aspects should be balanced. Without losing sight of the Orwellian dystopian vision.",
    "https://upload.wikimedia.org/wikipedia/commons/0/0b/Mooncolony.jpg": "Almost 50 years have passed since the last Apollo mission of NASA that brought astronauts to the surface of the Moon. Since then we have not re-stepped the surface of our natural satellite. Recently, however, the interest in returning to the Moon has resurfaced and for this purpose NASA has implemented the project \u201cArtemis\u201d, which seeks to establish a permanent base on the lunar surface for, among other purposes, preparing a manned journey to the planet Mars in a still undetermined future. What would be determined is the date of the initial journey to the Moon that would take place in 2024. While most of us would not think of changing our place of residence from Earth to a base on the Moon, or even spending there a few days or weeks in a tourist plan, we might perhaps be curious about what climatic conditions prevail on our natural satellite. As we know, the Moon does not have atmosphere, so that to walk on its surface it would be imperative to do so within a space suit. Another drawback is that by not having the Moon or atmosphere or a magnetic field such as Earth \u2013 by means of which a compass always pointing north. - we would be continuously bombarded by the high-energy radiations that come from interstellar space and that in our environment are attenuated by the atmosphere or are diverted by the Earth's magnetic field. In addition, we would be at the mercy of the intense radiations emitted by the Sun during solar storms. The Moon is then an unfriendly world. However, since there will be no shortage of those who will spend more or less time on the Moon, it is vital to know how intense the high-energy radiations on its surface are. This is certainly the case of astronauts who will participate in the \u201cArtemis\u201d project. How high are the high-energy radiations on the surface of the Moon? The answer is given to us by an article published this week by a group of researchers and institutions in China and Germany, headed by Shenyi Zhang of the National Centre for Space Science of China. In their article, Zhang and collaborators report high-energy radiation values measured by the Chinese Chang \u0301e 4 probe, which announced at the beginning of last year on the hidden side of the Moon. And collaborators find that astronauts on the Moon would be exposed to high-energy radiation 200 times more intense than those experienced on Earth. They would therefore have to protect themselves with some kind of radiation-absorbing cover. With regard to the latter, researchers estimate that a cover of at least 50 centimetres thick of lunar earth would be sufficient protection. In the event of a solar storm, astronauts would have to stay in a shelter protected by a volume of water of 10 meters thick.With precautions and many resources and work to build a lunar base, we could perhaps survive on the Moon for more or less long times. While for half a century manned missions of exploration of the Moon were suspended, there is now a renewed interest in visiting our natural satellite by various means.Not only by countries that pioneered space exploration, but also by other countries such as Japan, India, Israel and \u2013 it could not be otherwise \u2013 China, which has become the third country in achieving softly robotic probes on the lunar surface.As we know, in decades of years, as we know, Fifty-sixties the United States and the Soviet Union became involved in a space race. Initially, the Soviets clearly outnumbered the Americans. Within a few years, however, by massive injections of money to NASA, they managed to make an American astronaut the first to set foot on the surface of the Moon, thus surpassing the Soviets. One may wonder whether 50 years after the first space race a new race for the Moon could arise, this time between the United States, in conjunction with the countries and private companies that are collaborating on the \u201cArtemis\u201d project, and China on the other. Only time will tell.",
    "https://upload.wikimedia.org/wikipedia/commons/9/94/Methane-CRC-MW-dimensions-2D.png": "\u201cClimate scientists are terrified of a second Trump period,\u201d is the title of an article published last September 24 by James Temple in the MIT Technology Review of the Massachusetts Institute of Technology. And those who are not terrified will most likely be at least deeply concerned, given the initiatives taken by the President of the United States regarding measures to mitigate climate change. As we know, the President of the United States is not a believer \u2013 at least publicly \u2013 that the planet is suffering from climate change as a result of our activities and openly recognizes it. An example of this was given on September 2 during his trip to California on the occasion of the fires that fuel the state, which the President of the United States attributes to the fact that dry logs and leaves are not removed from the forests. In the meeting with Californian officials, according to the New York Times newspaper, the Secretary of the State\u2019s Natural Resources Agency urged the President to \u201crecognize climate change and what this means for our forests.\u201d Far from recognizing it, however, the President would have responded: \u201cHe will start cooling, And at the insistence of the secretary who replied: \u201cI would like science to agree with you,\u201d the president closed the exchange by saying: \u201cIn fact, I don\u2019t think science knows.\u201d As for this last statement, although the Earth\u2019s climate is an extremely complex subject of study, there is a scientific consensus that the sustained increase in the concentration of greenhouse gases in the atmosphere \u2013 which has risen by about 50 percent compared to its pre-industrial level, the highest in 800,000 years \u2013 has put the planet on the path of a climate disaster. There are some scientists, however, who consider that the high concentrations of greenhouse gases in the atmosphere are actually beneficial. It\u2019s the case of William Happer, emeritus professor at Princeton University and, until September last year, advisor to the president as director of the office of emerging technologies of the National Security Council of the United States. Happer, who is a professor of physics but doesn\u2019t have formal training in climate science, maintains that with more carbon dioxide in the atmosphere \u2013 let\u2019s remember that A majority of experts believe, however, that although the plants might be happier with higher concentrations of carbon dioxide, the increase in this gas in the atmosphere brings climatic consequences that are ultimately negative \u2013 an increase in global temperature and a greater acidification of the oceans, among others. President Trump\u2019s disbelief in climate change has led him to undo or attempt to undo regulations and initiatives that seek to mitigate climate change. We know that in June 2017 he announced that the United States would disengage from the Paris Agreement that has been ratified by 187 countries. This agreement seeks to reduce greenhouse gas emissions to limit the increase in global temperature to 2 degrees centigrade since the pre-industrial era, and to make efforts to limit this increase to 1.5 degrees centigrade. The formal separation of the United States from the Treaty of Paris is scheduled for November 4. Internally, as James Temple argues, the United States administration is dismantling its predecessor\u2019s initiatives to control. According to an analysis by the firm Rhodium Group, current deregulations will lead to an increase in greenhouse gas emissions in 2035, which would be equivalent to Russia's annual emission. Thus, those who are terrified wonder what will happen if the present administration has another four years to consolidate its efforts to change environmental regulations. Or if, as Temple points out, the country is in the course of a profound political change, in which case the climate would not be the biggest concern.",
    "https://upload.wikimedia.org/wikipedia/commons/2/21/Nature_volume_536_number_7617_cover_displaying_an_artist%E2%80%99s_impression_of_Proxima_Centauri_b.jpg": "Although Venus may not be as popular as Mars, this week became news when an international group of researchers, headed by Jeane Graves of Cardiff University, published an article in Nature Astronomy magazine in which it reports that it has detected phosphine gas in its atmosphere. According to the conclusions of that article, although phosphine may have a non-biological origin, it could also be originated by microbial life. This last one, although the environmental conditions on Venus are extreme and far removed from those prevailing on Earth. But let's go in parts.Let's first consider that Venus's orbit around the Sun is the second furthest away from Mercury, which would lead us to conclude that the surface of Mercury is warmer than that of Venus. This is not the case, however, because Venus has an extremely dense atmosphere of carbon dioxide \u2013 the greenhouse gas that is giving so many problems to the Earth's climate \u2013 which keeps the planet's surface above 400 degrees Celsius. The latter is responsible for the low popularity of Venus compared to Mars, which has a more moderate climate. Venus, on the other hand, has not always been a planet with little appeal. After all, seen from Earth, it is the second brightest night object in the sky after the Moon and has been well identified since we started searching the sky. Thus, as a prominent space body, Venus was in the decades of the sixties and seventies of the last century a planet of great interest to the space agencies of the United States and, above all, of the then Soviet Union. In fact, Venus and not Mars was the first planet on whose surface a controlled planetary probe was located. This occurred in December 1970, when the Soviet Union placed on the venus surface to the Venera 7 probe, which managed to transmit from there for 23 minutes information about the environmental conditions of the planet. The information sent by the Venera 7 probe confirmed that the temperature on the surface of Venus is around 450 centigrade degrees, and that its atmosphere is so dense. that the atmospheric pressure is about 100 times greater than that of our planet. Before the planetary probes made us aware of the true environmental conditions of Venus, it was conjectured that the climate of this planet was warm, dry or humid, but not incompatible with life. It competed in this way with Mars, among science fiction writers, as a seat of extraterrestrial civilizations. Unfortunately, the planetary probes taught us that, far from being a friendly place, Venus is a hell with an extremely dense and dry atmosphere, and with high concentrations of sulfuric acid. The appeal of the planet then suffered a considerable deterioration.The environmental temperature of Venus, however, is moderated as we rise above its surface, and to some tens of kilometers of height reaches about 30 degrees centigrade. It is there, conjection Greaves and collaborators, floating in the atmosphere, where the microbial life responsible for the phosphine detected in Venus could flourish. If this possibility were satisfied, Venus would surely recover its place that it has always had as one of the most outstanding objects of the planet. However, it should be noted that, in contrast to the stridency of the media that highlighted the conjecture of the existence of microbial life on Venus, Graves and collaborators are very cautious in their article and write in the same one that \u201cEven if confirmed, we emphasize that the detection of phosphine is not a robust evidence of the existence of life, but of an abnormal chemical process and for which there is no explanation for the moment.\u201d At the same time, however, they emphasize that, despite their efforts, they have not managed to find a non-biological explanation for their finding of phosphine on Venus. Will the non-biological origin of the phosphin found on Venus be confirmed? Or, on the contrary, will the existence of microbial life on this planet be confirmed? To find answers we will have to wait for further research to shed light on it.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d0/Ferdinand_of_Aragon%2C_Isabella_of_Castile.jpg": "With the Treaty of Tordesillas of 1494, the Catholic Monarchs and the King of Portugal divided the world by discovering by means of an imaginary line running from pole to pole and passing to 370 leagues west of the Cape Verde Islands. According to this treaty, Spain would have the territories to discover west of that line, while Portugal would take possession of those to the east of it. To agree and divide the world the way they did, Spain and Portugal certainly did not contemplate the possibility of asking the inhabitants of the world for an opinion to discover the convenience or non-advisability of such a distribution. Nor were they asked to other countries. In fact, Holland, England and France did not recognize the Treaty of Tordesillas and undertook their own voyages of exploration and of taking possession of territories throughout the world. All this comes to light by a recent announcement from NASA, that they will put in competition contracts with private companies to promote the development of mining on the Moon. The project was presented by Jim Bridenstine, administrator of the NASA. NASA, in a statement dated September 10th. According to Bridenstine, the winning company of the contest will have to collect small samples of dust or moon rocks at some location of the Moon and provide NASA with photographs of them. It will also have to provide information and photographs of the place where they were collected. Finally, it will have to transfer the ownership of the lunar samples to NASA. The contract does not include the transfer of lunar material to Earth, which would be implemented by NASA at some future time. The initiative announced by Bridenstine is given in the context of the Artemis program, through which NASA seeks to resume manned missions to the Moon in 2024, and to initiate a lunar exploration program with the long-term objective of establishing a sustainable presence on the Moon, which eventually serves as a support point for the dispatch of a manned mission to Mars. To accomplish these objectives, NASA seeks the competition of the private company that, as we know, is aggressively entering the space industry. NASA anticipates that it will pay between $15,000 and $25,000 dollars for lunar samples that weigh between 50 grams and 500 grams. 10 percent of the payment will be made at the signing of the contract, another 10 percent at the time of the launch of the mission to the Moon, and the remaining 80 percent after the successful completion. These will be the only payments that NASA will make so that the costs and risks of the mission, which will have to be completed by 2024, will be borne by the company involved. Under these conditions, the company in charge of the project would have to carry out as a complement to another project that would anyway bring it to the surface of the Moon. Although the company will not do a big deal, the initiative would constitute the beginning of commercial exploitation of space by private companies. As NASA explicitly states: \u201cThe collection and transfer will be a proof of concept for conducting space trade on the Moon.\u201d In the same vein, Casey Dreier, of the Planetary Society, states: \u201cThe importance of this announcement is not so much the financial incentive (which is tiny) but in establishing the legal precedent that private companies can collect and sell celestial materials (with the blessing of NASA/ In contrast to the times of the Treaty of Tordesillas, there is now a concept that the fate of resources that are common to all inhabitants of the Earth, as is the case with the Moon and all space bodies - to the extent that they are not inhabited by intelligent beings - is a collective decision. In this regard, the United Nations treaty on extraterrestrial space, in force since 1967, states that \u201cThe exploration and use of extraterrestrial space will be carried out for the benefit and in the interest of all countries and will be the competence of all humanity.\u201d According to NASA, its lunar mining project does not contradict the agreement on extraterrestrial space. Still, one should ask to what extent NASA\u2019s decision is in the interest of the world and not of particular interests. That is, to what extent would we find ourselves before a kind of echo of Tordesillas?",
    "https://upload.wikimedia.org/wikipedia/commons/7/71/LightningVolt_Wood_Floor.jpg": "It is not too difficult to understand that petrol or diesel motor vehicles are a source of air pollution. Especially if, as it happens, they fire a thick cloud of black smoke when they accelerate. Taking it with philosophy, we could perhaps convince ourselves that the smoke of escapes is the price of progress and that, in any case, we could overcome it by designing less polluting vehicles \u2013 as in fact it has happened \u2013 or by using electric vehicles. It happens, however, that the drawbacks \u2013 not to say misfortunes \u2013 do not always come alone and now we learn that the same asphalt tracks \u2013 streets and roads \u2013 on which cars and trucks run are sources of atmospheric pollution. To this conclusion comes an article published this week in the magazine \u201cScience Advances\u201d by an international group of researchers from the United States and Germany, headed by Peeyusk Khare from Yale University. To understand how an asphalt road can produce atmospheric pollution, it should be considered that the greater part of the asphalt that is commercially used is obtained from crude oil and that it contains organic components that are volatilized. These aerosols consist of microscopic particles suspended in the air, which are highly hazardous to health. Khare and collaborators decided to quantify the volume of gases released during the placement and lifetime of asphalt surfaces. As part of their research, the researchers subjected asphalt samples to a temperature of 140 degrees Celsius, which corresponds to the temperature of transport and placement of asphalt pavement, and measured the volume of gases released using sophisticated techniques. They found as a first result that after a week of warming the sample stopped emitting gases. They also found that during the first five hours of warming to 140 degrees Celsius 14 percent of the total gases contained in the sample was released. Thus, since it is precisely five hours the estimated time during which the asphalt maintains this temperature during transport and the process of the total gases contained in the sample. The researchers concluded that once placed still contains 86 percent of gases susceptible to release into the atmosphere. This in fact occurs on hot summer days when the pavement can reach a temperature of 60 degrees Celsius. On the other hand, the speed of gas release at 60 degrees Celsius is much lower than that observed at high temperature, which makes the asphalt pavement a source of long-lasting air pollution. To make things worse, Khare and collaborators find that the exposure of the pavement to a moderate intensity of sunlight increases the release of gases by up to 300 percent to the ambient temperature. Between paved areas and roofs of houses \u2013 where asphalt is also used \u2013 approximately 65 percent of the surface of North American cities is covered with asphalt. Under these conditions, Khare and collaborators estimate that the potential for generating polluting aerosols by asphalt surfaces in the city of Los Angeles is as large as that of internal combustion vehicles. internal combustion engines would not only make them more efficient and less polluting, but also mitigate the pollution of the paved surfaces on which they run. Not forgetting that global warming raises the temperature of the paved surfaces and therefore increases the emission of polluting gases and aggravates the problem. Moreover, pollution by paved surfaces would be aggravated according to the frequency with which the pavements are renewed. And in that sense, in Mexico we can be reasonably calm.",
    "https://upload.wikimedia.org/wikipedia/commons/e/e1/Led-lampa.jpg": "Those of us who are old enough have witnessed over the last half century a substantial increase in the efficiency of gasoline consumption that cars have experienced. In this regard, we remember the cars manufactured by the companies of our neighbor to the north in the decades of the fifties and sixties, large and equipped with powerful engines, and for which the efficiency in the consumption of gasoline was the least of the worries.The situation changed in the decade of the seventies of the last century because of the so-called oil embargo that produced great increases in the price of oil, and today energy efficiency is one of the virtues that we most appreciate in a car.In the days that run the energy efficiency of cars is also a virtue due to the atmospheric pollution caused by the burning of fossil fuels that threatens a climate collapse.In fact, an increase in energy efficiency in general - and not only of automobiles - is one of the strategies that have been implemented to mitigate climate change.According to this strategy, the more efficient we are, we will reduce energy consumption in transport, industry, lighting, and in general in all our activities such as We would perhaps agree that the latter sounds reasonable. It is not necessarily so, however, according to an article published this week in the online magazine PLOS ONE. The article was published by Timothy Garret of the University of Utah, Matheus Grasselli of McMaster University and Stephen Keen of University College London, who conclude that energy efficiency, rather than decreasing energy consumption, tends to increase it. But let's go about parts.Garret and collaborators conceive - in an unusual way - of human civilization as a biological or physical entity that consumes and wastes energy for the fulfilment of its functions. In this context, the motor of a car, for example, obtains energy from the combustion of gasoline and partially uses this energy to drive the vehicle. At the same time, and inevitably in accordance with the laws of physics, wastes part of the energy it consumes. Similarly, human civilization consumes and wastes energy, but, unlike the automobile, not only uses it to stay in operation -in all the face of physics, it wastes part of the energy it. And as civilization grows, so does its appetite for energy.The researchers exemplify the latter with the evolution that we suffer since we were born.That is, when children take energy from what we eat and use it to maintain our metabolism as living beings, and to grow into adults.The same happens with the human civilization that consumes energy to maintain its metabolism and to grow in size.And in the latter, according to Garrett and collaborators, it is where the problem lies, because as time goes by the growth of the global economy and to that extent its energy demand increases. Thus, by an effect of inertia, the demand for energy in the present depends on the level of energy consumption that was had in the past.To corroborate this last hypothesis, Garret and collaborators compared the annualized consumption of energy at the global level in the period 1980-2017, with the historical economic production that had been reached in each of the years of the period studied.They found that in that period, both quantities \u2013which multiplied by the number of energy consumed at the global level in 1980-2017, with the historical production reached in each of each of the years of the period studied. In this sense, Garret and collaborators conclude that economic growth is stimulated by innovations in energy efficiency. That is, that such innovations instead of contributing to energy savings would stimulate their consumption.And in these circumstances, we have only to cross our fingers so that the conclusion is incorrect and that the remedy does not aggravate the disease.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d8/NASA_Mars_Rover.jpg": "In December 1971, the Soviet Union was the first country to gently pose a probe on the surface of the surface of the planet. As we know, the successive explorers that NASA has placed on the surface of the Martian surface have increasingly had mobilitys. In December 1971, the Soviet Union was the first country to gently pose a probe over the surface of the surface of the planet, making the following reflection in an interview published this week by the University of Texas in Austin. \u201cImagine that you are an extraterrestrial who knows almost nothing about the Earth, and who lands at seven or eight points on the surface of our planet and moves over it for a few hundred kilometers. Would you know enough about the Earth?\u201d Obviously the answer is no: with such a superficial exploration \u2013 in a literal and figurative sense \u2013 you would get a very limited view of our planet. Ono makes his comments in reference to the exploration of the surface of the planet Mars by explorer robots and concludes: \u201cIf we want to represent the enormous diversity of Mars we need more measurements of its surface and the key to this is the explorations along substantially larger distances, hopefully covering thousands of miles.\u201d Four years later, NASA placed on Mars the Viking 1 and Viking 2 probes that provided us with the first panoramic and colour images of the planet\u2019s surface. The first exploration probes on Mars, however, did not have mobility and only provided us with information from a fixed point of view. Subsequent NASA missions sent explorer robots to Mars that were able to move along its surface and provided us with more varied images and information. The first one, the \u201cSoyourner\u201d arrived at Mars in July 1997 and travelled approximately 100 metres over 91 Martian days. Later, in January 2004, the explorers \u201cSpirit\u201d and \u201cOpportunity\u201d landed on the Martian surface. The first one travelled 4.8 miles and the second 28 miles, over five and fifteen years, respectively. Currently, the explorer \u201cCuriosity\u201d is active on Mars and has travelled 12 miles since its arrival in August 2012. On the other hand, as Masahiro Ono explains, if we want to have a more accurate knowledge of Mars. Four years later, NASA placed on Mars. Four years later, NASA placed on Mars, as well as well as we did on Mars. Mars needs to extend the mobility of future explorers. To do this, however, it is easier said than done. In fact, to move on the Martian surface robots must overcome multiple obstacles and for this purpose make decisions involving operators from Earth. Ideally, explorers should be autonomous and make their own decisions without the need to communicate with operators on Earth. As we know, in principle autonomous navigation on Mars would be possible as autonomous vehicles do here on Earth. In practice, such navigation has been difficult to achieve by the limited computing capacity that explorers have arranged on Mars \u2013 far from that of an iPhone phone \u2013 and also by limited availability of energy \u2013 provided by the Sun. In the near future, as explained by Ono, explorers will increase their computing capacity without increasing energy consumption through the development of new processors, and they are expected to reach a certain level of intelligence, but not at the level of autonomous vehicles that we know. A strategy to increase the mobility of explorers will combine the computing capacity available here in Earth for the development of plans of movement using sophisticated techniques of artificial intelligence, which indicate the steps to follow given the conditions of the terrain. These plans will be delivered to the explorer on the surface of Mars who will make use of their increased computing capacity to execute them. Otherwise, the photographs that the explorers have sent us from the surface of Mars show a dry and rocky landscape, in some way similar to some places on our planet. We would not have to deceive ourselves, however, because the two planets are very different in their ability to harbor life as we know it. In these conditions, and for the moment, there would be no reason to travel to Mars in person. But yes to explore it through robots that will feel more and more at ease on Mars, without suffering from our limitations as living beings.",
    "https://upload.wikimedia.org/wikipedia/commons/7/7d/Trapecistas_en_Circo_Americano_de_DavidDaguerro.jpg": "The story recounted here begins half a century ago when Mara, an Asian elephant born in captivity in India, was transferred after her birth to the Tierpark Hagenberck Zoo in Hamburg. Mara did not remain for much time at the zoo, since in May 1970 she was sold to the \u201cCirco Africa\u201d and moved to Montevideo, Uruguay. As part of the circus, Mara was exhibited in Uruguay, Argentina and Brazil making the lots of elephants in these circumstances. Apparently, and within what fits, this stage of Mara\u2019s life would not have been altogether bad. Her fate changed, however, when her owners withdrew from the circus business and sold her to the Argentinean circus Rodas. In Circus Rodas Mara was not happy. Evidence of this is that at some point she killed her coach tired of the ill-treatments. She spent there, however, 25 years of her life until 1995 she was rescued by the zoo in the city of Buenos Aires after she was found chained in a parking lot. In particular, Mara did not have enough space to move and was often seen swinging her head for hours in circles, which is interpreted as a sign of stress. She also had to share her space with two African elephants. The elephants' legions may not see too many differences between Asian elephants and Africans \u2013 perhaps outside of their size. Mara, on the other hand, is not apparently of the same opinion and, in fact, did not have the slightest sympathy for her fellow captives. In these circumstances, it was proposed to move Mara to an elephant reserve in the Mato Grosso region of Brazil, distant from Buenos Aires about 2,700 kilometers. Mara would have to change her country of residence, which involved a series of bureaucratic formalities that were complicated for her. And that were more so because the transfer coincided with the health emergency due to the coronavirus pandemic that closed the border between Argentina and Brazil. Among other requirements for her transfer, Mara had to undergo a quarantine. The transfer was originally planned for the month of March of this year, but was suspended because of the health emergency. It could finally be carried out on 9 May and for that purpose the elephant was confined in a narrow box that was raised with a crane to the platform of a truck for its transfer to the Mato Grosso. Two days after its departure the convoy arrived at the border with Brazil, which it was able to cross after nine hours of bureaucratic formalities. Three more days it took it to arrive at its final destination. Before this, however, it had to be transferred, by means of a crane, the box with the elephant to another transport that could travel the last 65 kilometers until the reservation. At this point, with its lockup and the hustle and bustle of the journey, Mara may have considered that it was going from bad to worse, and that it would have been more worthwhile to stay in the zoo. The story, however, had a happy ending, because it seems that Mara quickly adapted to her new habitat. She even became friends at first glance with Rana, another elephant -asian, of course - of the reserve and from which it is inseparable. They calculate those who know that Mara is now approximately 50 years old and that she is still in front of her about 25 years of life. However, they expect her caregivers to be better than the first 50, when she was forced by blows to sit or stand by her hands, or to languish, rocking her head for hours, in too small a space. And in addition, with two broads she did not carry.",
    "https://upload.wikimedia.org/wikipedia/commons/e/ef/B17g_and_b52h_in_flight.jpg": "Today, August 9th, marks the 75th anniversary of the atomic bombing of Nagasaki carried out by the United States at the end of World War II, three days after the city of Hiroshima had run the same fate. Both bombings resulted in an estimated 250,000 fatal casualties, including those who died at the time of the explosions and those who became ill by radioactive poisoning and died later.The psychological impact of these attacks on the Japanese population was, to say the least, of great proportions.And not so much because of the huge number of deaths among the civilian population, but because of the destructive power of the new weapons.In this sense, it should be remembered that while the attack on the city of Tokyo during the night of 9 to 10 March 1945 with conventional bombs resulted in about 100,000 deaths, in order for this to happen it was necessary to deploy 279 B29 bombers that launched over the city 1700 tons of incendiary bombs.In contrast, the destruction of Hiroshima carried out by a single B29 bomber by means of a single uranium bomb.The bombings of Hiroshima and Nagasaki have provoked, it could not be from the destruction of Hiroshima. Another way is for the Japanese population to have negative feelings against nuclear weapons and to oppose the development, and even the presence, of such weapons in their territory. No matter how much Japan relies on the nuclear power of the United States for its defense.A manifestation of Japan's traumatic experience with nuclear weapons is the film \"Godzilla\", directed by Ishiro Honda and released in 1954, just nine years after the end of the war.This film, which was very successful, constitutes an allegory of the atomic bombings of Japanese cities and includes explicit messages against the development of nuclear weapons.According to the plot of the film, the hydrogen bomb tests carried out by the United States on the atolls of the Pacific Ocean, uncomfortable and removed from their habitat at the bottom of the sea to Godzilla, a gigantic surviving monster of the Jurassic period. At the beginning of the film several ships were attacked and sunk by Godzilla, episodes that would have been inspired by the incident that occurred on March 1, 1954, in which the Japanese tuna ship Daygo Fururyu Maru was exposed to radiation from a nuclear test carried out by the United States in Bikini Atoll. As a result of this exhibition, one of the crewmen died of radioactive poisoning. Following his first encounters with humans, Godzilla went to Tokyo, resisting without major problem all the attacks that were directed to stop him. Once in Tokyo, the monster produced, with his fiery breath and enormous force, a destruction comparable to that of Hiroshima. Godzilla was finally put out of combat by the \u201cOxygen Destroyer\u201d, a powerful device invented by Dr. Daisuke Serizawa. Such was the power of such a device, that Serizawa feared that he might fall into the hands of governments that would use it. In these conditions, the scientist took on the role of hero and decided to immolate himself and die together with Godzilla, in order to avoid being forced into the future to reproduce his invention for aviable purposes. The original Godzilla film is therefore a metaphor for the nuclear attacks on Hiroshima and Nagasaki and a propaganda against atomic weapons. Literally taken, on the other hand, it is inaccurate in that a weapon with sufficient power to defeat Godzilla could be manufactured by an isolated scientist, and that a personal decision was enough to put it out of reach of governments willing to use it as a weapon of mass destruction. Indeed, we know that the nuclear weapons that devastated Hiroshima and Nagasaki were the result of a national effort involving numerous groups of scientists and engineers supported by huge amounts of resources; and that, certainly, it would be more than a personal decision to put them out of combat.",
    "https://upload.wikimedia.org/wikipedia/commons/2/2a/SH-60B_helicopter_flies_over_Sendai.jpg": "The measures that have been implemented to slow the spread of coronavirus in the world have led, among other effects at the global level, to a decrease in greenhouse gas emissions and a reduction in atmospheric pollution levels. This, for example, has made it possible for the Himalayan mountains to have been visible for the first time in thirty years from a distance of hundreds of kilometers in northern India. Another collateral effect of the pandemic, perhaps more surprising, at least for lay people in this field, has been the reduction in the seismic movements that human activities produce in the earth\u2019s crust. This reduction is documented in an article published on 23 July in the magazine \u201cScience\u201d. This article was published by a large group of researchers attached to research institutions throughout the world, including Mexico, headed by Thomas Lecocq of the Royal Observatory of Belgium. According to Lecocq and collaborators, seismic waves of very small magnitude are continuously produced by the interaction of the earth\u2019s crust with various natural forces; for example, by the forces that the sea waves produce on the surface of the earth have been reduced. In the same way, there are human activities that generate seismic waves. This is certainly the case of nuclear explosions, but also of ordinary activities such as transportation and industrial manufacturing. To carry out their study, the researchers made use of seismic data reported throughout this year by 268 measuring stations in 155 countries, including, both urban areas and isolated areas with little concentration of people. Of these stations, 185 reported a decrease in seismic activity due to the effect of the pandemic by up to 50 percent over the course of months. Moreover, although the most pronounced seismic casualties occurred in urban areas - in an understandable way-, these were also observed in areas with population densities less than one person per square kilometer. Lecocq and collaborators note that the period of seismic quiet caused by the pandemic is the longest and most prominent period of memory. As Lecocq and collaborators point out, during the pandemic it has been possible to capture subtle seismic movements of natural origin that under normal conditions would have been mixed with anthropogenic seismicity. They also point out that the greater knowledge of the natural seismicity of the Earth obtained during the period of seismic stillness -baptized as anthropopause - could help to better distinguish the natural seismic activity of the Earth from that anthropogenic seismic activity and thus contribute to the prediction of earthquakes and natural disasters. Likewise, researchers note that a greater knowledge of the natural seismic activity of the Earth will allow, once we overcome the health contingency, to identify more easily the anthropogenic components of earth seismicity and to use them as a monitor for our activity on the surface of the Earth. Thus, the coronavirus pandemic has provided us with tools that could be of great future utility. On the one hand, the period of seismic quietud that has caused us to listen to the natural vibrations of the Earth without anthropogenic interference and thus contribute potentially to its identification. The prevention of earthquakes in the future. On the other hand, it has put in the way of anthropogenic seismicity as a monitor for our mobility activities. Moreover, although, as the saying goes, of the evils the least, surely any of us - if we had had the option - would have gladly renounced the tools of marras if we had avoided the pandemic with it. To which an end is not seen in the short term.",
    "https://upload.wikimedia.org/wikipedia/commons/4/46/Metropolregionen.png": "\u201cLet\u2019s go doing less,\u201d said the slogan that the National Population Council launched in the 1970s in an attempt to mitigate the population growth of the country that at the time exceeded 3 percent per year. At this rate of growth the population of Mexico almost doubled in 20 years and constituted a stumbling block for the social development of the country. Today, despite the slogan \u2013and some caricatures that made mockery of Mexican males who left children irrigated by all colonies \u2013 we have not done less and continue to grow. We do so, however, at a considerably lower rate: about 1 percent per year. The reduction in the rate of population growth in the last fifty years has been a global phenomenon. This reduction, however, has not been uniform and while some countries still maintain a population growth rate greater than 3 percent, others have made the slogan of marras and their population is decreasing. This last one affects rich countries, as is the case of Italy and Japan, by giving two examples. Obviously, a fundamental factor that determines the population of a country to grow or grow. In order to achieve a population balance, each woman must procreate on average 2.1 children. Above this number, the population will grow in absolute terms and decrease below it. In the latter case, with fewer children and young people, the average age of the population will increase. An article published this week in the magazine \u201cThe Lancet\u201d discusses extensively the economic, social and geopolitical consequences that population changes will have over this century. This article was published by a group of researchers from the University of Washington in Seattle headed by Stein Emil Vollset. Stein and collaborators shape population growth throughout the twenty-first century and make predictions about the evolution that this population will experience in 195 countries. Contrary to the predictions of the United Nations Organization that the world population will continue to grow from its current level of 7.8 billion to 11 billion in the year 2100, Stein and collaborators find that this population will very possibly reach a maximum of 9.7 billion in 2064, and then gradually decrease to 8.8 billion in the year 2064, and then it will reach 8.8 billion. The researchers also find that by the end of the 21st century, in 183 countries, including Mexico, fertility will be less than the 2.1 births per woman necessary to maintain the population balance.All these countries would then be trapped in a process of population decline, unless the decline of fertility is compensated by immigration.In Spain, for example, the population would decrease from the current 46 million to 23 million in 2100, while in Italy the population would do so from 60 million to 30 million.In the United States, a country made of immigrants but which in recent years has tightened its policies in this regard, the population would have a marginal increase from 324 million in 2017 to 335 million in 2100, reaching a maximum of 364 million in 2060. Mexico, on the other hand, will go from 127 million in 2017 to 146 million in 2100, with a peak of 170 million in 2062.Population changes would have economic impacts and modify the classification of the world's economies. Thus, China would advance in 2050 to the United States as the first global economy, to later lose this position in favor of 2100. The latter is due to the fact that China will drastically decrease its population from the current 1.4 billion to 730 million by 2100. India, for its part, would have a population of 1.1 billion, substantially larger than that of China, becoming the third most economically powerful country displacing Japan. In this scenario of declining fertility rates, Stein and collaborators point out that immigration will be a key factor in maintaining the population level and health of the world\u2019s largest economies. A time in which we may be able to condition and control the flow of Mexican immigrants to the United States. At the same time we launch the slogan \u201clet\u2019s keep doing more.\u201d",
    "https://upload.wikimedia.org/wikipedia/commons/7/77/Tesla_Sarony.jpg": "On Friday, July 10th, 164 years after Nikola Tesla was born in the village of Smiljan in Croatia, then part of the Astro-Hungarian Empire. For more precision, the event happened just at midnight between July 9 and 10, according to Margaret Cheney in her book: \u201cTesla: A Man Out of Time\u201d. It is possible that the name of Nikola Tesla does not seem as familiar to us as that of Thomas Alva Edison, better known as the inventor and entrepreneur who commercialized the electric light. It is even possible that the first thing that comes to mind when we hear the word Tesla is the electric car manufactured by the American company Tesla, Inc. In fact, however, the name of this company refers to Nikola Tesla, who was an inventor whose ideas and developments shaped the current electrical industry in good measure.Through the pages of Margaret Cheney's book, a singular and extravagant Nikola Tesla was discovered that, for example, women bore earrings, especially if they were He also had the habit of calculating the cubic centimetres of the soup dish or the cup of coffee that he had in front of him, if not to enjoy them. As for his intellectual abilities, he had the singular ability to design mechanical and electrical systems entirely in his mind, without the need to resort to schemes and plans. This last, of course, limited his ability to interact with other colleagues who did not have the same skill. At the beginning of his career, after migrating to the United States in 1884, Tesla worked for Edison\u2019s company. Soon, however, problems arose. According to Cheney, Edison would have commissioned Tesla to redesign the company\u2019s electricity generators and offered him $50,000 for the job. Tesla put it to work for several months, with working days running from 10:30 a.m. until five a.m. On finishing the commission successfully Tesla claimed the payment offered. Edison denied it with the argument that everything had been A joke: \u201cTesla, you don\u2019t understand the American mood,\u201d he would have said. Nikola, however, was unreceptive of Edison\u2019s sayings and immediately renounced the company. According to Cheney, the breakup between the two inventors could have been anticipated, because while Edison recognized Tesla\u2019s great abilities as an electrical engineer, he actually distrusted him. In fact, let\u2019s remember that by the end of the 19th century, Tesla was competing for the electricity market two systems: the direct current scheme and the alternating current. Edison\u2019s electric system was those of direct current, while Tesla was defending the alternating current. After leaving Edison\u2019s company, Tesla partnered with the Westinghouse company to commercially develop the alternate current system based on its patents and with this began the so-called \u201cWar of the Currents.\u201d During this war, Edison defended himself by denouncing the alternating current as highly dangerous, considering that its distribution network employs -in contrast with the direct current- stages of high voltage. In the end, Tesla\u2019s ideas, for technical reasons, were imposed on Edison\u2019s ideas, and with this the electrical industry was primarily decanted by the alternating current, which is what we currently have in our homes. Nikola Tesla lived as a singular person who, with all of her extravagances, had a huge impact on the development of the electrical industry. She also died in a singular way: alone and of coronary thrombosis in a hotel in New York at 86 years of age. Without listening to the \u201cDon\u2019t bother\u201d sign, the changemaker accessed the room and found him dead in his bed the day after his death.",
    "https://upload.wikimedia.org/wikipedia/commons/3/34/TakakkawFalls2.jpg": "Why are plants usually green? This question at first glance seems frivolous, but it is actually far from being so, because the color of plants obeys well-defined physical principles related to the color of sunlight. This last one according to an article published on June 25 in the magazine \u201cScience\u201d by an international group of researchers headed by Trevor Arp of the University of California in Riverside.To understand the arguments of Arp and collaborators, let us first remember that the Sun contains all the colors of rainbow, from red to violet through green. Not all, however, are equally represented, the green being the most prominent. Let us also remember that the color of an object is determined by the light that reflects, so that the color of plants is due to the fact that they reflect green light more efficiently than light of other colors. On the other hand, we know that plants perform an essential function, photosynthesis, by means of which they synthesize the organic matter that makes life on the planet possible. To boost photosynthesis, plants We would have hoped that plants would have any color except green, since this color wastes the most abundant component of sunlight. However, we know that plants are generally green, which leads us to wonder why it is so. Why are they not red or blue - or black, which is the absence of reflection - to make a more efficient use of solar radiation?In his article, Arp and collaborators offer an explanation to this apparent contradiction. According to these researchers, plants waste green light because it is too intense and varies too much throughout the day. In fact, this intensity at a certain time may be high enough to damage the plant. We know from our own experience that sunlight can vary greatly and make us uncomfortable in a certain circumstance. Luckily, we could very probably remedy it. For example, if we are in the weather in full sun at twelve o'clock, we can move towards a place with shade and thus suffer less. With exceptions, plants do not have this possibility and have In fact, according to the reference article, plants do more than that, because for an efficient operation of the photosynthesis process, they solved the problem that represents the variability of the intensity of the solar radiation, both upwards and downwards of the necessary level. We can perhaps understand this problem if we think of a basin that is filled with water on the one hand by means of a key, and on the other hand it is evicted by the barrel. If we want to maintain a certain level of water in the sink, it is necessary to adjust the flow of water that enters with the one that goes through the drain. Otherwise, the basin would never be filled or overflowed. Applied to the photosynthesis process, the incoming water flow corresponds to the solar energy that affects the plant, and the outgoing flow to the energy used in the photosynthesis. To implement the solar energy regulation mechanism. , the plants developed two types of energy pickers, each sensitive to a single color of solar radiation. These colors were carefully chosen by nature in order to cushion the variations of solar energy that affects the plant. Thus, we understand that the plants are green, not by chance and yes by a careful design, to manage the high variability of solar radiation. On another planet, with a cooler or hotter star than ours it is possible that the plants are not green, but blue or red or of some other color. This, of course, is nothing but speculation.What is not speculation is the amazing engineering design of the photosynthesis process patented by nature.",
    "https://upload.wikimedia.org/wikipedia/commons/d/db/Mario_Molina_1c389_8387.jpg": "Two Sundays ago, we discussed in this space an article published in the journal \u201cProceedings of the National Academy of Sciences\u201d (PNAS) of the United States in which it argued about the benefits of the use of the mouth covers as a means to stop the advance of the epidemic of COVID-19. This article concludes that the main way of spreading the epidemic is the aerosol generated by people infected by coughing, sneezing or simply talking, which is kept in the air for a long time. In this case, the mouth covers can block the emission of aerosols by an infected person and prevent a healthy person from becoming infected by contact with them. Among the authors of the reference article is Mario Molina, who shared the Nobel Prize for Chemistry 1995 for the identification of chemical compounds destroying the ozone layer in the atmosphere. Molina's conclusions and collaborators were quickly questioned by a group of 45 researchers in a letter sent to the PNAS magazine. In that letter, the signatories stated that the article \u201cis based on false assumptions and suffers from methodological failures. In order to understand the objections made to Molina\u2019s article and the scope of the issues dealt with and its enormous and immediate public impact, they demand that the article be removed immediately by the magazine. To understand the objections raised to Molina\u2019s article and collaborators, it should be mentioned that the conclusions of the article are based on an analysis of the rate of growth of the number of cases of coronaviruses in New York City and in northern Italy, before and after the use of the mouth cover was made compulsory in public places. Through this analysis, the researchers found that in New York City \u2013 as in northern Italy \u2013 that rate of growth decreased significantly once the use of the mouth cover was introduced in April. In contrast, in the rest of the United States, where the mouth covers would not have been mandatory but there were other measures to contain the pandemic, there was no equivalent decrease. Based on these facts, they conclude that the main route of propagation of the coronavirus are aerosols that disperse the infected people and that other containment measures alone are not sufficient. Molina et al. argue that their conclusions are based on demonstrably false assumptions. For example, they argue that the claim that since April the only difference in virus containment measures between the city of New York and the rest of the United States was the implantation of the mouth covers in New York is false. They also argue that the authors of the article did not take into account the delay that exists between the implementation of a mitigation measure and the resulting reduction in the number of new infected ones; nor did the fact that the introduction of a public measure does not mean its immediate adoption by the whole population. Critics also denounce what they consider to be methodological flaws of the study, which would be attributable to the fact that none of the authors of the article are epidemiologists experts. The authors of the article, on the other hand, argue that the critics did not really understand it and that some of the criticisms they have received have been made using phrases from the article put out of context. Molina acknowledges, on the other hand, that perhaps the language they used was too strong and with some exaggerated phrases, saying that some of Moreover, the authors of the article are surprised by the incredible and naive criticism they have received, for the only fact \u2013 so they see it \u2013 that none of them are experts in COVID-19. The fact that an article on the spread of the coronavirus has been written by researchers who specialize in atmospheric sciences and not by epidemiologists is not necessarily a negative fact.In a way it could have positive aspects if it provided a non-orthodox view of a public health problem that has surpassed experts.In any case, all, Tyrians and Trojans \u2013 including critics of Molina's article and collaborators \u2013 consider that the mouth covers \u2013 in one way or another \u2013 contribute to curbing the spread of coronavirus.What is a step forward with regard to what some experts maintained just a couple of months ago.",
    "https://upload.wikimedia.org/wikipedia/commons/b/b2/Eagle_nebula_pillars.jpg": "Since the planets in the Milky Way similar to ours are counted by billions, it is worth noting that an article published this week in the magazine \u201cThe Astrophysical Journal\u201d concludes that only 36 of them harbor an intelligent civilization that would be able to communicate through interstellar space. The article was published by Tom Westby and Christopher Concelice of the University of Nottingham in the United Kingdom. To be more precise, Westby and Concelice set a range between 4 and 211 for the number of planets that in our galaxy harbor intelligent life with sufficient technological capacity to notice their presence through space. Since even 211 is a tiny number compared to the billions of planets existing in our galaxy with the right conditions for the development of life, it would be concluded that the development of intelligent life is a rather rare phenomenon, which would explain that it could not have been detected in spite of the campaigns that for this purpose have been mounted throughout the last half century. This is not surprising given that to calculate the number of worlds inhabited by intelligent beings is required of basic information that is not available. The most important, of course, is the proof of the existence of at least one civilization other than ours. Thus, although Westby and Concelice partially base their results on objective data on the speed of star formation in the Milky Way and on the detection of exoplanets similar to Earth, they had to make assumptions about other unknown aspects, and in this sense their work is largely speculative. Thus, and in virtue of the fact that the only proven case of intelligent life development in the Milky Way is precisely the one that has occurred on our planet, Westby and Concelice assumed that the process that took place on Earth is universal and that it has occurred in other parts of the Milky Way. They also assumed that, given the right conditions, the development of intelligent life is inevitable. Thus, as a universal phenomenon, intelligent life would have developed on all of those planets with the same conditions of the same way. This is, of course, speculation, with which some do not agree.A second, also controversial, assumption is that the interval of time that a civilization has enjoyed has been the ability to communicate through interstellar space - as we know, our civilization has had this capacity only over the last hundred years. Westby and Concelice assume that once a certain degree of technological development of communication has been achieved, civilizations also develop a capacity of self-destruction that eventually leads to their disappearance. In the case of our civilization, the ghost of self-destruction revolves around atomic weapons and global warming. Westby and Concelice set in one hundred years the average time that an extraterrestrial civilization enjoys the capacity of interstellar communication before its self-destruction.The short lifetime of one hundred years assumed by researchers for a technological civilization leads them to calculate the small number of 36 extraterrestrial civilizations in the Milky Way with the ability to let us know of their presence. Civilizations are certainly very few for the size of our galaxy, which has a diameter of about 100,000 light years \u2013 a light year is the distance that light travels in a year. In these conditions, the intelligent civilization closest to Earth would be about 17,000 light years away, which, according to Westby and Conselice, would make it impossible for us to establish communication with our current technological means. Thus, the efforts made to search space for signals from extraterrestrial civilizations are meaningless. Unless eventually it was possible to detect a message from a planet similar to ours circulating around a distant star. In which case the assumptions of Westby and Concelice should be thrown into the trash can.",
    "https://upload.wikimedia.org/wikipedia/commons/0/0f/Aerosol-India.jpg": "Until recently, the use of mouth covers as a means to combat the spread of the coronavirus pandemic was controversial. On the one hand, it was argued that although the mouth covers block the spread of viruses by an infected person to a certain extent, they do not actually protect those who carry them. In contrast, George Gao, director general of the Center for Disease Prevention, stated categorical that the United States had made a big mistake by not introducing the use of mouth covers since the beginning of the epidemic. As we know, today the controversy has diminished and the mouth covers are widely used by the population. And in support of this practice, an article appeared this week in the magazine \u201cProceedings of the National Academy of Sciences\u201d of the United States provides scientific evidence about the benefits of the mouth covers as a simple tool to stop the advance of the coronavirus epidemic. That article was published by a group of researchers from North American universities -including Mario Molina, Nobel Prize for Chemistry - headed by Renyi Zhang of Texas University A&M. In the article referred, Zhang As we know, the COVID-19 epidemic began in China in December 2019, and from there it spread to Italy and other European countries, and eventually to the United States and the rest of the American continent. China took rapid and drastic measures and managed to stop the spread of the virus in its territory. Italy and the United States, on the other hand, had less effective responses and the virus had the well-known consequences. Zhang and collaborators focus their analysis on the mouth covers and note that, while China implemented its use in the first stage of the epidemic, simultaneously with other aggressive measures of social distance and identification of infected persons, the response to the virus in Italy and the United States was not as strong. Specifically, researchers note that these two countries did not implement all mitigation measures at the same time and it was only on 6 April that Italy introduced the use of the coverbobo In Lombardy, the region most heavily affected by the pandemic, while in the United States, the state of New York made them mandatory until 17 April.The delay in measures to force the use of the mouth covers with respect to other mitigation measures, allowed Zhang and collaborators to evaluate their impact on the spread of the epidemic.With convincing arguments, based on an analysis of the growth of infected before and after the implantation of the mouth covers, researchers conclude that between 6 April and 9 May in Italy, and between 17 April and 9 May in New York, the mouth covers avoided, respectively, 78,000 and 66,000 new infections.In addition, Zhang and collaborators conclude that the main route of infection is aerosol - particles less than 5 micrometers - dispersed by a person infected by sneezing or coughing, and even simply when speaking, which is kept suspended in the air for a long time. Here it should be remembered that experts consider that the transmission of the virus can also occur by major saliva drops. These drops, by their size, can only advance small distances in the air before falling and depositing on the ground or on some surface. The latter has given rise to the concept of \u201chealthy distance\u201d, which dictates to stay at a distance beyond which the drops are kept suspended in the air. To stay at the \u201chealthy distance\u201d, however, would not prevent the contagion by means of the aerosol. In this case, as Zhang and collaborators explain, the only practical defense is provided by the mouth covers and to avoid, as far as possible, closed places with agglomerations and without ventilation. And since the main route of contagion would be aerosols, perhaps it would be worth seriously considering these defense options.",
    "https://upload.wikimedia.org/wikipedia/commons/0/00/Cabeza_Colosal_n%C2%BA1_del_Museo_Xalapa.jpg": "An article appeared this week in the journal \u201cNature\u201d reports the discovery in the state of Tabasco of an archaeological site with architectural structures of great proportions and an antiquity close to three thousand years. The site includes, in addition to other smaller structures, a huge rectangular platform of almost one and a half kilometers long and 10-15 meters high. The article was published by a group of archaeologists headed by Takeshi Inomata of the University of Arizona, and in which Mar\u00eda Bel\u00e9n M\u00e9ndez Mauer of UNAM is included. The discovery was carried out by means of a topographic survey on the site known as Aguada F\u00e9nix, located a short distance from the border between Tabasco and Guatemala. This survey was carried out by the LIDAR technique, which emits a pulse of laser light to the point of interest and measures the time that this pulse \u2013the echo- takes to return. Once determined this time, the distance to the object is obtained from the speed \u2013known- of the laser light. Aguada F\u00e9lix topographic survey was obtained by mounting the LIDA. R on an airplane and pointing the laser laterally towards different targets by means of a mirror as it advanced, sweeping the entire area of interest. As Inomata and collaborators point out, the structures of Aguada Phoenix had remained hidden because their large extension and relatively small height made them confused with the natural landscape. LIDAR, in contrast, does not experience any confusion and clearly reveals the existence of a site with numerous architectural structures. The largest of them, a rectangular platform aligned approximately in the north-south direction, 1413 meters long and an elevation on the ground of 10-15 meters. Some smaller structures are also visible on the surface of that platform. In particular, its edges are crowned by rows of smaller rectangular platforms and in its center is visible an elongated structure of 400 meters in length. In addition to the main platform, the site includes other structures and roadways that give the whole a great complexity. Inomata and collaborators fix the construction of the site Aguada Phoenix between 1000 and 800 years before our era. To appreciate the dimensions of the site, the site includes other structures and roadways that give great complexity. The researchers note that the volume of the main platform substantially exceeds that of the pyramids built during the classical period in the Mayan lowlands. Furthermore, they estimate that the construction of Aguada Phoenix would have required between 10 million and 13 million man-days of work. Aguada F\u00e9nix is placed in an intermediate point between the areas of the Olmeca culture of Tabasco and Veracruz and the low lands in which the Mayan civilization of the classical period developed. In this connection, Inomata and collaborators point out that although the platform of Aguada F\u00e9nix was probably influenced by the traditions of the site of San Lorenzo that belonged to the Olmec culture, the social traditions of both cultures differed to a certain degree. In particular, compared to the Olmec culture, the social inequalities in Aguada F\u00e9nix would not have been so marked, as indicated by the absence of sculptures representing individuals of high social position. The same could be said of the Mayan culture -of which Aguada F\u00e9nix would have been a precursor - that developed marked social inequalities. , the researchers speculate, while in San Lorenzo and other Olmec areas the constructions would have been carried out by a majority under the command of a hierarchically superior social class, in Aguada F\u00e9lix the participation of the population would have been the result of community work. This would have been reflected in the horizontality of the constructions of Aguada Phoenix, in contrast to the posterior Mayan pyramids, whose verticality facilitated the access of only a few privileged. Was Aguada Phoenix a seat of a culture in which the social hierarchies played a relatively minor role? If so, their architectural achievements, which shows us the echo of LIDAR, would be a sample of the possibilities of collaborative work. Which, by the way, would not be something to surprise.",
    "https://upload.wikimedia.org/wikipedia/commons/3/35/Congregational_Church%2C_East_Brookfield_VT.jpg": "Yesterday\u2019s launch of a manned mission to the international space station was the first of its kind carried out by a private company, Space X, in collaboration with NASA. The event is indicative of the growing role that private companies will play in space in the future. What will the space industry be like in the future? As we know, this industry has had a dizzying development in the last half century, certainly with many positive impacts. At the same time, however, the large number of satellites placed in orbit has congested space around the Earth, not only with satellites in operation, but also with satellites already out of use and debris from launch vehicles and other objects resulting from space activity. It is now known that approximately 20,000 artificial objects are rotating around the Earth. More than 15,000 of these objects circulate in the so-called low Earth orbit, defined by a band located between 160 kilometers and 2,000 kilometers above the Earth\u2019s surface. The increasing number of satellites and objects in orbit around the Earth increases the likelihood of collisions between them. If such collisions would occur, the number would rise. A process of generating cascading space debris that would make it impossible to use space for the transit of satellites, according to some speculations. Even without reaching this point, the congestion of space introduces costs in the space industry due to the risk of collisions in orbit with the consequent destruction of the satellites involved. To reduce this risk, several alternatives have been proposed, including that of surveying and accurately determining the trajectories of all space debris objects. Knowing these trajectories would be possible to anticipate a collision and avoid it by modifying the course of the satellite in danger. It has also been proposed to remove obsolete satellites and other space debris objects from their orbits by different techniques, forcing them to re-enter the atmosphere where they would disintegrate by friction with the air. An article published this week in the journal \u201cProceedings of the National Academy of Sciences\u201d of the United States, however, states that these proposals, which have been only technological and managerial, do not address the problem of funds. The article was published by a group of researchers led by Akhil Rao of \u201cMiddlebury College\u201d, in Vermont, United States. Rao and collaborators argue that the problem of spatial congestion arises because satellite operators do not consider the costs they impose on other operators through an increase in the risk of collision. Under these conditions, cleaning space debris orbits would only encourage the launch of more satellites, to the point where the risk of losing them equals their cost. Instead, researchers propose the establishment of a \u201corbiting usage fee\u201d \u2013 similar to the carbon tax, which would discourage greenhouse gas generation \u2013 that would correct the incentive problem. In the Rao and collaborators proposal, the rate for orbit use would be set at US$ 14,900 per satellite per year in 2020. This rate would be increased by 14 per cent annually to US$ 235,000 per satellite per year in 2040. With this scheme, researchers estimate that the value of the space industry would be quadrupled. The management of the space orbits around our planet runs in parallel with those of other phenomena on a global scale that have occurred over the last decades and that have made the planet Earth - which in principle looks huge - have remained small. With the emergence of private companies in space, one wonders whether it will worsen the spatial congestion. Or, although, through proposals such as that of Rao and collaborators, it will be possible to limit its growth. Otherwise, in the search for answers, it may be worth asking us to what extent the carbon tax has helped to mitigate environmental pollution.",
    "https://upload.wikimedia.org/wikipedia/commons/1/13/Human_skin_structure.jpg": "An article published on May 8 in the journal \u201cScience Advances\u201d by a group of researchers led by Colin Raymond of the California Institute of Technology, reports alarming data on the occurrence of extreme heat and humidity episodes in different parts of the world. This article reports an analysis of data provided by about 8,000 weather stations in the period 1979-2017. The authors find that climate events in which high levels of humidity and high environmental temperatures are combined are becoming more and more frequent because of global warming. As we know, the normal temperature of the human body is around 36.5 degrees Celsius, itself is maintained by a balance between the heat internally generated by our metabolism and the heat dissipated to the environment through the skin. In relation to the latter, it should be noted that the skin temperature is about 35 degrees Celsius, so that if the environmental temperature is less than this value, the skin has no impediment to emit heat to the environment and thus maintain our body temperature. In these conditions, a second mechanism goes into operation and the body releases excess heat by means of sweat. In short, the sweat evaporates when it is in contact with the skin and for this it needs a certain amount of heat that it removes from the body through the skin. So far, the heat dissipation mechanism of our body works according to how it was designed. The design, however, presupposes certain environmental conditions that Colin and collaborators find are being violated more and more frequently. To understand this, it is necessary to take into account that the rate at which the sweat evaporates depends on the environmental humidity, and that it is lower as the humidity of the air is the highest. In fact, the rate of evaporation is theoretically nullified when the environmental humidity is 100%. Assuming that this occurs, an environmental temperature higher than 35 degrees centigrade is theoretically the maximum compatible with life, at least for relatively long periods of time \u2013 if, of course, it is possible to withstand a temperature higher than 35 degrees centigrade with a humidity. In his study, Colin and collaborators found many cases in which combinations of humidity and temperature were achieved close to the maximum tolerable. Likewise, they found two locations where moisture-temperature combinations were reached, on multiple occasions, even higher than the maximum compatible with survival, although only for a space of one or two hours. The higher humidity-temperature values were found, among other places, at points located on the coast of the Persian Gulf, the east coast of India, the north of India and Pakistan, the north-west of Australia and the coast of the Red Sea. High humidity-temperature values were also found on the coast of the Gulf of California and on the coast of the Gulf of Mexico. In San Luis Potosi, specifically in Matlapa, the moisture-temperature combination reached, at some point, the maximum value compatible with life.According to Colin Raymond, it was anticipated that in some decades from now extreme episodes of humidity-heat would grow frequently as global warming progressed. However, they show that the projections were wrong and that the phenomenon is already happening today. Thus we have one more facet of the effects that global warming is generating. In rich countries, episodes of humidity and heat can be mitigated by air conditioning. This is not necessarily true with respect to countries with limited resources. Thus, as with the current pandemic, the worst affected can become the poorest countries. Or, in other words, the weakest dog will most likely be charged with fleas.",
    "https://upload.wikimedia.org/wikipedia/commons/3/3a/Influenza_virus_particle_color.jpg": "As we know, in order to reactivate its economy our neighbour from the north is beginning to lift the isolation measures due to the epidemic of COVID-19, although each state of the union following a particular strategy. The experts, on the other hand, have warned of possible epidemic outbreaks if due precautions are not taken, given that the number of infected is still very high. In this regard, the Center of Ethics of Harvard University published on 20 April a document entitled \u201cRoad map to pandemic resilience\u201d, which proposes a strategy to reopen the economy of the United States without new epidemic outbreaks forcing the implementation of new quarantines.In the absence of a vaccine or specific treatments to combat the virus, the main strategies to curb its expansion have been that of social isolation, personal hygiene and the prohibition of mass assistance events. These strategies are the same ones that were used 100 years ago to stop the spread of the Spanish influenza, and in that sense we have made little progress.The strategy of isolation part of the assumption that we could all be carriers of the virus, even though we are the same as we know, As opposed to the Spanish flu pandemic, however, there is now evidence that allows us to differentiate between those who are carriers of the virus and those who are not. In fact, the strategy followed by South Korea to mitigate the outbreak of COVID-19 during the past months of February and March was to isolate the infected people quickly, as well as to identify those with whom they had contact and assolate them also in case they proved positive to the virus. Among other factors, South Korea's success was based on massive testing to detect infected people.Following the Korean experience, the road map recommends carrying out massive tests, not only those with symptoms of the infection and those who are presumed to have been exposed to the virus \u2013 for example, health workers \u2013 but also their contacts, including those who were asymptomatic. All those who were positive would have to be quarantined. The proposed programme would require 5 to 20 million tests per day and would be accompanied by careful monitoring of the speed of the asymptomatic. An essential element of the road map is the follow-up of those who came into contact with an infected person. This includes notifying them about their exposure to the virus, as well as ensuring that they carry out an effective quarantine. For this purpose, digital tools such as those used at the time in China can be used to track people through their cell phones. At this point, however, and unlike what happens in China, the privacy requirements that prevail in the United States would make those tools less effective. Carrying out 5 to 20 million tests per day would involve making a great effort, even for a country with the resources of the United States. In this context, what would be Mexico\u2019s prospects at the time of ending the quarantine and initiating the reactivation of the economy? In this regard, the Ethics Centre of Harvard University published a document in which it analyses the situation of those who call the \u201cGlobal South\u201d, which includes India, Africa and Latin America and which concentrates 40 percent of the world population. The perspectives raised by the document for Latin America are not the It recommends, among other things, that the countries of the region make a joint effort to enable the pharmaceutical industry to develop the capacity to produce the millions of necessary test kits, which it deems difficult to carry out.On the other hand, and in comparison with India and the African continent, the population of Latin America is mostly urban, which in some ways is a positive point.In short, even adding positive points, the picture does not look flattering.At least according to the Road Map to Pandemic Resilience.",
    "https://upload.wikimedia.org/wikipedia/commons/2/21/Africa_satellite_orthographic.jpg": "An article appeared last April 30 in the magazine \u201cCurrent Biology\u201d takes us 500 years towards the past; precisely, at the beginning of the colonial period of Mexico, when a series of epidemics were unleashed that led to the death of 90% of the defenseless indigenous population before the pathogens brought by the conquerors. And when we were transported to the past, the article illustrates us about something that has remained largely in the dark: that the population of our country has a remarkable African genetic heritage, product of the import of African slaves to our country during the colonial period. The article in question was published by a group of researchers from Germany and Mexico, headed by Rodrigo Barquera of the Max Planck Institute and the National School of Anthropology and History.In their article, the researchers report the results of a study carried out with human remains discovered in the center of Mexico City, during the construction of the metro line 8 in the first years of the 1990s. The Royal Hospital of San Jos\u00e9 de los Naturales was founded by Fray Pedro de Gante in 1531, just ten years after the fall of Tenochtitlan. As its name indicates, the hospital was founded to care for the indigenous population. Not exclusively, however, during the excavations the remains of 600 people were dug up, 20 of whom appeared to have an African origin. This last one, judging by the shape of their teeth, carved in cone according to the usage of some places in Africa, and by their cranial characteristics. Here it should be noted that the hospital included a cemetery, among other facilities. Barquera and collaborators directed their efforts to confirm the African origin of three of the people whose remains were dug up at the site occupied by the hospital. For this, they designed a multidisciplinary strategy, using genetic, osteological, and isotope techniques to characterize the remains. Through their genetic studies, the researchers confirmed the African origin, sub-Saharan, of the remains studied. . These remains would have belonged to individuals killed at the beginning of the colonial period at an age of about 30 years. Moreover, they would have been presumably slaves, judging by the obvious physical abuse they presented, including gunshot wounds and a broken leg badly welded. The researchers also found evidence of the diseases they suffered in life. An individual suffered from hepatitis B and another from a disease close to syphilis, diseases that the researchers concluded were contracted before their arrival to the American continent.The latter gives an indication of the role that the African slave trade would have played in the introduction of unknown pathogens into the New World, and that led to the near extinction of the indigenous population in New Spain.In this connection, Barquera and collaborators note that until 1779, the year in which the importation of slaves was prohibited, had entered New Spain between 130,000 and 150,000 African slaves, which undoubtedly mixed among the general population.The researchers also venture that the death of the individuals studied could have been precisely due to an epidemic, although they have no evidence in this regard. The results published by Barquera and collaborators, using a multidisciplinary approach, are solid from a scientific point of view and shed light on a fact that occurred five centuries ago: the African slave trade towards our country, which has left an indelible genetic footprint among us. Trafficking that, in addition to being morally indefensible even at the time it occurred, would have contributed to triggering the epidemics that devastated an indigenous population without defenses against the new pathogens.",
    "https://upload.wikimedia.org/wikipedia/commons/9/95/Alabama_Capitol_Building.jpg": "What is the probability of dying hit by a meteorite? Certainly, it should not be very large, given that there is little news in the press about it. There have been cases, however, of close encounters with meteorites. It is known, for example, that on November 30, 1954 Ann Hodges took a nap at her home in the state of Alabama when a meteorite the size of a softball pierced the ceiling of the room in which she was found and after bouncing impacted on her hip producing a scorching in the form of a tree leaf of more than twenty centimeters long. Fortunately, Ann survived the incident and in a photograph of her, which we can find on the Internet, we see her lying down showing her wound.In another incident in the village of Peekskill, north of New York City, a meteorite the size of a ball of bowling precipitated on a parked car, a red Chevy Malibu 1980 that was severely damaged. Thanks to this, the car became a celebrity, to the degree it has been exposed. In fact, on the official site of the Peekskill Meteorite Car, he is offered precisely for exhibition purposes. On other occasions, close encounters with meteorites have not been so fortunate. The most well-known case is perhaps that of the Chicxulub meteorite, which 65 million years ago ended dinosaurs and caused a massive extinction of species. In this case, the dinosaurs on which the meteorite directly landed were undoubtedly killed instantly. They would have been the least, however, and the mass extinction of species came from the subsequent climatic consequences of the meteorite. Let us leave aside, however, such extreme situations and limit ourselves to incidents of death of persons directly hit by a meteorite. We find that in a remarkable way, there are no verifiable cases in this regard. In 2016, a man was killed in India because of what was initially thought to be a meteorite. Today, however, it is considered that it was not by an alien object that caused the incident. The impact of a meteorite is then very scarce and an estimate of its probability of occurrence is difficult to establish. In these circumstances, it is interesting to learn that, finally, the first solid evidence of death produced directly by a meteorite has been found. This would have occurred on August 22, 1888 in Sulaymaniyah, Iraq, then part of the Ottoman Empire, as reported in an article published by a group of researchers led by Ozan Unsalan of Ege University in Turkey.During the incident studied by the researchers, around 20:30 hours a large ball of fire was seen in the sky and an explosion was heard, followed by a meteor shower that fell on a village and lasted about ten minutes. As a result, one man died and another resulted in wounds that left him paralytic. This account was discovered by Unsalan and collaborators in three recently digitized official manuscripts of the Turkish government, in which the local authorities inform the central authorities about the incident and send them fragments of the meteorite. official documents are sufficiently solid \u2013 precisely because they come from official reports \u2013 to conclude that they have found the first evidence of a man killed by a meteorite. The difficulty in finding this evidence tells us that we would have to be extraordinarily unfortunate for a meteorite to fall just where we stand. Establishing the probability of this happening is difficult, but Clark Chapman of the Southwest Research Institute, in Boulder, Colorado, adventure a figure: the probability of dying from the impact of a meteorite is 1 in 1,600,000. For comparison purposes, the probability of dying from lightning in an electrical storm is more than ten times greater. We can thus live calmly without worrying that the sky can give us an unpleasant surprise.",
    "https://upload.wikimedia.org/wikipedia/commons/8/8b/Hendidor_en_mano.jpg": "A herd of wild goats wandering wide across the deserted streets of Llandudno - a coastal village in northern Wales - can be seen as an example of recovery by wild animals from spaces from which we have excluded them, while revealing our proximity to wildlife. In videos that we can easily find on the Internet, we can see a herd of hairy goats biting hedges and flowers, crossing streets, or simply resting in well-kept gardens. Actually, the herd of wild goats \u2013 around 120 animals \u2013 is well known to the inhabitants of Llandudno. The goats live on a nearby hill and apparently it is not unusual for them to come down to the village in periods of bad time. This time, however, the paralysis of Llandudno by the coronavirus epidemic has made things easier for them and have ventured into the village beyond the usual. , in a strict sense it could be argued that in this case wildlife cannot claim property rights. Indeed, the ancestors of the goats would have arrived in Llandudno from Kashmir - in northern India - only in the 19th century. The hill in which they live, in contrast, has been inhabited since the stone age, as we can read on Wikipedia. On the other hand, the invasion of Llandudno by the goats of the hill is not the only example in the times of coronavirus of the presence of wildlife in urban spaces where it was not normally seen. Thus, we learn that the city of Lopburi in Thailand was invaded by hordes of macaques in search of food. These macaques were fed by tourists who have disappeared today. A similar situation occurs in Nara, Japan, where the city has been invaded by groups of deers. Unusual sightings of coyotes, wild boars, squirrels, and rats have also been reported in several places in the world. An extreme case is that of a puma which has been invaded by groups of deers. was found wandering in the streets of Santiago de Chile. Our proximity to wildlife, revealed by the opportunist takeover of urban spaces that we have been forced to abandon, promotes, according to specialists, the appearance of infectious diseases such as the one we are now suffering. Indeed, as we know, the virus of the COVID-19, jumped from an animal species to our species, and it is not difficult to understand that the possibility of the appearance of human diseases of animal origin increases to the extent that we make closer our contact with other species.The appearance of a pathogen of animal origin, on the other hand, is not something that has surprised the experts.In fact, it has happened on several occasions in the course of the century.Never, however, with the serious consequences of the current pandemic, caused by a virus that does not seem to be particularly lethal, but that does expand rapidly.Given the particularities of the virus, in recent days the American government has considered the possibility that it had escaped from the laboratory of viriology existing in the city of Wuhan, in contrast with the explanation initially offered by the Chinese government in the sense that the origin It should be noted that the possibility that the virus would have been manufactured is not considered, as there is evidence that it has a natural origin, but that it would have escaped from a laboratory safety failure. From the origin of the virus, however, there is no clear evidence. Let us hope that in the not too distant future we will have them in one sense or another. Regardless of the above, for experts the frequency in the appearance of new infectious diseases of animal origin is growing because of the invasion we are making of the habitats of the wild fauna and the growing contact with it. And to show enough the button of the goats of Llandudno.",
    "https://upload.wikimedia.org/wikipedia/commons/8/85/Lingelbach_Karneval_in_Rom_001c.jpg": "On Wednesday, April 8, quarantine was lifted in the city of Wuhan, which had remained isolated since January 23. Some specialists, however, express concern that those who leave the city and are asymptomatic carriers of the virus may cause outbreaks of the disease in other Chinese cities. In due course, and as they overcome the epidemic, other parts of the world will face similar dangers.Ideally, in order to prevent a second wave of the epidemic, and in the absence of vaccines or medical treatments to combat the disease, social distancing measures would have to be maintained until the percentage of immune people - because they have already been infected and recovered - reaches a value that experts estimate about 70%. By reaching this percentage, the virus could only infect the remaining 30% and this would be insufficient to maintain the epidemic. Thus, ideally, it would be necessary to determine the degree of immunity of a population before declaring it free from the danger of COVID-19, and this is something that is hardly taking shape. This study - which has not yet been formally published, subject to peer review - was carried out with residents of the German village of Gangelt, of approximately 12,000 inhabitants, located on the border with the Netherlands. The reference study was published online on 9 April on the North Rhine-Westphalia State Network site. According to Streeck and collaborators, the beginning of the COVID-19 epidemic in Ganglet would have occurred during the carnival celebrations on 15 February, during which there was more than one occasion for the transmission of the virus. In fact, it is known that after the carnival several people were positive to COVID-19, and over time all Ganglet was strongly affected by the epidemic.The study carried out by Streeck and collaborators aimed to determine the level of infections it currently deprives in Ganglet, as well as the percentage of people who are immune. For this purpose, researchers interviewed and took samples from the throat of approximately 1,000 people. In their article, they report results obtained with 500 people. Streeck and collaborators found that 2% of the people studied were infected with the virus, while 14% carried antibodies that indicated that they had been previously exposed to the virus, some with symptoms of the disease and other asymptomatic ones. Interestingly, they found that the mortality rate, based on the total number of people infected, is 0.37%. They note that this percentage is five times lower than the 1.98 percent estimated for Germany by Johns Hopkins University and explain it because in their calculations they are including the total number of infected, serious, mild and asymptomatic. From the above, Streeck and collaborators preliminary conclude that 15% of the population of Ganglet is immune to the virus of the COVID-19 and could no longer get sick. Although this percentage is far from 70% necessary to extinguish the expansion of the epidemic, according to researchers it reduces to a considerable degree the speed with which the virus advances. Thus, in controlled conditions and with adequate hygiene rules - without carnivals or other. mass events that are known to have catapulted the advance of the epidemic \u2013 they consider that it will be possible to abolish quarantines and turn the leaf around. It should be mentioned, however, that some specialists do not agree that the presence of antibodies guarantees immunity to the disease, and in this scenario the conclusions of Streeck and collaborators lose their livelihood. Let us wait for the days to come and cross our fingers because it is not the case.",
    "https://upload.wikimedia.org/wikipedia/commons/a/af/KoreanWarRefugeeWithBaby.jpg": "We can, for example, travel on a commercial flight from Sydney, Australia, to New York \u2013 almost half the circumference of the planet \u2013 in just over 19 hours. This would have been unthinkable just over a hundred years ago. In another order of ideas, the emission of greenhouse gases into the atmosphere by burning fossil fuels has increased the temperature of the planet by about 1 degree Celsius in just over 150 years. An increase of this magnitude is not in itself extraordinary given the changes in the climate of our planet over the last tens of thousands of years. It is, however, because of the speed with which it has occurred. The ease with which we can carry thousands of kilometers along the Earth\u2019s surface and the influence we have had on its climate, are two facts that prove that, indeed, the planet has become small to us. We can mention other evidence in this regard: the Internet network that allows communication, practically instantaneous, between two places separated by thousands of kilometers, and the huge island of plastic waste of the ocean. The shrinking of the planet is the product of technological developments of various kinds, whether communications, transport, power generation or manufacturing, among others. A technology capable of making the Earth look even smaller is nuclear technology, developed from scientific discoveries made in the first decades of the last century. As we know, nuclear technology is capable of releasing energy in unprecedented quantities, and can be used to produce nuclear bombs with an unprecedented destructive power. The first nuclear bombs were developed by the United States towards the end of the Second World War and, in a highly controversial action, were used against the Japanese civilian population, destroying the cities of Hiroshima and Nagasaki. The Soviet Union soon developed its own capacity for the manufacture of this type of bomb and with this began the so-called Cold War. Throughout the Cold War, the United States and the Soviet Union developed thermonuclear bombs with a power thousands of times larger than those exploited over the Japanese cities, and accumulated arsenals with tens of tens of thousands. The size of the nuclear arsenal of the United States and the Soviet Union, which would lead to the destruction of the two countries - and of the world, by extension - in the event that one attacked the other, was supposed to ensure that none would take any initiative in this regard. However, the concept of \u201cnuclear winter\u201d was developed, which would result in a possible nuclear war between the two countries that would seriously endanger the survivors, as well as other species on Earth. With the demise of the Soviet Union, the Cold War was brought to an end and the risk of a global nuclear confrontation was reduced. However, and since at least eight countries have nuclear weapons, there is a possibility of nuclear confrontation on a regional scale. In particular, experts are concerned about the possibility of a nuclear confrontation between India and Pakistan, both possessors of nuclear weapons and maintain a conflict in the Kashmir region. An article appeared this week in the magazine \u201cProceedings of the National Academy of Sciences\u201d of the United States of America makes a nuclear confrontation between them and Pakistan, both possess nuclear weapons and maintain a conflict in the Kashmir region. Analysis of the impact on our planet, in particular on grain production, would have a nuclear conflict between India and Pakistan. The article was published by an international group of researchers led by Jonas Jagermeyr of the University of Chicago.Jagermeyr and collaborators consider a confrontation in which each country launches 50 nuclear bombs the size of the dropped on Hiroshima, representing one percent of the world's nuclear arsenal. The researchers assume that, as a result of the bombing of cities, the resulting fires throw 5 million tons of soot into the stratosphere. It will spread throughout the atmosphere, absorbing sunlight and producing a decrease in the temperature of the planet by a centigrade degree over five years. The decrease in temperature will affect the production of maize, wheat, soy and rice, which will descend by an average of 11 percent. The effect on cereal crops will be more pronounced in the regions of the western half of the United States, as well as in Canada and particularly in Russia. Paradoxically, however, more affected countries not located further south will be affected. In this sense, some 70 developing countries, with a population of 1.3 billion people, will see their availability of cereals reduced by 20 percent. Thus, a regional nuclear conflict with just one percent of the world's nuclear arsenal would result in global famines.A further indication of the smallness and weakness of the planet, and of our ability to harm it, even through relatively old technology, but certainly of great destructive power.",
    "https://upload.wikimedia.org/wikipedia/commons/a/a5/Toiletpapier_%28Gobran111%29.jpg": "The last few days we have been surprised by the panic shopping that has taken place before the expected, and then confirmed, arrival of the Wuhan coronavirus to the city. It is understandable, of course, that in the face of an unknown danger - and of the behavior of the coronavirus there are still things to be found - there are alarms that lead to buying and accumulating food and cleaning products in anticipation of the epidemic forcing us to stay locked in our homes. It is, however, difficult to understand that a product that is in great demand is the toilet paper. Phenomenon that, for the rest, happens on a global scale. Undoubtedly, toilet paper is an indispensable product. Judging by the images that one can find on the Internet, however, it is being acquired in quantities that are excessive cravings. Searching the Internet can find explanations for the phenomenon, offered by specialists in the field. Thus, massive purchases of toilet paper would give to those who make them a sense of control over the epidemic. It is not clear, however, why exactly the toilet paper is able to produce that sensation and not, let's say, the bath mats, for example, because we have a sense of the toilet paper. Other explanations go in a different direction: in the face of an unknown danger, people buy what others buy as a defense mechanism. This sounds reasonable, but it would have to be explained how the whole process started. That is, why it might have occurred to someone at some point that toilet paper is a defense against coronavirus. Otherwise, explanations aside, the excess in the purchase of toilet paper and the scarcity that this could cause is not too serious a matter and could be solved in various ways. For example, last March 5th edition of the Australian newspaper NT News appeared with eight blank pages. explicitly, so that they would be used in case of need. More serious is the epidemic itself that is spreading at great speed. In this regard, something that alarms experts is the possibility that an infected person can transmit the virus even before showing the first symptoms of the disease. An article deposited at the medRxiv pre-impress site on March 8 points to this possibility. Hasselt University in Belgium. Based on a study of outbreaks of COVID-19 occurring in Singapore and Tianjin, China, Tapiwa and collaborators conclude that 48% of infections occurring in Singapore occurred at a pre-symptomatic stage, while in Tianjin this figure rises to 64%. It should be noted, however, that the reference article has not yet been evaluated by peers, so its results should be taken with caution.One way or another, what is a fact is that the epidemic spreads at high speed and that those of us who are poorly versed in epidemics ask ourselves what will be the best defense against the coronavirus. Specialists give us an answer: we should wash our hands with water and soap frequently and avoid touching our faces. We must also clean the surfaces of the furniture with which we are in contact.The basis for these recommendations is simple: an infected person expels when coughing or sneezing microscopic drops of saliva with the virus that are either dispersed in the air or deposited in Belgium. A healthy person can become infected if these drops reach his or her nose or mouth. Or, if the hands collect viruses deposited on some surface or object and then carry his or her hand to the mouth, nose or eyes. The effectiveness of these ways of contagion will depend on the stability of the virus in the air or on the surfaces where it was deposited. As Wuhan\u2019s coronavirus is a new virus, this stability is not known. An article deposited in the medRxiv file last Friday, however, offers us a response. This article was written by a group of researchers attached to American research institutions, headed by Neeltje Van Doremales of the National Institute of Allergy and Infectious Diseases. According to Doremales and collaborators, Wuhan\u2019s coronavirus may persist in the air for up to three hours, while deposited on a copper surface it will do so for up to four hours, and up to 2-3 days on plastic or stainless steel. With these results, researchers conclude that a plausible way of transmission of Wuhan\u2019s coronavirus is, in fact, It should be noted, however, that the article referred to is in a peer review stage. Moreover, the results of Doremales and collaborators are in line with the recommendations of the experts: to avoid close contact with a sick person, to wash frequently the hands with soap and water, to disinfect the surfaces and objects with which we are in contact, and to avoid touching the face with the hands. As regards how to avoid infections of asymptomatic carriers - in the case of the phenomenon - specialists may not have an answer yet.To conclude, we may point out that, in the circumstances in which we find ourselves, the purchases of panic that end with the sanitary role in the shops result in a minor evil. It would be wrong to go no further than those that, those that do not accumulate toilet paper, we saw ourselves deprived of what today is an article of first necessity. Situation that would surely have an early solution.",
    "https://upload.wikimedia.org/wikipedia/commons/d/db/Marie_Curie%2C_portrait%2C_1900.jpg": "If we were asked about a woman who has made the most important contributions to the advancement of scientific knowledge, Marie Curie may be the most frequent answer. And not without reason, because of her scientific work on radioactive elements, Marie Curie was the first person to receive two Nobel Prizes, that of physics in 1903 and that of chemistry in 1911. These discoveries contributed to establishing physics as a dominant science during the first half of the twentieth century. Marie Curie, in addition, carried out her discoveries in disadvantaged conditions, first because she was a foreigner in France, where she resided, and second because she was a woman. In fact, she was not initially nominated for the Nobel Prize in 1903. In that nomination only her husband Pierre Curie and Henry Becquerel appeared. However, when Pierre Curie learned that his wife was not nominated, he declared that in his case he would reject the prize. With this pressure, Marie Curie was finally included in the nomination.If the first half of the twentieth century was a golden age for physics, the second half was for biology. At the beginning of the 1950s, and in which a woman also played a central role. This is the case of Rosalind Franklin, a British physicist whose X-ray measurements gave her the key to the discovery of the double-helix structure of the DNA molecule. Like Marie Curie, Rosalind Franklin did a scientific work of enormous importance. This work, however, has not given her such a notorious public presence as Marie Curie because of unfortunate circumstances she went through throughout her professional career. The most serious of all: her premature death at the age of 37 years affected by ovarian cancer.Rosalind Franklin is also remembered for circumstances that have been associated with her status as a woman and that occurred around the discovery in 1953 of the aforementioned DNA structure. James Watson and Francis Crick of Cambridge University and Maurice Wilkins and Rosalind Franklin of King's College of London. The story is as follows.On 25 March 1953, Watson and Francis published an article in the journal \u201cNature\u201d This article was accompanied by two more articles, one with Wilkins as co-author and the other with Franklin as co-author. In this last article the X-ray measurements of the DNA molecule carried out by Rosalind and a doctoral student were reported. Watson and Crick's proceeding at the time of reporting their discovery to \u201cNature\u201d, however, has been highly criticized. In fact, as they later recognized, in order to devise the structure they proposed for DNA, Watson and Crick made use of the X-ray results of Rosalind Franklin that were shown to them by Wilkins, without it being known. This use, moreover, was not recognized in the original article, thus violating fundamental principles of scientific practice.The controversy over Watson's and Crick's course of action was revived when the first published in 1968 the book \u201cThe Double Helix\u201d in which he reports the events that led to the discovery of the DNA structure.In that book, Watson referred to Rosalind as a researcher who did not He could interpret his own X-ray results, unwilling to cooperate with Wilkins, who was not his boss. Moreover, according to Watson, \u201cIt was enough to see her to know that she would not bend easily. She deliberately refrained from enhancing her feminine qualities. Although her features were somewhat angled, she did not lack appeal, and if she had lent a little more interest to her dress would have been dazzling. But she did not. There was never carmine on her lips that contrasted with her black hair and, at the age of thirty-one, her attire showed no more imagination than those of English girls in blue stockings.\u201d Today, these words are surprising in the mouth of a Nobel-winning researcher and co-author of one of the greatest scientific discoveries of the twentieth century. It should be remembered, however, that at the time when the DNA structure was discovered, at King \u0301s College there was an exclusive dining room for men, which is also surprising. By the discovery of the DNA structure to Watson, Crick and Wilkins was awarded the Nobel Prize for Medicine and Physiology 1962. . By then, Rosalind Franklin had four years of death and could not have been a candidate for the prize that cannot be awarded to an already deceased person. Had she been alive, Rosalind Franklin would have been distinguished with a Nobel perm. The question is idle, of course, but it would have to be remembered that the Nobel Prize can only be awarded to a maximum of three people, so one of the four, Watson, Crick, Wilkins or Franklin should have been left out. Rosalind, on the other hand, might also have been nominated for the Nobel Prize in Chemistry.On the other hand, the situation has changed over a few decades and today scientific research is considered a profession that can be practiced by both men and women. Fortunately, otherwise half of the world's intelligence would be wasted.",
    "https://upload.wikimedia.org/wikipedia/commons/0/0e/Urnas_elecciones_Chile_2017.jpg": "As we remember, on November 10, 2019, Evo Morales resigned from the presidency of Bolivia. He did so after protests by citizens over an alleged electoral fraud during the presidential elections held three weeks earlier. A central actor in the events that led to Morales\u2019 resignation was the Organization of American States (OAS). This body denounced that there was a manipulation of votes to favor the re-election of the president. According to Bolivian electoral legislation, a candidate who obtains more than 50% of the votes cast wins the presidential election. The same happens if he gets between 40% and 50% of votes, with at least 10% of the difference with the second place. Otherwise, the first and second places in the election will have to face in a second round to define the winner. On the day of the election, the quick count of votes -unofficial - will be suspended at 19:40 with 84% of polling places counted. The results gave Evo Morales more than 40% of the votes cast and a margin of approximately 8% of his most immediate pursuer. This would indicate that the first and second places in the election would have to face. However, in summarizing the rapid count the following day due to pressure from the OAS, with data of 95% of electoral records, Morales\u2019 margin on his immediate pursuer increased to slightly more than 10%. The numbers of the rapid count were subsequently confirmed by the official count and with this Morales was the official winner of the presidential election. The OAS expressed concern over the change in the percentage that Morales was ahead of second place, before and after the interruption of the rapid count. The OAS finds this change inexplicable, implying that there was a manipulation of votes and questioning the results of the election. In these circumstances, Morales agreed to go to a second round to define the situation. It did not take long, however, to give up the presidency pressured by the military. OAS arguments on manipulation of votes in the Bolivian election are discussed by an article published this week in the newspaper \u201cThe Washington Post.\u201d This article is signed by John Curiel and Jack Williams of the Massachusetts Institute of Technology and is presented and analyzed in it. In their analysis, Curiel and Williams consider only data of 84% of the boxes counted in the interruption of the rapid count. They consider, moreover, only those boxes that were verified both before and after the interruption. These boxes -1477- represent 30% of the total. The central idea of the analysis is as follows: if the interruption in the rapid count had been used to instrument a manipulation of the vote, there would have to be an inconsistency in the trend observed before and after the interruption of that count. Curiel and Williams find, however, that there is no such inconsistency, concluding that the final results of the election are consistent with the trend observed before the interruption of the count. They conclude that Evo Morales very probably won the election with a margin of more than 10%, as indicated by the official results. Of course, for Evo Morales to pass the margin of 8% observed with the 84% of the boxes, at the end of 10%, it was necessary that in the last 16% of the cells the preference for his 8% was increased. In this regard, Curiel and Williams point out that the last boxes to be counted are rural ones, which take longer to be counted and in which the preference for Morales is greater. Of course, although with statistical arguments it is not possible to speak of certainties but of probabilities, it should be considered that there are probabilities to probabilities. Thus, when the probability of an event is small enough, we can expect it never to happen, while a sufficiently large probability becomes almost a certainty. By way of example, few plan their lives thinking that they win the lottery jackpot, an event that has a probability of happening just one part in 3,000. At the same time, very few are encouraged to play Russian roulette, as the probability of ending up dead is one part in six. As for the results of Curiel and Williams -based on the statistical analysis of almost 1,500 squares - the probability that they correspond to the reality would be closer to the probability of dying playing Russian roulette, than to the probability of winning the lottery jackpot. Thus, while it is true that Evo would be more likely that they would be able to do so. Morales exceeded his time in search of a fourth presidential term, it is quite likely that he has won the election and, consequently, that the OAS has exceeded its functions, to say the least.",
    "https://upload.wikimedia.org/wikipedia/commons/f/fd/National_Park_Service_9-11_Statue_of_Liberty_and_WTC_fire.jpg": "According to statistics from the World Health Organization, the number of new cases of coronavirus-baptized COVID-19 in China would be decreasing. Thus, on 22 February, 397 new cases were diagnosed, compared to the more than 3,000 daily cases that came to be diagnosed in the first days of February. In contrast, outbreaks of the disease have appeared in other parts of the world whose rapid growth concerns experts, particularly in South Korea, Iran and Italy. In South Korea 142 new infections were reported on 22 February, bringing the total number of cases of coronavirus in that country to 346. Most of the new infections occurred in the city of Daegu, of two and a half million inhabitants, south of the capital Seoul. According to specialists, coronavirus has its origin in wildlife -possibly bats - and hence would have been transmitted by an intermediary to humans. Although there is no certainty, a market in the city of Wuhan where live animals are sold, it has been pointed out as the possible source point of the epidemic. , on the other hand, they have given the expert opinion various interpretations. The British Daily Mail newspaper, for example, contributed to making famous a young Chinese woman by publishing a video in which she appears in a sophisticated restaurant giving a bite to the wing of a bat -which she holds with a pair of Chinese chopsticks-. According to the Daily Mail, the animal consumed by the young woman was apparently part of a dish with bat soup placed in the center of the table. Next to the points of view of the specialists, there have also been various rumors and \u201cconspiracy theories\u201d regarding the origin of the coronavirus -that is, explanations that go against the official explanation, or that which is assumed by the majority. A conspiracy theory maintains that the coronavirus does not have a natural origin, but was developed in a laboratory of the Chinese Academy of Sciences that has its seat in Wuhan city. That laboratory works with pathogenic organisms, in particular with Wuhan\u2019s coronavirus, which would have been dispersed by an error among the population. . Tom Cotton, Republican Senator for the U.S. state of Arkansas, also echoes the possibility that the coronavirus \u2013 which would be part of a chemical weapons development program by the Chinese government \u2013 would have effectively escaped from the Wuhan laboratory. According to Cotton, according to the New York Times, \u201cWe have no evidence that this disease originated there, but given, to begin with, China\u2019s duplicity and dishonesty, we need to at least ask the question and see what the evidence is telling us, and China is currently not providing any evidence at all.\u201d Wuhan\u2019s laboratory, for its part, denies any involvement in the coronavirus epidemic and in this regard is supported by a group of specialists who published a paper this week in the prestigious medical journal \u201cThe Lancet\u201d, in which they condemn rumors about an artificial origin of coronavirus and express their support to Chinese scientists, doctors and health workers who are fighting against the epidemic. The authors of the statement are scientists from areas of health attached to universities and scientific institutions in the United States, Germany, Great Britain, Australia, Holland, Malaysia and Hong Kong. In their paper, specialists say that \u201cthey have observed that Chinese scientists, public health professionals and medical professionals have worked diligently and effectively to quickly identify the pathogen that is behind this outbreak, to put in place significant measures to reduce its impact, and to share its results transparently with the global health community. Their effort has been remarkable.\u201d Specialists also claim that: \u201cThe rapid, open, and transparent communication of Chinese scientists\u2019 data on this outbreak is now threatened by rumors and misinformation about its origins. We all agree to strongly condemn conspiracy theories that suggest that COVID-19 does not have a natural origin. Scientists from multiple countries have published and analysed genomes of the causative agent, and overwhelmingly conclude that this coronavirus originated in wildlife, as has been the case of other emerging pathogens. Conspiracy theories do nothing but create fear, rumors and prejudices, which jeopardize our global collaboration in the fight against this virus.\u201d Given the scientific consensus, it is therefore unlikely that COVID is likely that the case of other emerging pathogens. -19 be an artificial virus, part of a secret program of the Chinese government, that has escaped from a laboratory. Nor would they have sustained the stories about the dangers of enjoying a bat soup, because, according to specialists, the coronavirus would not have passed directly from these animals to humans, but would have done so through an intermediary animal, not yet identified.You could then proceed with complete confidence.Conspiratory theories aside, what is shocking is the rapid development that are having some outbreaks of coronavirus, independent of the epidemic in China, such as the one that is ongoing in South Korea.Breaks that we hope will remain sufficiently distant from our country.",
    "https://upload.wikimedia.org/wikipedia/commons/a/a5/El_Atazar_dam_view01.jpg": "While there is still doubt about global warming, a large majority of climate science specialists agree that such a change is real and that urgent action is needed to mitigate it. Given that such warming is the product of fossil fuels for energy generation, experts consider it essential to gradually replace such fuels with clean renewable energy sources. As a source of renewable energy, the Sun is a very attractive option, because it has a power thousands of times greater than is necessary to meet our needs, and is virtually unlimited and clean. For the use of solar energy, photovoltaic cells are in turn a very attractive option. Such cells convert solar radiation directly into electrical energy, a very convenient form of energy that can be easily manipulable. Solar cells have made use of all their virtues and, as we know, are increasingly common as electric power generators, both at the level of homes-habitation to reduce electrical bills, as well as in medium capacity installations, and even in plants for the generation and distribution of energy through the electricity grid. the most important is that it is intermittent and we can only count on it during the day. Thus, for a full substitution of fossil fuels by solar energy it is necessary to complement solar panel installations with a means to store the energy generated during the day -for example, with rechargeable batteries- to be used at night. Energy storage means, however, do not have the same degree of technological development as solar panels and with their high price expensive a solar installation. In these circumstances, photovoltaic solar facilities would have to be considered only as complements of power generating plants that use fossil fuels and not as substitutes for them. In this context, an article appeared last January in the magazine \u201cACS Photonics\u201d describing the possibility of building a solar cell that generates electric energy during the night. That article was published by Tristan Deppe of the University of Maryland and Jeremy Munday of the University of California in Davis. To understand the proposal of Deppe and Munday it would be necessary to remember that a solar cell that absorbs solar radiation and delivers electricity. It works because of the great disparity between the temperature of the surface of the Sun - more than 5,000 degrees Celsius - and the temperature of the cell that receives the solar radiation. That is, the operation of a photovoltaic cell is based on the interaction between a hot object - the surface of the Sun - and a colder object - the solar cell.The device analyzed by Deppe and Munday generates electrical energy based also on the interaction between a hot object and a cold object.In contrast to a conventional solar cell, however, the hot object corresponds to the solar cell while the cold object is the deep space, which is at a temperature close to absolute zero - at least 273 degrees Celsius. The device also works by emitting radiation to deep space - pointing its surface to the sky - and not absorbing it as in the conventional cell. In order for all this to be possible without violating the principle of energy conservation -which is accepted by everyone, including nature in the first instance - it is necessary for the device to absorb energy from some side. ppe and Munday points to the feasibility of building a device that generates energy during the night so it has been baptized as an anti-solar cell. This may not be entirely correct, as the cell analyzed by Deppe and Munday does not differ in its basic aspects of operating a conventional photovoltaic cell, beyond which one works absorbing radiation and the other emitting it. Furthermore, both cells take their energy from the Sun. The conventional cell directly, and the Deppe and Munday cell from the environment and ultimately from the Sun, whose radiation maintains the temperature of the surface of our planet.How much electrical power could be obtained from the solar cell of Deppe and Munday? Researchers calculate that under ideal environmental conditions could be a fourth of the power obtained in full sun from a conventional solar cell. It is therefore not a negligible amount.The solar cell analyzed by Deppe and Munday is only at a conceptual stage and in order to attest to its manufacture and demonstration of its functioning we will have to wait for future years. On the other hand, even demonstrating its feasibility, surely it would not be a simple process. After all, the solar photovoltaic industry depends on multiple factors, including economic and political factors, and has progressed very slowly since the invention of the solar photovoltaic cell in 1954. Moreover, aside from all these considerations, the possibility of generating energy is fascinating simply by pointing a solar cell towards the ultra cold deep space.Using the environment as a kind of rechargeable battery.",
    "https://upload.wikimedia.org/wikipedia/commons/5/5f/Esperanza_de_vida2013.png": "In the last two hundred years, life expectancy at birth, that is to say, the average time that a person would be expected to live at the time of birth, has increased dramatically.In industrialized countries this expectation has doubled since the mid-19th century to date and in other parts of the world this increase has been even greater.The increase in life expectancy is the product of the medical and public health advances that have occurred in the last two centuries.The increase in our life expectancy, on the other hand, has been largely the result of a drop in infant mortality and does not imply that we have doubled the length of our life.In respect, however, it is illustrative to consider the historical evolution that our life expectancy has had once we have exceeded the child's age, which, although to a lesser extent, has also had substantial increases.The white population of the United States, for example, between 1850 and 2011, has increased its life expectancy to ten years by 40%. It serves as an introduction to comment on an interesting article published last month in the magazine \u201ceLife\u201d by a group of researchers at Stanford University, led by Myroslava Protsiv, who come to an amazing conclusion: the average body temperature of the population of the United States has gradually decreased over the past 150 years. Protsiv and collaborators note that in 1851 the German physician Carl Wunderlich carried out millions of axillary temperature measurements with 25,000 patients who established a body temperature standard of 37 degrees Celsius. Modern body temperature measurements, however, are systematically lower than the Wunderlich standard. In these circumstances, Protsiv and collaborators proposed to find out whether body temperatures have actually decreased over the years, or whether the discrepancy between current measurements with those of Wunderlich are the result of a difference in the thermometers employed or in the temperature measurement methods. To find out, researchers examined about 700,000 body temperature measurements with three groups of people over 160 years, including 84,000 measurements. In general, Protvis and collaborators found that the body temperatures of the veterans of the civil war are higher than those of modern patients. Likewise, the temperatures measured in the period 1971-1975 are higher than those measured in 2007-2017. For greater precision, the average body temperature of the American men born in the early nineteenth century was more than half a centigrade than at present. They also found that American women have decreased their body temperature by one third of a centigrade degree since 1890. In both men and women, the decrease in temperature has been gradual in all the groups studied. Given this last circumstance, Protvis and collaborators consider that it is highly unlikely that the decrease in body temperature is the result of measurement failures or possible inaccuracies of the thermometers employed in the nineteenth century. They also rule out that the method of measuring body temperature, axillary in the nineteenth century and oral in In this sense, Protvis and collaborators interpret the historical decrease in body temperature in terms of a decrease in the metabolic activity of the body. For this latter they venture two possible explanations. One of them is related to the expansion that has had in the United States the heating and air conditioning used to cushion the changes in environmental temperature. Thus, not having to deal with very high or very low temperatures, the body spends less energy to maintain its temperature and reduces its metabolism. A second explanation, which Protvis and collaborators consider the most feasible, is based on the decrease in the levels of inflammation of the North American population that enjoys today a better standard of life and health. This results in a decrease in chronic infections, increased dental hygiene, reduced exposure to tuberculosis and malaria, and access to antibiotics. All this, the researchers argue, has very likely decreased the number of chronic infections, increased dental hygiene, reduced exposure to tuberculosis and malaria. level of chronic inflammation of the American population, as well as its body temperature. Protvis and collaborators conclude that their results indicate that humans in rich countries have changed physiologically in the last 200 years and that their body temperature is 1.6% lower than in the industrial era. Is this physiological change related to the increase in our life expectancy? This is a fascinating possibility that they briefly address Protvis and collaborators. Only to point out, however, that the role that physiological \u201cevolution\u201d plays in increasing human longevity is unknown.",
    "https://upload.wikimedia.org/wikipedia/commons/8/87/HongKongCollage1.jpg": "So much has the world's health been improved by the invention of antibiotics and by the introduction of hygiene measures, and in general by the advancement of medical practice and science, which seem to us to be far from the moments of terror experienced by our ancestors trapped in the midst of an epidemic and to which they had little means of defense. This is the case, for example, of the bubonic plague epidemic that decimated the European population in the fourteenth century. It is also the case of the smallpox epidemic that almost extinguished the indigenous population in Mexico after the Spanish conquest.From time to time, however, the pathogenic micro-organisms remind us of their presence in the world. Thus, just a century ago, the so-called Spanish flu killed between 20 and 50 million people. But recently, the HIV epidemic has led to the death of 32 million people, according to the World Health Organization. And even more recently, the coronavirus epidemic originated in Wuhan, China, threatens to expand around the world.As it has been widely disseminated by the media, the first cases of the coronavirus epidemic occurred. This city is the capital of the province of Hubei in central China. Its metropolitan area has a population of 11 million inhabitants. It is an important communications center, with air and land connections with other Chinese megacities, as well as air connections with cities outside mainland China and this enabled the spread of viruses. The development of the epidemic in Wuhan is currently in the stage of exponential growth and its statistics change rapidly day by day. Until yesterday, a total of 14,551 infected and 304 dead people have been confirmed, the vast majority of them in Hubei province. On the other hand, while deaths have only occurred in mainland China, coronavirus infection has already spread to 24 countries, as well as to Hong Kong and Macao. In total, 171 infected people have been reported outside mainland China. Japan has reported 20 infected people, followed by Thailand with 19, Singapore with 18 and Hong Kong with 14. Our country has not reported any infected persons, as any other Latin American country. Instead, they have reported 8 infected, so the virus is already on the other side of our northern border. An article appeared online last Friday in the medical magazine \u201cThe Lancet\u201d tries to forecast the course that will follow the epidemic. This article was published by three researchers from the University of Hong Kong. To make their prognosis, researchers make an estimate of the size of the epidemic in Wuhan based on the number of infected who were exported from Wuhan, both to other Chinese cities, as well as to outside mainland China. They also make use of data on passenger transportation by train, road or air, both within mainland China and to other countries or territories of the world. They find researchers who from the start of the epidemic on December 1 to January 25, each person infected with the coronavirus would have infected on average two or three more people, and that the number of infected people would have doubled every 6.4 days. Thus, in that period up to 76,000 people could have been infected. Gabriel Leung, one of the authors of the reference article, considers that the discrepancy may be due to the delay between the infection and the onset of the first symptoms of the disease. In addition, people infected and already with symptoms, do not immediately seek medical help. The time needed to make a laboratory diagnosis also introduces a delay before the patient enters the statistics. On the other hand, the study concludes that they have most likely already been exported to other Chinese megacities infected enough to initiate local epidemics. At the same time, researchers point out some weaknesses in their study. These include the assumption that travel patterns were not modified by the development of the epidemic and that all infections, even the mildest, produced symptoms. If this were not true, they would have underestimated the size of the epidemic. To what extent the researchers at the University of Hong Kong are successful in their predictions, it is something that will not take us long to figure out. Although a dead person is already too many dead, Wuhan's coronavirus does not seem to be particularly lethal, as the total number of deaths is only 2.1% of the total number of infected.One way or another, it should be recognized that today we are much better armed to defend ourselves from epidemics than our ancestors were. During the episodes of bubonic plague in the Middle Ages people died without having the slightest idea of the cause of the disease. Today, in contrast, we know that Wuhan's disease is caused by a virus, of which we know even its genome.",
    "https://upload.wikimedia.org/wikipedia/commons/b/b2/Plastic_household_items.jpg": "Anyone who has seen the famous film \u201cEl Graduado\u201d, released in 1967, may remember the scene in which the protagonist, Benjamin Braddock \u2013 characterized by Dustin Hoffman-, receives advice for his future career. The scene takes place during the meeting that the wealthy parents of Benjamin have organized in his residence on the occasion of his recent graduation from a prestigious university in the east of the United States. A friend of the family, Mr. McGuire \u2013 we don\u2019t get to know his first name \u2013 is who advises Benjamin. He does so with a paternal attitude and in a theatrical way, moving him away from the party to wait for him in front of the pool: \u201cI want to say a word to you.\u201d \u201cJust a word.\u201d \u201cYou listen to me?\u201d When Benjamin answers in the affirmative, McGuire simply mentions: \u201cpl\u00e1sticos.\u201d Before Benjamin\u2019s confusion, McGuire is more explicit: \u201cThere is a great future in plastics.\u201d The dialogue between Benjamin and Mr. McGuire is as famous as the film itself and has been interpreted in the context of dislocation between generations that he is more explicit. So, for Benjamin, who finds himself in a great confusion about what he wants to do about his life, it is absurd that McGuire, a member of his parents' generation, attaches such importance to plastics, a material that is a cheap imitation of others very superior, as is the case with metals or wood. On the other hand, beyond the allegorical interpretation that we can make of the dialogue between McGuire and Benjamin, if we take it in its literal sense it should be recognized that McGuire was not lacking in reason. A visible proof of this is the increasingly acute problem of environmental pollution from plastic waste, as a result of the disproportionate increase in the worldwide production of these materials since the premiere of El Graduado. With regard to the latter, according to a July 2017 article published in the journal \u201cScience Advances\u201d by a group of researchers headed by Roland Geyer of the University of California in Santa Barbara, between 1967 and 2015, the production of plastics worldwide increased about 17 times, to reach about 400 million tons per year. According to the same source, the accumulated production of plastics between 1950 and 2015 is approximately 8.3 billion tons, of which 2.6 billion are still in use, and 5.7 billion are already discarded plastics. Of the latter, only 14% have been destroyed by incineration. The remaining 86% is accumulated in deposits, more or less safe, or scattered over the surface of the planet. It should also be noted that only 7% of the total plastics produced have been recycled and that a certain percentage of the recycled material has ended up being disposed of.A measure of the overall level of plastic contamination has been obtained if we divide the mass of discarded plastics and they have not been destroyed, by the number of inhabitants of the world.If we do this division, each of us would have around 750 kilograms of plastic waste.The increasing contamination by plastic materials has triggered the alarms and this has led, among other initiatives - and we know that - to ban the plastic bags provided by supermarkets. Thus, according to the organization \u201cOcean Conservancy\u201d, a campaign to clean coastal areas carried out in 2018 found that the biggest pollutants are, in that order: cigarette butts, food wraps, popotes, plastic covered, plastic bottles, bottle caps, and supermarket bags. Thus, while the prohibition of supermarket bags could alleviate the problem of plastic contamination, it could not in itself solve it by not constituting such bags the only polluting source. In fact, the measure is controversial, and as there are those who support it, it also has detractors who consider that it could even aggravate the problem of air pollution, given that the manufacture of the substitutes of supermarket bags could lead to a greater consumption of fossil fuels. Moreover, the measure of banning supermarket bags has gained momentum, although we will have to wait for years to come to tell us of its effectiveness. What is clear now is that Mr McGuire did not err with his advice to Benjamin Braddock in that there was a great future in plastics. . Future that, however, was not in Benjamin's interest that he renounced the security offered him by the well-to-do social position of his family, according to the plot of the film. It is also possible that it also did not coincide with the interests of the planet.",
    "https://upload.wikimedia.org/wikipedia/commons/5/53/Meerenge_NASA_World_Wind_Globe_4.jpg": "When Christopher Columbus landed on Guanahani Island on October 12, 1492, he found natives who seemed very attractive to him, \u201c...very well made, of very beautiful bodies and very good faces.\u201d At the same time, he noticed that some of them showed wounds on their bodies, which they told him had been violated by people from other islands. Columbus concluded that the attackers had arrived from the mainland with the purpose of capturing the Guanahani natives who, on the other hand, were peaceful, because \u201c...they do not bring weapons or know them, because I showed them swords and they took them by the edge and cut themselves.\u201d Very contrasting was the view that Columbus had of the Caribe Indians that he later found in Spain and that according to him they were wild cannibals who terrorized them with their incursions into the territories of peaceful Indians in search of human flesh. According to Columbus, canniba\u2014that\u2019s what Caribs meant\u2014\u201cthey are nothing other than the people of the Great Can, who must be very close here, and they will have ships and come to captivate them, and how they With regard to the latter Col\u00f3n made a mistake caused by his belief that he had arrived on the Asian continent. Otherwise, mistakes aside, with Col\u00f3n was born the black legend of the American cannibals. The fact that the Carib Indians were cannibals, however, is not something universally accepted at present. According to Reg Murphy, of the University of Syracuse, for example, on the basis of an analysis of the diet of the Carib Indians, it is possible to conclude that they were mainly fed fish and seashell animals and that, if it were the case, their consumption of meat -animal or human - would have been only sporadic. Another argument against the cannibalism of the Caribe Indians of the Spanish, is based on the belief of the experts that said Indians, who migrated through the Minor Antilles from the north coast of South America, never arrived beyond Guadalupe Island. Under these conditions, the cannibals of Colon could not correspond to the Caribbeans of today. An article appeared this week in the magazine \u201c Scientific Reports\u201d, however, concludes that the Caribbean Indians arrived much further north than the experts had considered. This article was published by a group of researchers from American universities and research centers, headed by Ann Ross, of the State University of North Carolina in Raleigh. In order to investigate the origin of the inhabitants of the Caribbean islands, Ross and collaborators analyzed 16 facial characteristics, such as the size of the eye cavity and the length of the nose, of 100 skulls excavated on those islands, dated from the 800 to 1542 of our era. Through this study it was possible to determine the relations that exist between the different Caribbean populations. The analysis showed that there are three groups of inhabitants of the Caribbean. It showed, in addition, the migration routes that led to the formation of these groups. The first migration to the Caribbean occurred about 7,000 years ago, from the Yucatan peninsula to Cuba. In a second migration, the Arahuacos peoples expanded from the coast of Venezuela to the island of Puerto Rico, between 800 and 200 years before our era. Finally, one was one. third migration was that of the Caribbean peoples, who crossed the Caribbean Sea and arrived in Spain around 800 C.E., continuing with a rapid expansion towards Jamaica and the Bahamas Islands - where Guanahani Island is located. Thus, according to Ross and collaborators, the Caribbean Indians had arrived to the Bahamas and the Spanish at the time when Columbus arrived in the New World. This supports his version of the existence of ferocious tribes of anthropophagous Indians who ravaged peaceful peoples in search of women to kidnap and men for slaughter. It does not, however, prove it to be only a myth. Five centuries ago, when knowledge of the geography of the world was incomplete, Europeans believed that there were remote places where beings lived with one eye, or beings without head and with eyes and mouth in the chest: or, in torrid places, beings with one leg but with a foot so large that they used as umbrella. In these conditions it would not have been difficult to create a myth about the existence of cannibals, beings So depraved that they used to devour their fellow men.We would thus have an interested version of the American Indians that was very convenient to morally justify the European domination of the New World. A version that was also easily propagated and with impunity, because if it is still not clear if the Caribs were ferocious cannibals, five centuries ago it would have been impossible to verify thousands of miles away and sea in between.",
    "https://upload.wikimedia.org/wikipedia/commons/9/9e/Obesity-waist_circumference.PNG": "To close the Guadeloupe-Reyes bridge for the 2019-2020 season, it is necessary to make a count of the good moments that it has provided us. Although, at the same time, in some cases the bridge has had consequences not entirely positive. Thus, for example, when eating and drinking a little beyond the usual, we gave the scale an opportunity to read us also beyond the usual. On the other hand, although the Guadalupe-Reyes bridge provides us with a good opportunity to gain weight, it is also true that bad eating or overeating is not exclusive to the holidays of the end of the year. An evidence of this last one gives us the epidemic of overweight and obesity that is driving us and with respect to which Mexico occupies a prominent place. Indeed, according to the Ministry of Health, 73% of Mexicans are obese or overweight. Overweight is defined by a Body Mass Index (IMC) between 25 and 30, while an IMC greater than 30 defines obesity. To have an idea of what I Mexicans is obese. MC means, to a person of 1.75 meters of height and 75 kilograms of weight corresponds a BMI of 24.5, near the upper limit of the normal range. According to data from the World Health Organization, in 2014 the average BMI of the population of Mexico was 28.1.The epidemic of obesity and overweight is not limited to Mexico, of course, but has global reach. Indeed, according to data from the World Health Organization, 1.9 billion adults aged 18 or over are overweight and of these 650 million are obese. Translated to percentages, these figures mean that 39% of the adult population of the world is overweight and 13% is obese. To gain weight it is, of course, necessary to have at our disposal food - nutrients or junk - to ingest, and in this regard it is not surprising that the countries of the world with minor BMIs are precisely poor countries of Africa such as Eritrea, Ethiopia and Burundi, with an BMI between 20 and 21 -values, however, within the range considered normal.The world obesity epidemic has alarmed the experts because of the health and the consequences that it has for the health and In this regard, a group of researchers from universities in the United States published an article in the journal \u201cNature Communications\u201d, in which they report the identification of a brain circuit between the hypothalamus and the hippocampus that influences the impulsive consumption of food. The group of researchers was headed by Emily Noble of the University of Southern California. As Noble and collaborators point out, impulsiveness, i.e. impulsive response without considering the consequences of an action, has been linked to excessive consumption of food, overweight and obesity, and to several psychiatric disorders, including drug addiction and excessive addiction to gambling. In their study, the researchers proposed to determine the influence that the production of a hormone in the hypothalamus has on the impulsive behavior of laboratory rats in terms of food consumption. For this purpose, Noble and collaborators trained rats to press a lever and with this they obtained The animals were trained - without food restriction - to wait 20 seconds before pressing the lever and receiving the reward. If the rat pressed the lever before passing 20 seconds, it did not get the pill and the clock was restarted for another 20 seconds. Once the rats participating in the experiment were trained, the researchers encouraged the production of the melanin-concentrating hormone in their brain by establishing a neural circuit between the hypothalamus and the hippocampus. The latter, it is known, is an area of the brain that is related to learning and memory. Noble and collaborators found that by stimulating the production of the hormone the frequency with which the rats activated the lever before 20 seconds was increased. This did not increase the amount of food obtained and therefore the efficiency of their attempts was lower, indicating an increase in the impulsive behavior.Conclude Noble and collaborators that from their research have identified a neural circuit between the hypothalamus and the hippocampus that governs the impulsive behavior of consumption. This could lead to the development of therapies to control the excessive intake of food and therefore to tackle the global epidemic of obesity. If this is the case, we could perhaps enjoy future Guadalupe-Reyes bridges without worries and without the need to make firm purposes of submitting to a strict diet from January 7th -except, of course, Candelaria Day. Although it is also possible that, with the hypothalamus-hypocampus neuronal circuit under control, the end of the year holidays will not be the same again.",
    "https://upload.wikimedia.org/wikipedia/commons/0/04/Cmglee_Cambridge_Science_Festival_2015_ExoMars_Rover.jpg": "During the maximum approach of Mars to Earth in 1894, several observatories throughout the world detected a flash of great intensity on the Martian surface. The general public heard of the event by a note published on 2 August in the magazine \u201cNature\u201d. At that time it was not known, but that flash was the product of an explosion and marked the beginning of the invasion of the Earth by the Martians. This is narrated by the British writer H.G. Wells in his novel \u201cThe War of the Worlds\u201d published in 1898. Whoever has read this novel, of which there are versions for cinema and television, will know that Martians arrived on Earth on board capsules launched from the surface of Mars by means of a kind of cannon. Once on our planet, Martians, who came in the plan of conquerors, deployed huge three-legged machines that launched deadly rays of heat, causing great destruction and panic among the population. Martians and their machines were invincible with the weapons of the terr. However, and for our fortune, they were defeated in the end by an unexpected enemy: the terrestrial microbes for which they had no defenses. Today we know that in case of life on Mars this will be microbial and in no way intelligent. Thus, the facts reported by \u201cThe War of the Worlds\u201d had very little chance of being real. Undoubtedly, the absence of intelligent life on Mars decreases to some degree our fascination for the planet. It does not nullify it, however, and Mars remains one of the favorite targets of space agencies. Indeed, as pointed out by the British magazine \u201cNature\u201d - the same one that would have published the note on the explosions sighted on the surface of Mars in 1894-, in the year ahead an invasion of Mars will be carried out by landcrafts sent from the surface of our planet. The ships will be launched by NASA, by the European space agency in combination with the Russian space agency, by the Chinese space agency, and even by the space agency of the United Arab Emirates. NASA will launch in July-August 2020 the mission \u201c Mars 2020\u201d that, at a cost of $2.5 billion, will place an explorer on the surface of Mars in February 2021. The explorer has the same appearance as the previous explorer \u201cCuriosity\u201d but with entirely different scientific instruments. It will have the size of a compact car and a weight of one ton. The purpose of the mission is to carry out geological studies of the planet, as well as as astrobiology studies to detect the presence of organic molecules and determine the possibility that Mars has harbored life in a remote past. The explorer will also take samples of Martian material that will be stored in metal cylinders. Such material would be brought to Earth for study, at a time and through a mission that is not yet defined. The European space agency, in conjunction with the Russian space agency, plans to launch in 2020 the \u201cExoMars\u201d mission that will also place an explorer robot on the surface of Mars. Such an explorer has an arm to drill the surface of the planet to a depth of 2 meters, with the purpose of obtaining samples of the Martian soil and investigate the existence of biological markers indicating the presence on the planet. In addition, China plans to launch in mid-2020 the \u201cHuoxing 1\u201d mission, which will place an orbiter around Mars and bring down to its surface an explorer robot of about 200 kilograms of weight. As scientific objectives, the Huoxing 1 mission will look for organic materials that indicate the present or past presence of life on Mars. The previous missions that will be started in 2020 and aim to place explorer robots on the Martian surface will be complemented by the \u201cHope\u201d mission of the United Arab Emirates, which seeks to insert an orbiter around Mars. The \u201cHope\u201d mission will be launched from Japan, and will aim to study the Martian atmosphere. For all of the above, we can conclude that the year 2020 that is coming will be particularly rich in initiatives to study the planet Mars. Thus, in the most remote case of Martian astronomers pointing their telescopes to the Earth, they could observe throughout 2020 a series of flashes on the surface of our planet \u2013 the ignition of rocket engine fuel destined for Mars \u2013 that would be indicative of a series of flashes on the surface of 2020. A Martian writer would thus have the opportunity to write, not a fictional novel, but the chronicle of the invasion. Which, for the fortune of the Martians, and given the enormous difficulties to get there, would have to be peaceful by necessity. At least for the time being. Later there would be no guarantee. One way or another, it would be necessary to wish everyone, Earthlings and Martians if that were the case, a very happy year 2020.",
    "https://upload.wikimedia.org/wikipedia/commons/2/21/Transistorer_%28cropped%29.jpg": "We are once again immersed in one of the already traditional Guadalupe-Reyes bridges, in which the country is semi-paralysed for almost a month. During this period, we Mexicans significantly -or flatly interrupt - slowed down the pace of work and entered into party mode \u2013 which is activated in some cases even before the formal start of the bridge. Already racing, we celebrate meals and dinners at the end of the year, a whole week of inns, and a couple of Christmas dinners and New Year dinners, among other activities. On January 6 with a thread of kings and with this we return to our normal activities. As a corollary, however, and perhaps resisting a little to losing the festive atmosphere, the one who is graced with a doll when breaking the thread of kings must offer a tallada on February 2. It is necessary to ask, however, if slowing the activity of country for a month a year is advisable given our situation of underdeveloped country. In this context, and taking into account that the science -and the technology that derives from it - has been and is One of these discoveries was that of the transistor, whose operation was demonstrated by John Bardeen, Walter Brattain and William Shockley on 23 December 1947 at the Bell Laboratories of the AT&T telecommunications company in New Jersey, United States. Bardeen, Brattain and Shockley formed a working group in that laboratory. The transistor demonstrated before Christmas 1947, however, was only developed by Bardeen and Brattain without Shockley\u2019s collaboration. The latter considered himself the true brain of the group and, touched in his professional pride, ended up strongly upset by the situation. In these conditions, it was closed after the demonstration of the transistor in a hotel room to work intensely for several weeks in the conceptual development of a transistor that excelled in characteristics to the invention by Bardeen and Brattain. With great success for the rest, by The transistor has been considered the greatest technological discovery of the 20th century, which has had enormous consequences for the development of electronics as we know it. By its discoveries, Shockley, Bardeen and Brattain were awarded the Nobel Prize in Physics in 1958. Another discovery associated with Christmas is that of the disintegration of the atom carried out by Lise Meitner and Otto Frisch. Meitner was an Austrian researcher of Jewish origin who, fleeing the Nazi regime, had taken refuge in Stockholm. There, shortly before Christmas 1938, she received from Berlin a letter from Otto Hahn - with whom she had collaborated in the past - telling her of the results of an experiment in which she had managed to produce barium atoms from bombing uranium atoms with neutrons. Hahn could not interpret the results of her experiments so she consulted Meitner. Hahn\u2019s letter coincided with the visit of Otto Frisch, Meitner\u2019s nephew, to Stockholm. Frisch had traveled to that city for that purpose. Meitner and Frisch discussed the results of Hahn\u2019s experiments and came to the correct conclusion: by bombarding Hahn with neutrons the uranium atoms had disintegrated them, generating an unprecedented amount of energy in the process. As we know, this discovery had enormous consequences, from the manufacture of the atomic bombs that destroyed Hiroshima and Nagasaki, to the construction of nuclear reactors for the generation of electrical energy. Moreover, of course, of the cold war that had the world for decades in vil for the danger of an atomic war on a global level. Transistors and atomic fission are two of the most transcendent discoveries of the twentieth century. Both were carried out around Christmas by researchers immersed in their work. We cannot, of course, expect that there would be a direct connection between Christmas and such discoveries, which occurred at the precise moment dictated by the advance of investigations, regardless of a particular date. Far from this, we might perhaps understand the temporal coincidence of the transistor\u2019s discoveries and atomic fission with Christmas, in terms of the intellectual maturity of the countries that made this coincidence possible. Maturity that we are obliged to pursue as a country and that certainly has no contact points with the Guadalupe-Reyes bridge.",
    "https://upload.wikimedia.org/wikipedia/commons/a/ae/Piltdown_gang_%28dark%29.jpg": "In December 1912 the paleontologist Charles Dawson announced at a meeting of the Geographical Society of London the discovery of a fossil, half human and half ape, in Piltdown, in the south of England. The fossil remains discovered by Dawson consisted of fragments of skull, two teeth and half of a jaw. The skull was similar to that of a modern human, but with a smaller volume, while the jaw was clearly similar. These combined characteristics were precisely what experts expected from the \u201clost link\u201d, which would have been an intermediate step in the process of evolution of our species. The fossils of Piltdown would thus have shown that in the evolution of homo sapiens, England would have had a prominent role. The latter did not find the British in any way out of the way. After all, they were the power that dominated the world and it was natural for them to think that England would have been the cradle of our species. It appeared, however, that the fossils discovered by Dawson -baptized like the Piltdown Man - were a carefully machined fraud: the skull was the The deception, however, lasted for a long time, and it was not until 1953 when it was finally identified as such conclusively. Thus, it turned out that England would not have had a central role in the evolution of our species. Indeed, today it seems surprising to us that British prejudices have played a role in the episode of the Piltdown Man \u2013 so it is a minor role \u2013 as some of our desires and another of the world\u2019s reality, which can only be explored using scientific methods. And yet, it does not seem that our attitude to prejudge has disappeared altogether. It is worth the above in the case of the French Janne Calment, who was born in 1875 in Arl\u00e9s, France and died in the same city in 1997 at the age of 122 years and is considered the longest person of the news. However, the latter is not universally accepted and there is one who challenges Calment his record of longevity. Calment is unlikely to have died at the age of 122. He bases his statement on a statistical study of longevity achieved by people who reached a century-old age and finds that at 122 Calment would constitute a highly unlikely statistical anomaly. Zak was also given to the task of investigating details and events in Calment\u2019s life and comes to the conclusion that in fact Calment would have died in 1934, at the age of 59. At his death he would have been supplanted by his only daughter Yvonne Calment who would have been the one who actually died in 1997 at the age of 99. The reason for carrying out this supplantation was to avoid paying taxes on his mother\u2019s inheritance. As part of the plot, Yvonne would have formally died in 1934 at the age of 36. Zak published his results in the magazine \u201cRejuvenation Research\u201d in January of this year. The reactions in the West to Zak\u2019s claims are astonishingly negative and in a certain way typical of the Cold War. We would not expect, of course, that in France, and in Arl\u00e9s in particular, where Calment is one of course, In this regard, an article published last September in the journal \u201cJournals of Gerontology: Medical Science\u201d by a group of researchers from France, Switzerland and Denmark, led by Jean Marie Robine of the Institute of Health and Medical Research of France, writes in its conclusions: \u201c...in relation to the article published by Zak, we would like to highlight the unacceptability of publishing an article with unfounded allegations that the Calment and Billiot families collectively committed a fraud. How is it possible that an article so full of insubstantial assertions could survive a peer review and be subsequently published in \u201cRejuvenation Research\u201d. Based on the evidence we present in this article, we request that Zak\u2019s article be withdrawn.\u201d He has published a scientific article in ten years since his graduation as a mathematician, as his critics point out to the least opportunity \u2013 he reveals that it is indeed written in an unusual way for a scientific article, including a lot of anecdotal information and personal interpretations of events from Janne Calment\u2019s past about which there is not enough clarity. However, as a paper published this week in the British newspaper \u201cThe Guardian\u201d points out, on both sides there are arguments in favour of and against Janne Calment\u2019s longevity record. These arguments could be clarified by means of a DNA analysis of his mortal remains. Option proposed by Zak, but not contemplated by his opponents. And with regard to this last point, one should ask whether we are not facing a manifestation of what we might perhaps call the Piltdown syndrome.",
    "https://upload.wikimedia.org/wikipedia/commons/1/1e/Altiplano%2C_Bolivien_%2811214843326%29.jpg": "Would you seriously consider purchasing a fully electric car instead of a gasoline car? While there will be no shortage of customers for electric vehicles - given that there is everything in Lord\u2019s vineyard - most of us would prefer a gasoline car. This is a matter of prices, since a medium-sized electric car is something like 70 percent more expensive than a gasoline equivalent. However, it is expected that the cost of electric vehicles will gradually decrease in future years and will be tied to gasoline cars. With this, electric cars will become more attractive and eventually dominate the market. When is it anticipated that the costs of electric vehicles and gasoline will be equaled? Given the problems of predicting the future date is uncertain, but a study carried out by the Massachusetts Institute of Technology -MIT - comes to the conclusion that it will not happen before 2030. The study, entitled \u201cInsights into future mobility\u201d, may be found on the MIT website. In the years ahead it will be determined by the evolution of the cost of the battery needed to store the electric charge that drives them, and that represents a significant fraction of the total cost of the car. It is estimated that currently the cost of a battery is between 175 dollars and 300 dollars per kilowatt-hour. To put these numbers in perspective, let us consider that - according to an article published on 19 November in the magazine \u201cMIT Technology Review\u201d signed by James Temple - an electric car of medium range is equipped with a battery of 60 kilowatt-hour that would have a cost between 10,500 and 18,000 dollars. According to the MIT study, the price of the batteries per kilowatt-hour in 2030 would fall to some 124 dollars per kilowatt-hour. This still leaves it at a considerable distance of 100 dollars per kilowatt-hour, which is the price for which the price parity between electric cars and gasoline would be reached. The conclusion of the reference study is that the incursion and eventual domination of electric cars in our life will not be as fast as some would be. However, it will happen safely in some future time. In relation to the above, although there are several alternatives to manufacture the batteries of electric cars, the dominant technology is based on the chemical element lithium.This element thus becomes a raw material of great strategic value.In addition, given that lithium batteries are used in laptops and smart phones.As strategic material it is equated even with oil.In its pure form, lithium is a silver white metal, very light and oxidized quickly to contact with air.The world's largest producer of lithium is Australia, but by far the largest reserves of the planet are found in the so-called lithium triangle, located in southern Bolivia and northern Chile and Argentina. Lithium in this case is associated with large salt or salt deserts: the Salt Salar of Atacama in northern Chile, the saltlands of the provinces of Jujuy, Salta and Catamarca in northern Argentina, and the salt of Uyuni in the Department of Potos\u00ed in Bolivia. The salt of Uyuni, located in the province of Jujuyyy, Saltar and Catamarca in northern Argentina. The Bolivian highlands at an altitude of 3,600 meters above sea level, is a spectacular salt plain with an extension of close to 10,000 square kilometers. Below this surface is a sixth of the world's lithium reserves. In addition to their media visibility as an essential component of the emerging electric automobile industry, lithium has received the attention of the media in a different context in recent weeks, although certainly connected with its role as strategic raw material.In fact, as we know, Bolivia is going through great political problems resulting from the forced resignation of President Evo Morales. Some analysts have associated this renunciation with foreign interests that try to control Bolivian lithium reserves. Bolivia, despite the enormous amount of these reserves, is just beginning to exploit them, in contrast to Chile and Argentina, which are two of the world's largest producers of this element. Moreover, the Bolivian model of lithium exploitation is -also in contrast to Chile and Argentina - strongly controlled by the state, which is intended to change according to some interpretations. of the present time, that the same thing is responsible for a revolution in the transport that will occur in some future time - not yet clearly defined - than of political problems - according to interpretations - that occurred in an underdeveloped country rich in deposits of white gold.",
    "https://upload.wikimedia.org/wikipedia/commons/c/cc/Napoleons_retreat_from_moscow.jpg": "Arthur C, Clarke imagined in his novel \u201c2001: A Space Odyssey\u201d a mission of five astronauts to Saturn\u2019s J\u00e1peto moon to make contact with extraterrestrials who would have been responsible for the development of human intelligence. As Saturn is very far away \u2013 to NASA\u2019s Cassini probe, it took almost seven years to get there \u2013 the mission spacecraft was manned only by two astronauts, while the other three traveled in a state of hibernation. Whoever has read the novel or seen the Stanley Kubrick film based on it, will know that only one of the two crew members managed to reach its destination, and that three hibernation astronauts died without ever regaining consciousness. Without the Clarke novel and Kubrick\u2019s film \u2013 which made time \u2013 are fascinating, if we have brought them here to talk is in reference to the state of hibernation in which three of the astronauts were traveling. Tisherman, is carrying out at the University of Maryland on the development of hibernation techniques to deal with medical emergencies. The work in question was presented by Tisherman last Monday at a symposium held at the New York Academy of Sciences, and released this week to the general public by the magazine \u201cNew Scientist\u201d. The magazine quotes Tishemarn saying: \u201cI want to clarify that we are not trying to send people to Saturn. We are trying to buy time to save lives.\u201d In this sense, Tishherman and his collaborators are using deep hypothermia techniques to try to save the lives of people who have suffered traumatic injuries, such as gunshot wounds or white gun wounds, which put them on the verge of death. Candidates for the intervention must have lost more than half of their blood and their heart stopped beating, which gives only minutes to carry out an operation and try to save their lives. According to the Tisherman and collaborators procedure, once the injured person up to the hospital is quickly reduced their body temperature to about 10-15 degrees Celsius replacing all their blood with the procedure. This leads to a state of hibernation, or suspended animation as it is known, in which the brain activity is almost completely suppressed and with this the demand for oxygen is essential for the patient\u2019s survival, since the brain is left without oxygen flow for more than five minutes, irreversible neural damage occurs. In contrast, through suspended animation, the surgeon has about two hours to perform the operation. Once this is finished, the patient\u2019s body temperature rises slowly to its normal value and his heart rate is restored. Tisherman and collaborators aim to compare the results obtained with ten patients who receive suspended animation treatment, with those obtained with ten other patients who follow the traditional treatment. Although to date the researchers have not provided information on this comparison, the suspended animation treatment has been carried out with at least one patient. There are isolated cases of people who have accidentally entered a state of suspended animation and who have returned to life without neurological damage. He was trapped for 80 minutes in frozen water under an ice cap. He suffered a severe hypothermia and, when his body temperature was derelict, was 13.7 degrees Celsius. He also had a cardiac arrest after 40 minutes of being trapped. The victim woke up after ten days of the accident, paralyzed from the neck downwards. However, he recovered almost entirely after two months in an intensive care unit. Fortunately, he did not suffer neurological damage despite the time passed without oxygenation of the brain. This would indicate that his body temperature decreased rapidly, decreasing brain activity and oxygen demand, before cardiac arrest. He would have returned to life from a state of suspended animation close to death.Will techniques be developed in the future so that humans could enter a state of suspended animation for indefinite time? If so, long-lasting space travel could be carried out as envisioned by Arthur C. Clarke, with astronauts in hibernation to the care of the computer on board. And more disturbing possibilities could also become reality. For example, someone With an incurable disease it could be put into suspended animation until a cure for its evil develops. If this happens in, say, fifty years, you will find when you come back to life a very different world. Can you adapt? And it goes without saying that this possibility will be an option only for the richest, thus exacerbating social differences. But it all depends on which groups like Tisherman and collaborators succeed in their endeavours. What is yet to be seen.",
    "https://upload.wikimedia.org/wikipedia/commons/a/ab/Assyrie_general_es.png": "Some 2,600 years ago, in Mesopotamia, in what is now the territory of Iraq and Syria, a surprising event occurred: in just thirty years after reaching its maximum splendour and territorial extension, the Assyrian empire, the most powerful of its time, was conquered by a coalition of the Medes and the Babylonians. Until its collapse, the Assyrian empire\u2014or neo-Asian empire\u2014had had a life of three centuries and in its maximum extension range ranged from Egypt and the Mediterranean Sea, to the Persian Gulf and western Iran. The collapse of the Assyrian empire has puzzled specialists. It has been attributed to various causes, including internal revolts, political instability, economic problems and military defeats inflicted by the coalition of the Medes and Babylonians -which, however, were far from having the military strength of the Assyrians. An article appeared this week in the magazine \u201cScience Advances\u201d, published by an international group of researchers headed by Ashish Sinha of the State University of California, proposes an additional explanation. According to Sinha and collaborators, the collapse of the \u201cScience Advances\u201d magazine, published by an international group of researchers headed by Ashish Sinha Sinha of the State University of California, proposes an additional explanation. This was the result of climate change. Specifically, severe droughts that affected agricultural productivity and lasted for decades. They came to this conclusion after conducting a study to determine the climate that has prevailed in northern Iraq over the last 4,000 years.For this purpose, they measured the composition of oxygen isotopes and stalagmite coal found in a cave in northern Iraq near the site where Nineveh, the capital of the Assyrian empire, was located. As we know, stalagmites are conical structures that gradually form layer by layer on the floor of a cave, by the water that falls from the roof dragging dissolved minerals. From the composition of isotopes of a stalagmite, it is possible to determine the climatic conditions that prevailed at the time of its formation. Thus, by piercing a stalagmite and measuring its composition of isotopes for different depths, Sinha and collaborators were able to determine what was the climate in the past. On the other hand, although measuring of the weather in the past, while measuring of its formation. The compositions of isotopes give us information about the climate in preterite times, it does not allow us to know the precise moment when such or what climatic conditions occurred. To find out, Sinha and collaborators took advantage of the fact that the water filtered by the cave roof has traces of the uranium element, which is known to be radioactive and decaying - at random but in a well-known average time- in the thorium element. The different layers of stalagmites have then trapped uranium and thorium in different proportions, more thorium and less uranium in the older layer. Thus, determining these proportions, Sinha and collaborators fixed the age of each layer of stalagmite and combining this information with that obtained from the measurements of isotopes of oxygen and carbon, they obtained a complete picture of the climate that prevailed in the north of Iraq at the time of the disintegration of the Assyrian empire. According to its results, northern Iraq enjoyed exceptional and favorable climatic conditions for agriculture for a period of about 200 years. This period corresponds to the splendor and expansion of the empire. In this period, however, and coinciding with the collapse of that empire, the region suffered from an extreme drought for several decades that would have seriously affected agriculture. The climate would thus have played a double game for the Assyrians: on the one hand, it would have created exceptional conditions for its expansion, and on the other, abruptly would have taken things to the opposite extreme, causing its collapse as a society.Although Sinha and collaborators find a correlation between the climatic conditions, and the development and collapse of the Assyrian empire, they recognize that such correlation does not necessarily imply a cause-effect relationship. They argue, however, that the source of the agricultural products that supported the Assyrian empire was located right in northern Iraq, where extreme climatic changes reported in their article occurred. Certainly, it is not possible to avoid putting Sinha\u2019s results and collaborators in the current climate change context in which our planet is located and we would end by quoting a paragraph from Sinha and collaborators in an article appearing on the website \u201cThe Conversation\u201d: \u201cClimate change came to stay. 21st century we have what the Assyrians did not have: a retrospective understanding and an abundance of climate data. Unsustainable growth in politically volatile regions with water problems is a recipe for disaster, well proven over time.\u201d",
    "https://upload.wikimedia.org/wikipedia/commons/9/94/Rhino.iguana.claw.arp.jpg": "On September 6, 1856, in the newspaper of Elberfeld, a German city near Dusseldorf, the following news appeared: \u201cIn the neighboring Neander valley, in the so-called \u201cRocas\u201d, a surprising discovery was made in recent days. During the demolition of the limestone cliffs, which cannot be sufficiently lamented from the aesthetic point of view, a cave was discovered, which over the centuries had been covered with clay sediments. After digging in these sediments, a human rib was discovered that would certainly have passed without being noticed and lost had it not been, fortunately, by Dr. Fuhlrott of Elberfeld who assured and investigated the discovery.\u201d All this according to Friedmann Schrenk and Stephanie Muller in his 2005 book \u201cThe Neanderthals\u201d. Fuhlrott\u2019s discovery had an enormous scientific significance. This, however, was not evident to the editors of the Elberfeld diary, who, according to Wikipedia, supplemented their note with phrases -not included in the Schrenk and Muller, who added a considerable colour to it. Thus, wrote Elberfeld\u2019s diary: \u201cAfter examining the skeleton, precisely, the skull, it was discovered that the individual belonged to the tribe of the Flatheads, which still live in the American West and of which several skulls have been found on the high Danube and in Sigmaringen. Perhaps the discovery could clarify whether the skeleton belonged to one of the primitive inhabitants of central Europe or whether it was simply one of the men of the vagrancy hordes of Attila.\u201d Actually, far from belonging to a member of the tribe of the Flatheads or the hordes of Attila, the remains discovered by Fuhlrott, we now know, belonged to an individual of the Neanderthal species, who would have died about 40,000 years ago. Compared to our species, the Neanderthals were of short stature and more corpulent, had a larger brain, a more elongated skull, and prominent superciliary arches, features that reflected the In fact, some refused to accept it. For example, for the German anatomist and physiologist Franz Mayer, the remains discovered by Fuhlrott were those of a Russian Cossack who died during the liberation war against Napoleon. Soon, however, it was evident that it was a new species, which was baptized as \u201cHomo Neanderthalensis\u201d in 1864. Perhaps, hopefully, as we learned that at some point we had a competitor as a species, the natural reaction was to assume that it had a very poor intelligence compared to ours. After all, Neanderthals had become extinct while we were still here, on the surface of the planet. Little by little, however, it has been revealed that it was not necessarily so and that Neanderthals were not in any way stupid. They could even think symbolically. This week in the magazine \u201cScience Advances\u201d sheds light on the latter. This article was published by an international group of researchers, headed by Antonio Rodr\u00edguez-Hidalgo of the Institute of Evolution in Africa, Madrid, Spain, and it presents an analysis of a phalanx of the left leg of an eagle, which was recovered from the site known as Foradada Cave in Catalonia, Spain. This phalanx shows characteristic marks that were made to separate the claw from the eagle\u2019s leg, presumably for use as I said in a necklace. It is known that Neanderthals in Europe made use of eagle claws to make necklaces for use as ornaments. Rodr\u00edguez-Hidalgo\u2019s results and collaborators show, for the first time, that such symbolic behavior extended to the Iberian peninsula, which was the last reduct of Neanderthals in Europe before its extinction about 40,000 years ago. Rodr\u00edguez-Hidalgo\u2019s article and collaborators add evidence about the cognitive capacities of Neanderthals, particularly about their ability to think in shape. That position, on the other hand, has been improving to the extent that increasingly sophisticated techniques have been developed to study the past. Thus, we know now that we have a common ancestor with Neanderthals, and that they lived with our ancestors and even crossed and produced fertile descendants, so that Neanderthal genes are among us. We also know that they buried their dead and produced works of art. Had all this been known, 19th-century Europeans would surely have clashed. After all, even for specialists it was difficult to get rid of the racial prejudices of a time in which Europe dominated the world. So, if for a 19th-century European the superiority of the white race over the other races of the world was obvious, it was unthinkable that a different species - which no different race - would have been able to cast any shadow over them.",
    "https://upload.wikimedia.org/wikipedia/commons/5/5b/2018_Nissan_Leaf_Tekna_Front.jpg": "An article published this week in the magazine \u201cScience\u201d, published by George Crabtree of the National Laboratory of Argonne and the University of Illinois in Chicago, gives us a perspective of the penetration of electric cars and of the technological problems that would have to be solved so that the replacement of gasoline or diesel vehicles by electric vehicles will be in full. According to figures quoted by Crabtree, some countries are taking aggressive measures to achieve this in the short-medium term. Thus, by 2025 100% of cars in Norway will be electric or hybrid, while in that same year Holland will ban gasoline or diesel cars and the same thing Germany will do in 2030. A little later, in 2040, France and England plan to stop selling gasoline and diesel cars. China, on the other hand, is the largest consumer of electric cars in the world. It owns almost half of the cars of this global type, with 1.1 million units sold in its territory in 2018. By comparison, the United States and Europe, each of them have about 20% of the total vehicles. One of the virtues of electric automobiles is to contribute to reducing greenhouse gas emissions by burning fossil fuels, given that transport makes use of more than 25% of the energy consumed in the world. This, of course, will happen if the electric energy to drive the electric cars of the future is obtained from non-polluting sources. That is, from sources such as solar, wind, nuclear or hydroelectric, among others. While, assuming the latter, the reduction of greenhouse gases is one of the advantages that electric cars will have, their emergence, as Crabtree points out, will also have geoeconomic consequences. In other words, the regions where fossil fuels are concentrated will lose relevance, given that the sun and wind, two of the supposed sources of energy that will move electric cars of the future, are more democratically distributed throughout the world. The future technological developments of this battery will determine the course of the electric vehicle industry. These developments will determine the cost of the electric car, its recharge time, the autonomy between recharges, its life time and its level of safety. As for the cost of an electric car, including its acquisition, maintenance, fuel and insurance costs, this is, according to Crabtree, substantially lower than that of the petrol car for intensive vehicles, as is the case with a taxi or rental car with a travel of 100,000 kilometres per year. For a private car, the cost of purchasing and operating an electric car is about twice as high as that of a petrol car. It is estimated that both costs would be matched at some point between the years 2022 and 2026.In the previous context, it would be expected that public transport by car in urban centres will be the first to be converted into electric for economic reasons. . When this happens, the transformation from gasoline to electricity will be driven by economic reasons rather than by environmental considerations of reducing atmospheric pollutants. And ultimately, according to Crabtree, by the development of the technology of lithium batteries. In the context described above, it would not be difficult to predict that in a few years, as the technology of lithium batteries further develops, we will witness the replacement of gasoline cars with electric cars. We would have advantages with this conversion. For example, urban pollution would be reduced by the emission of pollutants resulting from the operation of gasoline vehicles. Also, presumably, the cost of automobiles, as well as of their operation and maintenance will be reduced. But, on the other hand, the number of cars in our crowded streets and avenues could be increased. And this would not seem to be able to bear it. Neither the streets nor us.",
    "https://upload.wikimedia.org/wikipedia/commons/0/04/Phosphorescent_pigments_1_min.jpg": "The Nobel Prize in Physics 2014 was awarded to Japanese researchers Shuji Nakamura, Isamu Akasaki and Hiroshi Amano for having invented a compact light source \u2013 or LEDs \u2013 of blue color. What was the relevance of a LED of this color that deserved its developers a Nobel perm? This question is valid, given that before the appearance of blue LEDs there were already LEDs of red light \u2013 as well as LEDs of green light, although not so efficient \u2013 whose inventors did not receive the same distinction. It turns out that although the blue color might not be more relevant than red for us humans \u2013 given that our eyes are sensitive to both colors \u2013 blue LEDs unlike reds can be used to make white LEDs. These are compact and efficient light sources, which have caused a revolution in the field of artificial lighting, and are gradually replacing the old and inefficient incandescent spotlights, as well as the fluorescent lamps, more efficient but polluting in the environment by the mercury they contain. As with other developments such as the transistor or compact lasers that were both Nobel laureates' motive \u2013 they certainly have numerous advantages and have had a massive impact on our daily lives. At the same time, however, they have disadvantages. Indeed, there is concern among specialists about possible health damage that they might cause, including damage to the retina and the affectation to our sleep patterns and to the circadian rhythm that regulates us. To put this last into perspective, some details should be considered regarding the technology of white LEDs. These devices are made up of a blue LED coated with a phosphorescent material that emits yellow radiation in response to the excitation of the blue light of LED. LED emits thus a combination of blue and yellow light that gives it a white light appearance. The blue light content emitted by typical white LEDs, however, is too large compared to sunlight - under which we have evolved as a species - and this is what specialists have found to be harmful to our health. ging and Mechanisms of Disease\u201d published by a team of researchers led by Trevor Nash of the University of Oregon, finds that specimens of fruit fly exposed to blue light suffer a substantial reduction in their life time compared to flies maintained in the dark, or under white light from which the blue component was removed. During their study, Nash and collaborators exposed a group of flies to a 12-hour regime under blue light and 12 hours in darkness, resulting in damage to the retinal cells, a neuronal degeneration and damage to the fly locomotion system, which affected their ability to climb walls. Nash\u2019s results and collaborators are certainly bad news as they point to the possibility that the neural damage and shortening of life observed in fruit flies may also occur with humans, who are continually exposed to the blue light generated by both LED lamps for night lighting, such as phones, electronic tablets and computer screens. White LEDs have actually been among us only for one reason. In this context, more research is needed to confirm - or refute - the results of Nash and collaborators, as well as the results of other researchers who, likewise, point to the harmful effects of blue light. Soon and as long as we find out that the blue threat is so real, we could perhaps take some precautions. For example, we could make ourselves some glasses with amber crystals that filter blue light and use them at night. We would lose some light, but instead we would be perhaps safe from danger. And as for devices such as phones, electronic tablets and computer screens, these can be adjusted to mitigate the emission of blue light. Thus, the situation would not be so desperate and we would not have to resort to extreme measures such as giving up night lighting and returning to times already overcome in which darkness reigned at night. Without losing sight, of course, that the danger may be real and that it is best for us to find out as soon as possible.",
    "https://upload.wikimedia.org/wikipedia/commons/c/c3/NGC_4414_%28NASA-med%29.jpg": "On February 17, 1600, Giordano Bruno was burned alive in Campo de Flores Square in Rome after the Roman inquisition condemned him for heresy. Although it was not the main reason for his conviction, Bruno was accused of holding that the universe is infinite and that every star we see in the sky is actually a sun like ours, with planets orbiting around him. On October 31, 1995, 365 years after his execution, we knew with certainty that, with respect to this last point, Bruno had full reason. We knew this day that the magazine \u201cNature\u201d accepted the article submitted by Michel Mayor and Didier Queloz of the University of Geneva, Switzerland, in which they reported the discovery of a planet outside our solar system, orbiting around a star similar to our sun. That planet, and more properly, exoplanet, was later baptized as Dimidio.Dimidio is located at a distance of approximately 50 light years from the Earth - a light year is the distance passing through the light in one year - and is similar in composition to the planet Jupiter. . In contrast to Jupiter, however, Dimidius orbits his star at a considerably lower distance and this makes his temperature above 5,000 degrees Celsius. Dimidius\u2019 discovery gained relevance this week when Major and Queloz were awarded the Nobel Prize in Physics for having carried it out. The impact that this discovery has had on our knowledge of the universe has been very great, and as a result of it more than 4,000 exoplanets have been discovered spinning around stars in our galaxy. We know that when Galileo pointed his telescope towards Jupiter \u2013 which looks like a bright spot at a glance \u2013 he could observe a disk with four luminous points around it \u2013 the four Galilean satellites. Either of us with a relatively simple telescope can repeat the experience of Galileo. If, on the other hand, we turn our telescope towards a star, we will continue to see a bright spot. Obviously, this is because the stars are vastly larger than the distances to which the planets are located. Dimidium, for example, is almost a million times farther away than Jupiter\u2019s Earth in its own. In these conditions, it is not difficult to conclude that it must be tremendously difficult to discover an exoplanet orbiting a star, which has a huge size compared to the size of the planet to detect. Moreover, since there is no light of its own, the brightness of the exoplanet is much smaller and this makes it difficult to distinguish it from the star. With all these difficulties, how do astronomers manage to discover exoplanets? One way to do so is by measuring the intensity of the light emitted by the star, bearing in mind that when the exoplanet is placed in front of the star it blocks a tiny part of the light it emits. Thus, if its measurements of light intensity are sufficiently precise, astronomers will be able to detect small periodic variations in the brightness of the star that will reveal the presence of an exoplanet orbiting around it.Another way to detect an exoplanet -which was used by Mayor and Queloz- makes use of the so-called Doppler effect. This effect is the one that produces the change in the siren tone of an ambulance when it crosses in front of us. We know, that tone is more serious when the ambulance moves away at great speed than when it approaches.A similar effect occurs when we look at the light that emits an object when an object moves away or approaches.In this case the changes are observed in the color of the emitted light, which is bluer for the object that approaches it compared to the one that moves away.To discover an exoplanet by means of the Doppler effect astronomers make use of the swinging forward and backward that a star suffers when a planet turns around it and that makes it approach and move away from us over and over again.A measurement of the periodic changes in the color of the light emitted by the star will then reveal the presence of an exoplanet. Such changes, of course, are extremely small, so that astronomers must use measuring instruments with great sensitivity. Given all these impressive results, what could we expect for the future? Among other things, that an accelerated pace of discovery of new exoplanets, including Earth-like ones with suitable conditions for the emergence of life, is maintained. The latter, given the immense amount of exoplanets in our galaxy and the continuous advancement in detection techniques, will surely be achieved sooner rather than later. And with this, Giordano Bruno\u2019s vision of an infinite and uniform universe will come true with all its consequences.",
    "https://upload.wikimedia.org/wikipedia/commons/f/f8/ESPA%C3%91OL_Carbon_cycle.jpg": "When climate activist Greta Thurnberg, 16, crossed unscheduledly with Donald Trump on September 23 during the UN climate summit, she gave a gun-eyed look that was widely disseminated by international media. Certainly, manipulated or not, the Swedish teenager did not lack reasons to be resented by the US president, who in 2017 withdrew the United States from the Paris climate agreement that negotiated 195 countries to limit the emission of greenhouse gases into the atmosphere. In fact, during her intervention at the summit, Greta Thurnberg had made a strong appeal - acted, according to some - to world leaders for her inaction to combat climate change to the detriment of future generations.On the other hand, while the Swedish activist's speech has generated conflicting reactions - including negative criticisms from presidents Trump and Putin - it is difficult to refute her claims about the severity of the ongoing climate change. One way to appreciate such gravity is as follows. Climate change is attributed primarily to the increasing emission of carbon dioxide into the atmosphere by the U. This emission has disrupted the so-called carbon cycle that regulates the concentration of this chemical element on the surface of our planet. As an article published this week in the journal \u201cElements\u201d, published by a group of researchers headed by Celina Su\u00e1rez of the University of Arkansas, carbon exists on the surface and inside of the Earth in various forms -combined, for example, with oxygen to form carbon dioxide. On the surface of the Earth, carbon dioxide is captured by plants and algae to make organic matter through the photosynthesis process. This organic matter is ingested by animals that, when they die and are buried, cause the growth of new plants. Thus, the biological cycle of carbon is closed. There is also a geological carbon cycle through which this chemical element is exchanged between the surface of the Earth and its interior. Thus, carbon in the form of carbon dioxide is emitted to the atmosphere during volcanic eruptions and returned to the interior of the Earth through various processes, including its capture by plants through the photosynthesis process, its in terrament at death, and its transfer to great depths by geological processes. Carbon can be returned equally to the interior of the Earth by its chemical incorporation into surface rocks, which are later buried -in a geological scale of time - at great depths. Thus, the amount of carbon on the surface of the Earth, and therefore its concentration in the atmosphere, is determined by a balance between the surface carbon that is captured by some mechanism and sent to the interior of the Earth, and that is released from that interior to the surface. At present, this balance has been disturbed by the extraction of carbon in the form of fossil fuels and its dispersion in the atmosphere in the form of carbon dioxide. The crucial point is, of course, the relevance of this disturbance in comparison with the natural mechanisms of dispersion of this pollutant in the atmosphere. Suarez and collaborators, in the above mentioned article illustrate us in this regard: carbon dioxide emissions to the atmosphere by burning fossil fuels are forty to one hundred times larger than emissions due to the processes of vulcanism. This, certainly, refutes those who still argue in this article: that the gradual increase in the concentration of greenhouse gases in our atmosphere is due to natural causes. Suarez and collaborators also point out that four of the five largest mass extinctions of species that have occurred in the history of the Earth are associated with major disturbances of the carbon cycle. The most famous of these disturbances is the one that occurred 66 million years ago by the meteorite that crashed near Chicxulub on the coast of Yucat\u00e1n and that led to the extinction of dinosaurs.Today, the amounts of carbon dioxide that we are emitting to the atmosphere by burning fossil fuels are far from those due to disasters such as Chicxulub. Such emissions, however, are gradually growing and at this time are already far superior to those due to natural causes, which is undoubtedly cause for concern.In these conditions it is difficult to understand those who criticize the performance of Greta Thurnberg. Among other things because she is too young and because of the suspicion that she may be manipulated by dark interests; but also because of the emphasis with which she gave her speech at the climate summit of the In any case, the messenger would be disqualified, but hardly his message.",
    "https://upload.wikimedia.org/wikipedia/commons/e/e2/Jupiter.jpg": "If you are interested in travelling to space, NASA offers to take you as a tourist to the international space station for $58 million. It is necessary to clarify that this cost is only for transportation and does not cover the accommodation costs, which are about $35,000 per night. Thus, if you plan a 30-day stay in space add a million dollars to the cost of transportation.Unfortunately for many of us, with these costs the space travel is out of any possibility. We would expect that in the future that cost will be reduced and the group of those who could cover it will grow, at the same time the space tourist destinations, the Moon and other places in our solar system will expand. If this were to happen, what would be the favorite destinations? At the outset, we would safely rule out Mercury and Venus - the two planets closest to the Sun - whose temperatures on their surface are far from welcoming. In the case of Mercury they oscillat between 430 centigrade degrees and less 180 centigrade degrees, while the surface temperature of Venus is around 500 centigrade. Mars, ours. The photographs that have brought us the NASA probes that have been located on its surface show us a dry and dusty place, but that reminds us of some places of our planet; the Atacama desert in the north of Chile, for example. However, we should consider that on Mars the temperature of its surface varies by more than 100 degrees centigrade between day and night. Another drawback is that the Martian atmosphere, besides being dim, is mainly composed of carbon dioxide and therefore there would be no way to breathe it. And one more is that the surface of Mars is continuously bombarded by dangerous high-energy radiations that arrive from space. Thus, it would be necessary to take with the reservations of the case the photographs of NASA that show a relatively friendly planet, but that in reality is inhospitable to a great extent.The outer planets, gas giants, Jupiter, Saturn, Urano and Neptune, may not necessarily be entirely attractive for a tourist visit. Titan, for example, Saturn\u2019s largest satellite, is fascinating for many reasons. It is, for example, the only body of the Solar System, apart from the Earth, where there are seas, lakes and rivers of liquids that evaporate, condensate and precipitate in the form of rain. Moreover, in contrast to our planet, these liquids are methane and not water. The latter is due to the fact that at the temperature of Titan\u2019s surface -minus 180 degrees centigrade - water is frozen, while methane, which is a gas on Earth, is in liquid form. We do not know much about Titan because of its hazy atmosphere that hides the details of its surface. In January 2005, the European Space Agency\u2019s Hyugens probe descended towards Titan and lay gently on its surface. At about 70 kilometres high, the cameras of the probe were able to see through the thick mist, observing a landscape with ice mountains, a system of canals through which apparently flows rivers of methane, and what is supposedly the dry bed of a fog. So, Titan turns out to be a fascinating world, with many similarities to ours, and in which the role of water has methane. In fact, it is possible that it is the most interesting place to visit within the Solar System and possibly would be a favorite place for the hypothetical tourists of the future -as much as its ambient temperature is significantly lower than that to which we are accustomed. We do not know, of course, whether space technology will ever allow for tourist trips to such remote places as Titan. In any case, for the time being, we will have to settle for exploring this exotic satellite by other means. For this purpose, NASA plans to send the \u201cDragonfly\u201d mission to Titan in 2026, same as it will arrive at its destination in 2034. In addition, NASA has just announced a robot development project to explore Titan. That robot, which has been baptized \u201cShapeshifter\u201d, will have the ability to adopt various forms as a function of lake. In this way, \u201cShapeshifter\u201d will be able to roll, swim and even split into two halves, each of which will be able to fly in the style of a drone. NASA intends to send Titan not one but a group of \u201cShapeshifter\u201d robots, which will be able to act on their own, or operate in a coordinated and autonomous manner to perform a common task. For space exploration, given the difficulties and dangers it entails, the rational strategy to continue goes through the use of automatic probes as opposed to manned travel. The tourist, however, has his own non-utilitarian logic and, given the favourable conditions, might perhaps be willing to pay $59 million \u2013 or whatever it takes \u2013 to visit an exotic world outside our planet, despite the risks that this would entail. Fortunately, for the vast majority of us there would be no chance of taking any risk. But possibly to meet Titan and other worlds through remote probes.",
    "https://upload.wikimedia.org/wikipedia/commons/6/6f/Brillanten.jpg": "An unusual exhibition was opened on September 13 at the New York Stock Exchange with the title \u201cRedemption of Vanity\u201d. The exhibition features a 16.78 carat diamond (slightly over three grams of weight) with a spectacular yellow colour and a value of 2 million dollars. The exhibition is unusual, not so much because of the spectacularness of the exposed stone, but because of the coating that was applied to it and for which it lost its color. In fact, it lost it completely, because the diamond looks at the exhibition with a deep black color never seen before. But let's go in parts. We know that in some cases we can see objects by the light they emit, as with the Sun or the lamps for night lighting. We also know that most of the cases the objects do not emit light of their own and that, however, we can see them by the light that they reflect. Thus, the objects look red or green because it is fundamentally red or green the light that they reflect. White objects, instead, do not show preferences and reflect all colors equally. Black objects reflect very little of the light. A perfectly black object does not reflect light at all and one can wonder what it would look like. It is not difficult to come to a conclusion. Let us think, for example, of the mouth of a deep cave through which light penetrates that hardly comes out again, and that consequently we can think of it as a perfectly black virtual object. A real black object would then look like the mouth of a deep cave; that is, like a black and flat shadow defined by the silhouette of the object in question, without the slightest indication of its profile in depth. There are, of course, perfectly black objects and all reflect light to a greater or lesser extent. However, coatings have been developed that, applied to an object, make it look like a deep black, not far from perfection. One of these coatings was applied to the diamond displayed in the New York Stock Exchange. This coating is made up of a carbon nanotubes forest that traps the light it receives, in the same way it does a deep cave. The layer of carbon nanotubes absorbs 99.995 % of carbon. The display is part of a collaborative project between Brian Wardle, professor of aeronautics and astronautics at the Massachusetts Institute of Technology, and the artist Diemut Strebe. It can be consulted by typing in Google \u201cThe Redemption of Vanity\u201d. The artist plays with several concepts in the exhibition. In particular, he notes that both the diamond and the nanotubes of the coating are formed from the same chemical elements; that is, carbon atoms. The contrasting visual aspect presented by both types of materials is due to the way in which carbon atoms are ordered inside. Thus, a diamond, a highly luminous object with a high commercial value, can be destroyed and its brightness brought to zero by a nanotubes \u201cforest\u201d with the same constituent chemical elements. On the project website you can read: \u201cThe project explores the material values and its luminosity brought to zero by a nanotubes \u201cforest\u201d with the same constituent chemical elements. We are presenting the literal devaluation of a diamond, which is highly symbolic and of a high economic value. We are presenting a challenge to the mechanisms of the art market, at the same time that questions are expressed about the value of art in a broad context. Thus, we are inquiring about the meaning of the value of art objects and the art market.\u201d The carbon nanotube coating used to make the diamond \u201cdisappear\u201d was developed by Kehan Cui and Brian Wardle at the Massachusetts Institute of Technology and reported this week in the magazine \u201cACS Applied Materials and Interfaces.\u201d Cui and Wardle\u2019s research was not intended to develop an ultra-black coating for diamonds, but to make layers of nanotubes of carbon on a plate of an electric conductor such as aluminum. Once reached its goal, however, Cui and Wardle realized that, in addition to fulfilling the physical properties they sought, the layers of nanotubes of carbon developed were ten times. This opened up the possibility of developing collaboration between science, technology and art deployed on the New York Stock Exchange. It is not clear whether the diamond coated with carbon nanotubes can be restored to its original condition and its recovered value, or whether its destruction as a conventional diamond is permanent. If this is the case, it will maintain a commercial value as a \u201cinvisible\u201d diamond that may not be negligible. Apart from these considerations, the project has public relations benefits for the researchers who developed the coating, as well as for the artist who conceived the project. And surely for the house that provided the brown diamond.",
    "https://upload.wikimedia.org/wikipedia/commons/a/ae/Amarna_Akkadian_letter.png": "About five thousand years ago, a culture flourished in the region of the Indo River Valley, in the present-day Pakistan, northern India and southern Afghanistan, contemporary of the cultures of Mesopotamia and ancient Egypt, which was remarkably advanced for its time. With regard to the latter, archaeologists know that their cities were the subject of careful urban planning and had straight streets forming a rectangular mesh, as well as a drainage system and barns for the storage of crops. They even had a public bath. On the other hand, the houses, enjoyed private bathroom and drainage connected to the public network, as personal hygiene would have been an important part of daily life. Likewise, for commercial exchange purposes, the Indo Valley civilization developed a standardized system of weights and measurements. And despite all of the above, experts know relatively little about that civilization. This is partly explained by the fact that it has not been possible to decipher its writing. As we know, the Egyptian hieroglyphics were deciphered thanks to the Rosetta stone -found in 17th century. 99 near Alexandria during the expedition of Napoleon in Egypt- containing a text in three distinct structures: hieroglyphics, demotic and ancient Greek. Comparing texts written in Egyptian and Greek allowed Champollion to decipher Egyptian writing. A similar and equally fortunate situation allowed deciphering the cuneiform writing of Mesopotamia. In the case of the civilization of the Indus Valley, experts have not been lucky enough to find a text written in the languages, one of them known, that would allow deciphering the writing of the civilization of the Indus Valley and to know more about it. Despite the little fortune, experts have succeeded in another direction: an article appeared this week in the magazine Cell sheds light on a particular aspect of the civilization of the Indus Valley, specifically on the genetic composition of its members. This article was published by an international group of researchers headed by Vasan Shinde of the College of Graduates and Research Institute of Deccan, in Pune, India, and Vagheesh Narasinham, Harvard Medical School, Boston, United States In that article, Shinde and collaborators report the results of a genetic analysis done on the remains of an individual, possibly female, recovered from a tomb in northern India with an age of about five thousand years. Initially, the researchers tried to determine the DNA of 61 bone remains, but the time elapsed since his burial and the conditions of the ground only allowed to recover the DNA of one of them.The DNA that could be recovered turned out to be a mixture of ancient Iranian DNA -previous to the appearance of agriculture ten thousand years ago- and DNA of hunter-gatherers of Southeast Asia.The recovered DNA also shows coincidences with that of the current inhabitants of Southeast Asia, indicating, according to the researchers, that these latter are direct descendants of the former inhabitants of the Indo Valley.On the other hand, Shinde and collaborators conclude that there is no close genetic relationship between the individual unearthed in the Indo Valley and his then-farmers of Iran, which would prove that agriculture in that valley was not developed by large populations of immigrants who arrived from the west. explained: either agriculture developed in the Indus valley independently of Mesopotamia, or was developed by travelers who visited Mesopotamia and knew agriculture, then returning to the Indus valley to put it into practice. However, as is common with a scientific result - and especially if it is with respect to something that happened thousands of years ago, as is the case - there are those who are cautious and consider that Shinde and collaborators' conclusions should be taken as provisional. This, because they are based on the DNA analysis of a single individual, which could be non-representative of the population in general. Thus, it would be necessary that such concussions be validated with additional studies. In so far as this happens, it is interesting to speculate whether agriculture would have appeared at a single point on the planet and from there would have been expanded by the migration of farmers to other parts of the world, or although it was a phenomenon that occurred independently in several places. On the one hand, agriculture has existed only for a small period of time since our species appeared, which is measured in hundreds of thousands of thousands. It is also true that it is not uncommon for a scientific discovery to have been made by more than one scientist independently.What if it is not speculation is that, five thousand years ago, there was a surprisingly advanced civilization, with large cities, with streets, pipes and public baths, and with inhabitants concerned about their personal hygiene. And this is certainly fascinating.",
    "https://upload.wikimedia.org/wikipedia/commons/b/b6/Australopithecus_afarensis_%28%E2%80%9ELucy%29_Rekonstruktion.jpg": "The scientific news of the week was undoubtedly the publication in the journal \u201cNature\u201d of two coordinated articles in which the discovery of a fossil skull, almost complete, of a bipedal primate with an age of 3.8 million years is reported. This skull, called in an unattractive way MRD\u2014VP-1/1, corresponds to the species \u201cAustralopithecus anamensis\u201d, which is the oldest of the genus australopitecus and which preceded the species \u201cAustralopithecus afarensis\u201d. The latter is the species of the famous fossil known as Lucy, discovered in Ethiopia in 1974 and which has an age of 3.2 million years. One of the articles, in which the discovery itself is reported, was published by an international group of researchers headed by Yohannes Haile-Selassie of the Cleveland Museum of Natural History, in Cleveland, Ohio, and Stephanie Melillo of the Max Planck Institute for Evolutionary Anthropology in Leipzig, Germany. The second article reports the techniques used to date the skull of the week. And it was also published by an international group of researchers, led by Beverly Saylor of Case Western Reserve University in Cleveland, Ohio. Haile-Selassie's discovery and collaborators provoked great enthusiasm among specialists as it helps to clarify details of the evolution of the biped primates of the genus Austrolopitecus, particularly about the transition between the species \u201cA. anamensis\u201d and \u201cA. afarensis\u201d. As we know, the genus australopitecus gave origin to the genus homo to which our species belongs some two million years ago, so that its evolution is part of our evolution. According to some opinions, a linear evolution would have occurred according to which the species \u201cA. afarensis\u201d emerged from the \u201cA. anamensis\u201d, at the same time that it became extinct. Fossils discovered by Haile-Selassie and collaborators, however, indicate that both would have coexisted for at least 100,000 years. Evolution would have thus produced two branches, one of which ended by extinction. The discovery of Haile-Selassie and collaborators of the skull with 3.8 million years of age allows us to reconstruct the aspect that had a very distant predecessor of ours, which did not belong to the homo genre, did not handle tools and had a brain the size of a chimpanzee, but that was already walking in an upright position. In fact, an artistic reconstruction of the aspect that would have had in life MRD\u2014VP-1/1/1 can, for example, be found in this week\u2019s issue of the magazine \u201cScience\u201d. On the other hand, while it is possible to know with some precision the aspect that the \u201cA. anamensis\u201d would have had, other details of his life are not so easy to deduce. This is not surprising, of course, given the enormous temporal distance that separates us from this species and the few fossils that we do not have to study it. We know, however, that it did exist, in a remote past, and that in one way or another is our predecessor. This last is difficult to cast doubt today, which until very little time ago we do. So, there was someone who argued that our species somehow occupied a special place in the world, and to argue that we are descendants of a species with an ape aspect and a brain the size of a chimpanzee would have been complicated. The loss of our supposed privileged position among the other species of the world - by the advance of paleontological knowledge - somehow evokes the loss of our supposed privileged position as the center of the universe that occurred in the sixteenth and seventeenth centuries, when, by advances in astronomy, it became clear that the world is better explained if we consider that it is the Sun and not the Earth the celestial body around which planets revolve, including ours. Thus, to deny the evidence that fossilized living beings give us in remote times, in order instead to maintain that we occupy a privileged position among the other living beings, complicates in too much that we can elaborate a rational explanation of the world.In the future, to the extent that paleontology and all the analytical techniques of which are aided, and that more fossil remains are discovered, we can expect to develop a rational explanation of the world. that we will have a clearer view of what happened in the remote past as to the evolution of living species. For the time being, we settle for the wonderful MRD\u2014VP-1/1 skull and the fabulous image of the remote past that transmits us. Which is not little, despite the little sexy name that someone decided to impose on it.",
    "https://upload.wikimedia.org/wikipedia/commons/e/ed/Vern%C3%BCnftige_und_Christliche_Gedancken_%C3%BCber_die_Vampirs_-_001.jpg": "In what would well happen as a story of terror, about two hundred years ago an unidentified group of people exhumed John Barber's body several years after his death, cut his head off and opened his chest, possibly with the intention of extracting his heart. Done this, they returned him to his grave, not without first placing his skull on his chest together with the femurs on the cross, in the style of pirate symbols. All this happened in the village of Griswold in the state of Connecticut in the United States. Why would someone have done something so macabre? When in 2012 archaeologist Nicholas Bellantoni explored John Barber's tomb, he found no explanation. Soon, however, a plausible hypothesis was ventured: it was possibly an episode of vampireism, which at that time - the beginning of the 19th century - was not unusual in some areas of New England. At that time, however, no firm conclusion was reached and the mystery remained unresolved.Recently, with better techniques of DNA analysis and using the use of DNA analysis. On the one hand, he managed to identify John Barber as the owner of the reference tomb and, on the other hand, he concluded that the desecration of Barber\u2019s tomb was indeed intended to remove him from this world because he was considered a vampire. According to an article signed by Michael Ruane in The Washington Post, the results of the new investigation were presented on 23 July at the National Museum of Health and Medicine in Silver Spring, Maryland. But let\u2019s go about it. During the 18th and 19th centuries, there was a terrible tuberculosis epidemic in New England, so serious that around 1800 it would have been responsible for 25% of deaths in the east of the United States. As there was no effective treatment to cure it, a diagnosis of tuberculosis was equivalent to a death sentence. As tuberculosis progressed, patients were underweight and seemed to be consumed, and in fact, the disease was known at that time as a conunction. They also suffered, among other symptoms, from severe cough attacks. It should be noted that the bacillus of Koch causing tuberculosis was discovered until the end of the 19th century, while the antibiotics necessary to cure it did not develop until the decade of the forties of the next century. In these conditions, without a rational explanation of the origin of the disease, the inhabitants of New England resorted to the theory of vampireism, according to which the consunction was the product of some already deceased from the disease and that they were not really at all. These semi-dead or vampires stole their life force from their victims until they were consumed. When it was suspected that someone already dead would have become vampire, the procedure to remedy the situation was to remove them from their grave and observe if there were signs of life, such as the presence of fresh blood in their heart. If such a thing happened, they would have to remove their heart and burn them. The victims of a vampire were their own relatives, so that the procedure of exhuming the corpse in search of signs of vampireism was carried out by a member of the family.Returning to the case of John Barber, and according to this scenario, Griswold's neighbors would have suspected that he was a vampire, and the desecration of his grave would have had the purpose of ascertaining with certainty.According to the evidence, the neighbors would have found positive evidence in this regard and proceeded accordingly.Very probably, however, Griswold's neighbors were wrong about the tail and John Barber was not a vampire, but probably a field worker judging by the arthritis he suffered.He would probably have died, yes, of tuberculosis, as revealed by the terrible injuries he presents in the ribs.And most importantly, the skull lacks all front teeth, which definitely disqualifies him as a vampire -at least according to the modern standards imposed by Hollywood.The flourishing of vampires occurred in the 18th and 19th centuries when science, as we know it today, took strength to, with the modern standards imposed by Hollywood. Both developments can be seen as two processes, one rational and the other irrational, moving in parallel and thus opposing one another. Of course, Griswold\u2019s neighbors had no information that this was happening and could not be blamed in any way. On the other hand, putting ourselves in place, it would have had to have been terrifying to deal with a disease as terrible as tuberculosis without too many weapons to fight it. Vampireism provided them with a certain theoretical basis to try to understand it. Unfortunately, without too much success to judge by the results.",
    "https://upload.wikimedia.org/wikipedia/commons/9/9f/Pinatubo_Crater_Lake_%28052005%29.jpg": "Let us imagine on a hot summer day - of which there is more and more, because of the well-known phenomenon of global warming - in a room with large closed windows through which abundant solar radiation enters. It is possible, unless such a room has an artificial climate, that the temperature inside reaches too high a value for our comfort. The physical phenomenon by which this happens - called the greenhouse effect - is well known and in simplified terms explained as follows. Since the windows are transparent, they allow the passage of the solar rays into the room, where they are absorbed by the walls and other objects that they find in their passage. This results in an increase in the temperature, both of these objects and of the room itself. On the other hand, it is a well-known physical fact that any object, by the mere fact of being at a certain temperature, emits infrared radiation and with this tends to cool. The intensity of the radiation emitted, moreover, is greater as the temperature is higher. Thus, the temperature that reaches the room is reached by a balance between the solar energy that enters the windows and that tends to cool. It happens, however, that the glass of the windows is not transparent to the infrared radiation emitted by the objects and this one cannot leave the room. The temperature of the room then tends to rise. Otherwise, we certainly do not need to have a deep knowledge of the physical phenomena that cause the greenhouse effect to remedy our uncomfortable situation inside the room with the windows closed in the middle of the hot summer. Thus, one resource at our fingertips is to open the windows so that in this way the infrared radiation can escape, at the same time that the air of the room is exchanged with the air from the outside. Suppose, however, that the windows are sealed and it is not possible to open them. In this case, an alternative solution - albeit less effective than the previous one - is to lower the blinds and thus block the entrance of the solar radiation into the room.It is valid to introduce the concept of solar geoengineering, which is the topic of this article and which emerged as a possibility to mitigate the effects of global warming that occur to the planet. We know that the increasing emission of greenhouse gases is generating a gradual increase in the temperature of the Earth\u2019s surface by the accumulation of such gases in the atmosphere. The mechanism by which this increase occurs is analogous to the greenhouse effect in our room with closed windows. In the case of global warming, the room corresponds to our planet, while the glass of the windows constitutes greenhouse gases in the atmosphere. These gases allow the passage of solar radiation and block the infrared radiation emitted by the surface of the Earth, which would otherwise be lost in space. The sustained increase in the concentration of greenhouse gases has made such a blockade increasingly pronounced, and this has led to a gradual increase in the temperature of the Earth\u2019s surface. The most natural solution to remedy global warming is, of course, to stop emitting or reducing the emission of greenhouse gases into the atmosphere. As this is not feasible in the medium term, however, it has been thought of alternative solutions. As for these, it is not possible to \u201copen windows\u201d and let the infrared radiation emitted by the surface of the atmosphere. The Earth dissipates in space. On the other hand, it is possible to \u201cdrop the blinds\u201d to reduce the entry of solar radiation into our planet and this is what solar geoengineering poses. An alternative posed by solar geoengineering is to disperse gases or particles that reflect part of the solar radiation into the upper layers of the atmosphere and thus limit their entry to the surface of the Earth. It is known that this is possible by some volcanic eruptions that have thrown into the atmosphere large volumes of particles that have remained in the air for a couple of years and that have changed the Earth\u2019s climate. One of these eruptions was that of the Pinatubo volcano in the Philippines, which in June 1991 threw into the atmosphere large amounts of sulphur dioxide that produced, by the end of 1992, a global reduction of temperature by 0.5 degrees centigrade. The proposals of solar geoengineering, however, are highly controversial. On the one hand, the planet\u2019s climate is such a complex system that at the moment it is not possible to safely anticipate what the possible collateral effects of attempting to modify the climate at the global level. On the other hand, computer studies agree that placing a reflective layer of solar radiation in the atmosphere would lead to a reduction in rainfall and consequently to a reduced availability of drinking water globally. Likewise, it is anticipated that the ozone layer, agricultural production would be affected and the acidification of the oceans would increase. However, and in the midst of the controversy, some are seriously considering solar geoengineering, if not as the solution to climate change, as a palliative for it. Although it would be equivalent to taking slimming pills to continue eating as always. Without attacking the root of the problem, it is the increasing emission of greenhouse gases into the atmosphere.",
    "https://upload.wikimedia.org/wikipedia/commons/7/7a/Isotopes_and_half-life.PNG": "On 2 October 2017, an Italian laboratory, part of the network of European laboratories for the monitoring of radioactive isotopes, detected the presence of the Ruthenian-106 isotope in the atmosphere, although in concentrations that did not threaten the health of the Italian population. Later that same day, similar findings were reported by other laboratories in Austria, Norway and the Czech Republic, and in the following days in other European countries. Ruthenian-106 is a radioactive isotope that has a half-life of just over a year - which means that in this period its radioactive activity is reduced by half-. It occurs during the artificial disintegration of uranium-235 and its presence in the European atmosphere was an indication that somewhere - at those times unidentified - a considerable amount of that isotope had been released. It was ventured that the release of rutenium-106 could have occurred at the Russian nuclear facility in Mayak, located in the south of the Ural Mountains. This was denied by the Russian authorities on the basis that no high levels of contamination had been measured around the Mayak nuclear facility, located in the southern Ural Mountains. Instead, they suggested that radioactive contamination could be caused by the disintegration, by re-entry into the atmosphere, of a satellite equipped with a nuclear power generator based on rutenium-106. Due to insufficient data, however, the origin of the Ruthenium-106 cloud detected on the European skies, which remained in the mystery, was not conclusively established. Until now, if we are to believe an article published on 26 July in the United States journal \u201cProceedings of the National Academy of Sciences\u201d, which purports to have revealed it, this article was published by an international team of researchers led by Oliver Masson and Georg Steinhauser, of the Institute of Radioecology and Radiological Protection in France and Leibniz Hannover University in Germany, respectively. In their article, Masson and Steinhauser compiled information from the European monitoring network of radioactive isotopes and data banks of different origin, including banks of the Russian Federation. All this, in 330 sampling locations and covering a period of time from the end of September 2017 to the middle of October of the same year.On the basis of their analysis, Masson and collaborators, rule out that rutenium-106 contamination could have been caused by accidental mixing of radioactive material in a metal foundry. This has already happened on previous occasions, including the recalled case of cobalt-60 construction rod contamination that occurred in Mexico at the end of 1983. In the case of rutenium-106 contamination, researchers conclude, because the territorial extent of the phenomenon, the smelting of the radioactive material would have to have occurred in different locations simultaneously. Masson and collaborators also rule out that the radioactive cloud would come from the reentry of a satellite into the atmosphere, as the short break-up time of this isotope \u2013 a little more than a year \u2013 makes the construction of an energy generator based on ruthenium-106. In addition to the fact that the power that would be obtained would be very low. The results point to the Russian plant in Mayak as a possible source of contamination with rutonium-106. While the radioactive contamination that was observed in Europe at the end of 2017 was weak and had no consequences for the population, the attention it attracted is a measure of the dangerousness of nuclear radiation. In addition, since it was not a rare event - at the beginning of 2017 - it was detected, for example, another radioactive cloud, this one from iodine-131, on Europe. - is evidence of the relative ease with which a nuclear accident can occur. Even with serious consequences, as happened in Chernobyl, the Three Mile Island and Fukushima. Even so, it is sometimes presented to nuclear energy as a clean energy, which leaves no carbon footprint and therefore does not contribute to global warming. While this is true to some extent, the risk of contamination of the planet with high energy radiations incompatible with life, makes it difficult to label nuclear energy as \u201cclean\u201d in a strict sense. For this, it is certainly necessary to have a particularly wide sleeve.",
    "https://upload.wikimedia.org/wikipedia/commons/9/97/The_Earth_seen_from_Apollo_17.jpg": "According to statistics, almost one third of the world\u2019s inhabitants \u2013 more than two billion people \u2013 are addicted to video games. They are to such an extent that on average the time they spend on video games is about six hours a week, while for 7% it is more than 20 hours a week. Given the extent that the phenomenon of video games has reached, it is not surprising that it has affected us as a society in several ways. It has been found, for example, that the time a student spends on video games is inversely related to his or her grades at school \u2013 that is, the lower the playing time is the grades. Also, there are studies that have found that video game players with violent content develop a more aggressive behavior than those who play non-violent video games. Not all the impacts that have been documented from video games, however, are negative. Thus, those that require a quick reaction in response to a given signal or visual image, promote the development of faster reaction times in real-life situations. An article appeared this July in the magazine Creativity Research Journal documents another example in This article was published by a group of researchers from Iowa State University, headed by Douglas Gentile of the Department of Psychology of this university. In their article, Gentile and collaborators report the results of a study carried out to determine the effects that video games have on the creativity of players. Specifically, they compared the creativity of bachelor students who played video games \u201cMinecraft\u201d and \u201cNASCAR\u201d. Minecraft is an open game, of which 100 million copies have been sold, in which there is no goal determined to pursue, which is determined by the participant. In contrast, NASCAR is a video game of car racing in which vehicles always turn in the same direction. The demands in creativity for players are then considerably greater in Minecraft than in NASCAR. They also compared the creativity of students who were simply engaged in watching a television program during the experiment. To carry out the study, Gentile and collaborators recruited a group of 352 undergraduate students from Iowa State University, who were divided into the Two of these groups participated with Minecraft, while a third did it with NASCAR and a fourth passively watching TV. One of the groups that participated with Minecraft was given complete freedom to play, while the other was asked to do it creatively. Video games and the TV session lasted for 40 minutes. At the end of the experiment the creativity of the participants was evaluated using four criteria. They were asked, for example, as a test of divergent thinking, to give in two minutes as many different ways as they could use a knife, beyond their primary function as a cutting instrument. They were asked the same with regard to a clip to hold papers and a paper newspaper. As another proof of creativity, in this case convergent, students were given several groups of three words and asked, for each of the groups, to find a word that related to the three words that make it up. In addition, to measure their creative production, they were asked to draw a being that had developed in a world very different from ours. This case, creativity is greater as far as the morphological differences imagined with respect to us are greater.For example, one or more of two eyes, or certain bodily asymmetries.At the end of their research, Gentile and collaborators found that the creativity of those who played Minecraft was superior to the creativity of those who played NASCAR or only watched TV.This was something they expected.In contrast, they were surprised to find that the creativity of those who participated with Minecraft in a free way was superior to that of those who were asked to be creative, as they expected just the opposite.Gentile and collaborators speculated that this might be because the participants they were asked to be creative were less free to proceed in the way they had wanted and that this led to a certain degree of frustration that was prolonged until the time they did the creativity tests.Or that the effort to be creative during the game exhausted them so that they did not arrive in good shape at the final test session. . They suggest, however, that the result would indicate that creativity is promoted, not only by the type of video game, but by the way it is played.Like mobile phones and other high-tech devices, video games are signs of the time we have had to live and will surely remain around us permanently. Given the speed with which they have broken into our lives, it is not clear whether, in balance, their effects will be positive or negative. Time will tell us, but, for the time being, and as Gentile and collaborators point out, video games offer opportunities for education. Thus, they would be potentially positive elements. Everything is that we take advantage of them in the right way.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d2/Asklepios.3.jpg": "Although there have been substantial differences between rich and poor countries, thanks to antibiotics and in general to advances in the prevention, diagnosis and treatment of diseases, life expectancy has grown dramatically over the past century. In the future, we can expect this growth to continue, insofar as medical science progresses towards limits not yet determined. In this context, attention is drawn to an article published last June in the magazine Population and Development Review which reports the results of a study carried out to determine the evolution of life expectancy in the United States in recent decades, specifically in terms of the white population. This study indicates that the rate of growth in life expectancy of this segment of the American population has slowed down over the last three decades, and in some cases has even had a setback. The reference study was published by a group of specialists headed by Irma Elo of the University of Pennsylvania, and data from the National Centre for Health Statistics and the United States Population Census were used for the purposes of the study. The population was also divided into 10 groups with ages between 0-25 years old, 25-44 years old, 45-65 years old and over 65 years old. The population was also divided into 10 groups by their place of residence. Among these regions were considered rich areas such as New York and California, and depressed areas such as the Appalachians and the Midwest. The researchers also considered the urban or rural character of the population under study, disaggregating it into four categories: 1) major metropolitan area -more than one million inhabitants-, 2) suburb of a major metropolitan area, 3) minor metropolitan area and 4) rural area. In addition to the above mentioned disaggregations, Elo and collaborators present comparisons between the life expectations observed in the years 1990-1992 and the corresponding expectations for 2014-2016. Likewise, they present comparisons between the years 2009-2011 and 2014-2016. In the first case, changes in life expectations over 14 years are evaluated, while in the second case, these changes are evaluated in a shorter period -5 years- and more recent. By comparing the years 1990-1992 with the years 2014-2016, Elo and collaborators The population of the greater metropolitan areas increased their life expectancy by 5.09 years, while the inhabitants of the rural areas did so for only 2.25 years. The population of the suburbs or of the smaller metropolitan areas increased their life expectancy by 3.45 and 2.81 years respectively. These figures contrast with those of the female population who increased their life expectancy by 2.98 years in the larger metropolitan areas, and only by 0.2 years in the rural areas. Thus, a first conclusion of the study by Elo and collaborators is that the life expectancy gap between men and women -who live considerably more than men - is closing rapidly. On the other hand, the comparison between the years 2009-2011 and 2014-2016 shows, not only that the rate of growth of the life expectancy of the North American population has been significantly reduced in recent years, but in some of the categories considered has even become negative -that is to say that the expectation of life expectancy of the North American population has increased significantly in recent years. This is the case of the populations, male and female, of the rural and small metropolitan areas.But perhaps what most attracts attention are the figures that result when the population is disaggregated by age.In particular, when the young population was considered, with ages between 25 and 34, they found a negative tendency in terms of their life expectancy.This, for all the populations considered, urban and rural, male and female. Similar effects were found with the population aged between 44 and 65, excepting those living in the larger metropolitan areas. These results depend, in addition, on the geographic region considered. Thus, they are more accused in the region of the Appalachians or the Midwest than on the Pacific coast.Elo and collaborators are asked about the causes of the latter and come to the conclusion that the phenomenon is mainly due to deaths due to overdose of recreational drugs in the case of men, and to mental and nervous disorders in the case of women. Although, as Elo and his collaborators recognize, their results provide clues about the causes that are acting against the life expectancy of white Americans, their conclusions cannot be considered definitive. Thus, as often happens in the field of science, they would have to be validated - or denied - by new analyses. At the moment, the possibility that drug use is reversing, in a rich country, a trend that had been maintained for a century, is undoubtedly worrying. To say the least.",
    "https://upload.wikimedia.org/wikipedia/commons/b/bc/Eratosthenes.jpg": "As we know, next Saturday, July 20th marks the 50th anniversary of the landing of the \u201cEagle\u201d module of the Apollo 11 mission that took a human for the first time to the surface of the Moon, and that in the words of Neil Armstrong represented \u201ca great leap for humanity.\u201d Although this leap has not yet materialized, since after the Apollo program there have been no more manned missions to the Moon or to more distant destinations, the anniversary is undoubtedly worthy to be celebrated. Not everyone thinks the same, however, and there is a minority who doubt that the trip to the Moon really happened and that it was all part of a NASA montage to deceive the public. The American space agency would have been forced to proceed in this way, say the unbelievers, because of the strong pressure it was subjected to to to to comply with President Kennedy\u2019s offer, made public in 1961, to put an American on the surface of the Moon before the end of the decade. For this reason, or because there are some who are attracted by so-called conspiracy theories, in the United States 6% of the People think that there was no such lunar mission and that everything was part of a television show and montage. 12% of the British think the same thing, just like 20% of Italians and 57% of Russians. Moreover, lunar missions are fertile ground for conspiracy theories because of what it is necessary to \u201csee to believe.\u201d Certainly, hundreds of millions of people around the world saw the landing of the \u201cAgle\u201d module. This, however, was via television and not in a face-to-face way, which is not visual evidence for unbelievers. In fact, part of the arguments that argue against the journey to the Moon is based precisely on the analysis of photographs and moon landing films that are presumed to be false. On the other hand, not all that we take for granted is based on visual evidence experienced directly. Most of us, for example, take it for granted that the Earth is spherical without ever having a visual experience that confirms it. And so, in the sixth century B.C.E., the Greek thinker Anaximandro conceived the Earth as a cylinder, with a diameter three times greater than its height. We would inhabit the upper face of the cylinder, which would be surrounded by water and floating in space without any support. There are, however, numerous indirect evidences that contrast with a flat Earth and soon the Greek thinkers - even without direct visual evidence such as that of astronauts travelling into space - came to the conclusion that it is spherical. Eratosthenes, in the third century B.C., even managed to measure the radius of the Earth with reasonable precision. For this, he measured the length of the shadow projected at noon two rods of equal length placed, one in the city of Aswan and the other in Alexandria, separated about 850 kilometers in the south-north direction. , direct as well as indirect, that the Earth is spherical and this is almost universally accepted. Most of us, however, accept it based on the opinion of the experts - or of the few who have traveled into space. For example, an evidence of the roundness of the Earth gives us the fact that when one looks at the sea a ship that approaches the first thing that becomes visible is the highest part of it. This experience, which is possibly common for those living on a coast, is not so for those who live on the highlands. In the case of those who write this, while I have a firm belief that the Earth is spherical, I must confess that such a belief is largely based on evidence observed by other people. It is equally based on the opinion of experts who have found that the simplest way to describe the things we can observe in our environment, is to suppose that the Earth is spherical. Otherwise we would enter into contradictions or we would need an image of the world too complicated. The same could be said with respect to the image that we currently have of the Solar System, with the Sun in the center. And the planets, including ours, orbiting around them. This idea is not intuitive, and in fact, for a long time it was assumed - because it seems to us from Earth - that the Sun is the one orbiting around us. Putting the Earth in the center of the Solar System, however, led to too many complications to describe the movement of the other planets, which disappeared once the Earth was renounced to be the center of the Universe. In the case of the skeptics of lunar journeys, while they may argue that they do not have first hand evidence to prove them, it is more difficult to deny them than to accept them. Indeed, on the one hand, all the arguments that have been advanced have been strongly refuted by the experts. On the other hand, is it reasonable to think that a montation with the magnitude of the proposed one could be carried out without being discovered? Wouldn't it have been quickly denounced by the Soviets, competitors of the United States in the space race? Thus, the simplest thing is to accept -even without having been eyewitnesses- that Americans traveled to the Moon 50 years ago. Consequently.",
    "https://upload.wikimedia.org/wikipedia/commons/5/56/Sargazos.png": "From the diary that Christopher Columbus took during his first trip to the American continent, we learned that, on September 16, \u201cthey began to see many herds of very green grass that there was little, it seemed to him, that he had taken off from land, so everyone judged they were near some island.\u201d It was not the case, as we know, and the mainland was still more than three weeks away. In the days that followed, the explorers continued to see more of that green grass. At dawn on September 21, for example, \u201cThey found so much grass that looked like the curded sea of it.\u201d Likewise, on September 23, they found that \u201cThe herbs were many, and they found crabs.\u201d Today we know that the herbs that Columbus found on his first trip to America were floating algae from the so-called Sargazo Sea, located in the North Atlantic Ocean, between the Azores Islands and the east coast of the United States. That sea has a changing extension of about three and a half million square kilometers, and at the time of the ships driven by the force of the wind presented obstacles for navigation. In recent weeks, seaweed banks are no longer a problem for navigation. In Mexico, in recent weeks, the seaweed has gained great visibility because of the invasion of seaweed that have suffered the beaches of the Mexican Caribbean. In particular, there has been controversy about the seriousness and magnitude of the problem that threatens the tourism industry in our country. In this sense is the accumulation of sargaso on our beaches a temporary phenomenon that will disappear in the coming years? Or, on the contrary, is the manifestation of a phenomenon associated with atmospheric or climatic changes that will be persistent in the years to come? An article published this week in Science magazine tries to shed light on this. This article was published by a group of scientists attached to universities in the United States, which was headed by Mengqiu Wang, of the University of South Florida in Tampa. Wang and collaborators report the results of a study carried out on the seasonal sargaz band that, according to satellite images, has been formed in the Central Atlantic Ocean between the West Coast of Africa and the Gulf of Mexico. This band has been formed in an area in which the volume of sargaso was previously very small.Wang and collaborators made estimates of the volume of algae contained in the sargaso band from 2011, a year in which an abrupt and significant increase in that volume was observed.With the exception of 2013, there was a progressive increase in the volume of sargaso between 2011 and 2015, while in 2016 and 2017 it was observed a decrease of this volume, to increase dramatically in 2018 to 20 million tons by weight.This amount is significantly larger than that observed in 2015. On the other hand, although the reference article does not include data for 2019, it is known that in these months the situation has worsened, which is in line with the crisis on the beaches of the Mexican Caribbean. In order to understand the causes that caused the increase in the sargasozo band in the Central Atlantic in recent years, Wang and collaborators developed computer simulations based on satellite data and some measurements taken directly in the places of interest. According to the results obtained, the increase in the sargasozo band in the central Atlantic band in the last years, Wang and collaborators developed computer simulations based on satellite data and some measurements taken directly in the places of interest. In the Central Atlantic it is not related to exchanges with the Sargazo Sea, but to an increase of nutrients on the surface of the ocean due to two causes. One of these causes is of natural origin and has to do with the transport of nutrient-rich water from the bottom of the ocean to the surface, off the west coast of Africa. This occurs by variation in climatic conditions. A second cause is related to human activities: the discharge of water from the Amazonas river enriched with nutrients by the increase in deforestation and the use of fertilizers. Wang and collaborators recognize that their conclusions, based on satellite data and few experimental data taken on site, must be corroborated by additional research and measurements. They note, however, that satellite data from the last 20 years show that from 2011 onwards there were abrupt substantive changes in the formation of sargazo in the Central Atlantic - outside of the \u201ctraditional\u201d since the time of Col\u00f3n, Sea of the Sargazos - and that this is indicative that such changes will be permanent. gazo in the Mexican caribbean would involve more than simply removing the volume of algae accumulated today.",
    "https://upload.wikimedia.org/wikipedia/commons/f/fa/Mare_Tranquillitatis.jpg": "Next July 20th marks the 50th anniversary of the landing of the Eagle module and the walk of Neil Armstrong and Edwin Aldrin on the Sea of Quietness on the surface of the Moon. The event, broadcast live on television, was indeed spectacular. Those of us who are old enough, were fortunate enough to be able to testify, on the night of July 20, 1969, as Armstrong slowly descended down the stairs of the lunar module and stepped on the surface of our satellite. It was at that time that Armstrong uttered the phrase that has become famous: \u201cA small step for a man, a giant leap for humanity.\u201d President Nixon spoke on the phone with Armstrong and Aldrin as they stepped on the surface of the Moon and, among other things, told them: \u201cFor what you have done, the heavens have become part of the world of man,\u201d adding, \u201cand given that they speak to us from the Sea of Calmness, this inspires us to redouble our efforts to bring peace and tranquility to the earth.\u201d In particular, for those who were against the involvement of this country in the Vietnam War and who increased their protests over the invasion of Cambodia. In this context, four students from Kent State University in Kent, Ohio, died from gunfire by the National Guard, which led to student demonstrations of rejection at the national level. On a personal level, Nixon also had his moments of unrest in 1974, when he was forced to resign his position as president by the Watergate scandal.As for the claim that the skies had become part of our world, it would have to be recognized that Nixon was not too fortunate either. Indeed, although after the landing of Armstrong and Aldrin there were 5 manned missions to the Moon, the last in December 1972, after this date no human has traveled to our natural satellite. Subsequent manned missions to space have been limited to low altitude Earth orbits, that is to our immediate space neighborhood.And the same could be said of the famous phrase of Armstrong, because to date, 50 years later, no longer, An article appeared in the latest issue of the magazine MIT Technology Review, signed by Konstantin Kakes, expresses it in these terms: \u201cFifty years after Neil Armstrong stepped on the surface of the Moon, it is not difficult to conclude that he saw things the other way around. The landing was a giant leap for a man \u2013 Armstrong\u2019s life changed forever \u2013 but only a small step for humanity.\u201d Unmanned robotic space missions, on the contrary, have made a huge leap in the last 50 years. Thus, prior to July 1969, only two planets of the Solar system had been explored with spacecraft or spacecraft: Mars and Venus. Today, NASA has managed to place several probes and explorers on the surface of Mars that, among other relevant scientific data, have brought us shocking images of the Martian landscape. Likewise, all other planets of the Solar System, including the giant outer planets, Jupiter, Saturn, Urano and Neptune, have been explored. Pluto and its Charon moon, as well as Ultima Thule, the small object photographed by the New Horizons probe at 6.5 billion kilometers from Earth. As a further advance in the robotic exploration of the Solar System, NASA has announced a project of exploration of Titan, Saturn\u2019s largest moon. Titan constitutes an exotic world that nevertheless shares some similarities with our planet. Thus, it has a dense atmosphere that is composed of 94% nitrogen. It also has lakes, rain cycles and sand dunes. The similarity with the Earth, however, does not go much further, since the temperature of the surface of Titan, due to its distance from the Sun, is approximately 179 degrees Celsius. In these circumstances, water cannot exist in liquid form and its role is taken by methane -the main component of natural gas. Thus, Titan\u2019s lakes are of liquid methane, as well as its raindrops. It is also known that in Titan there are dunes of \u201carena\u201d, formed by organic matter. NASA's exploration of Titan has been assigned to the Johns Hopkins University Laboratory of Applied Physics and will be carried out by means of an 8-helix drone that has been named Dragonfly-lib\u00e9llula-. The drone will measure 3x3 meters and will take advantage of Titan's atmosphere for its flight, which is about 1.5 times denser than that of Earth, while its gravity is just 14% of that of our planet. The explorer will be released in the region of Titan dunes and will advance by 8 km jumps. In total it will travel 175 kilometers on a 2.7-year mission. According to NASA, one of the mission's objectives is to investigate the existence of conditions in Titan that are thought to be precursor to the origin of life. The Dragonfly project will have a cost of 1,000 million dollars and will start in 2034. It constitutes a further advance in the development of robotic probes for space exploration, even though it may advance more in this direction than in the form of manned missions. These missions are much more expensive and without being undertaken in 2034. scientific advantages sufficient to justify them, although possibly with more possibilities of political manipulation.",
    "https://upload.wikimedia.org/wikipedia/commons/a/ae/Typicalbusyoffice20050109.jpg": "Imagine that he lost his wallet on the street with some money and important documents, including a credential that identifies him, would he give it up or would he hope that someone would find it and get it out? As it is said, hope dies to the last, but we would agree that the probability of something like this happening in our country is rather low. In fact, an article appeared the week that ends today in the magazine \u201cScience\u201d quantifies it: it just exceeds 15%. But let\u2019s go around. The reference article was published by an international group of researchers headed by Alain Cohn of the University of Michigan, Ann Arbor, and Michel Andr\u00e9 Mar\u00e9chal of the University of Zurich and it describes the results of an extensive study carried out in cities all over the world, to find out the degree of civic honesty of its inhabitants. For this purpose, Cohn and collaborators designed an experiment through which they \u201clost\u201d in various public and private sites, portfolios containing various amounts of money and business cards from their alleged owner with an electronic contact address. The study was carried out in 355 cities in 40 countries, in each of which between five and eight of the largest cities were selected. Countries from the five continents, both developed and undeveloped, were included. Portfolios -17,000 in total - were delivered by research assistants at various sites with a public reception area, including banks, theatres and museums, post offices, hotels, as well as police stations, courts and other public offices. Some of the portfolios included a small amount of money, equivalent to about $13. In others, this amount was increased to some $90. In a third case, the portfolios did not contain cash. All the portfolios, in addition, contained a key - of value only to their owner- and a receipt for food purchases at a local store. The latter to indicate that the owner of the portfolio was next to the location. The results of Cohn's research and collaborators are little surprising in some respects and surprising in others. Thus, they hopefully find that the percentage of portfolios that tried to be returned varies greatly between countries. This percentage is considerably higher in developed countries, such as Denmark and Sweden, where it reaches 70-80 per cent, which in non-developed countries - in some cases called euphemistically developing countries - such as Peru, where that percentage does not reach 15 per cent. In Mexico, the corresponding percentage is between 18 per cent and 25 per cent, with a particular characteristic that we will mention later. Since citizen honesty is a basic feature for the development of a country, it was expected that Cohn's study and collaborators will find that more lost portfolios are returned in advanced countries than in countries that are not so much. Other research results, in contrast, were more surprising. It could be expected that a portfolio with money inside would be less likely to be returned than an empty portfolio. Cohn and collaborators, however, found that the exact opposite is the case, since a portfolio with $13 is more likely to be returned than an empty one. To verify this trend, researchers increased the content of the portfolio to $90 and with this they increased the probability of it being returned. This is the case in 38 of the 40 countries studied. The exception to the rule is Peru, where it makes no difference that the portfolio is full or empty, and Mexico, where an empty portfolio has a probability of being returned to its owner, in contrast to a portfolio with money where this probability decreases to 18%. Thus, Mexico is a singularity among the 40 countries studied. What is driving citizens of 38 countries - including non-developed countries such as Kazakhstan, Ghana and Brazil - to return a lost portfolio, with more determination as the amount of money it contains? Based on their study, Cohn and collaborators conclude that the main cause is one of self-esteem. That is, by returning the portfolio they avoid appearing before themselves as thieves. Thus, the impulse will be greater in the greater the content of the portfolio, at least until reaching the amounts -90 dollars- employed in the study. Otherwise, the statistics of Cohn and collaborators are not enough to provoke our enthusiasm, since they would indicate that in Mexico the impulse of self-esteem is effectively inhibited. Although, certainly and seen in that context, the results of the research are not entirely surprising.",
    "https://upload.wikimedia.org/wikipedia/commons/a/a4/Bibliotheca_Chemica_Curiosa_%28Pagina_titularis%29.jpg": "Imagine that on board a time machine we traveled four hundred years into the past. Certainly, we would find a very different world. And not only because in 1619 there were no cars, no computers, no internet, no antibiotics, no X-rays, to mention only some of the technological developments that we enjoyed today, but also because the conception of the world that was four centuries ago was radically different from the current one. With reference to the latter, four hundred years ago Katharina Guldenmann was subjected, at 68 years of age, to a trial for witchcraft in a city in southern Germany, accused by a woman of poisoning her after a dispute. The trial lasted six years, one of which Katharina suffered in prison chained to the floor of her cell and under psychological torture, with threats of subjecting her to physical torment if she did not confess. In the end she was acquitted of the charges in 1621, but died six months after being released from the ill-treatment she suffered in prison. In contrast, according to the method developed in the 16th and 17th centuries, the explanation of a phenomenon must be based on experimentation and the explanation of a phenomenon based on the experience of many thousands of sorcerers and witches who were burned in Europe in the 16th and 17th centuries \u2013 if they had not dealt with Johannes Kepler's mother, one of the most prominent astronomers in history, who helped establish the current model of the Solar System, according to which the Sun occupies the central position, with the planets, including the Earth, orbiting around it. In fact, it was Kepler who defended his mother during the trial and achieved her absolution. Together with Nicolas Copernicus, Tycho Brahe, Galileo Galilei and Isaac Newton, among others, Johannes Kepler was a prominent participant in the scientific revolution that took place in Europe in the 16th and 17th centuries. The science that led the onslaught against the prevailing ideas was astronomy, in which Kepler played a central role. That is, he established that the planets follow elliptical orbits and not circular orbits around the Sun, which move them away from the center of rotation in each revolution. That the planetary orbits are elliptical and not circular was at the time a more drastic change than they seem. Indeed, according to the prejudices of Kepler's time, the orbits of the planets should be circular and follow certain sized relationships for the different planets. Otherwise, they would be imperfect and incompatible with the supposed perfection of the sky. Thus, Kepler had to get rid of preconceived ideas and admit that the orbits are elliptical and noncircular, based on what was told by the measurements of great precision about the movement of the planets he had inherited from Tycho Brahe. However, they may not have always been rational. At least this is what an article appeared on May 26 in the magazine \u201cTalanta\u201d, published by a group of researchers from Israel and Italy, led by Gleb ZIlberstein of Spectrophon company, Rehovot, Israel. In that article, ZIlberstein and collaborators present evidence in the sense that Kepler may have been a practitioner of alchemy, discipline, which although it is said gave rise to modern chemistry, was essentially anti-scientific. The latter given that the knowledge of alchemy was secret and shared only by a group of initiates, in contrast to the scientific practice that demands that scientific results be freely disseminated so that they are publicly criticized, accepted or discarded according to consensus. The evidence that ZIlberstein and collaborators offer about Kepler alchemist practices were obtained by means of an analysis of a manuscript of theirs that is stored in the archives of the Russian Academy of Sciences in St. Petersburg. This manuscript was submitted to chemical tests using Kepler\u2019s practices. Sophisticated instruments that revealed the presence of gold, silver, lead, and mercury, metals that are associated with the practice of alchemy. According to ZIlberstein and collaborators, this suggests that, although Kepler may not have been a great enthusiast of alchemy, he would have practiced it to some extent. Thus, the metals found in the manuscript could have been carried there through his fingers or the sleeves of his clothes. Did Kepler practice alchemy? The results of ZIlberstein and collaborators point in this direction, but as they themselves point out, there is no more data to indicate it. However, it would not be surprising that he had done so, for it is known that other scientists of his own intellectual stature, such as Brahe and Newton, were interested in alchemy. Apart from these interests, which can be explained by the time of transition that they had to live, the contribution of Kepler, Brahe and Newton, and others of his own height, in favor of a rational conception of the world was decisive. In particular, to discard - if not in the whole world, At least in much of it - the barbaric practice of witch burning.",
    "https://upload.wikimedia.org/wikipedia/commons/4/43/2006-01-14_Surface_waves.jpg": "In the early morning hours of February 4, 1975, the population of the Chinese city of Haicheng, which at that time had about a million inhabitants, received an order from the authorities to evacuate the city in order to prevent an imminent earthquake. On the afternoon of the same day, Haicheng was hit by a earthquake of 7.3 magnitude, which resulted in about 2,000 fatalities, tens of thousands of injuries and the collapse of thousands of buildings. Had there not been evacuation, it is estimated that there would have been about 150,000 deaths.Haicheng's earthquake was predicted on the basis of different signs that occurred during the preceding months, from increases in subsoil water levels and variations in soil levels, to changes in the behaviour of animals.There were also series of small earthquakes, which increased before the earthquake occurred and triggered evacuation alert.Haicheng's earthquake is the first in history to be predicted. Unfortunately, it is also the only one, as the experience has not been repeated. The science of earthquakes is not at present sufficiently developed to predict them with a certain degree of certainty.In these conditions, there is no alternative but to seek to develop systems to alert the population once a tremor occurs and it can be safe. As we know, Mexico has installed one of these systems, which aims to issue an early warning about the occurrence of an earthquake on the coasts of the Pacific Ocean. The system is based on the fact that the speed with which the warning signal travels - through an electrical means of communication - is much higher than the speed with which seismic waves travel and is more effective as far away from the population is the epicenter of the phenomenon. Thus, the inhabitants of Mexico City have about a minute since they receive the warning signal, before the seismic wave arrives. To mitigate the effects of a potentially catastrophic earthquake, experts are also looking to predict its magnitude from the evolution of its magnitude during the first few seconds after the earth rupture that originates it. This article was published by Diego Melgar and Gavin Hayes of the University of Oregon in the United States on May 29, and in it they analyze a database that includes 3,000 earthquakes with magnitudes between 6 and 9, which occurred since the 1990s. They studied both data taken from seismic stations on the ground and data taken by satellites. In their research, Melgar and Hayes studied the evolution of earthquakes during their first moments, in order to find out if this evolution contained any signals indicating in advance what magnitude they finally reached. They found that from 10 to 15 seconds after an earthquake began it is possible to predict the magnitude that it will reach. This, in the case of earthquakes with magnitudes between 7 and 9. Thus, according to the results of Melgar and Hayes, it is possible to determine, with seconds in advance, whether the magnitude of a earthquake will be moderate or potentially catastrophic. So, although it is not possible to predict an earthquake before it occurs, apparently we can determine the magnitude that it will reach seconds before it reaches its maximum development. This may not be of great help in an emergency situation - given that we can do nothing to prevent the earthquake from reaching its maximum amplitude - but at least it tells us that the earthquakes show - at last - a weak flank. That is, although the earthquakes are apparently all-powerful, as part of the physical world they follow rules that would make them predictable if we could know them. These rules have been difficult to discover. The work of Melgar and Hayes, however, shows that earthquakes can be predicted, so only a few seconds in advance, and therefore indicates that we would be on the right track to find out what is driving them. After all, the objective of scientific research is to understand the world in order to predict it. And once we know the rules that govern it, we can predict it. The occurrence of earthquakes, not for seconds, but for hours or days in advance, and not by chance, as was apparently the case with the Haicheng earthquake.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d5/Waffensammlung_Armeria.JPG": "We learned in days past by the media of the occurrence of the umpteenth mass shooting in the United States, this time with 13 fatal victims. The shooting took place on Friday, May 31 at the Virginia Beach municipal offices in the state of Virginia. The shootings in public places in the United States are events that constitute a manifestation of a broader phenomenon. Indeed, we have that the victims of these events are only a small fraction of the total number killed by firearms in that country, which in 2017 reached close to 40,000 according to data from the Atlanta Center for Disease Control. This number makes the United States an anomaly in the world of developed countries; moreover, given that about 60% of the deaths by firearms in the United States correspond to suicide cases. Thus, according to figures published by the American Medical Association, the United States occupied the second place worldwide in gun deaths, surpassed only by Brazil, and above Mexico that occupies the third place in this matter. In this context, firearms are a public health problem in the United States and this has led to scientific studies to try to understand the reasons why a normal person could decide to use, at a certain time and for murder purposes, a firearm of the many that are within his reach. One of these studies appeared on May 31 in the magazine \u201cJAMA Network Open\u201d, edited by the American Medical Association. The corresponding article leads Justin Chiang and Brad Bushman of Ohio State University as authors. In their article, Chiang and Bushman report the results of an investigation that had the purpose of determining the influence that computer games in which a certain degree of violence is displayed, have on the behavior of a child in the handling of a weapon. For this purpose, Chiang and Bushman brought together a group of 250 children between the ages of eight and twelve, who were told that the test in which they would participate had to do with what the children liked to do in their free time, such as playing with video games and toys. The children were divided into three groups and put to play for 20 minutes the game \u201cMinecraft\u201d. Each group played a different version of the game, two violent versions and one without violence. In one of the violent versions monsters are killed using guns and in the other they are killed by means of sables. In the peaceful version there are no monsters or weapons. The children played Minecraft in pairs. One of the couple manipulated the game while the other only watched. At the end of the video game each couple was transferred to a adjoining room with toys and board games, as well as with two pistols, real but disabled, kept inside a closet. The children were told that they could make use of everything in the room by means of fire. 20 minutes. They were left alone, but watched through a video camera.In the analysis of the results of the experiment, the researchers dismissed 30 children for different reasons - some did not find the pistols stored in the closet - and evaluated their behaviour with the pistols. They found that 62% and 57% of the children who, respectively, played the video game with pistols and sabers, manipulated the pistols found in the room. In contrast, only 44% of the children who played the non-violent version did. Also, those who played the violent versions of Minecraft manipulated a pistol for longer than those who played the non-violent version. In addition, those who played the version with pistols pulled the trigger and pointed at themselves or their partner more times than those who played the non-violent version of the game. Chiang and Bushman conclude that their results show that the exposure of a child to a violent video game increases the likelihood of a gun touching in a given situation and of being manipulated for longer. Similarly, it makes it more likely that it points to itself or others and pulls the trigger. At the same time, researchers recognize that their study has limitations. For example, they point out that there is a possibility that children might be inhibited by being in a laboratory and not at home and acting differently. They also mention that Minecraft is not a particularly violent game. In relation to the latter, however, they note that a video game with cruder scenes would probably increase the effects they observed.For all those who are lay people on the subject, the conclusions of Chiang and Bushman seem convincing. Like all the results of scientific research, however, they have to be validated by independent research. Otherwise, it may be worth heeding Chiang and Bushman's recommendations on the inconvenience of exposing children to violent video games, as well as having weapons at their fingertips.",
    "https://upload.wikimedia.org/wikipedia/commons/d/dd/M%C3%A9todo_cient%C3%ADfico.jpg": "In the last two hundred years the world has witnessed technological progress that has taken place at an unprecedented scale and speed. To mention some of these advances, the last two centuries have brought us: the steam engine - the protagonist of the Industrial Revolution - electricity, synthetic materials, telecommunications, digital computers, modern techniques for the treatment and diagnosis of diseases and, of course, the Internet. And in all this, scientific knowledge has played the central role. Indeed, as we know, the scientific method - which as we know it had its origins in the Europe of the sixteenth and seventeenth centuries - has allowed the development of highly sophisticated technologies through strategies involving a certain scientific theory and which go beyond a simple test and error procedure. During the Second World War, for example, the theoretical knowledge that scientists had achieved about atomic and nuclear physics was central to the development of nuclear energy and the atomic bomb - with which tragically ended the war between Japan and the United States in 1945. Sophistication, the development of the basic science on which these technologies are supported requires -of necessity - that the scientists involved enjoy the freedom to investigate and publish the results of their work, as well as to criticize -positive or negatively - the work of their colleagues. Otherwise, it interferes with the development of the science that requires an open discussion of scientific ideas and results. The freedom of research is thus a basic premise for the activity of professors and academic staff of the so-called research universities, one of whose objectives is to advance the state of knowledge. In these conditions, it is surprising to learn this week from the press that two professors of Emory University in Atlanta, Georgia, were dismissed from their jobs for maintaining research relations with colleagues in China. These professors respond to the names of Li Xiao-Jiang and Li Shiua, are married and of Chinese origin, although American citizens. Li husbands are specialists in genetics, particularly in the development of gene editing techniques for the treatment of Huntington disease. They had been working in Emory for more than two decades supported. Their resignation was motivated by allegedly not having informed them that their research had also been supported by Chinese government agencies and that academic institutions had participated in them. The separation of the Li husbands from Emory University was announced to them on 16 May while Xiao-Jiang was travelling to China. Following this, their laboratory was closed and information about it was removed from the university\u2019s Internet site. Likewise, the four postdoctoral researchers of Chinese origin working in that laboratory were ordered to leave the country within 30 days \u2013 it seems, however, that one of them has a \u201cGreen Card\u201d permit to work in the United States. In their defense, the Li husbands claim that they were not given the opportunity to defend themselves from the accusation that they found unfounded, as they had provided information to Emory University about their work connections when requested. In fact, in an article they published in March 2018 in the magazine \u201cCell\u201d, they declare their affiliation, both It is also interesting to mention that in a blog published in 2017, Francis Collins, director of the National Institutes of Health, highlights the work of gene editing carried out by the Li husbands in their search for a treatment for Huntington's disease. According to information published this week in the magazine \u201cScience\u201d, the resignation of the Li husbands is part of a crusade undertaken by the National Institutes of Health in response to the concern of the US government that some foreign countries, particularly China, are unfairly taking advantage of research supported by federal funds. It thus seems that the episode of the Li husbands could be registered in the broader context of the US offensive against China, which includes the imposition of tariffs on imports from that country and actions against the Huawei company, which is alleged to be a threat to national security. In this case, the science of genetics seems to be a victim of its own success. That is, to the extent that it is able to provide solutions to problems of great practical interest - like many other branches of science - it faces a toxic environment of commercial and national interests, far from the environment of free research and dissemination of results it aspires to as science.",
    "https://upload.wikimedia.org/wikipedia/commons/5/53/Central_Obesity_011.jpg": "It is all to enter a supermarket - of which there is more and more - to find ourselves surrounded by all kinds of foods, both fresh and processed, and of origin the same animal as vegetable.All this, without a doubt, makes life easier for us.At the same time, however, processed foods rich in fats and carbohydrates are pointed out as guilty by the epidemic of obesity and diabetes, which plagues many countries of the world, including ours.The latter makes sense if we consider that we are a product of a long evolutionary process and that many of the processed foods offered to us by supermarkets and that we consume daily appeared only a few decades ago. Thus, we have not had enough time to adapt to the new food.Some two million years ago the ancestors of our species survived as hunters and under these conditions would have developed a capacity to process the meat of the animals they hunted.In fact, it has been suggested that the consumption of meat, which has a great energy density, would have been one of the factors that made possible the development of the human brain that, as we know, consumes 20% of the energy used by the body. Some 10,000 years ago, our predecessors turned to their eating habits and incorporated grains into their diet. They would have gone this way, according to the vision of some specialists, against the evolution to which they were exposed over millions of years ago, with the consequent hypothetical diseases that would have suffered from a poor diet. Thus, if we wanted to stay healthy, we would have to resort to a diet similar to that followed by the ancestors of our species hundreds of thousands, not to say millions of years ago.The fact is that we do not know precisely what prehumans consumed in such remote times and, for the time being, we have nothing left but to speculate about it. On the other hand, what we do know is that we have a medical problem, the so-called metabolic syndrome -a set of conditions that include high blood pressure, and high levels of cholesterol and glucose in the blood - that specialists think is associated with the food change that the food industry has brought us. So, rather than speculating about the food of hundreds of thousands of years ago, it is more useful to investigate what we are eating. At present and how this affects our health. And in this sense, it would be necessary to mention an article sent on April 30 to the repository of scientific articles \u201carXiv\u201d maintained by Cornell University in the United States. In that article, a group of three researchers led by Luca Maria Aiello from Nokia Bell Labs, Cambridge, United Kingdom, reported the results of an investigation carried out to find out what Londoners eat and how this relates to the development of metabolic syndrome. To carry out their research, Aiello and collaborators made use of the information contained in food purchase receipts in 411 locations in the city of London of the TESCO supermarket chain, which was compared with medical prescriptions extended to patients in the same area in London. The receipts from the TSCO chain -which include a total of 1,600 million products purchased during 2015 - do not identify the buyer, but the area in which he lives, and include a description of the foods purchased with their respective volumes. Medical prescriptions, extended during 2016, do not identify the patient either, but the area in which he lives. With this information, the researchers determined food consumption patterns in 937 locations throughout the city of London. They considered five food categories: fats, carbohydrates, sugars, proteins and fiber, and drew up maps of their consumption by locality. They also determined levels of calorie consumption and nutrient diversification by area. Medical prescriptions were also analyzed to determine the distribution in the different locations in London of drugs that are prescribed to treat high levels of cholesterol and glucose in the blood, and high blood pressure. With this information, the researchers determined the distribution of these medical conditions, assuming that it was the same as the drugs used to treat them.Through a comparison of the information provided by supermarket receipts and medical prescriptions, Aiello and collaborators found that metabolic syndrome was positively correlated with the consumption of fats, carbohydrates and sugars, and negatively with fiber consumption. They also found a clear positive correlation with calorie consumption, and an equally clear negative correlation with the diversification of nutrients. and collaborators that it is possible to determine the degree of metabolic disease of a population on the basis of its food consumption patterns. Specifically, its calorie intake -especially of products with high energy concentration- and the diversity of nutrients of its diet. Aiello and collaborators finish their article with practical advice not to end up associated with a chronic disease \u201cEating less than we instinctively would like, balancing all the nutrients, and avoiding the large amounts of food that are at our disposal.\u201d And, we could add, entering supermarkets with capajos to not see sideways.",
    "https://upload.wikimedia.org/wikipedia/commons/f/ff/SatTiticacaSee-placenames.jpg": "Coca, which is not cocaine, has been consumed since time immemorial by the Andean populations, from Colombia to Bolivia. In fact, in Peru and Bolivia its consumption is legal and the coca leaf can be acquired for this purpose without restrictions. In Bolivia, in particular, it is very striking for the newcomers how widespread its use is. It is to such an extent that they have even invented the verb \u201caccumulate\u201d for the act of chewing and keeping in the mouth a bolus of coca leaves. Coca is used the same as a medicinal plant - to relieve stomach pains, for example - that to combat fatigue and mitigate the demands of hunger. For those not accustomed to the Andean heights of 3,500 meters and above, coca is also used to combat the so-called \u201cmountain mal.\u201d We have thus that coca has multiple uses -which we usually associate with narcotics - and has traditionally formed part of Andean cultures. In these circumstances, the inhabitants of the high regions of South America find out of place the demands of the cocaine-importing countries to eradicate the cultivation of cocaine. We have two visions that have been found on the same issue. Certainly, the inhabitants of the Bolivian highlands can try to base their position on several arguments. They can even make use of the results of an article that appeared this week in the journal \u201cProceedings of the National Academy of Sciences\u201d, referring to archaeological discoveries in a site known as the \u201cCueva del Chileno\u201d located in the south of Bolivia, near the border with Chile. This article was published by an international group of researchers headed by Melanie Milles of the University of Otago, in New Zealand, and includes researchers from the University of San Andr\u00e9s in Bolivia and the State University of Pennsylvania. In that article, Milles and collaborators describe the finding in the Chilean Cave of a leather bag, which was assigned an antique of approximately 1,000 years using radiocarbon techniques. According to the authors, this antique corresponds to the period of disintegration of the Tiahuanaco culture, which spread in the Bolivian highlands from the region. From Lake Titicaca, to the north of Chile and Argentina. Inside the bag, archaeologists found several objects: two wooden tablets to inhale substances -decorated with anthropomorphic figures-, a finely sculpted wooden tube to inhale substances, two bone spatulas, a polychromatic weaving band for the head, and fragments of dried plants tied with wool threads and fibers. The leather bag also contained a bag manufactured, unusually, with three fox snouts in which traces of various substances were found.To identify these substances, Milles and collaborators scraped the inside of the bag and obtained a small sample of them. A chemical analysis using sophisticated techniques found traces of at least five psychoactive substances, including cocaine and the two main components of Ayahuasca, a drink with hallucinogenic properties used in South America for ceremonial purposes. The finding shows that, at least a thousand years ago, coca was used in the Bolivian altiplano, as well as hallucinogenic drugs and objects found in the lake Titicaca. Cueva del Chileno probably constituted the instruments of work of a shaman. Likewise, since the substances identified in the Cueva del Chileno are obtained from plants that do not grow in the region, but in lower lands in the case of coca and in the Amazon as regards the ingredients of ayahuasca, the finding shows the existence of trafficking routes between the lowlands and the Bolivian highlands a thousand years ago. The consumption of coca in Bolivia thus has ancestral roots and not to doubt the Bolivians have enough arguments to defend their production of coca leaf. The issue is not so simple, however, as it seems that the cocaine market in the developed countries has generated a growth of the areas of cultivation of the coca plant in Bolivia beyond what is strictly necessary for the consumption of the Bolivian population. In fact, this growth is one of the reasons of controversy in the framework of the presidential elections scheduled in Bolivia for next October. As we know, the current Bolivian president Evo Morales has acceded to the presidency of Bolivia in 2006 supported by coca growers - During his tenure, he has had two re-elections and goes for a third this year, coca cultivation has been promoted in the Chapare region that coincidently is where Morales has its political base. Also, in a congruent way, the Morales government built an international airport in this region, which has a very small movement. Critics of the president, in addition, say that something like 90 percent of coca produced in Chapare -which would not be suitable for farming - is aimed at the production of cocaine for export and that in this the semi-empty airport plays a role. If Morales\u2019 critics were right, the issue of Bolivian coca is complex and his possible defense would have to invoke arguments beyond those that could offer a result such as that of Milles and collaborators. Certainly, in matters of such complexity the science would have little to offer.",
    "https://upload.wikimedia.org/wikipedia/commons/5/57/Zenit.gif": "Just a couple of decades ago few would have anticipated what cellular phones have made possible today: that a majority of people have at their disposal a good quality camera that can be used to film or photograph at any time what might happen to them. Thus, in conjunction with the Internet, we continually learn graphically of events that otherwise would have gone unnoticed or result of little relevance. With the proliferation of smartphones, we are all exposed to being photographed or filmed, and to becoming inhabitants of cyberspace against our will. And with this, we certainly lose something of our privacy. Fortunately, photographic cameras can be used to obtain sharp images only up to a certain distance. Images of very distant objects lose sharpness and do not allow us to differentiate fine details. Thus, in a photograph of a person taken with an ordinary camera at a distance of hundreds of meters it would be difficult to distinguish their identity. There are, of course, specialized cameras with a large number of pixels -the elements inside the camera that detect the light - capable of producing images with a larger distance of hundreds of meters. This article was written by a group of researchers from Shanghai University of Science and Technology, headed by Zheng-Ping Li, Xiin Huang and Yuan Cao, and in the same article was written by a group of researchers from Shanghai University of Science and Technology, headed by Zheng-Ping Li, Xiin Huang and Yuan Cao, and on the Internet we can find examples in this regard. It is not all a question of the number of pixels, however, because when the distance of the object to photograph decreases the amount of light that reflects or emits that object and that enters through the lens of the camera. As we can easily see by taking a photograph with our cell phone in a room with little lighting, the lack of light severely compromises its sharpness. Thus, the camera of a cell phone could undermine our privacy if it is at a distance of meters or tens of meters. Beyond this it will not produce sharp enough images to reveal identities. It describes a camera capable of obtaining images at a distance of 45 kilometers. While it can produce images with a certain sharpness of very distant objects, the device reported by Chinese researchers is not in fact a photographic camera in the ordinary sense. To understand its functioning, let us first consider that to generate a photograph an ordinary camera collects the light -environmental or artificial- that reflects the object to be photographed and focuses on the element that produces the image. The camera reported by Zheng-Ping Li and collaborators, in contrast, illuminates the object to be photographed with a laser beam, collects the light that reflects, and focuses it on the detector that forms the image. Thus, the camera developed by Chinese engineers can obtain images even during the night, as it produces its own light to illuminate the object to be photographed. Moreover, since for the latter it employs a laser -which spreads in a single direction-, the object to illuminate can be located many kilometers away. The amount of laser light that is reflected by the photographed object and that manages to reach the camera is, of course, extremely small, given the large distance it has been located many kilometers away. In this way, to form an image it is necessary to use a light detector with an extreme sensitivity, beyond the sensitivity characteristic of the detector of an ordinary photographic camera. In addition, Zheng-Ping Li and collaborators had to attend to an additional problem: the light that comes to the camera after being reflected by the object to be photographed is corrupted by the ambient light, which was not reflected by that object and which, of course, will degrade the quality of the image. To solve this problem, Chinese engineers measured the time it took for the light of the laser to go and return from the photographed object and reasoned that any amount of light that came up to the detector at a different time could not have been reflected by the object of interest. Thus, it was discarded at the time of forming the image by the computer that controlled the camera.Employing all the techniques described above, Zheng-Ping Li and collaborators were able to obtain images from the top of a building located at a distance of 45 kilometers, with a resolution that clearly showed all its morphological characteristics.From all of the above we can obtain two conclusions: 1) If Zheng-Ping Li and collaborators were able to obtain images from the top of a building located at a building located at a distance at a distance at a distance at a distance of 45 kilometres, with a resolution which they were able to obtain a distance. Well Zheng-Ping Li's camera and collaborators is impressive, so far it is too expensive for it to be incorporated into a cell phone. From this point of view we can sleep calmly. However, even if we are hundreds of meters away from a cell phone, perhaps we should try to keep smiling in case anyone would think of incorporating us into cyberspace using some unconsidered trick here. 2) Chinese technology is advancing paces and surely will soon reach a level of competition with that of the United States. Any lessons to learn from us?",
    "https://upload.wikimedia.org/wikipedia/commons/d/d1/Cerro_ricco.jpg": "I had the opportunity to visit the city of Potos\u00ed in recent days, Bolivia, which is located in the south of the Bolivian highlands, at the foot of Cerro Rico. With an altitude above 4,000 meters, Potos\u00ed competes with the city of El Alto, also in Bolivia, as the city with a population higher than 100,000 inhabitants in the world. Potos\u00ed is a city with a cold and dry climate, which seems to be crazy at the end of the world. As we know, during the Spanish colony, the Cerro Rico of Potos\u00ed was a seat of the richest silver mines on the planet, which produced a substantial part of this metal that circulated around the world. Cerro Rico was particularly relevant between 1545 and 1650, when it began its exploitation, and Potos\u00ed reached a population of 160,000 inhabitants that rivaled that of the largest European cities of those times. We know, on the other hand, that the name of our city includes the word Potos\u00ed in reference to the silver mines of Cerro de San Pedro that could reach the importance of Cerro Rico. . Although the expectations in this regard were not met, the production of silver from New Spain as a whole reached very high levels - although not as high as those of Cerro Rico - with mines in Zacatecas, Guanajuato, Real del Monte and San Luis Potos\u00ed. It is known that an important part of the production of silver in New Spain and Upper Peru -where Potos\u00ed was located - went to China for the purchase of products such as silk and tea that were in great demand. In this sense, China was at that time an advanced and self-sufficient country that was not interested in European or American products other than precious metals. One more part of the production of silver remained in the Spanish colonies, while another, of course, was going to Spain. Moreover, through the payment of the debt acquired by the Spanish crown to finance its wars, or through the theft of Spanish galleons loaded with silver by the English pirates, American silver reached other European countries. It has been considered that the flow of silver from the New World to Europe was one of the factors that caused inflation in the New World. The study of Desaulty and Albarede was based on the measurement of the isotopic composition of silver, copper and lead of 15 English coins coined in the period 1272-1649, and their comparison with the respective compositions of Potosi and Mexico deposits, as well as coins coined in Medieval Europe. We know that chemical elements such as silver, copper and lead are found in nature in the form of different isotopes, which are varieties of a chemical element with different weights. The usefulness of this fact for the study of Desaulty and Albarede lies in the fact that the composition of silver, copper and lead isotopes of Cerro Rico is characteristic and different from the respective composition of mines. Thus, the measurement of the isotopic composition of the English coins allowed the researchers to determine the origin of the silver contained in the English coins and from it the silver flows from the New World to Europe. As a result of their research, Desaulty and Albarede found that the isotopic composition of the coins minted before 1553 coincides with the composition of the medieval coins. In contrast, the composition of the coins minted between 1553 and 1649, with one exception, coincides with the composition of the Mexican deposits, but not with that of Potosi. This proves that there was a flow of silver from New Spain to Europe in the 16th and 17th centuries. Likewise, it would indicate that the silver of Cerro Rico had not reached Europe by the middle of the 17th century. Only towards the end of the reign of Charles I of England in the middle of the 17th century would have reached the silver of Potos\u00ed to the English coins. Thus, before 1650 the fate of the silver of Potos\u00ed would have been China and not Europe. Given the geographical situation of Potos\u00ed, the metal would have been first taken to the English coins. To the coast of the Pacific Ocean, crossing the Andes mountain range, and once there transported by sea to Acapulco. From Acapulco, the Gale\u00f3n de Manila would have taken the silver cargoes to China via the Philippines. In fact, a route to the west is more natural from Potos\u00ed than one to the east, which would imply crossing Brazil to reach the Atlantic coast. In contrast, for Mexican silver it was more natural a route to the east, arriving first to Veracruz and then to Europe crossing the Atlantic Ocean. This would explain the delay of the silver of Cerro Rico in reaching Europe. One way or another, although in the present appearance Cerro Rico looks like it should have done in its time of splendor, internally it is an empty gruyee of silver. In fact, Bolivia currently occupies only the sixth place worldwide as a producer of this metal, far from the very first place it once occupied. All this as a product of the overexploitation of Cerro Rico. And with little benefit -not to say a maleficion - for the many Bolivians who perished in its bowels.",
    "https://upload.wikimedia.org/wikipedia/commons/b/b0/Culebra_bastarda.jpg": "During his first term as president of the United States in the 1950s \u2013specifically, on September 25, 1955 \u2013 Dwight Eisenhower suffered a myocardial infarction that had him six weeks in the hospital. Although he recovered to such a degree that he was even chosen for a second period, the public notoriety of his medical mishap made him take force from the opinions of some specialists against foods rich in saturated fats as causing diseases of the circulatory system. Thus, saturated fats acquired a bad reputation and in 1977 a committee of the United States Senate published a document recommending a reduction in his intake and increase in the consumption of substitute carbohydrates. Specifically, among other things, the American Senate recommended increasing the consumption of fruits, vegetables and whole grains, and reducing the consumption of red meats, and high foods in sugar or salt content.In some way, however, something went wrong and the diet of Americans, reflected in his health, not only did not improve, but it worsened. Saturated fats have lost much of their role as food villains that is now shared by sugar-rich foods. In these circumstances, and given the changing recommendations that experts have given us over time, one may wonder what a \u201chealthy\u201d diet would be \u2013 in the event that there was one. An answer in this regard is given by an article published on 3 April in the medical journal \u201cThe Lancet\u201d, published by an international group of researchers headed by Christopher Murray and Ashkan Afshin of the University of Washington in Seattle. In that article, the results of a study carried out to assess the consumption of food and nutrients in 195 countries and to determine the impact that a suboptimal intake of these foods has on mortality and morbidity from various non-transmissible diseases.As part of their research, Murray, Ashkan and collaborators determined optimal levels for the consumption of food groups that minimize the risk of death for any of the causes considered, including cardiovascular diseases, cancers and diabetes 2. Whole grains, nuts and seeds, milks, red meats, processed meats and sugary beverages.The researchers also established optimal levels for the intake of calcium, fiber, sodium, trans fats, and omega-3 fatty acids.In general, Murray, Ashkan and collaborators found imbalances between the actual consumption of food and nutrients and their optimal levels of consumption.In some cases, below these levels and in others far above them. Thus, the intake of fruits, whole grains, nuts and seeds, and milk, is in all regions of the world far below what is recommended. In contrast, the over-consumption of sugary beverages and to a lesser extent of processed and sodium meat is widespread. On the other hand, it is the low consumption of whole fruits and grains, and the high intake of sodium that have a greater influence on public health. Thus, of the 11 million deaths that occurred in 2017 attributed to a bad diet, more than 70% were due to inadequate intake of fruits, whole grains and sodium.The previous are global numbers and there are substantial differences. In contrast, the intake of fruits, vegetables, legumes, whole grains and nuts and seeds is below recommended levels. A similar situation occurs in the countries of Western Europe. On the other hand, in the countries of East Asia, red meats, sugary beverages, and particularly sodium are consumed above optimal levels. In reference to Mexico, among the 20 most populous countries in the world according to Murray, Ashkan and collaborators, we are ranked first in terms of low consumption of nuts and seeds, the second in terms of low consumption of vegetables, the third in terms of low consumption of whole grains, the fourth in terms of low consumption of fruits, the fifth in terms of high consumption of sugary beverages, the sixth in terms of low consumption of omega-3, the seventh in terms of high consumption of trans fats, the eighth in terms of high consumption of sodium, the ninth in terms of low consumption of polyunsaturated fats and the tenth in terms of low consumption of fiber. conclusion, according to Murray, Ashkan and collaborators, the world feeds terribly badly, although not all for the same reason. We, on our side and from what is seen, do not sing the ranchers badly. We would thus have to modify our dietary habits if we want to have a better health. Before this, however, we would have to make sure - with additional studies that corroborate it - that Murray, Ashkan and collaborators are right.",
    "https://upload.wikimedia.org/wikipedia/commons/9/97/New_guinea_named.PNG": "As we know, with the introduction of hygiene measures the subsequent appearance of antibiotics, today we expect to live considerably longer than what our predecessors experienced just two centuries ago. This expectation has, of course, objective bases, because if we look at the tables published on various Internet sites, we would find that while in 1800 life expectancy at birth was just over 30 years, today it exceeds 70 years. These numbers, however, are global figures and there is a great disparity in life expectancy among the various countries of the world, taking into account their degree of development. Currently, the country with the greatest life expectancy is Japan with 84.2 years, according to the World Health Organization. In addition to this country, the \u201ctop ten\u201d of countries with higher life expectancy is made up of Switzerland, Spain, France, Singapore, France, Australia, South Korea, Italy and Canada. At the other end of the classification there are African countries such as Angola and the Central African Republic, which barely exceed 50 years of life expectancy. On this basis Chiang and collaborators, extra years are desirable, we would agree that it is also necessary to live them with the greatest possible health. The latter, moreover - and regardless of any personal desire - is relevant from a purely economic point of view, given the temporary or permanent disability that a sick person may suffer. In these circumstances, indices have been developed to characterize the age of a population with regard not only to life expectancy but also to the quality of life expectancy. One of these indices - DALYS - measures the number of days lost, both due to premature death beyond life expectancy, and to days lost due to the disability resulting from a disease. In an article published on 6 March in the journal \u201cThe Lancet Public Health\u201d, an international group of researchers headed by Angela Chiang of the University of Washington Seattle, reports the development of a new index that reflects both mortality and the state of health of a population. This index is based on a group - determined by them according to a certain criterion - of 92 diseases related to aging and that are potentially inhabilitable. They investigated the cost in lost years of life that represented these diseases in 195 countries in the period from 1990 to 2017. Additionally, taking as a reference the index corresponding to an average population at a global level of 65 years, they determined to what extent the index of the population of each of the countries studied coincides or departs from the average index. Specifically, they determined the chronological age of the inhabitants of each country to which they experience health problems similar to those suffered by the average population of the world at 65 years. As expected, the countries with the highest degree of development tended to be better qualified in the study. Thus, the country with the least years lost by disease in 2017 was Switzerland with 104.9 years for every 1,000 adults over 25 years of age. They followed him, in that order, Singapore, South Korea, Japan and Italy. A notable exception among the rich countries was the United States, which at 161 years lost occupied the 53rd place, between Algeria and Iran. At the other end and occupying the last place, Papua New Guinea had in 2017, 500.6 years lost by disease, followed in ascending order by 53 years between Algeria and Iran. As far as Mexico is concerned, it was 48th with 156.2 years lost, a relatively high position and even above that of the United States. In relation to the age at which the average inhabitant of a given country feels as ill or healthy as the average inhabitant of the world would be at age 65, the results obtained by Chiang and collaborators are showy - if we have to rate them in any way. - Indeed, the country with healthier older adults is Japan, where at 76.1 the average inhabitant feels as healthy as the average person is at age 65. Switzerland, France, Singapore and Kuwait in that order follow. Far away, in 54th place with 68.5 years, the United States is left, immediately after Iran and just above Cuba occupying the place 57. At the other end of the Papua New Guinea scale is by far the worst rated at 45.6 years. Thus, the average inhabitant of this country is as sick as an average Japanese 30 years older. Our country, at 70.3 years of age, is also relatively well placed in the United States. This category, above countries such as the United States, Brazil and China, but below Peru, at 74.3 years old, as well as Panama, Costa Rica, Colombia, Ecuador and Chile.In general, of these last numbers it is found that the populations of the countries of the South American coast of the Pacific tend to have good health in the advanced age, even better than that of some European countries such as the United Kingdom and Germany. Chiang's article and collaborators make no mention of it. In this context, it is interesting to ask why some countries - including ours - do not have as many tributaries as others, however, have healthier populations.",
    "https://upload.wikimedia.org/wikipedia/commons/7/73/Nicolas_P._Rougier%27s_rendering_of_the_human_brain.png": "You may have experienced the feeling that time is running faster as we age. Once we have enough years, we feel that time is \u201cflying\u201d and that years are happening at a speed considerably greater than that we experience in times of youth. For this fact there are two possible explanations. One of these is that time has indeed been shortened in recent decades. Alternatively, we would have to assume that the perception of shortening of time is only an illusion. According to the first explanation, the Earth would be spinning on its axis ever faster so that the days would be shorter. It could also be that the speed of our planet around the Sun is growing continuously and with this the years would last less and less. We would perhaps agree that the first explanation is not convincing, because the speed of rotation of the Earth is actually decreasing continuously, as well as its orbital period around the Sun as it moves away from the same -the latter because the Sun loses mass by the energy it emits and therefore decreases its pull force over the Sun. Earth-. Moreover, both effects are extremely small and would not be appreciable in the course of a life: the duration of the day has hardly changed 1.7 thousandths of a second in the last one hundred years and the Earth is moving away from the Sun only about 1.5 centimeters per year. Thus, there would be no astronomical causes that explain our perception of shortening of time, which should therefore be only an illusion. At this point we must ask ourselves about the mechanism by which this illusion occurred. An answer is found in an article published this week in the magazine \u201cEuropean Review\u201d, published by Adrian Bejan of Duke University in the United States. In that article, Bejan analyzes the mechanism by which we perceive the passing of time and concludes that, as we age, we lose the ability to process the stimuli we receive from the world through the senses and that this entails a perception of temporal acceleration. The latter, which seems counterintuitive at first sight, is explained by Bejan in the following way. We perceive the time through the stimuli we receive through the senses, such as On the other hand, a change in time is perceived by the mind when the images recorded by the brain change. The length of a time interval that the mind perceives is thus determined by the number of images that the brain receives throughout that interval.The eyes acquire visual information through rapid movements that fix the view at certain points.Once an image is captured by the eyes, it is sent to the brain for processing.As we age, however, we lose the ability to perform these functions.On the one hand, it decreases the speed with which the eyes can generate images; on the other, the length through which the nerve impulses have to travel from the sensor organ to the brain, at the same time as it decreases the speed with which the impulses travel through the nerve channels.As a result, the number of images perceived by the mind decreases throughout life at a given time.Bejan summarizes the above as follows. He notes first that a greater part of the images travel through the nerve channels. It also concludes that the speed of time perceived by the human mind should be increased throughout life, as the time measured by a physical clock between successive mental images increases with age. The perception that time \u201cflys\u201d in the advanced age is then explained by the deterioration we suffer as we age in our ability to acquire and process the information we receive from the world through the senses. As a result of that deterioration, there is a changing decouple throughout life between physical time \u2013 measured by clocks \u2013 and the subjective time perceived by our mind. Unfortunately, little can be done at the moment to lessen or reverse the deterioration of our sensory abilities. However, if everything were to be a question of the number of images perceived by the brain as Bejan claims, what we could possibly do is to keep our senses and our brain at the maximum possible state of occupation, abrupting them with images and novel experiences; as we did in our youth. To that end, we would have to avoid repetitive and repetitive activities as possible. that do not leave us lasting impressions. We would thus extend our perception of time, which would make us \u201cfly\u201d - we hope - at a lower speed.",
    "https://upload.wikimedia.org/wikipedia/commons/a/a1/JacktheRipper1888.jpg": "Between August 31 and November 9, 1888, five women were killed in the London neighborhood of Whitechapel. The legend of \u201cJack the Ripper\u201d was born, both as a result of the brutality of the murders and as a result of his media coverage by the Victorian press that sought to cultivate the morbid public. The story is well known: five women were attacked in the street in the early hours of the morning -with the exception of the last victim who was found dead in their chamber - by a murderer who was never identified. All the victims were found killed; four of them, in addition, with wounds in their belly. Of the latter three were removed some internal organs, including sexual organs. And above all, the murderer, who would have had the luxury of sending a challenging letter to the police accompanied by a piece of kidney supposedly from one of the victims, was never discovered. For example, Jack the Ripper has been identified with Prince Albert Victor, the grandson of Queen Victoria and assiduous visitor to London\u2019s underworld. Alternatively, he has been identified with the Queen\u2019s doctor, who would have acted to conceal the wanderings of Alberto Victor in London\u2019s slums, during which he fathered children with women who would have to be eliminated in order to prevent possible extortion. He has also been identified with the painter Walter Sickert and has even been suggested that the killer was not a man but a woman. Other more landed hypotheses include suspects who were also involved in the investigations carried out by the police at the time, but who could never be charged for lack of evidence. These include the American pseudo-doctor Francis Tumblety, who would be an attractive option for the alleged knowledge he would have had of human anatomy, useful for the extraction of the victims\u2019 internal organs. The latter hypothesis is supported by an article published this week in the journal \u201cJournal of Forensic Sciences\u201d, by Jari Lohelainen and David Miller, of the universities of Liverpool and Leeds, respectively. According to Lohelainen and Miller, his is the first research on the identity of Jack the Ripper that has been published after having been evaluated and approved by other scientists who did not participate in it, which is the standard practice in all scientific research. To reach their conclusions, Lohelainen and Miller carried out an investigation of the mitochondrial DNA of some blood stains and seminal fluids observed in a silk shawl that would have been found at the crime scene of Catherine Eddowes, one of the women killed in Whitechapel. The researchers presumed that blood and semen came, respectively, from Eddowes and his victim, who assumed that they were Kosminski. To prove this, they compared the DNA found in the shawl with that of living relatives of both Eddowes and Kosminski, finding that in both cases they agreed. Thus, on the one hand, it would be demonstrated that the shawl was indeed at the crime scene and that Kosminski was the killer. Not everyone agreed, however. Thus, for example, an article of dissemination - not research - appeared in the past days in the magazine \u201cScience\u201d criticizes Lohelainen and Miller for not publishing in detail the results of their DNA determinations. In this regard, such researchers argue that the Data Protection Act of the United Kingdom prohibits publishing detailed information of the DNA of living individuals. Other scientists, however, maintain that mitochondrial DNA sequences do not represent a risk against the privacy of individuals and that Lohelainen and Miller should publish their results in detail. Otherwise, they could not be judged. Experts also note that, based on mitochondrial DNA, only suspects could be excluded. \u201cScience\u201d, the DNA found in the shawl could indeed be from Kosminski, but it could also be from thousands of other people who lived in London at that time. All of the above, together with the fact that it has not been reliably demonstrated that the reference shawl was actually at the crime scene. So, while the results of Lohelainen and Miller represent a significant advance towards the establishment of Jack the Ripper\u2019s identity, there are still doubts to be dispelled. In fact, there is no certainty that we will ever know it. Which, on the other hand, certainly only has a relative importance. Apart from the above, we can conclude that with his work Lohelainen and Miller show us the impressive analytical capabilities available to modern science, which allow us to shed light on events that occurred more than a hundred years ago, starting from just a few spots on a cloth.",
    "https://upload.wikimedia.org/wikipedia/commons/8/80/Sunshine_at_Dunstanburgh.JPG": "As we know, the light of the Sun is the ultimate source of all life on the planet. Without solar radiation, plants could not reproduce or generate the organic matter that animals need to survive. Certainly, without the Sun, life as we know it could not have arisen on the surface of our planet. Thus, during the millions of years in which we have evolved as a species we had to adapt to the particular characteristics of the rays emitted by the Sun and that reach the surface of the Earth. We have, for example, that the periods of day and night occur every 24 hours and that, consequently, we develop a circadian rhythm with this periodicity. Had the Earth had a different rotation rate, our circadian rhythm would have evolved differently and would have adapted as the case may be. Another important characteristic of the radiation of the Sun that has demanded an adaptation is its composition of colors that determines its hue. The solar radiation such as we perceive it has a yellowish tone. This is because its content of green and blue-green-green colors is relatively large in comparison with its content of blue and red. If we lived in another solar system, with a hotter or colder star than our sun, which would emit radiation with a different colour composition, perhaps the maximum sensitivity of our eye would correspond to a different color. On the other hand, on very recent dates in terms of evolution \u2013 a little over a century ago \u2013 a form of artificial light appeared \u2013 the incandescent light \u2013 which drastically changed our night habits. The light emitted by the incandescent light has a red hue \u2013 in contrast to the yellowish hue of sunlight \u2013 which reveals its greatest content of red light, and which brings it closer to the shade of sunlight during the twilight. On even more recent dates \u2013 just a quarter of a century ago \u2013 a new revolutionary lamp appeared for environmental lighting: the LED, which has a series of virtues that have placed the incandescent light on the path of its extinction. The tonality of light emitted by LEDs may differ greatly from that of sunlight because of its high content of blue light, and from this point of view it conflicts with our evolutionary adaptation. Indeed, we know that the human eye, apart from the two types of receivers specialized in daytime and night visions, has a third type of receptor that causes physiological effects as a response to changing conditions of ambient lighting. These responses include the production of melatonin, which prepares the body for the sleep period. In this sense, it has been found that night lighting with LEDs with a high content of blue light interferes with the production of melatonin and consequently with the circadian rhythm. This result indicates that LEDs with a high content of blue light \u2013 cold light \u2013 should be avoided for night lighting in homes-habitation for the benefit of \u201cwarm\u201d LEDs. In contrast, LEDs of \u201ccold\u201d light would be useful in the early hours of the morning to clear the drowsiness after waking of night sleep. This, at least, according to an article published the past month. In January, in the journal Scientific Reports, a group of researchers from the Advanced Institute of Science and Technology of Korea, led by Kyungah Choi, reported the results of a research with 15 students to determine the physiological and psychological effects that environmental lighting produces in the morning hours with two types of light: \u201ccold\u201d light with a high blue content and \u201cwarm\u201d light with a dominant red component. During the study, students were exposed for one hour to the two types of light. As a result of their study, Choi and collaborators found a significantly higher decrease in students\u2019 melatonin levels after their exposure to \u201ccold\u201d light than to \u201cwarming\u201d light. Similarly, exposure to light with a higher blue content significantly improved the feeling of drowsiness compared to exposure to light with a higher red content. According to Choi and collaborators, the results of their study have important implications for the design of indoor lighting systems. In this sense, they point out that such design should not contemplate In order to achieve this, it would take advantage of both the flexibility of LED sources in terms of the tone of their emission and the technology of the \u201cInternet of Things\u201d that would allow them to be controlled. In this way, the technology of night lighting would be adapted to our conditions as a human species, which are the result of millions of years of evolution. To do so in reverse would undoubtedly be considerably more difficult.",
    "https://upload.wikimedia.org/wikipedia/commons/d/db/Cairo_Montage.png": "In the past few days in the international press, an unusual news appeared: customs personnel at Cairo airport, Egypt, when examining a piece of luggage by means of X-rays, discovered parts of the body of two mummies with thousands of years old. Such parts - a piece of torso, an arm, a hand, two legs and two feet - were hidden inside two honks and were intended to be smuggled into Belgium. The fragments of mummie were confiscated by the Egyptian authorities and sent to the Museum of Antiquities of Cairo for study and preservation. It is not, of course, unusual that the objects of ancient Egypt are the targets of smuggling and the black antique market. After all, Egypt has fascinated Europeans for hundreds - not to say thousands - of years, especially after the invasion of this country by Napoleon at the end of the 18th century. Proof of this is the innumerable Egyptian art objects found in museums and private collections of the developed world, many of them as a result of theft and looting. It is, however, surprising that this fascination It extends to a piece of mummy to the degree of generating a black market, however old it may be. On the other hand, it must be recognized that Egyptian mummies are fascinating; they have even been the subject of horror films of great success, among other signs of their great popularity. This is due, among other things, to the fact that they are very old and abundant, because mummification in ancient Egypt was a widespread practice by Egyptian belief in life after death and the need to preserve the body for that life to take place. In these conditions mummification was practiced not only by the ruling class but also by the population in general, with all the economic sacrifices that it represented for the lower classes. In fact, mummification in ancient Egypt was so widespread that it was practiced even with dogs and cats. Thus, with a large overproduction of mummies, it is not surprising that they have accumulated in large quantities. The mummies lost their original meaning. And given their abundance, they were victims of practices that would surely have horrified the common mortals in ancient Egypt. Indeed, it is known that throughout the Middle Ages and even until the first decades of the last century, it was thought that Egyptian mummie dust had healing properties and was used as medicine. Although this turned into cannibals to those who used such powders to cure their evils, it is assumed that at the time things were not seen in this way and it was considered that, by their great antiquity, Egyptian mummies were objects and not remains of people. Likewise, they would surely have been offensive some thousands of years ago in Egypt the feasts carried out by the wealthy classes in Victorian England whose main appeal was to \u201cunroll\u201d an Egyptian mummy. And as a further demonstration of their practical value, mummies were also used as paint pigments and as a hunting trophy for those Europeans who returned from a journey to Egypt in the nineteenth century. Thus, once they were used as a sign of their practical value, mummies were also used as paint pigments, and as a trophy of hunting for those who trophys who were returning from a journey to Egypt in the 19th century. He lost the original intention with which they were created, the Egyptian mummies were given numerous applications by virtue of their abundance; abundance that Mark Twain illustrates by stating that they were used as fuel for locomotives - which was a joke, of course. Given the sensitivity and scientific knowledge of our time, the previous applications of Egyptian mummies do not in these days represent a business opportunity that originates a black market and smuggling operations. This week\u2019s episode at Cairo airport would then be understood as one of Egyptian antiquities trafficking. It is known that the market for illegal trafficking in art objects and objects of cultural value is flourishing and, according to experts, is exceeded in size only by drug trafficking and arms trafficking. In the case of Egypt, such trafficking has been increased since 2009, coinciding with the global economic crisis. Thus, if the sarcophagus of a mummy is dealt with, it is not difficult to conclude that it would have a value on the black market. The Cairo airport episode shows us that, apparently, too, has simple fragments of mummy. Legally these cannot be removed from Egyptian territory, which, of course, increases their value on the black market.",
    "https://upload.wikimedia.org/wikipedia/commons/9/9b/Daspletosaurus_hunting.jpg": "Being the very popular animal dinosaurs, so is the story that the fall of an asteroid at the end of the Cretaceous period erased them from the face of the Earth. Indeed, it is enough to look for \u201cextinction of the dinosaurs\u201d on the Internet to appear on the screen numerous images of dinosaurs terrified by the vision \u2013 and the roar is understood \u2013 of a massive fireball approaching at great speed. And it would not have been for less, because the asteroid measured about 10 kilometers in diameter and at the speed at which it collided with the ground produced a crater of 180 kilometers in diameter, generated fires, earthquakes and tsunamis, and threw into the atmosphere large quantities of dust that blocked the sunlight and caused a drastic cooling of the planet.If on a geological scale the dinosaurs died in a very short time after the impact of the asteroid, they did not do so immediately but through generations -except, perhaps, in the case of those who had the bad fortune of finding themselves in the wrong place and at the wrong moment, just after the impact of the asteroid, they did so much so immediately. In this regard, it is known that the marras asteroid impacted on the coast of the Yucat\u00e1n peninsula near the village of Chicxulub some 66 million years ago. The evidence of this impact is provided by a geological stratum throughout the planet with a higher concentration than expected of iridium metal -which is more abundant on asteroids than on Earth-, a stratum corresponding to that age. The iridium present on the asteroid was dispersed globally after the impact.There is no doubt that there was a collision with the Earth of a large asteroid 66 million years ago that led to drastic climate changes worldwide.This collision marks what is known as the KP border.They have no doubt that simultaneously -on a geological time scale - there was a massive extinction of species. There is no consensus among experts, however, that the first has been the cause of the second; this, contrary to popular belief.In this regard, it is known that at the end of the Cret\u00e1cico period, there were large volcanic eruptions. In the region known as Escaleras del Dec\u00e1n in what is today the territory of India. These eruptions dispersed large amounts of carbon dioxide and sulphur dioxide into the atmosphere that changed the climate of the planet.The experts thus have two possible causes for the extinction of species on the border KP: the Chicxulub asteroid or the massive eruptions of India.These possibilities are discussed in two articles published this week in Science magazine, published by two international groups of researchers.One of these groups is headed by Courtney Sprain of the University of California Berkeley and the other by Blair Schoene of Princeton University. In both articles they discuss the causes of the mass extinction of species in light of new measurements of the age of the igneous rocks of the Dec\u00e1n Escaleras. To date these rocks, both groups of researchers used radioisotopes techniques -which are similar to the technique of carbon dating 14-. They do not agree, however, in their results. Sprain and collaborators find that the largest part of the volume of volcanic emissions are found in India. In contrast, these eruptions occurred in pulses, the first of which began tens of thousands of years before the border. It is known, on the other hand, that at the end of the Cretaceous, a climate change occurred that must be explained by the emission of pollutants into the atmosphere. Schoene and collaborators explain it by this first pulse of volcanism. Sprain and collaborators, on the other hand, venture the hypothesis that, even without volcanic eruptions there is emission of atmospheric pollutants that filter through cracks in the earth's crust. They also venture that the impact of the asteroid on Yucatan stimulated volcanism in India, which had its greatest activity after that impact. Thus, for Schoene and collaborators the massive extinction of species can be attributed, both to the volcanic eruptions of India, and to the impact of the Chicxulub asteroid. For Sprain and collaborators, on the other hand, the most responsible would have been the impact of that asteroid. The last issue of the magazine Science thus includes two scientific articles. In both cases volcanic rocks were dated using similar but not identical techniques. While there are similarities between the two articles, there are also discrepancies in their conclusions. This is not surprising, given that the events investigated occurred in an inconceivably remote past. Moreover, the two articles on the extinction of dinosaurs published this week by Science illustrate one of the essential aspects of the scientific method: the open and public confrontation of views based on the results of experiments and measurements, which will serve as a support for future research on the same topic. And thus \u201cinfinitum\u201d, increasingly close to the correct result.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d9/Library-shelves-bibliographies-Graz.jpg": "In 1963, Derek de Solla Price, then professor at Yale University in the United States and father of what is known as \u201cCyenciometry\u201d or \u201cScience of Science\u201d, published a book entitled \u201cLittle Science, Big Science\u201d - translated into Spanish as \u201cTowards a Science of Science\u201d - which became a classic. In that book, among other things, de Solla Price analyzes the growth of the number of scientific articles published in the last 300 years, finding that this number doubled every 15 years. Thus, between 1660 and 1960 the number of scientific articles grew by a factor of one million, which, according to Solla Price, would explain the scientific and industrial revolutions.It is not all a matter of numbers, however, and it must also be considered the impact produced by scientific publications that is not uniform. One characteristic of scientific activity is that it is based on work previously done by other researchers, which is revealed in the bibliography cited by the article in question. Thus, the success of a scientific article is measured by the number of articles that cite it, what it, what is According to an article published this week in the journal \u201cNature\u201d, however, the number of citations received by an article is not a sufficient parameter to fully evaluate its scientific impact and more detailed criteria must be considered. This article was published by a group of researchers from North American universities headed by Lingfei Wu of the University of Chicago. Wu and collaborators designed an index to characterize the novel -disruptive- impact of a scientific article and for this purpose considered a novelty index that quantifies to what extent an article is cited by other articles without at the same time quoting articles cited by the article in question. That is, if the article that cites does not include quotations referred to in the cited article, it would be completely novel and it was assigned a novelty index equal to 1. If, on the contrary, quotes to an article are accompanied by quotations to works that have been cited by the article, that article receives a novelty index equal to less than 1. Researchers conducted a bibliographic study with 65 million articles, patents and software products that include the period from 1954-2014. Basically, they showed that small groups of researchers tend to generate scientific and technological advances that involve novel ideas -with a higher rate of novelty- more frequently, than groups with a greater number of members. In contrast, the latter are more efficient to develop advances with negative novelty rates -which does not have a pejorative meaning- based on pre-existing ideas. Wu and collaborators also find differences in the practices of exploring articles published in the past, which tends to be deeper in time in the case of small groups. These conclusions are relevant given the trend towards growth in the number of members of research groups. Wu and collaborators can be understood by the increasing complexity of the scientific and technological problems that demand for their solution multidisciplinary groups of researchers. The integration of these groups, in addition, is facilitated by advances in communication technologies. Wu's results and collaborators, however, point to the fact that the most novel scientific results are the result of small groups of researchers.Wu and collaborators conclude that small groups of research must receive support for their work, and that both groups - These conclusions are, of course, relevant to the industrialized countries; they are more efficient in developing advances based on pre-existing ideas; they are essential to \u201ca flourishing ecology of science and technology.\u201d These conclusions are certainly relevant to the industrialized countries; they are important for their flourishing scientific and technological systems. The very fact that in the United States initiatives are supported to study science using scientific methods is an indication, if necessary, of the central role that science has in that country. In Mexico this is not the case and science usually does not attract much attention. The exception has been the week that ends today when CONACyT was in the eye of the hurricane. Undoubtedly, all those who have something to do with this institution believe that it should be the reason for greater attention at the national level. Although not in the way it was in recent days, we would agree. CONACyT, founded in December 1970, has the mission to promote the scientific and technological development of Mexico and not to doubt the country has advanced in this area during these years. Given the limited resources that we have invested and that have not reached half a percentage point of GDP, despite repeated announcements that it would reach one percent. Hopefully the waters will calm down and the science of the country will come to a good port. Assuming that it does, the research groups of our country, which by necessity tend to be small, will have the advantage of being precisely small. At least if we are to believe Wu and collaborators.",
    "https://upload.wikimedia.org/wikipedia/commons/c/c5/InternationalPaper6413.jpg": "On December 1, at the request of the United States, the Canadian government arrested Meng Wanzhou, vice president and head of finance of the Chinese company Huawei. He is accused of technology theft and financial fraud from US institutions. It should be noted that Huawei is the world\u2019s largest manufacturer of communications network equipment and that Meng is the daughter of the founder of the company. Huawei is also said to have connections with the Chinese government. It is easy to say that Meng\u2019s detention has been highly controversial and criticized by China which rejects the accusations made to Huawei. The incident has been put into the context of the commercial war being waged by this country and the United States, given that Huawei is the leader of the new wireless communications technology known as 5G. Also, given that last year it exceeded smartphone sales to the Apple company and with this it became the second manufacturer of these devices worldwide, surpassed only by Samsung. 5G technology will substantially increase the speed and capacity of the current 4G technology and allow to do things qualitatively different. In particular, it will enable the so-called \u201cInter The Internet of Things will allow, for example, to monitor without human intervention the level of domestic gas in the stationary tank of a house and to ask the gas company to fill it if necessary. It will also allow permanent monitoring of the blood pressure of a hypertensive patient and transmit it in real time to his doctor for surveillance. In the case of autonomous cars, high-speed wireless connections will be essential to ensure that the car passes along the way avoiding other cars, whether autonomous or guided by a human. Certainly, 5G technology and the Internet of Things will change our lives to a very small extent. At the same time, a wireless network with a huge number of connected objects will facilitate the intrusion of \u201chackers\u201d and the theft of information, and this is cause for concern among specialists, and particularly the government of the United States. In this sense, an article appeared in this sense, a net of things\u201d, technology that involves the wireless connection with the Internet of a large number of objects of a diverse nature, from bread toasters and refrigerators, to automobiles and heart pulse monitors. This week in the magazine MIT Technology Review, says that the real cause of Meng\u2019s arrest last December is the concern of the US government over the danger posed by the penetration of Huawei\u2019s technology into the future 5G networks of the United States and other countries of the world. A 5G network with a large component of Huawei technology, it is argued, would leave them exposed to espionage by the Chinese intelligence system. In these conditions, it would constitute too great a risk to national security. On the other hand, apart from the security problem there is also the commercial aspect because, according to the article of MIT Technology Review, Huawei being the largest manufacturer of communication equipment and the second largest manufacturer of smart phones, is in good position to stay with the lion\u2019s share of the 5G technology market, which is estimated to be US$ 123,000 million in five years. Thus, the reference article continues, blocking Huawei\u2019s entry to the US market as well as to other markets in the world, would give its competitors time to reach it. Today, apart from the United States, Australia, New Zealand and Japan have vetoed Huawei for the development of their 5G networks, and so could other countries in the future, including Germany and Canada. Next week, the US Secretary of State will be visiting countries in Central Europe and will express his concern about Huawei's growing presence in that region of the world.In one way or another, whether it is a matter of commercial gain or national security issues, it is certainly shocking to witness the technological confrontation between the United States and China, which would have been unthinkable only a few decades ago. And at this point there is a reflection of why Mexico has made so little progress in technology. Certainly, it has not been because it has not invested enough resources in the preparation of highly skilled engineering scientists, as CONACyT has operated a comprehensive post-graduate scholarship programme since 1971. The explanation may be found in the little effort that has been made to establish technological development lines in areas that are considered priority areas. Certainly, there hasn't even been one in the oil sector, which is saying something.",
    "https://upload.wikimedia.org/wikipedia/commons/0/04/Stubble_below_Tinto.jpg": "As was widely disseminated by the media, in recent days, the city of Chicago was invaded by a polar air mass that brought the ambient temperature down to levels far below those usual at this time of year. Although the minimum ambient temperature did not reach the record of less than 33 degrees Celsius on January 20, 1985, the less 30 degrees Celsius suffered by Chicago last Wednesday is not that they have been too far away either. Moreover, it should be noted that the wind speed causes a sensation a temperature lower than the temperature that marks the thermometer and that Chicago is characterized by being a windy city. In these circumstances, the tweet of the US president last Monday 28 January was not well received referring to the impending cold wave that would strike the north of the United States, asking the global warming to please return because they needed it. The low temperatures that affected the north of the United States were due to the overflow of the circulating cold air mass, the so-called polar vortex, which is normally contained in a region around the north pole. Although it is a controversial idea, there are scientists who think that global warming - which affects the Arctic region in an amplified way - weakens the confinement of the polar vortex. If so, the American president would be invoking the wrong entity. Although, in fact, it is not clear if he genuinely thinks that global warming is a hoax or if his comments are interested.What is clear is the emission of greenhouse gases into the atmosphere by industrial activities has produced changes in the environment at a global level that, among other effects, has led to a sustained increase in the temperature of the planet, and that it has reached about a centigrade degree above its pre-industrial levels.In this context it is interesting to comment on an article that appeared in the last issue of this year's journal Quaternary Science Reviews, which presents a study of the impact of the European conquest of the American continent, reaching a surprising conclusion: the collapse of the indigenous population after the conquest was of such a magnitude that it affected the climate of the We will mention first that the reference article was published by a group of researchers from British universities headed by Alexander Koch of University College London and that it analyses the abandonment of farmland after the arrival of Europeans. This abandonment was due to the collapse of the indigenous population, which would have been reduced by up to 90%, by the extermination wars, by the slavery to which they were subjected, or by the introduction by the conquerors of pathogens that did not exist on the continent and for which the Native Americans had no defenses. By abandoning the farmlands -which at the continental level constituted an area approximately equal to a quarter of Mexico's territory - they were reforested by the original flora that had been dismantled at the time to prepare those lands for agriculture.This caused a greater green area that increased the rate of removal of carbon dioxide -the main greenhouse gas - from the atmosphere.Here it should be remembered that during the photosynthesis process plants take carbon dioxide to make organic matter.As a result, there was a reduction in the concentration of carbon dioxide in the atmosphere. As these researchers point out, this concentration is approximately 30% of the reduction in carbon dioxide that is known to have occurred in the 14th century and which in turn gave rise to the low-temperature period known as the Little Ice Age. Thus, the annihilation of the indigenous population of the American continent contributed to cooling the planet in a period prior to the Industrial Revolution. That is, it contributed to creating an inverse effect to the current global warming. This conclusion is undoubtedly surprising and we would only hope that it would not be taken too seriously by the American president, who has shown little sympathy for us.",
    "https://upload.wikimedia.org/wikipedia/commons/8/85/Ultimo_m%C3%A1ximo_glacial.PNG": "As we know, the global temperature of the Earth has increased by almost one degree centigrade in the last two centuries. This would have nothing extraordinary if not because such an increase has been given at an unusual speed. Indeed, we know that the temperature of our planet has undergone changes of several degrees centigrade approximately every 100,000 years that have produced the so-called ice glaciations or ages. This is because with this periodicity the orbit of the Earth around the Sun is modified and with this the amount of solar radiation it receives. About 15,000 years ago the Earth was in a process of warming after the last glaciation and, according to NASA, it took about 5,000 years to increase its global temperature between 4 and 7 degrees centigrade. In contrast, in the last century that temperature has increased at a rate almost ten times greater. Scientists, on the other hand, do not find that this latest increase can be explained by the influence of natural phenomena, such as changes in the radiation of the Sun, volcanic eruptions or climatic phenomena such as El Ni\u00f1o. And if they find, on the other hand, that there is a concordance between such an increase in the Earth. and the rise of greenhouse gas levels in the atmosphere that is known to have the effect of retaining the heat emitted by the surface of the Earth that would otherwise be lost in space. There are reasons, therefore, to believe that the temperature of the Earth is increasing by our actions. An article appeared this week in the magazine \u201cNature Communications\u201d puts into a millennial perspective the warming that is currently experienced by the Earth. This article was published by a group of researchers from universities in the United States headed by Simon Pendleton of the University of Colorado and focused on the study of the flora that has been exposed by the retraction of the Arctic ice as a result of global warming. The research was carried out on the island of Baffin in the Canadian Arctic. It is known that the effects of climate change are amplified in the Arctic region that is being heated at a speed of two to three times greater than the rest of the planet. In particular, the masses of polar ice are rapidly reducing its volume, leaving areas that could have been buried by thousands of thousands of people in the world. Or tens of thousands of years ago.Possibility Pendleton and collaborators set out to investigate.For this purpose, they collected plants that had recently emerged to the surface by retracting the layers of ice that covered them.The researchers note that once exposed in the open, the plants are quickly destroyed by environmental erosion, so that a plant collected on the edge of the ice sheet would presumably have emerged to the surface for the first time since it was originally covered by the ice layer.It would thus carry the information of when such a layer was formed.This information was recovered by measuring its carbon content-14.As we know, the time that has elapsed since the death of a plant can be determined by measuring its concentration of this carbon isotope that has a radioactive decay time of 5730 years.The beginning for this dating is very simple: while the plant is alive it absorbs a certain amount of this carbon isotope, which it ceases to do at death. Thus, the determination of the carbon-14 content of a plant that died thousands of years ago. And in the case of the determinations carried out by Pendleton and collaborators, it allowed them to determine when the ice covered the surface on which the plants investigated grew. The results of the study show the surface newly discovered by the withdrawal of the ices on the island of Baffin remained buried for more than 40,000 years. In order to confirm their findings, the researchers carried out a carbon-14 dating of rocks equally discovered by the withdrawal of the ices. In this case, the coroner-14 generated in the body of the rocks by the effect of cosmic rays. These rays produce carbon-14 in rocks exposed to the surface, but not in those buried by an ice layer. The study of the rocks confirms the results obtained by the dating of the plants. From the results of Pendleton and collaborators it is clear that, for the first time in at least 40,000 years, we can see landscapes of the Canadian Arctic that had remained hidden by the ice. Likewise, the researchers note that, based on paleo-climatic studies of the Arctic regions. , it is possible that global warming like that experienced by the planet over the last century had not occurred in the last 115,000 years. Something that is undoubtedly worrying. To say the least.",
    "https://upload.wikimedia.org/wikipedia/commons/4/45/Lume_a_petrolio_1.jpg": "The incandescent lamps, introduced commercially by Thomas Alva Edison just over a century ago, illuminated the darkness of the nights and with this brought us a substantial change in our way of life. These lamps were not, of course, the first artificial means of lighting that we used throughout history. Before this, we used campfires and, to the extent that our technology was successful, of torches and gas lamps, among other options.The electric light, however, represented an important leap in terms of the lighting efficiency that turned out to be above ten times greater than the efficiency of gas lamps.As we know, today and a hundred years after its appearance, the incandescent lamps have lost the battle against LED lamps that have numerous advantages, including greater reliability and, above all, substantially greater efficiency.This last can be attested by those who have replaced the old incandescent light bulbs in their homes with LED lamps.The advantages of LED lamps, on the other hand, are not only reduced to greater reliability and efficiency. . On the contrary, the characteristics and flexibilities of LED technology have the potential to produce greater impacts, not only in a reduction in the consumption of electric energy used for lighting worldwide - which is of the utmost importance to them - but in fields as diverse as health and food production This, at least according to an interesting article published in the issue of 22 November last year in the magazine \u201cNature\u201d. This article was published by a group of researchers from various American research centers, headed by Paul Pattison of the consulting firm \u201cSolid State Lighting Services\u201d. In his article, Pattison and collaborators point out the importance of light for all living beings on the face of the Earth. Not only because of the process of photosynthesis -essential to maintain life on the planet - that employs the light of the Sun as one of its fundamental ingredients, but because light provides much of the information that allows living beings to adapt to the environment. Researchers note that the importance of light for humans is reflected in three facts: of the human eye as an optical instrument, the great fraction of the human brain dedicated to processing visual information, and the extreme dependence that we have on technologies to improve our vision, as is the case of glasses to see from near or far away. In contrast to the incandescent lamps that emit only light with a red-yellow color, LED lamps are able to emit light in a varied range of colors. A conventional LED lamp emits a primary light of blue color which is partially absorbed in a material known as a phosphorus that converts it into yellow light. The combination of yellow light and primary blue light is perceived by the eye as white light. Depending on its design, however, a LED lamp is able to emit a primary light with a color that goes from violet to green blue, which can be converted by a phosphorus into a green, yellow or red light. Thus, the light of the LED lamp, as perceived by the eye, can have a whole range of hues. It is also possible to combine several LED lamps, without converting matches, which emit in colors. The flexibility of LED lamps to generate light with different colors and tones opens up a whole range of applications. In this regard, Pattison and collaborators note that blue light of certain shades affects the production of melatonin, the circadian rhythm, and the waking state and performance. Thus, the possibility of having flexible sources of light of different colors would allow, among other things, to increase productivity at work. The flexibility of LED lamps to emit light with a particular color is also of therapeutic importance for certain diseases. This would be the case, for example, of the sufferings associated with disturbance of the circadian rhythm. Pattison and collaborators also consider the potential of LED lamps in food production. In this regard, they note that in plants, which have a larger number of luminous receptors, light has a greater influence than that it has on humans. Thus, it could be possible to control the growth in greenhouses, of plants with characteristics chosen at will using LED light with a certain range of colors. Pattison and collaborators, LED lamps are not just more efficient light sources that will lead to significant energy savings. Beyond this, such lamps, with unprecedented flexibility to manufacture light sources with characteristics to choose from at will, will be a promoter of a technological revolution of similar reach to that produced by the incandescent lamps just over a century ago.",
    "https://upload.wikimedia.org/wikipedia/commons/5/57/Cara-oculta-luna.jpg": "As widely disseminated by the media, on January 3, China managed to gently pose a space probe with a ground explorer on board on the hidden face of the Moon. In the past, both the United States and the then Soviet Union carried out smooth landings, including those of the manned flights of the Apollo program. Such landings, however, occurred on the visible face of the Moon. We know that the Moon always presents the same face from Earth, because the period of translocation of the Moon around the Earth is exactly the same as its period of rotation.It is not difficult to understand that landing on the hidden face of the Moon presents more difficulties than doing so on the visible face. It is not possible, for example, to establish direct contact between the probe in the process of landing with the Earth control station to guide the descent since the Moon interposes between them. China solved this problem by placing a communications satellite in orbit around the Moon that served as a link point between the probe and the control station. In 2018, China was the country with the largest number of rocket launches that reached an Earth orbit, even above the United States, which was second in this respect:35 successful launches by China against 30 United States launches.All of this is, of course, consistent with the impressive economic development that China has had in recent decades, which has taken second place in gross domestic product, only behind the United States. China is expected to surpass the United States in this regard in the coming years. 200 years ago, China\u2019s domestic product was the largest in the world, compared to the United States, which was 15 times smaller. China\u2019s turbulence over the years of the nineteenth and twentieth centuries, together with the economic discontinuance of the United States in the first half of the twentieth century, caused this disparity to be reversed by the average of the twentieth century. In the years that followed, however, China grew at such a pace that it has made both economies feel the In addition to the tariff war that the President of the United States has unleashed in recent months, the New York Timeshabile newspaper has caused the possibility of a new economic cold war, in analogy with that which the Soviet Union and the United States held in the second half of the twentieth century. China\u2019s current rivalry with the United States is discussed in a series of articles published in December last year\u2019s MIT TechnologyReview magazine, published by the Massachusetts Institute of Technology. Among others, technological aspects relating to the manufacture of automobiles, microcircuits, nuclear energy, space exploration, quantum computing and communications are discussed. In particular, one of these articles argues against the possibility of a cold war being repeated. In that article, entitled \u201cThe United States and China are not in a cold war, stop calling it that way,\u201d it argues that the current relations between China and the United States are not similar to those prevailing between the United States and the Soviet Union during the original cold war. the article of marrassa has pointed out that at the time these two countries had independent scientific and technological systems to a great extent and that this is not the case today between the United States and China that have a great technological interdependence. They have it to such an extent that, for example, devices manufactured in China depend heavily on components manufactured in the United States and vice versa. However, aside from the technological interdependence between the United States and China, the latter country is making great efforts to develop technologically. In this regard, another of the articles appeared in MIT TechnologyReview refers to the manufacture of microcircuits. This manufacture involves highly sophisticated technologies that very few companies in the world possess and that have not been able to reach in their most advanced versions of Chinese companies. However, a paradigm shift in technology involving the design of microcircuits destined to artificial intelligence applications is opening the doors for them.In the same way, the irruption of electric cars with fewer mobile parts than their counterparts with internal combustion engines, and therefore simpler to manufacture, have opened opportunities for Chinese car companies. We could perhaps conclude that the twenty-first century will be the century of China, unless a catastrophe occurs. After all, as the editor of MIT TechnologyReview points out: \u201cWhen visiting China comes to mind the impression that Europeans will have had when visiting the United States a century ago \u2013 that of a land where everything is bigger and where everything happens faster, a place full of energy and ideas.\u201d",
    "https://upload.wikimedia.org/wikipedia/commons/5/50/Gregory_XIII.jpg": "It is now about to start 2019 and with this will not miss the good purposes for the new year, including those of losing weight, doing more exercise, quit smoking or drinking, and saving money. Bringing these purposes to a good end, which requires a great willpower, would certainly bring us great benefits. On the other hand, it is possible that the eve of the new year is not the best time to state our purposes of improvement, if we fail to look unconvincing. For example, if our intention is to lose some kilos of weight, the best proof that our desire is sincere is to moderate the intake of food during the so-called Guadalupe-Reyes bridge. Likewise, if our purpose is to save money, we should moderate our expenses during the feasting. Given the difficulty of achieving such goals, it is concluded that we may have to wait a few days to design our improvement plans.After all, we must take into account that the start date of the new year is a convention that does not have a firm basis, to say astronomical. The annual cycle of 365 days and something more certainly has, certainly has, , an astronomical base and corresponds to the period of rotation of the Earth around the Sun; the beginning of that cycle, in contrast, is a convention that varies from culture to culture. Thus, recognizing that the date for the beginning of the new year is relative, there is no compelling reason to wait for the new year in order to start an improvement in our lifestyle, which we could begin at any time. We should recognize, however, that we attach great importance to our conventions, which we end up with believing have a firmer basis than they actually have. In the years leading up to the end of the first millennium of our era, for example, it was predicted that the end of the world would come in 1000 AD, which would have caused a great dismay among the population of Europe. Although this latter is considered to be an exaggeration resulting from the nineteenth century \u2013 since, with exceptions, the population of Europe had no notion of the year in which it lived \u2013 in one way or another it was attached to the year 1000 AD. 2000 A.D., for which disasters were also anticipated at a global level of different types. The truth is that the predicted disasters did not occur, and this could have been anticipated by using common sense \u2013 at least from a modern perspective. Indeed, much of the world is governed by the Gregorian calendar, imposed by Pope Gregory XIII in 1582 in place of the Julian calendar. The Julian calendar assumed that a year consisted of 365.25 days and that the annual cycle began on 1 January. To simplify, that calendar considered 365 days years, interspersing a year of 366 days \u2013 bisiest year \u2013 every four years. The number of days that actually has one year, however, is slightly smaller than that assumed by the Julian calendar and this caused it to produce a 10-day lag with respect to the astronomical date. To correct this imbalance, the Gregorian calendar advanced ten days so that on Thursday 4 October 1582 of the Julian calendar happened on Friday 15 October. of 1582 in the Gregorian calendar. In addition, and with the aim of preventing future setbacks, the leap years that are multiples of 100 \u2013 for example, 1500 and 1700 \u2013 were eliminated, with the exception of the multiple years of 400 \u2013 for example, 1600 and 2000\u2013. Still, one day's adjustment every 3,300 years would have to be made. Of the above it is clear that the start date of a Gregorian year and the year itself depends on conventions and artificial rules that were established at a certain time. We could not expect, as it would be too pretentious of our part, that such or which date or year has special characteristics only by our decision. And that said, we can try to do justice to the coming year of 2019. It happens that this year is apparently one of the lot, without features worthy of notice. That is, it is not a year with which ends or begins a century; and not even a decade. And that is not a year with a bold combination of digits \u2013 for example, 1999\u2013. The lack of merit of 2019, however, is only apparent, since conventions aside, every year are exactly equivalent.In addition to these profound considerations, 2019 is for us and at this time a special year, for the simple reason that it is the one that is coming. And for which many of us will have amendment purposes, which, however, according to statistics, will fall into oblivion by 80 percent sooner than later.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d2/Wizard_title_page.jpg": "It is surprising to learn that the color of the Santa Claus costume, which today we would not hesitate to affirm is bright red, at some point it was green or a pale tan, among other colors. At what time did the transition of color occur? It has been said that the image we have today of Santa Claus, as a character with a large belly and white beard, dressed in a suit and sleeping cap in red and white colors, is due to Haddon Sundblom, who in the year 1931 was hired by the Coca Cola company to develop advertising images based on Santa Claus. According to this version, the colors of the Santa Claus costume would correspond to those of the corporate image of the Coca Cola. It is clear, however, although the advertising campaign of Coca Cola helped to establish the image that today we have of Santa Claus, this is actually previous to that campaign. Thus, for example, the cover of the December 1902 issue of \u201cPuck\u201d magazine shows a Santa Claus that coincides practically with the current image of the character, including the red color of the costume, the sleeping cap and At the same time and in contrast, the cover of the novel \u201cLife and Adventures of Santa Claus\u201d, published in 1902 by Lyman Frank Baum \u2013 the author of \u201cThe wonderful Wizard of Oz\u201d \u2013 shows a Santa Claus in green suit and cap, about to go down the chimney of a house with a bag of gifts on his shoulder. In the same way, the illustrator Thomas Nast, published in the magazine \u201cHarper \u0301s Weakly\u201d in the second half of the 19th century images of Santa Claus dressed in pale red or tanned costumes. We could thus conclude that Santa Claus does not always wear intense red \u2013 although Coca Cola has convinced us that this is so. This, certainly, is not what we would have expected from a character handed over to the children and that for the same reason we would seek to create an image that identifies him at first sight. Thus, one might wonder why Santa Claus would have to change his appearance, wearing some intense red and others of pale red or even green. Unless the apparent changes in the Santa Claus costume were made in the white beard. Claus were mere visual illusions, in which case the appropriate question would revolve around the causes of such illusions. To search for an answer we did an investigation on the Internet, finding a surprising number of entries in which Santa Claus\u2019s physics is analyzed. In one of them there is a possible answer to the question we are interested in. The information is hosted on the site EurekaAlert maintained by the American Association for the Advancement of Science for the dissemination of scientific news and was published by Kathy Sheen of Exeter University in the UK. According to this researcher, Santa Claus has to distribute gifts to some 700 million children in the world; and she has to do so in just 31 hours, taking into account the different time zones of the world. For this, she would have to travel at a huge speed. So great that the phenomenon known as the Doppler effect would have an appreciable influence on the apparent color of Santa Claus, her reindeer and her sleigh. In this regard, it is necessary to remember that the color of an object is a sensation produced by light that is reflected in that object and reachess our eyes. explanation, the Doppler effect is that by means of which the sound of the siren of an ambulance approaching at great speed sounds sharper than when the ambulance is at rest. Applying this to the Santa Claus suit and according to the laws of physics, a sharper sound corresponds to the green color while the red one is the most serious. So, when Santa Claus with his sled approaches at great speed the red color of his suit will appear to be green. When it stops, in contrast, it will recover its real red color. This would explain the discrepancy in the colors attributed to that suit by different illustrators. I would explain it, of course, assuming that the Santa Claus sled can accelerate to the required speeds, which does not seem to be a simple thing to achieve, among many other things because of the great amount of energy that would be required for such effect and that they would have to provide the reindeer of the sled. In these circumstances and at the margin of the Doppler effect \u2013 which has a real existence and a huge number of applications, from measuring the speed of an automobile to the speed of the orbit of an exoplanet\u2013, We would be tempted to admit that a more likely cause for the diversity of colors of the costumes attributed to Santa Claus is the great imagination of those who have given themselves to the task of representing it in graphic form. One way or another, what is not at issue is: 1) the great success that the advertising campaign of Coca Cola had that managed to eliminate from Santa Claus's costume those colors that did not reflect their own and 2) that the children, the main beneficiaries of the character, are careless about the way Santa Claus acquired their color.",
    "https://upload.wikimedia.org/wikipedia/commons/9/9c/Queen_Victoria_1887.jpg": "As we know, the Industrial Revolution, originated in England at the end of the 18th century, has had a profound impact that has changed \u2013 for better or worse \u2013 our way of life. The Industrial Revolution was driven by the scientific and technological knowledge accumulated in Europe since the 16th century and that, in the case of the former, had their most finished expression in the laws of mechanics and the theory of universal gravitation of Isaac Newton. In its first phase, during the first half of the 19th century, the steam engine and the development of the coal fuel industry, greatly multiplied the production capacity of the traditional industry and generated new jobs. The latter led to the exodus of the population from the countryside to the urban centres where the new industry settled. The Industrial Revolution caused social tensions between factory owners and workers who worked and lived in deplorable conditions, in an environment degraded by pollution and overcrowding due to rapid urban growth. Life in the industrial centres of Victorian England is described in the novels of the English writer Charles Dickens. In 1854, Dickens wrote about Coketown, the fictional city in which history unfolds: \u201cIt was a city of red brick, or brick that would have been red if smoke and ashes had allowed it; but as it was, it was a city of an unnatural red and black, like the painted face of a savage. It was a city of machines and high chimneys, from which endless smoke snakes would come out that never dissipated. It had a dark canal and a stream that dragged dirty and smelly waters, and numerous buildings with windows that resounded and resuscitated all day long, while the piston of the steam machines climbed and descended slowly, like the head of an elephant sick of melancholy.\u201d As for the living conditions in the Victorian era, Dickens exemplified them with worker Stephen Blackpool, who lived \u201cin the most industrial area of Coketown, in the most intimate fortifications of that ugly citadel, where Nature had been cancelled by a rare atmosphere.\u201d Blackpool was 40 years old in the novel, but he looked considerably older because of all the misfortunes and sufferings he had had to endure, including strenuous work days and his wife\u2019s alcoholism. Through his novels, Dickens dramatically describes to us, through fictional situations and characters, the social contrasts that occurred in England in the first half of the 19th century and the hardships that led to the least favoured majority. An equally dramatic description, but this one with real facts and characters, gives us the recent discovery of human skeletons carried out by the British company Wessex Archaeology in an old cemetery that was located in what is today the new market of Convent Garden in the city of London. The skeletons discovered correspond to the period from 1830 to 1850, when the site in question experienced in a few years a transition from a rural area to a heavily industrialized and urbanized one. The excavated skeletons show the harsh living conditions suffered by poor Londoners in the Victorian era. Specifically, Wessex Archaeology reports three cases. The first is that of an older woman who, despite a chronic illness of her entire life, had an exhausting occupation that required the heavy use of her arms and shoulders. The remains also showed characteristic signs of congenital syphilis, as well as a broken nose and loss of front teeth. As for the cause of her death, there is a suspicion that she was killed, as the skull shows a stabbing wound behind the right ear that would indicate that she was stabbed, probably from the back. A second case is that of a man with a stature of about 1.80 meters with a fully crushed nose and a depression on his left eyebrow, indicating that she was involved in severe altercations. One possibility in this regard is that she was a clean hand boxer. She suffered as well as syphilis, possibly acquired, and lacked frontal teeth. She probably died from the discovery. The third case is that of a two-year-old girl for whom there is no indication of the cause of her death, although there is evidence that she suffered from malnutrition. In any case, Wessex Archaeology notes that at that time the death of an infant was not unusual and that 40% of the bone remains excavated correspond to children under 12 years of age. Certainly, no one would doubt that Charles Dickens, who was a direct witness of the harsh living conditions that suffered the least favored in the Victorian era, would be missing the truth with his novels. It is to be impressed, however, that the discoveries of the Convent Garden cemetery give us direct evidence of these harsh conditions with real people and situations.",
    "https://upload.wikimedia.org/wikipedia/commons/5/5d/Newtons_laws_in_latin.jpg": "On Monday, November 26, NASA announced that the \u201cInSight\u201d probe had managed to lie gently on the surface of Mars after a seven-month trip. The \u201cInSight\u201d probe, weighing 360 kilograms, has as its mission to study the interior of Mars \u2013 which is little known, according to NASA. For this purpose, according to the American space agency\u2019s website, \u201cInSight\u201d has a highly sensitive seismometer that will allow it to detect seismic vibrations produced by the activity of the planet\u2019s interior or by the impact of meteorites on its surface. The \u201cInSight\u201d probe is also equipped with an instrument to study the temperature of Mars. In this regard, mission scientists are interested in finding out how the heat flows from the inside of Mars to its surface and in this way determine the materials that make it up. \u201cInSight\u201d also has a third instrument for the measurement of the globe that experiences the rotation axis of Mars as it moves along its orbit around the Sun. If the center of the planet is liquid or rocky, \u201cInSight\u201d is the sixth probe \u2013 all of NASA\u2019s \u2013 that has successfully landed on the Martian surface. Achieving this is not an easy undertaking. In fact, it has not even been easy to take a ship to the vicinity of Mars and of the more than half a hundred attempts to do so, more than half have resulted in failure, according to Wikipedia. To gently deposit a probe on the surface of Mars, as a first step it is \u2013 obviously \u2013 necessary to take it to its immediate vicinity. Mars seen from Earth is just a luminous point in the sky and certainly launching from Earth a ship that reaches it is not a simple undertaking. Among many other things, it should be taken into account that the journey would take months, so that we would have to calculate the position that Mars would have at the moment when the probe reached it and point our launch to that position. Otherwise, interplanetary trajectories are not drawn in a straight line. InSight followed a curved trajectory that progressively drove it away from the orbit. Once it arrived near Mars, the \u201cInSight\u201d probe separated from the module that housed it on the interplanetary journey and entered the Martian atmosphere. It did so at a height of 130 kilometers and at a speed of approximately 20,000 kilometers per hour. Interaction with the atmosphere slowed down this speed gradually, reaching about 1,400 kilometers per hour at an altitude of 11 kilometers above the Martian surface. At that time a parachute was opened to further decrease the probe speed, which reached about 200 kilometers per hour at a kilometer high. For the final approach to the surface of Mars, the probe lit retro-propellant rockets, touching land at a speed of about 8 kilometers per hour. Gently putting a probe on the surface of Mars is not to doubt an extremely difficult operation, and one must ask about the skills that have been developed to carry it out. First, we could ask ourselves about the essential knowledge to trace interplanetary trajectories and to achieve that a very difficult operation. The answer to this question is known by a student of elementary physics: part of such knowledge \u2013 although not all indispensable \u2013 is contained in the three laws of mechanics and in the theory of universal gravitation that Isaac Newton discovered in the 17th century. As regards gently posing an object on the Martian surface, knowledge of Newton\u2019s three laws and the theory of gravitation is equally crucial. Of course, space exploration needs, in addition to the laws of mechanics, numerous other scientific and technological knowledge. We need, for example, knowledge about electricity, magnetism and telecommunications, rocket technology, materials, power generators and computers, to mention just a few indispensable elements. Without the knowledge developed by Newton, however, it would have been impossible to gently pose to the \u201cInSight\u201d probe on the surface of Mars. Isaac Newton\u2019s contributions, on the other hand, are not reduced to having made it possible to send interplanetary probes and not even to the development of a huge number of ingenutures. far away from that, Newton\u2019s laws of mechanics \u2013 which apply equally to the fall of a mature apple from a tree that to the movement of a planet around the Sun \u2013 put in the same basket the terrestrial and celestial phenomena and with this changed the perception that one had of the Universe, according to which celestial phenomena were governed by physical laws different from those of terrestrial phenomena. And so they changed it, that nowadays the images that send us the inn probes on the Martian surface \u2013 including \u201cInSight\u201d \u2013 show us arid landscapes not too different from those that we have in some places on our planet.",
    "https://upload.wikimedia.org/wikipedia/commons/0/0c/Infrared_dog.jpg": "There is an alarm among experts about the increasing warming that the planet is experiencing by the emission of greenhouse gases into the atmosphere. And the degree of alarm has reached such a level that to mitigate such warming actions are being proposed that are looking desperate. As one of these actions has been proposed the dispersion of large amounts of sulphur dioxide in the lower part of the stratosphere to reduce the amount of solar radiation that reaches the surface of the Earth. As we know, we depend on solar radiation to maintain the temperature of the surface of our planet. Such temperature is determined by the balance between the solar radiation that is absorbed by the Earth, and the radiation that is re-emitted to space by different mechanisms. Through one of these mechanisms the surface of the planet emits infrared radiation that crosses the atmosphere and escapes into space. Certainly, it is not obvious that the Earth emits infrared radiation. This, however, is a physical law that we can easily verify by approaching the hand to an object with a temperature of a few hundred degrees centigrade \u2013 without touching it, of course. Earth is not apparent because its temperature is only a few dozen degrees Celsius. Such emission, however, is present, although it is relatively weak. The balance between the radiation absorbed by the Earth and the radiation emitted into space has been disturbed in the last two hundred years by the greenhouse effect produced by the accelerated use of fossil fuels. In this regard, we know that the burning of these fuels generates carbon dioxide that is incorporated into the atmosphere generating an air layer that reflects part of the infrared radiation; radiation that would otherwise escape space. Thus, in balance, more solar energy is retained by the Earth with the consequent increase in global temperature. According to all of the above, the preferred solution to mitigate the global temperature increase is the reduction of the concentration of carbon dioxide in the atmosphere, either removing it from it or controlling its emission in the future.However, as it is not obvious that this will occur in the short term, emerging measures such as the dispersion of sulphur dioxide in the stratosphere mentioned above have been proposed. This would contribute to stabilizing and even reversing global warming. Is it technically and economically feasible to artificially and significantly alter the Earth\u2019s energy balance? This is the case, at least according to an article published this week in the journal \u201cEnvironmental Research Letters\u201d published by Wake Smith and Gernot Wagner of Yale University in the United States. Wake and Smith were given the task of assessing the real possibility of dispersing in the stratosphere the amount of sulphur dioxide needed to halve the rate of growth that the Earth is experiencing by the emission of greenhouse gases. According to Wake and Smith, sulfur gases would have to be raised and dispersed at a height of 20 kilometres and for this purpose they analyzed all possible options, including commercial and research aircraft, military aircraft, air balloons and rockets. They ruled out commercial aircraft because they would not be able to reach the necessary height, nor even modifying them. Military fighter aircraft that could reach it but would not have the capacity to complete the mission. Hot air balloons could do the job but at too high a cost. The same is true for aircraft to fly at high altitudes developed by NASA and with rockets. Wake and Smith conclude that there is no suitable vehicle to disperse sulphur dioxide into the atmosphere at the moment and that it would have to be developed. According to Wake and Smith this could be done at a relatively low cost of about $2.350 million. Wake and Smith considered a 15-year program that would start in 2033. 95 aircraft would be built at a total cost of $9.5 billion plus $2.350 of prototype development, which would carry out about half a million operations. The total cost of the program for the 15 years, including the operation, would be about $36 billion. If Wake and Smith were correct, the cost of dispersing sulphur dioxide in the stratosphere in sufficient quantities to have a appreciable effect on the Earth's temperature is relatively low. It is highly controversial because of the side effects it could have. A decrease in solar sunshine, for example, would have a negative impact on agriculture and food production. Similarly, there would be less incentives to limit greenhouse gas emissions to the atmosphere, causing the problem that is intended to be solved. To reduce solar sunshine to solve the climate problem is then equivalent to, for example, taking pills to lose weight after an opiper meal. A solution in a desperate situation, no doubt.",
    "https://upload.wikimedia.org/wikipedia/commons/c/c5/Parque_estatal_Chugach%2C_Alaska%2C_Estados_Unidos%2C_2017-08-22%2C_DD_80.jpg": "Although there is everything in the Lord\u2019s vineyard, perhaps we would agree that the weather that we suffered in the past days was far from what we would have chosen to have given us the opportunity. Fortunately, the icy wave has withdrawn, although we will surely have to suffer more episodes of cold in the remainder of the winter season that is just beginning. In this perspective, we hope that some comfort will bring us to know that although from here on the arrival of spring some cold days await us, possibly they will not be more so than others that occurred in past times. In particular, in the year 536 of our era, which is considered by Michael McCormick, of the Harvard University\u2019s Department of History, as \u201cthe beginning of one of the worst periods to be alive, if not the worst year.\u201d This, according to an article published this week in the magazine \u201cScience.\u201d Is justified McCormick\u2019s opinion? Judge you. According to \u201cScience\u201d, in the year 536 a mysterious fog submerged in the darkness to Europe, the Middle Ages East and parts of Asia for 18 months. As a result, temperatures in the summer of that year fell between 1.5 and 2.5 degrees Celsius, starting the coldest decade in the past 2,300 years. Among other things, this brought snowfall in China during the summer, and impacts on agriculture in Europe with consequent famines. And, to complement the climate disaster, the bubonic plague epidemic known as Justinian Plague broke out in 541, decimating \u2013 in fact, strictly more than that \u2013 the population of the Byzantine Empire. The fog that obscured Europe in 536 has been attributed to a volcanic eruption of great magnitude that occurred in Iceland. To this conclusion came a team of researchers headed by McCormick and Paul Majewski, the latter from the University of Maine, through a study of ice samples collected from the Colle Gnifetti glacier in the Swiss Alps. How can glaciers account for events that occurred centuries ago? It is possible since glaciers accumulate ice over time, which trap particles and chemical substances. The presence of these substances at a certain depth in the ice then reveals their presence in a past time. Thus, the study of the ice of glaciers can reveal events that have occurred in remote times as they have generated substances that have in turn been expelled into the atmosphere and transported to a glacier. Experts can date a certain event by the depth of the ice layer in which their traces appear; this, from knowing the speed with which that layer was formed over the centuries.McCormick and collaborators studied ice samples from the Colle Gnifetti glacier with a technique of great precision that allowed them to conclude that in the first months of 536 a volcanic eruption occurred that dispersed ashes to that glacier.This eruption would then be the main suspect of causing the darkness that struck Europe for 18 months with the catastrophic consequences described.On the other hand, despite the magnitude of the climate disaster, its consequences were overcome in This is also written in the ices of the Colle Gnifetti glacier. In this case, not by traces of volcanic ash, but by evidence of air pollution by lead. The above is discussed in an article published in the magazine \u201cAntiquity\u201d by McCormick and collaborators, which reports a study carried out with ice samples from the Colle Gnifetti glacier. Among other results, researchers found that air pollution by lead increased substantially in the year 640 of our era. McCormick and collaborators attributed the increase in air pollution by lead to a substantial increase in mining activities for the extraction of silver from lead-containing galena minerals. Silver was intended for the manufacture of coins and the increase in its production reveals an increase in commercial activities. It thus indicates a recovery of the European economy from climate calamity. It teaches us two things. First, that the history of the world can be read in surprising places and until recently unsuspected. . It also teaches us that our ancestors suffered from cold weather and harsh weather considerably more severe than those we can suffer in this city, and that despite this they survived as a civilization and as a species. Although, thinking better, the latter may not serve as great comfort in the midst of a cold wave.",
    "https://upload.wikimedia.org/wikipedia/commons/9/9b/Strasbourg_Observatory.JPG": "On October 19, 2017, Robert Weryk, a postdoctoral researcher at the Pan STARRS Astronomical Observatory at the University of Hawaii, noticed in the firmament about 30 million kilometers away an otherwise unusual object. So much so that it turned out to be the first known object from somewhere outside our solar system. Given the circumstances, he was baptized as \u0301Oumuamua, a name of Hawaiian origin that roughly means \u201cfirst distant messenger\u201d. It is estimated that \u0301Oumuamua has a cylinder shape about 230 meters long and 35 meters wide. Of this, however, there is no security because we do not have a visual image of him because of the great distance he was seen. How do we know that \u0301Oumuamua is an interstellar object? We know that by the great speed at which he travels that is not typical of the objects of the solar system. For this speed he cannot be retained by the gravitational force of the Sun, so inevitably he will abandon us after his brief visit. We know that orbiting around the Sun, apart from the solar system. The latter usually have very eccentric orbits that distance them and bring them closer to the Sun periodically. We also know that comets can become very eye-catching during their approach to the Sun, when they develop a tail that can cover much of the sky. This tail is formed by gases and dust particles expelled from the surface of the comet by the warming that they experience as they approach the Sun. Asteroids, in contrast, do not develop a tail since they are formed by materials that are not vaporized by the heating by the solar radiation. Although at first it was classified as a comet by an international group of researchers headed by Marco Micheli of the European Space Agency, having not developed a tail when approaching the Sun was reclassified as asteroid. An article appeared last July in the magazine \u201cNature\u201d, however, has cast doubts about it. In that article, published by an international group of researchers headed by Marco Micheli of the European Space Agency, it is reported that \u0301Oumuamua suffered a greater acceleration than expected only by the Sun\u2019s force. To explain it, Michel and collaborators postul that, after all, \u0301Oumuamua behaves like a comet and suffered an additional force to that of the Sun by vaporization and emission of substances from its surface.This, by a mechanism similar to how a rocket is driven by gases escaping from its engines.An alternative explanation, which repositions \u0301Oumuamua in the category of asteroid, is offered in an article published this week in the ArXiv repository of manuscripts, hosted by Cornell University. The authors of that article \u2013which has been accepted for publication in the journal Astrophysical Journal Letters \u2013 are Samuel Bialy and Abraham Loeb of Harvard University. According to Bialy and Loeb, the cause of the additional acceleration experienced by \u0301Oumuamua is directly the solar radiation, which, when \u201cshocked\u201d with the asteroid, slows it when it approaches the Sun or drives it forward when it moves away from it. It is known that the force exerted by solar radiation on an object is a real effect, analogous to the force exerted by the wind against the candle. Bialy and Loeb speculate that \u0301Oumuamua has the shape of a thin sheet with a thickness of a fraction of a millimeter, which allowed him to take advantage of the impulse of solar radiation as do the sailboats.Bialy and Loeb, however, do not merely offer an alternative explanation for the additional acceleration experienced by \u0301Oumuamua and speculate \u2013 but do not claim \u2013 that it could be an artificial structure built by an alien civilization outside our solar system.According to this hypothesis, \u0301Oumuamua could correspond to the debris of an out-of-operation space ingenuity, or it could be a fully operational ship that uses the radiation of the stars to boost itself.This is an exotic explanation \u2013 at the same time attractive \u2013 that has naturally provoked negative reactions from the community of experts. Thus, for example, Marco Micheli notes that the hypothesis about the impulse of solar radiation was considered in his article of Nature, reaching the conclusion that it is highly unlikely because this would imply that the weight of \u0301Oumua The discussion between scientists about hypotheses and results, moreover, is normal and part of their professional practice. Finally, to be accepted, a hypothesis has to be validated by the results of experiments designed for that purpose. In the case of \u0301Oumuamua, it must be recognized that this will be difficult to achieve because it has disappeared in the firmament for many months. However, if the visit of another similar object occurs \u2013 hoping that it will receive a name easier to remember \u2013 \u0301Oumuamua will serve as a reference and we will be better prepared to understand its meaning. It should be understood that the hypothesis about the alien origin of \u0301Oumuamua is that, a mere hypothesis without firm support. And yet, as a scientific hypothesis may be, it would be as valuable as it could be.",
    "https://upload.wikimedia.org/wikipedia/commons/7/7f/Manhattan_panorama_under_clouds.jpg": "The archaeological site of Santa Ana/Florida was discovered in 2002 by a team of Ecuadorian and French researchers in the province of Zamora Chinchipe in the south of Ecuador. This site corresponds to the so-called Mayo-Chinchipe culture that flourished in the Chinchipe river basin in the upper Amazon 2,500-5,500 years ago. Santa Ana/Florida constituted a ceremonial center with a circular central square of 40 meters in diameter, bounded by a double stone wall, a necropolis, two elevated platforms and a circular temple for performing ceremonial activities. In addition to building builders, the inhabitants of Santa Ana/Florida were skilled manufacturers of stone objects and ceramic containers. As proof of this, among the objects excavated on the site is a bottle with a handle of stylized human faces of great perfection. Another object excavated is a partially closed container with four legs and a human head emerging from one of its ends, with very large eyes, a bulging cheek and the mouth of a sharp. According to Francisco Valdez of the Research Institute for Development in France, one of its discoverers, Santa Ana/Florida demonstrates that the Amazon was a seat of civilizations with a high degree of sophistication. This, contrary to the belief that the conditions in that region are too inhospitable for the development of human groups with cultures beyond that of simple nomadic hunter-gatherers. The fact that the Mayo-Chinchipe culture has also flourished 5,000 years ago is undoubtedly doubly surprising.Not for that reason, however, because an article appeared this week in the journal Nature Ecology and Evolution states that it was the Mayo-Chinchipe culture that first made use of cocoa as food. This, contrary to the widespread belief that it was in Mesoamerica where the cocoa plant was domesticated for the first time. This article was published by an international group of researchers headed by Sonia Zarrillo of the University of Calgary in Canada. We know that among the Mayans, Among the latter, cocoa beans were used even as a currency and for the payment of tribute by the conquered peoples. There is also evidence of the consumption of cocoa in Mesoamerica, specifically on the coast of Chiapas, as early as 1,900 years before our era. There were therefore reasons to believe that cocoa originated in Mesoamerica. It would not have been so, however, at least according to Zarrillo and collaborators. These researchers base their conclusions on three independent studies of finding cocoa remains carried out with various objects found in Santa Ana/La Florida. These objects include cazuelas, jars and ceramic bottles, as well as stone cazuelas and mortars. It was also in the interest of Zarrillo and collaborators to study the residues found in the ceramic container bottom. Cocoa remains were searched through DNA analysis, as well as by chemical analysis of the cocoa characteristics that would have penetrated the porous walls of the containers that contained them. As a result of their studies, Zarrillo and collaborators found a characteristic cocoa substance in 25 ceramic objects and 21 stone objects. They also found that six of the objects analyzed contained starch grains from cocoa. Regarding DNA studies, these also support the presence of cocoa in Santa Ana/La Florida. To reinforce these results, the researchers note that three of the objects analyzed positive the presence of cocoa in the three independent tests that were applied to them, while 17 objects did so in at least two. Thus, the consumption of cocoa in the upper Amazonia was solidly tested. From their study, Zarrillo and collaborators concluded, moreover, that the patterns of consumption of cocoa in Santa Ana/La Florida were prolonged at least from 5,300-2,100 before the Christian era. This implies that cocoa was consumed in the upper Amazonia 1,500 years before it was consumed in Mesoamerica. If Zarrillo and collaborators were correct, Mexico would lose its status as the place where it was located. This is not something we would have wished for, nor is it catastrophic. If, on the other hand, it is regrettable that a country like ours, which in one way or another spread cocoa all over the world, today does not profit from its cultivation. That does not prove it the statistics of world-wide cocoa production dominated by African countries \u2013 which did not have it four centuries ago \u2013 with Mexico occupying a very distant eighth place. Although in our discharge we could argue that, while the original inventors of cocoa-based drinks declined as a civilization long ago despite all their advances, we continue in the struggle with everything and our problems.",
    "https://upload.wikimedia.org/wikipedia/commons/2/2e/Mercedes-simplex-508.jpg": "In these times of unprecedented technological change, a revolution at the door is that of self-employed vehicles that are driven without a driver on board. Given the complexity of vehicle traffic, this revolution will inevitably cause accidents, some of them with serious consequences, even fatal, for the people involved.In this perspective, questions have arisen as to how autonomous vehicles should be programmed to respond to an emergency situation.An autonomous vehicle, for example, could confront a situation in which when circulating on a high-speed avenue it encounters a person crossing the street recklessly, having to choose between two options: to continue front-and-forward, or to turn sharply and crash against an obstacle risking the life of its passengers. The autonomous machine will thus find itself faced with the choice of those who have priority to get out of the accident that could have fatal consequences. In these circumstances, how should autonomous vehicles be programmed to handle emergency situations in which one inevitably has to choose between saving or condemning such a person or which person? Will children have priority over adults? Will the autonomous machine have the obligation to minimize the number of victims? The answers to these questions are not simple and to help find them a group of researchers from the Massachusetts Institute of Technology led by Iyad Rahwas, designed an online platform that was baptized with the name \u201cMoral Machine\u201d, by means of which it collected about 40 million opinions regarding people from 233 countries and territories in the world. The results of study with the \u201cMoral Machine\u201d were published this week in Nature magazine. To carry out its task, the platform \u201cMoral Machine\u201d presents to the user 13 situations in which an autonomous vehicle without brakes advances towards people crossing a street. In all cases the vehicle has two possibilities to act: to follow front or turn sharply, both with fatal results. In each situation the platform asks the user their opinion on which of the options to choose the vehicle. Thus, the platform confronts the user with a dilemma that involves, for example, deciding whether women have priority over men, or whether the The platform also confronts the user with the dilemma of deciding whether the self-employed vehicle should act in a way that minimizes the number of victims. By way of example, in a situation presented by the \u201cMoral Machine\u201d an autonomous vehicle moves directly towards a group of three women crossing the street, one of them overweight. If the vehicle does not deviate its course it will run over the three women with fatal results. The option is to turn to the left, in which case the vehicle will crash against a concrete barrier by killing its three female occupants, two of them athletes \u2013 and therefore in an excellent physical condition, in contrast to the overweight woman.The results of the study by Rahwas and collaborators were expected in some respects and surprising in others.For example, hopefully they find that the platform users showed a strong tendency to save young people to the detriment of people globally. The future will tell us on what basis the automotive companies will design their self-contained vehicle control programmes. As long as this is resolved, it is appropriate to take note of some of the results of the study by Rahwas and collaborators that reveal the dangers to which we are exposed when walking the streets and how these dangers depend on our gender, age, social condition and even overweight. Although little or nothing we can do to minimize most of these risks, at least we could consider putting ourselves in a better physical condition. Which, on the other hand, is intrinsically healthy.",
    "https://upload.wikimedia.org/wikipedia/commons/c/c1/Klassieren.jpg": "Within the framework of the Paris climate agreement of 2015, 195 countries agreed to seek to limit the global temperature increase to a value well below 2 degrees Celsius with respect to its pre-industrial level, making efforts to ensure that the increase did not exceed 1.5 degrees Celsius.This, in order to avoid a global climate catastrophe.As part of the Paris climate agreement, the Intergovernmental Panel on Climate Change (IPCC) of the United Nations received an invitation to prepare a report on the effects that would result in a global temperature increase above 1.5 degrees Celsius. The IPCC accepted that invitation and as part of its response it released on 8 October the first of three papers that it has prepared on this topic, comparing the two scenarios that would arise with increases of 1.5 and 2 degrees Celsius of global temperature. According to the IPCC report, limiting the temperature increase to 1.5 degrees Celsius would significantly reduce the rate of growth of the ocean level, as well as the thawing of the polar caps. If we limit the warming to 1.5 degrees Celsius, it will survive between 10% and 30% of coral reefs, which would almost disappear if the increase reached 2 degrees Celsius. Thus, according to the IPCC, it is essential to carry out a rapid transformation in terms of \u201cland, energy, urban infrastructure and industrial systems\u201d to limit the emission of atmospheric pollutants causing climate change. A strategy for energy transformation is the substitution, as far as possible, of fossil fuel-based energy sources by renewable energy sources. In this regard, wind and solar photovoltaic energy are currently playing a central role. Wind energy can be harnessed using windmills that transform wind energy into wind energy that rotates the mill\u2019s blades, and from it into electric energy by means of electricity generators. Photovoltaic cells, on their side, capture solar radiation and transform it directly into electric energy. The solar panels, for example, absorb a certain amount of the solar radiation that affects them and that would otherwise have been absorbed by the environment. Such radiation is converted into electricity that is sent by means of a transmission line to another location where it is consumed, generating heat that is dissipated in the environment. Solar panels thus contribute to regional cooling around the solar installation and to a warming in the place where the electric energy they produce is consumed. However, given that in some regions the temperature would rise while in others the overall effect would be much lower than at the regional level. Windmills, on the other hand, slow the wind speed that affects their aspas and thus alters the exchange of heat and humidity between the surface of the earth and the atmosphere. According to the experts, this produces a rise in temperature around the installation area of the earth and the atmosphere. This effect is the subject of an article that appeared online last October 4 in the magazine Joule whose authors are Lee Miller and David Keith of Harvard University. Miller and Keith proposed to study the effect that, on the ambient temperature, the installation on the continental territory of the United States of windmills in sufficient quantity to generate all the electrical energy consumed by that country. Interestingly, they find that the operation of these mills would increase by 0.24 degrees centigrade the ambient temperature at the level of the entire territory of the United States. Miller and Keith note that this increase in temperature is much greater than the decrease of 0.1 degrees centigrade that is estimated to be achieved by eliminating all installations in the United States that generate electricity by means of fossil fuels. Thus, far from helping climate change, windmills would aggravate it. Certainly, this situation would become less unfavorable as the burning of fossil fuels was eliminated and greenhouse gas emissions decreased. The point of equilibrium from which the use of wind energy would be advantageous, however, would only occur. At the end of this century, wind power would not be the ideal short-term solution to the problems of climate. In contrast, Miller and Keith note that the climate impact of photovoltaic solar energy is ten times less than wind energy, which would make it a more favorable option. On the other hand, and without a doubt, the issue is controversial because of the complexity of climate phenomena. It would seem, however, that photovoltaic solar energy brings wind power an advantage as a solution to the climate problem. At least if we are to believe the results of Miller and Keith.",
    "https://upload.wikimedia.org/wikipedia/commons/2/24/LA2-NSRW-1-0149.jpg": "An article published this week by Paul Mitchell of the University of Pennsylvania in the online magazine PLOS Biology shows us how much our perception of the racial diversity of the planet has changed, in just a century and a half. In that article, Mitchell discusses the research carried out by Samuel Morton, a well-known American physician and anthropologist of the first half of the 19th century, on the level of intelligence of the different human races. Morton was interested in determining the cranial volume of human races and for this purpose was given the task of gathering skulls from all over the world. His efforts crystallized into a collection of some 600 skulls that could be studied. To determine the volume of a skull, Morton poured white pepper seeds to fill it and subsequently mediated the volume of seeds by means of a graduated vessel. In subsequent experiments, and with the aim of obtaining more accuracy in his determinations, Morton replaced the seeds with lead ammunition. Morton published his results in three books, the first of which was titled \u201cAmerican Crania\u201d and appeared in 1839. Morton published his findings. Ton considered five races: Caucasian, American, Mongoloid, Malaya and Ethiopian (African) and of his measurements he found that the Caucasian race has on average the highest cranial volume and Ethiopian the minor. An idea in vogue at the time held that the cranial volume was a measure of the level of intelligence. Thus, Morton concluded that the white race is superior to all others and that the African race is at the bottom of the scale of the intellect. Morton\u2019s conclusions today have no sustenance and are considered to be the result of his racial prejudices, much in accordance with the time he had to live. Among other things, it is criticized that Morton has not considered that the size of the skull depends on the size of the body and that it in turn results from an adaptation to the environment. Likewise, today, there is no support for the division of races considered by him. In an article published in 1978 in the magazine \u201cScience\u201d, the paleontologist and American scientific divulderator Stephen Jay Gould brings out Morton\u2019s work and accuses him of having interpreted his measurements in a trampocious way. . He comes to this conclusion by comparing the cranial volumes obtained using pepper seeds with those that throw the lead munitions that turn out to be larger. He finds, moreover, that the discrepancy is greater for African skulls than for Caucasians and that this could have been due to Morton having poured more seeds into Caucasian skulls \u2013 presumably shaking them to settle \u2013 than into the skulls of other races. This, Gould speculates, would have done unconsciously, driven by his conviction in the superiority of the white race. Paul Mitchell, however \u2013 in the reference mentioned at the beginning of this article \u2013 argues that there are not enough cranial volumes obtained by means of pepper seeds that can be directly compared to volumes obtained by lead munitions, so that we cannot reach a definitive conclusion about Morton\u2019s possible measurement errors. Mitchell reaches this conclusion by analyzing manuscript notes from Morton on the results of his measurements and that they were not from Gould's knowledge.Mitchell concludes, however, that Morton's research Ton were strongly influenced by their racial prejudices and in this regard cites the case of the German anatomist and physiologist Friedrich Tiedemann who in 1836 published an article in which he reports measurements of cranial sizes with 248 skulls of five racial groups. Tiedemann finds results similar to those of Morton but his interpretation is diametrically opposite and concludes there is such dispersion of cranial volumes among human beings \u2013 so that an American may well have a bigger head than a European\u2013 that cannot be said on this basis that there are differences of intelligence between races. Undoubtedly Morton had racial prejudices. To prove it enough to read what he wrote in \u201cAmerican Crania\u201d with respect to the Caucasian race: \u201cThe Caucasian race is characterized by a naturally clear skin, susceptible of all dye. Long and curly combed and of various colors. The skull is large and oval, and its former portion is full and elevated. The face is small in proportion to the head, oval in shape, with well proportionate features. This breed is distinguished by the ease with which it obtains the highest intellectual achievements.\u201d The above in contrast to its opinion with respect to Native Americans: \u201cThe American race is marked by a brown complexion, long hair, black and white hair, and deficient beard. Tall cheekbones, large nose and aguile\u00f1a, large mouth and swollen lips. The eyes are black and deep, the eyebrows low. The skull is small, wide in the parietal bumps, prominent in the vertex, and flat in the occipucio. The character of Native Americans is reluctant to learn and slow to acquire knowledge. It is restless, vengeful and fond of war, and totally contrary to maritime adventures.\u201d Certainly, in 150 years much has changed our racial prejudices; although there are still some resabios of the past as we know well.",
    "https://upload.wikimedia.org/wikipedia/commons/5/5a/PUERTADEMAR.jpg": "For 2,500 years the Mayan civilization flourished in an extensive region of about 400,000 square kilometres, located in the south-east of Mexico, Guatemala, Belize and parts of Honduras and El Salvador. As we know, and for reasons that are not yet clear to archaeologists, the Mayan civilization went into decline towards the end of the first millennium of our era, moving the population towards the north of the Yucatan peninsula. As a result, the cities of the lowlands were abandoned and eventually swallowed by the jungle.As far as the Pet\u00e9n region is concerned, in the center of the Mayan area and during the so-called classical period, cities such as Tikal, Calakmul, Naachtun and Palenque flourished, hidden by vegetation until relatively recent times. Some until the twentieth century, as is the case of Calakmul and Naachtun. The situation of the Mayan cities of Pet\u00e9n, buried by the jungle, have naturally made it difficult for archaeologists to unearth the elusive secret secrets they conceal, including the lifestyle of their builders. is. Fortunately, the technology has come to your aid. In a precise way, it has been done by the technique known as LIDAR \u2013 the acronym of the English expression \u201cLaser Imaging Detection and Ranging\u201d \u2013 that allows you to see through the mantle of trees and discover buildings and constructions hidden by it. LIDAR technology allows you to measure the distance to which an object is located by means of a laser beam pointing to that object. Basically, the LIDAR technique measures the time it takes for the laser light to reach the object and return to the starting point after it is dispersed by it. That is, it measures the time it takes to produce the \u201ceco\u201d of the luminous ray. Knowing the speed at which the light travels, the distance to the object can be determined from that time. Sound echoes are phenomena that are familiar to us since the delay time between the production of sound and its return to the starting point after being reflected by an object is typically seconds or fractions of second, time that we can easily perceive. They are impossible to perceive because the speed with which the light travels is almost a million times greater than that of the sound. Thus, it seems to us that the light goes and returns instantly. It is not so, of course, as we can verify through the use of specialized instruments, one of which is precisely the LIDAR. An article published this week in the journal Science, published by an international team of researchers headed by Marcello Canuto of Tulane University in New Orleans, shows us reliably the possibilities offered by LIDAR for archaeological research. In that article, the results of a study carried out by LIDAR in 12 archaeological sites in Pet\u00e9n, including Tikal and Naachtun.Canuto and collaborators employed a LIDAR device mounted on an airplane that flew over the study area and directed the beam of a laser towards the treetops as it tracked that area and measured the time it took by the light beam to return to the point of departure. If the treetops constituted a barrier. Insurmountable to light, the reflected beam could not reveal anything that was hidden beneath such cups. Fortunately, it is known from experience that some of the light is able to penetrate through the hollows that leave the leaves of the trees and reaches the ground, producing not only an echo but several according to the obstacles it encounters on its way. An analysis of the different luminous echoes can thus give information about hidden archaeological structures to the naked eye. And this is precisely what is shown in his article Canuto and collaborators who traced a total area of 2,144 square kilometers, identifying 61.480 old structures that include buildings of various types, as well as military fortifications, agricultural terraces, roads, canals and water deposits. A large amount of information can be deduced from these data. For example, Canuto and collaborators estimate between 150,000 and 240,000 the number of inhabitants in the area studied in the late classical period. Extrapolating the entire Maya area of lowlands in Guatemala, Belize, Campeche and Quintana Roo, researchers estimate that it was inhabited between 7 and 11 million people. And more important for the light, the light, the light beam reflected beam could not reveal that it could not reveal anything that was hidden below these cups. Perhaps the researchers conclude that the results of their study \u201csupport unambiguously the notion that the Maya of the lowlands built variable and combative space in which a network of densely populated and defended cities was supported by a series of agricultural practices that optimized the productivity of the land, the diversity of resources and the sustainability on a scale much larger than what has been considered so far.\u201d Science and modern technology that results from it thus gives us a further demonstration of its power to investigate the past. In this particular case, facilitating the task to archaeologists by providing them with a tool to carry out a detailed study of the archaeological sites of Pet\u00e9n, which would have meant a considerably greater effort using traditional methods. Study that, moreover, has evidenced the high degree of development reached by the Mayas of the lowlands.",
    "https://upload.wikimedia.org/wikipedia/commons/9/9d/Archaeocyatha.jpg": "Dickinsonia are undoubtedly strange animals, both by name and physical appearance. As far as the name is concerned, there is an explanation: this was imposed on them by their discoverer, Australian geologist Reg Sprigg, in honor of his boss, Ben Dickinson, then Director of Mines of Southern Australia. It should be added that the fossils of Dickinsonia, more than 550 million years old, were discovered by Sprigg in 1946 in the Ediacara mountains in southern Australia. But apart from an unusual name, the Dickinsonia also had an unusual appearance, as evidenced by the rock impressions that these organisms have left and that have been discovered by paleontologists in various places on the planet. Dickinsonia had an oval body divided into approximately symmetrical and segmented parts in a cross-section. They did not have a digestive system, so they could absorb their food through their lower face anchored in a bed of bacteria. This article was published by a group of experts, and was published by a group of experts in the journal Science, convincingly supporting those who claim that Dickinsonia is a member of the animal kingdom. It was published by a group of experts, and it was published by a group of experts, with a skeleton or shell, and reached sizes from a few centimeters to a meter and a half. In order to have a more complete description of the strange aspect of the Dickinsonia, a good number of Internet sites can be consulted with photographs of the traces they have left. About 540 million years ago Cambrian period began, during which there was an explosion in the diversity of life on Earth that in the next hundreds of millions of years led to the appearance of the higher animals. Dickinsonia predates the explosion and in this context paleontologists have had difficulty placing them in the evolutionary line of life. In fact, it has been discussed whether Dickinsonia were animals, plants or even a species of giant amibas. It has also been discussed whether they constitute a direct history of the life forms that developed in the Cambrian period, or whether they were an evolutionary experiment. The basic problem was that in the 550 million years that had passed, the alleged organic materials would have been broken down without leaving a trace. Bobrovskiy and collaborators, however, were not very convinced that it would be successful. The basic problem was that in the 550 million years that had passed, the alleged organic materials would have been broken down without leaving a trace. Bobrovskiy and collaborators, however, were not on the hunt for the original organic compounds but the product of their decomposition. That is, they were looking for the \u201cfossil\u201d remains of those materials. And to the surprise of all, they found them. As Bobrovskiy relates in an interview, in order to obtain the fossil remains for his study \u201che had to travel by helicopter to a remote region of the White Sea in northern Russia,\u201d and once there \u201cgo down roped by the edge of a cliff to shed stone blocks, throw them down, wash them and repeat the process until he found the fossils he was looking for.\u201d Once he got his samples, Bobrovskiy returned to Australia to analyze them. For this purpose he learned a very thin layer of the fossil surface and subjected it to sophisticated chemical analysis. These analyses identified the presence of organic materials that indicated that the original tissues of the organism that produced the fossil contained cholesterol molecules, which demonstrated that the organism belonged to the animal kingdom. Thus, Bobrovskiy and collaborators point out, the 558 million-year-old Dickinsonia become the oldest animals on the face of the planet whose existence has been demonstrated. They also conclude that \u201cthe presence of Dickinsonian animals reaching sizes of 1.4 meters reveals that the appearance of a pre-camber biota in The fossil record is not an independent experiment with large-body animals, but a prelude to the Cambrian explosion of life.\"And on our side, seeing the bulls from the barrier, it is only possible for us to be amazed that it is possible, using the methods and techniques of science \u2013in addition to the determined will of a researcher \u2013 to obtain information about the nature of organisms that lived in an inconceivably distant time and that by their appearance we would think from another planet. So we would think of it not being because we now know that they are probably an essential part of an explosion that has had an impact to the present.",
    "https://upload.wikimedia.org/wikipedia/commons/2/2c/Fixed_Tilt_Solar_panel_at_Canterbury_Municipal_Building_Canterbury_New_Hampshire.jpg": "Do you consider that you have changed the climate in the city of San Luis Potos\u00ed in recent decades? In particular, do you consider that today there are more hot days than there were twenty years ago? If you think so you would agree with Climate Impact Lab, an organization that brings together specialists in climate science from the University of California, Berkeley, the University of Chicago and Rutgers University. Indeed, according to an analysis of Climate Impact Lab, while in 1985 we would expect there to be in San Luis Potos\u00ed about 2 days a year in which the ambient temperature will reach or exceed 32 degrees Celsius, we should now expect that there will be about 12 days a year with these temperatures. In addition, the number of hot days in San Luis Potos\u00ed will continue to increase for the rest of the century, so that in 80 years we can expect about 40 days with temperatures of at least 32 degrees Celsius. All this information is available on an interactive website of the New York Times newspaper. The progressive growth of the number of hot days is, of course, as a result of the climate change that is at least 32 degrees Celsius. The United States, the second largest emitter of greenhouse gases after China, withdrew last year from the agreement reached by 196 countries at the Paris climate summit in 2015. The agreement seeks to limit the increase in global temperature by 1.5 degrees centigrade with respect to its pre-industrial values of two hundred years ago. It should be noted, however, that this increase today reaches almost a centigrade degree and could reach the limit of 1.5 degrees set by the Paris agreement in the next five years.This, according to the United Kingdom weather office.The attitude of the United States federal government with regard to climate change, on the other hand, contrasts with that of the state of California that has issued laws that seek to drastically limit greenhouse gas emissions.In this regard, the California legislature adopted last Tuesday a law requiring that by 2045 100% of the electricity generated in the state be by Global warming is certainly a problem whose solution must be met by all countries of the world, particularly the industrialized countries. California\u2019s example, however, is important because it is the fifth economy in the world \u2013 only surpassed by the United States, China, Japan and Germany \u2013 and it is a fertile ground for the development of technologies and strategies of global importance. In California, electricity is generated by 43% of thermoelectric plants that consume natural gas, while renewable energy generates around 30%. The remaining percentage is generated mainly by nuclear power plants and large hydropower plants. Renewable energy includes small hydropower plants, biomass, geothermal power, wind power and solar power. Wind energy contributes with just over 6% of electricity generated in California. Solar energy, while its contribution was virtually non-existent in 2008, grew steadily to 12% from that date. wind panels do not generate greenhouse gases during their operation, they are very attractive sources of energy to attack the climate problem. In particular, photovoltaic panels generate electricity directly from the energy of the sun so that they turn out to be perhaps a more natural option. Solar and wind energies, however, have the disadvantage of their intermittance. Thus, solar energy is not available during the night and its intensity can decrease substantially on cloudy days, as well as it varies significantly throughout the year depending on latitude. Thus, to provide a stable flow of electrical energy it is necessary to complement solar panels and wind turbines with means of energy storage. Electric batteries are the natural means for this purpose. Such batteries, however, are expensive and have a short operating life. In these circumstances, photovoltaic and wind plants have to be supplemented by traditional means of electricity generation in order to provide electricity when solar panels or wind turbines cannot do so. electric power from sources free of environmental pollution will be excessively expensive, at least with current energy storage technologies. Moreover, possibly all these considerations would be inconsequential in the decades to come if the world did not take the example of California and implement effective global agreements to combat climate change. And given the worst auguries, our descendants would have to get used to living among heat waves. As well as cold, global warming causes extreme weather events in multiple directions.",
    "https://upload.wikimedia.org/wikipedia/commons/7/72/Battle_of_Waterloo_1815.PNG": "It is said that Napoleon Bonaparte considered his wife Josefina to be his star of good luck and that he carried an image of him in his military campaigns. Whether this story is true or false, what we do know is that luck was not on Napoleon\u2019s side in the battle of Waterloo. That battle took place in the month of June 1815 \u2013 when, by the way, he had already divorced Josefina \u2013 and in it he suffered a severe defeat that marked the end of his days in Europe. Certainly, luck was not on Napoleon\u2019s side in the battle of Waterloo. Or perhaps more appropriately said, the climate did not stand on his side and yes on the side of the English and Prussians. Indeed, according to an article published in June 2005 in Weather magazine by Dennis Wheeler and Gaston Demar\u00e9e, on June 17, 1815 and the first hours of the following day it rained intensely in Waterloo, leaving the battlefield turned into a muddy. This made it difficult for the French troops to act that delayed the start of hostilities, giving time for the arrival in Waterloo. The bad weather would thus have influenced decisively the outcome of the battle and marked the course of Europe for the next hundred years. With regard to the weather conditions that prevailed the night before the battle of Waterloo - which began at 11:20 hours on June 18th - and the consequences that they brought, Wheeler and Demar\u00e9e quote Victor Hugo who in Los Miserables writes: \u201cHad not rained on the night of June 17-18, 1815 the future of Europe would have been different...An unusual cloudy sky was enough to cause the collapse of a world.\u201d That the unusual climate was one of the factors that determined the outcome of the battle of Waterloo is a conclusion that is supported by an article published this week by Matthew Genge of Imperial College London in Geology magazine. Genge associates the heavy rains with the eruption of the Tambora volcano on Sumbawa Island in Indonesia \u2013 the most powerful ever recorded \u2013 two months before the Battle of Waterloo. The obstruction of sunlight by floating ash caused 1816 to be known as \u201cthe year it did not have summer.\u201d According to Genge, experts conventionally assume that volcanic clouds rise in the atmosphere in the same way as a mass of hot air rises \u2013 that is, because it is less dense than the coldest air of the upper layers. Thus, conventionally experts consider that volcanic clouds can reach a maximum height of about 50 kilometers, given that height and naturally, the temperature of the air is higher than that of the lower layers of the atmosphere. Genge, however, states in his article that volcanic clouds are loaded with electricity and that this gives them an additional imposition to climb to higher heights. He supports his conclusions by computer calculations showing that, depending on their size, volcanic particles can reach heights above 100 kilometers. This would have been the case of June 17-18, 1815, on the eve of the Battle of Waterloo. So Napoleon ran with a very bad luck in what was his last battle\u2014bad luck that, we would have agreed, would have had nothing to do with his divorce\u2014because in an untimely manner for him, just two months before his battle in Waterloo, the biggest volcanic explosion ever occurred in memory. We would not, of course, expect Napoleon to think in a superstitious way that the success of a battle depended on more than the objective circumstances of it. After all, he was not at all far from scientific thinking and, for example, in his campaign in Egypt he brought with him a group of 167 scientists and scholars, some as remarkable as the physicist and mathematician Joseph Fourier. Moreover, as we know, in that campaign, the Rosetta stone was discovered, which ultimately gave the key to deciphering the Egyptian hieroglyphics. We would not expect Napoleon, two hundred years away, to have been able to conceive that a volcanic eruption two months earlier 10,000 kilometers away could have caused his defeat in the battle of Waterloo. And even today, for the common people, it is certainly a surprising fact.",
    "https://upload.wikimedia.org/wikipedia/commons/8/82/Hand_tools.jpg": "About two and a half million years ago our distant ancestors, not yet human, learned to make tools by striking one stone against the other. As was to be expected, these tools were very simple, only stones with sharp corners. They were useful for, for example, to uncover animals. Their descendants, about a million and a half years ago \u2013 these are already human \u2013 considerably sophisticated the techniques of making tools and developed great manual skills to work the stone. The technique they developed, known as Achelense, allowed them to mold by percussion bifacial stones \u2013 that is, with two opposite faces shaped in a symmetrical way \u2013 with a pear shape, destined for the manufacture of hand axes.The Achelense technology survived for about a million years being replaced by more elaborate ones that allowed greater control in the shape and size of the tools.They also enabled a more efficient use of the raw material for the manufacture of them, being able to obtain several tools from a single original stone. In particular, according to specialists, the sophistication of the tools advanced associated with the development of communication skills and the transmission of acquired knowledge. And to the extent that primitive men endeavored to develop tools, they adapted better to their environment and advanced in their colonization of the planet. And we will have to recognize that the effort developed was major, if we are to judge by the success our species has had. It seems, however, that there were populations of primitive humans who did not strive so much in the development of new technologies and in their adaptation to the environment with disastrous results. This apparently was the case of the population of Homo erectus \u2013 a human species that ended up being extinct \u2013 that inhabited the center of the Arabian Peninsula at the beginning of the Stone Age. This, according to an article published on 27 July in the magazine Plos One by an international group of researchers headed by Ceri Shipton of the Australian National University in Canberra, Australia. Shipton and According to Shipton, the inhabitants of the site used a culture of minimal effort when they manufactured their tools and there is the possibility that this could have led to their disappearance. Specifically, it seems that these inhabitants made their tools using the materials they found in their immediate surroundings and that they had a mediocre quality. This, despite the fact that on a nearby hill there was a rock mine with an open sky of good quality. Shipton describes them as a population of \u201cfloods\u201d who did not want to strive to climb the hill and carry the materials they needed to make their tools, conforming to what they could find around them, since they did not find evidence that they had used the materials of the stone mine. This contrasts with the behavior of later species such as Neanderthal and Homo sapiens who transported their materials from long distances. Shipton and collaborators also have the impression that, in addition to lazy, the population of Homo erectus was too conservative and They did not take the appropriate measures, maintaining their own practices, when their habitat began to lose moisture. Thus, their passivity to climate change and the little effort they were willing to make to improve their technology would have sealed their evolutionary fate. It is undoubtedly surprising the technology and manual skill that primitive men developed to make tools hundreds of thousands and even millions of years ago, particularly towards the end of the Stone Age. In fact, very few of us could manufacture a stone tool such as those that the primitive members of our species managed to produce and to convince us we would have to see the many videos that we can find on the Internet in which the techniques developed by our ancestors are shown. It is also surprising to learn that there were populations of humans who could have extinguished by their laziness to make their maximum effort for technological development. Does this leave us some teachings in Mexico where this activity receives a very low priority?",
    "https://upload.wikimedia.org/wikipedia/commons/0/08/Go-Equipment-Narrow-Black.png": "When we are born do we have an innate knowledge that determines in a good way what we will become adults? Or on the contrary, what we are is entirely the result of the experiences we have throughout life?These questions, which have been debated by philosophers over the last centuries, have been a subject of discussion in recent months in the light of new developments in the field of artificial intelligence made known by the company DeepMind, based in London, England, and which is currently part of Google.The chess confrontations between computers and humans has been a parameter used to evaluate the advancement of artificial intelligence technology.As we know, a reference year in this sense is 1997, when the Deep Blue computer of the IBM company defeated chess champion Gerry Kasparov. From there, computer programs have progressed continuously developing capabilities far beyond human ones for board games such as chess, shogi (Japanese chess) and Go Chinese. In that sense, DeepMind announced last December the development of a program in which we are born. This development is described in an article that was deposited last December in the arXiv database hosted at Cornell University, Ithaca, New York. The article has as authors a group of DeepMind researchers headed by David Silver.The programs prior to AlphaZero that were able to defeat humans in chess were fed with knowledge of the game strategy developed by us throughout history.The AlphaZero program, instead, was not provided with any knowledge about that strategy remaining at the expense of its own capabilities.In these circumstances, AlphaZero developed its own strategy of playing during a training period.It also did so, in a fairly efficient way in time.In fact, when they were put to compete AlphaZero and Stockfish \u2013an alternative chess program, winner of the chess championship for computers in 2016\u2013 the first one surpassed the second in just four hours of training. Mo, World Shogi Champion, in 2 hours, as well as the AlphaGo Lee program in 8 hours. Based on these results, Silver and collaborators conclude that AlphaZero shows super-human capabilities that allowed him to master chess games, shogi and Go in a few hours without employing any previous knowledge of them. Not everyone agrees, however. Thus, Gary Marcus of New York University in an article that he deposited last January in arXiv, while recognizing AlphaZero's impressive abilities as a chess player, shogi and Go, at the same time it is not true that such skills have developed without the help of humans. In support of the above, Marcus argues that in fact the hand of humans is implicit in the design of AlphaZero's algorithm, which was carried out with a specific purpose: mastering the strategy in chess games, shogi and Go. Thus, human knowledge about such games accumulated throughout his history is poured into AlphaZero's design, which is not equally efficient to solve problems outside the domain for In addition to the controversy over AlphaZero's degree of intelligence, his ability to learn is undoubtedly impressive \u2013 as Marcus acknowledges it \u2013 and shows the high degree of development that artificial intelligence technology has achieved. And as this technology is also moving forward by leaps and bounds, even if AlphaZero can only do one thing extremely well and others not so much, this situation will surely be reversed in the immediate future that will see the emergence of machines with super-human intelligence capabilities. And once such machines make their appearance, we may perhaps be able to resolve the centuries-old dilemma: we are born with some basic knowledge so that our brain is in a certain way \u201cbarred\u201d entry, or well, our development until we become adults is determined by the environment and the influences to which we are subject.",
    "https://upload.wikimedia.org/wikipedia/commons/c/c9/A_woman_discovering_a_man_who_has_committed_suicide_by_hanging_himself_from_a_balcony_MET_DP868023.jpg": "While regions of the world will benefit from climate change, their consequences will generally be negative. Coastal regions, for example, could be flooded as the level of the oceans increases due to the melting of polar ice and the expansion of sea water. Likewise, there will be regions that will face risks of desertification. And, of course, there will be an increase in the frequency of extreme weather events \u2013 indeed, it already happens \u2013 including droughts, heat waves and high-intensity hurricanes. In contrast to all these consequences, which have been widely publicized by the media, there is an effect associated with climate change that is surprising and little known. This is the one related to the increase in the rate of suicides due to high environmental temperatures. At least this is what an article published this week in the journal \u201cNature Climate Change\u201d published by an international research group headed by Marshall Burke of Stanford University in California. To reach its conclusions, Burke and collaborators carried out a study with 850,000 cases of suicide in the United States and more than 600,000 in Mexico, in thousands of counties. In the United States and municipalities in Mexico, researchers were basically interested in determining the relationship between the suicide rate and an increase or decrease in environmental temperature with respect to its usual value, in a given locality and over a given month. By measuring changes in the suicide rate as a response to changes in ambient temperature, researchers eliminated other causes that at the local or seasonal level could also generate changes in that rate. Significantly, Burke and collaborators found that an increase in ambient temperature of a degree centigrade above the monthly average raised the suicide rate in the United States by 0.7 per cent between 1970 and 1990. This percentage also showed a moderate upward trend between 1990 and 2004, the last year for which data were reported. Similarly, in the case of Mexico, researchers found that the suicide rate rose by 2.1 per cent per cent for each degree of environmental temperature increase, in the period 1980-2010. However, it is not the case, because Burke and collaborators find that the increase in this rate is the same in the cold and hot places. The adaptation to a warm climate does not make an appreciable difference. It is also not made by the socioeconomic level and degree of development of a country, given that the same phenomenon occurs in the United States and Mexico. In particular, Burke and collaborators find that having air conditioning does not impact the increase in the suicide rate, which is also insensitive to the sex of the suicide bomber and the method he chose to take his life. Why is the rate of suicides increased by increasing the ambient temperature? Burke and collaborators do not provide a definitive response to this but speculate that a high temperature can alter mental well-being, possibly by side effects to body thermoregulation; that is, by changes in the blood flow in the brain when the body tries to maintain its normal temperature.To explore this possibility, Burke and collaborators analyzed more than 600,000 messages in Tweeter located in the United States \u2013issued between May 2014 and July 2015 \u2013 in search for language patterns to express. In response to a fluctuating ambient temperature, researchers found a correlation between these fluctuations and the appearance of messages with words that denoted a depressive state, such as alone, anxiety, depression and trapped. While Burke and collaborators recognize it, this is not a definitive test of their hypothesis, it is an indication that high temperatures alter the state of mental well-being. The consequences of the previous results in the context of climate change are direct. That is, if the Earth is increasing its temperature globally, the suicide rate will rise in the same proportion. Assuming a global temperature increase of 2.5 degrees Celsius by 2050 compared to the year 2000, Burke and collaborators estimate that between the years 2000 and 2050 more than 21,000 additional suicides will have accumulated due to the effect of global warming, 14,000 in the United States and 7,500 in Mexico. If Burke and collaborators are correct, climate change not only brings hurricanes, droughts, heat waves and raw winters, but is also able to influence on the effects of global warming. This is not to be dismissed if we take into account that, according to data from the World Health Organization, around 800,000 deaths by suicide occur annually at the global level. In fact, according to the same source, suicide is the seventh cause of death at the global level and the second among those between the ages of 15 and 29 years. Climate change has consequences that are at the same time surprising and worthy to be taken into account.",
    "https://upload.wikimedia.org/wikipedia/commons/6/63/Alfred_Hitchcock_NYWTS.jpg": "A particularly shocking scene at the beginning of the film \u201c2001: Odyssey of Space\u201d by American film director Stanley Kubrick, released in 1968, shows two groups of primates, alleged forerunners of our species, arguing for a puddle of water. The fight is carried out on the basis of shouting, screaming and threatening gestures without reaching physical contact \u2013 what is understood would have been a rule to resolve differences between rival groups \u2013 and ends with one of the groups taking over the puddle.The way to settle disputes, however, would have changed radically after a group of primates encountered a strange black stone monolith, which initially infused them with fear. It did not take long, however, to overcome the fear that inspired by the monolith and approached and even touched it, and with this changed the course of the evolution of human intelligence. Indeed, contact with the monolith gave one of the primates with sufficient mental clarity to discover that making use of the femur of an animal could increase with the effect of the monolith. Considerably its physical strength and this gave it an advantage in the hunting of animals, as well as in the disputes with its primates enemies. Thus, in a new confrontation the illuminated primate strikes a deadly blow to one of its enemies that falls down. When testing its new power, the primate throws euphoric the bone up that gives turns followed by the camera and at that moment there is a leap in time for millions of years and the femur is replaced on the screen by a spaceship. Although from this point Kubrick\u2019s fiction follows other courses, it is interesting to reflect on the evolution of the weapons of destruction from the primal femur, over the millions of years that in \u201c2001: Odyssey of Space\u201d last only a sigh. This, in the context of an imminent revolution in lethal armament \u2013 after those that brought the invention of firearms and atomic energy \u2013 product of the new technologies of artificial intelligence. There is, of course, no evidence of the veracity of the story told by Kubrick that has , certainly, more poetic than scientific value, particularly with regard to the monolith issue. We could expect, however, that in an accidental way our remote ancestors \u2013 at a time not yet determined \u2013 have indeed discovered the usefulness of a club to put an adversary out of combat. We have, moreover, scientific evidence that the clubs became sophisticated over time and that they were a common weapon during the Neolithic period and until relatively recent dates. A stone thrown at great speed constitutes an offensive or defensive option that was also available to our primitive ancestors. The option is also lethal by employing a slingshot that essentially constitutes an extension of the launching arm. A revolution in the speed of the shells used to put an adversary out of combat came with the invention of the firearms that reached at its time more than 400 kilometers per hour and supersonic speeds in the current versions. Already in recent times, a second revolution that substantially increased the destructive power of the weapons was the result of scientific advances that led to the development of the nuclear bomb that had amazingly multiplied the power of conventional weapons, as was left As a result of the destruction of the cities of Hiroshima and Nagasaki at the end of the Second World War. At the present time, and as a result of advances in artificial intelligence technologies, there is a further revolution in the development of lethal weapons, which, according to some experts, may have even more serious consequences than the two previous revolutions. This time, the development of war machines is under way, which could themselves locate and attack targets determined autonomously, without human intervention. According to their critics, the ability of new weapons to decide at a certain point who must live or die is contrary to all moral considerations and therefore their development must be completely banned. In this sense, a group of 2,400 specialists in the field of artificial intelligence was recently pronounced in a deployment promoted by the organization \u201cFuture of Life Institute.\u201d In this deployment, specialists, including representatives of technology companies such as Google and Tesla, undertake not to participate in the development of autonomous lethal weapons. The signatories of the deployment urge \u201cgovernments and rulers to create a future. With strong international standards, regulations and laws against autonomous lethal weapons.\u201d Likewise, they ask companies and technological organizations, as well as political leaders, to join their promise. In the years to come we will be able to know if the initiative promoted by the Future of Life Institute is successful or if, on the contrary, autonomous weapons will make their appearance in the world with their frightening ability to decide who lives or dies in a given circumstance. In the latter case, a lot of water will have run under the mill since millions of years ago one of our ancestors discovered that he could put his enemy out of combat more effectively using a club.",
    "https://upload.wikimedia.org/wikipedia/commons/4/4a/Geoid_undulation_10k_scale.jpg": "What is the shape of the Earth? If a survey were to be conducted among the general public to find out opinions about it, an overwhelming majority would most likely reply that it has the shape of a globe. Even so, if the sample were broad enough, surely there would be no shortage of people who would think that the Earth is not spherical but flat. Indeed, such an opinion seems to be gaining adherents in recent years. Indeed, according to publications in various media, the number of those who think that the Earth is in the form of a disk in whose center the north pole is. The periphery of that circle, which corresponds to what is the Antarctic continent, would be formed by an ice wall of 45 meters of altitude, which would be necessary to contain the water of the oceans that would otherwise overflow by the edges. All this according to the Internet page of the Society of the Planet Earth. While events such as moon eclipses prove that the Earth is spherical, it would be necessary to grant that the arguments on which the greater part of us base our beliefs about the shape of the Earth. So, we have the certainty that the Earth is not flat because, for example, we know that Sebasti\u00e1n Elcano circumnavigated the planet in the 16th century by demonstrating that it is spherical. Likewise, we know of the roundness of the Earth by the photographs taken from the space that show it. At first sight, however, the Earth looks flat \u2013 even at the height at which commercial planes fly \u2013 and this is what those who refuse to be spherical argue. Seeing the matter further, however, we find that the hypothesis of the flat Earth offers too artificial and forced explanations for certain astronomical phenomena, which, in contrast, can be explained simply assuming that it is spherical. Let us consider, for example, the succession of periods of day and night. To explain them, the Society of the Planet Earth assumes that the Sun is at a height above the Earth\u2019s surface of about 5,000 kilometers \u2013 less than the distance between Madrid and New York\u2013 and that it revolves in circles about the same. . Thus, at a certain moment, those regions of that surface that are closest to the Sun will receive greater illumination as happens at noon. To explain the nights, on the other hand, it has to be assumed that the Sun somehow directs the light down as in a bur\u00f3 lamp. With respect to sunsets, in which the solar disk descends and disappears on the horizon, the page of the Society of the Planet Earth offers an explanation that looks also very forced. According to this, as it happens as a flock of birds that by effect of perspective seems to descend to the extent that it moves away even if it does not decrease the altitude to which it flies, the Sun as it departs descends and ends up disappearing on the horizon. Even more difficult to sustain are the claims that there is an ice wall that surrounds the circular end of the world and that the lands beyond that wall are unknown and very possibly suffer from temperatures close to absolute zero. Indeed, without the bulk of mortals we have never stepped on the Antarctic continent, we know that it has already been explored and that even some countries have scientific bases there. that it is a continent certainly very cold, but that the temperatures reached there are far from the absolute zero of less than 273 degrees Celsius. How does the Society of the Planet Earth argue against these facts? Affirming that they are false, the product of an international conspiracy that wants, for some reason not clear, to keep the flat earth's planitude secret. The hypothesis of a flat Earth thus offers complicated and forced explanations \u2013 at best \u2013 in contrast to the assumption of a spherical Earth that allows explaining in a very simple and natural way phenomena such as the succession of day and night, the rotation of the stars, the eclipses of the moon, the sunsets and sunrises and the seasons of the year. And in such a complicated natural world, the simplest explanations are the ones that must be adopted.The confrontation of the models of spherical Earth and flat Earth can be put in the perspective of a confrontation between science and pseudoscience.A scientific explanation, besides being as simple as possible, must be predictive. That is to say, it must be able to predict the occurrence of a phenomenon given certain initial conditions. The science of predicting phenomena, which does not have pseudoscience, is what has allowed the development of modern technology, which has led, among many other things, to the development of the Internet and smartphones, to mention only some of the technological applications in vogue. Given the obvious impact that science has had in our days, it is disconcerting to see that pseudoscientific hypotheses such as those of flat earth, creationism, the futility of vaccines and the denial of climate change have followers, even in increasing numbers in some cases. In others, which fortunately make a majority, scientific arguments are more attended, even with evidences that are not necessarily of first hand.",
    "https://upload.wikimedia.org/wikipedia/commons/4/42/Rice_terraces-Nishihata%2CIkoma.jpg": "While every day we witness the rapid growth that the city of San Luis Potos\u00ed is experiencing, we rarely stop to think about what this means from the point of view of the natural resources necessary to sustain that growth. That is, we do not reflect on the fact that to build buildings, houses and paved streets, large amounts of cement and iron are used, among other inputs, that are made from raw materials extracted from subsoil; making use, in addition, of fossil fuels also extracted from the subsoil. And seen globally \u2013 regardless of how not all countries of the world grow at the same speed \u2013 there is an increasing use of non-renewable resources for the construction and maintenance of infrastructure that poses problems of sustainability and environmental impact.In addition, non-renewable raw materials are used not only to build infrastructure but also to manufacture, in an increasing way, all kinds of consumer goods; including automobiles, as we also know those that we live in many cities in Mexico and suffer from the growing traffic of vehicles that collapse or threaten to collapse our roads. On the other hand, one of the facets that reflect the health conditions of the planet, which, according to an editorial published last Thursday in Science magazine, is in a \u201cdangerous state\u201d. This editorial further states that \u201cThe combined effects of climate change, pollution and the loss of biodiversity have put our health and well-being at risk.\u201d The reference editorial, entitled \u201cThe Earth of Tomorrow\u201d, was intended to launch a series of monthly articles in which \u201cwill indicate some of the options that we still have to shape the Earth of tomorrow.\u201d Last Thursday\u2019s edition featured articles that deal with genetically modified organisms, education for the future, a sustainable system of exploitation of raw materials and energy generation systems with a net zero emission of atmospheric pollutants. The article on the exploitation of raw materials, entitled \u201cTowards a sustainable system of materials\u201d, was written by a group of researchers headed by Steven Davies of the University of California, Irvine and in it discuss various ways to make this exploitation sustainable. Davies and collaborators first note that in 2017 were extracted from subsoil 9 They also mention that among the negative effects of the exploitation of materials are land degradation, habitat loss, waste generation, degradation of water quality and pollution of ecosystems.In addition, researchers mention that metal production accounts for 8% of total energy consumed globally, a percentage that is expected to increase as metal minerals become poorer in the future with the potential increase in environmental pollution.The authors also note that while the emission of atmospheric pollutants occurs largely through the use of fuels during the refining or manufacturing process, cement production directly generates carbon dioxide through the treatment at high temperatures to which the limestone materials used in that process are subjected.This, in addition to the generation of carbon dioxide by the burning of fossil fuels.Davies and collaborators consider several strategies to achieve sustainability in the extraction of materials, including the extension of the life time of the product, and the reduction of the amount of carbon dioxide produced by the burning of fossil fuels. As with the invention of the transistor that replaced the vacuum bulbs, they also consider as a strategy greater manufacturing efficiency, the recycling of materials and the replacement of a material in one product with a lower environmental impact. However, the authors of the reference article point out that although the strategies discussed are not new and have been used in some cases, their implementation to achieve sustainability in the extraction of materials is complex. Among other things, because the implementation of a particular measure that improves a certain part of the cycle of use of materials can produce negative effects in another part of that cycle.There does not seem to be a simple solution to achieve sustainability in the extraction of materials from the subsoil and perhaps we could expect in the immediate future only slow advances in this respect.In any case, and in terms of our environment, it is illustrative to learn that the economic and urban growth that our city is experiencing, in addition to its obvious benefits, also has its not so positive aspects.",
    "https://upload.wikimedia.org/wikipedia/commons/a/ae/Artist%27s_impression_of_the_planet_orbiting_Proxima_Centauri.jpg": "As we know, in the mid-19th century, a plague severely affected potato crops in Ireland with devastating consequences for the peasant population who were fundamentally dependent on it for their subsistence. As a result, between 1841 and 1851 around one million Irish people died and another million emigrated in search of better living conditions, decreasing by 25% the population of the island. Some Irish people \u2013 who were certainly not among the poorest \u2013 were able to buy a passage by boat and emigrated to distant places such as Australia or the United States. On the other hand, they had not too much hope of being able to return to Ireland one day and were saying goodbye to their land forever. A small stone bridge in Donegal County in north-west Ireland, called the Bridge of Tears, the evidence.This bridge \u2013which one can visit through Google Maps \u2013 constituted the point where relatives and friends of those emigrants from the locality arrived to the port of Derry to embark on their destination. It says: \u201cThe family and friends of the traveler heading for faraway lands reached here. Here was the separation. This is the Bridge of Tears.\u201d The migration of people to foreign countries in search of a better life is, of course, not something of the past. On the contrary, and as we know, it is unfortunately a phenomenon of great currentity. Yet, modern means of transport have reduced the planet and with this have attenuated to some extent the inevitable bridges of tears.It would not necessarily be the case, however, if in a hypothetical future migrants were to undertake a trip to a destination outside the planet Earth, as discussed by Fr\u00e9d\u00e9ric Marin and Camille Beluffi, from the Universit\u00e9 de Strasbourg and from the company Casca4de, in respective form, in an article submitted this week to the database arXiv.org hosted by Cornell University. In their article, Marin and Bellufi discuss details of a hypothetical trip to the exoplanet Next Centauri b discovered in 2016. Centauri, the closest star to the Sun, is located at a distance of 4.2 light years from the Earth. Experts have gathered a good amount of information regarding Next Centauri b. They know, for example, that it is a rocky planet with a very similar size to the Earth and that it completes an orbit around its star in 11.2 days. They also know that the temperature of the planet would make possible the existence of liquid water on its surface. Next Centauri then has conditions of habitability, which, according to Marin and Bellufi, makes it an attractive candidate for a future manned mission. By the remoteness of Next Centauri, however, would not be a mission that could carry out a single generation of travelers. Indeed, Next Centauri is at such a distance that it takes 4.2 years to reach the light and since it is not possible to accelerate a vehicle up to that speed, the tempo that would take the trip would necessarily be greater. For example, the Apollo ship that arrived on the Moon would take more than 100,000 years. Today there are space ships faster, but the tempo that would take the trip would necessarily be greater. In this context, and in order to study the evolution of the number of crew members during the trip to Proxima Centauri and determine the chances of success, Marin and Bellufi simulated through a computer such evolution under different conditions. Among these conditions, the size of the initial crew and the related member mating restrictions to avoid endogamy and preserve genetic diversity. Marin and Bellufi find that with an initial crew of 25 men and 25 women and restricting in total the endogamy, there is a 50% chance that the crew will be extinguished at some time during the trip. To ensure that this does not happen, they found that a minimum initial population of 49 men and 49 women is necessary.Certainly, no manned mission to Proximo Centauri is foreseen in the near or distant future and in that sense the investigation of Marin and Bellufi is not necessary. It has little practical use in the immediate. In fact, in a way it approaches science fiction. It puts into perspective, however, the problems that our descendants would face to preserve a genetically healthy crew on an interstellar journey of colonization, which are qualitatively different from those found by the colonizers and migrants of the past.There are some points of contact, however.So, like the Irish migrants of the nineteenth century, the first crew of an interstellar journey would have to pass through its own bridge of tears.",
    "https://upload.wikimedia.org/wikipedia/commons/c/c0/Sapa_inkakuna.jpg": "It is no doubt surprising to learn that of the total number of human skulls of the Neolithic period that have been discovered, 5% to 10% show climbs carried out with living patients. What motives did our ancestors have thousands of years ago to carry out this type of practices? With remarkable success, moreover, because they managed to make the patient survive in a significant percentage of cases. A possible answer to the above question is offered to us by Plinio Prioreschi in his work \u201cA History of Medicine\u201d. According to Prioreschi, the man of the Neolithic had in no way enough knowledge to understand the medical benefits that a climb could have had. Moreover, he did not conceive of death as part of the human condition but as a product of an act of violence. Thus, death could come from an arrow in the abdomen or a claw in the head. To the wounds in the head, however, the man of the Neolithic would have placed them in a category different than that of wounds in other parts of the body. The reason for this is that, depending on its magnitude, a blow to the head, however, the Neolithician man would have put them in a category of a different parts of wounds. in the head could cause only a temporary loss of consciousness that primitive man did not distinguish from death. Thus, before the recovery of the consciousness of the fainted, in the eyes of the man of the Neolithic death by a blow to the head could be reversible, which was certainly not the case of other types of wounds. Thus, the head occupies a special place in the body.In addition, death could occur due to a disease that was conceived as due to the influence of evil spirits or the absence of the benign, same that would have to be expelled or admitted to the body as the case may be. And given its special position in the body, the head was the natural channel to achieve it. Thus, Plinio Prioreschi concludes, the head climbs in the Neolithic period were intended to expel the evil spirits from the body \u2013 or to allow the entry of the good \u2013 in order to cure a disease. In any case, and aside from the speculations of Prioreschi, what is indeed a fact that for thousands of years has been practiced climbing skulls. , as discussed in an article published this week in World Neurosurgery magazine, published by a group of three researchers led by David Kushner of the University of Miami. In that article, the result of a research of prehistoric skulls with trepanations, discovered in coastal and mountainous regions of Peru, is reported.Kushner and collaborators studied more than 800 skulls corresponding to a period of almost 2,000 years, from the year 400 before the Christian era to the year 1,500 of our era. Among other aspects, the researchers sought to determine if the operations of trepanation were associated with the existence of previous cranial traumas, as well as to determine the survival percentages of patients based on the healing of bone cuts. For this last purpose, the skulls studied were divided into three groups. In a first group, those that did not show any evidence of evolution of bone cutting, indicating that the patient died during the operation or a few days later, were included in a second group the cases of moderate recovery with a survival of the patient for a few weeks. Finally, a third group included the climbs. As a result of their study, Kushner and collaborators found that in the Peruvian coast, between the years 400-200 before our era, 10.3% of the cases were associated with a fracture due to head trauma and had a long-term survival of 40%. In the central mountains of Peru, between the years 1,000-1,400 of our era, 26% of the cases were associated with cranial fractures and survival was 53%. Finally, in the region of Cuzco during the Inca empire, between the years 1,400 and mid-1,500, there was a survival of 75-83% and only 11.9% of the climbings were made associated with a previous cranial fracture. Kushner and collaborators\u2019 research concluded that only a minority percentage of climbings were made by previous cranial fractures and that the survival of those operations reached astonishing values for the time, attesting to the skill and knowledge anated In fact, as discussed by Kushner and collaborators, the survival percentages achieved by Incas in climbing operations in the 15th and 16th centuries is twice the corresponding percentages during the American civil war in the 19th century. It is not clear, however, what were the main motivations of Incas to practice climbing. Were they seeking to facilitate the entry into the body of benign spirits or expel the evil ones? If this were the case, the skill of Peruvian surgeons was not used in the best way and more than one Inca had to cope with unnecessary perforation in the skull. Which, of course, would not have been the fault of surgeons but the result of the time they had to live.",
    "https://upload.wikimedia.org/wikipedia/commons/2/25/Fmrtuebersicht.jpg": "Physics, we would agree, is not the most popular subject of the preparatory school. Far from this, for many students physics is an arid and difficult to address discipline, constituted by a set of unrelated formulas that must be memorized and applied blindly; with a practical utility, moreover, that is not immediately obvious. In these circumstances, it is not surprising that, with exceptions, physics courses in the preparatory school are not too successful. And the same happens with some introductory courses of physics at university level. Contrary to the desolate previous panorama, however, physics is far from constituting a set of unrelated formulas without greater practical utility. On the contrary, it is a highly structured discipline with a wide range of applications as we know. In these conditions, the development of pedagogical methods for an efficient teaching of elementary physics acquires a great relevance.Physics is a discipline with relatively complex concepts and an improvement in its teaching methods requires the development of schemas to facilitate the student's acquisition of such concepts. This scheme, however, is commonly in contradiction with the accepted concepts of physics. An effective teaching of this discipline must then eradicate these misconceptions and replace them with the correct ones. Traditionally, students learn physics, as well as other disciplines, through classes taught by a teacher versus blackboard. In this scheme, the teacher carries the active part while the role of the students is that of passive receivers of the knowledge exposed by the teacher. In active learning schemes, in contrast, students acquire knowledge by themselves through experiments, own reasonings and discussion with other students. All this process is guided by an instructor who, however, has a relatively passive role. According to experts who have employed active learning methods to teach physics, these methods are more effective than traditional ones to eradicate the incorrect intuitive concepts of students and replace them with the correct concepts. An article published on May 24th in Frontier magazine, published on May 24. s in ICT by a group of researchers led by Eric Brewe from Drexel University, Philadelphia, Pennsylvania, provides hard data that support these findings. In that article, Brewe and collaborators report the results of a study conducted to determine the effect of taking a physics course under the active learning method, on brain processes experienced by a student at the time of solving a physics problem. For this purpose, the researchers joined a group of 55 students, 33 men and 22 women, from Florida International University. As part of the test, the participating students, who had not previously taken an introductory course in physics at university level, enrolled in a physics course that employed active learning and conducted physical reasoning tests before and after taking it. Concurrent with the physical reasoning tests, the students were subjected to functional magnetic resonance testing. In this connection, it should be remembered that the technique of functional magnetic resonance imaging allows to determine which areas of the brain are active at a certain time and therefore gave researchers an indication of the brain processes associated with physical reasoning, before and after training. As a result of their experiments, Brewe and collaborators found that the students, as they hoped, improved their performance in the physical reasoning tests. More significantly, they also found that active learning put into operation areas of the brain that were previously inactive. With this result, the researchers provide solid evidence in favor of the value of active learning techniques for the teaching of physics. Brewe and collaborators conclude that brain activity during physical reasoning can be modified with a physics course with an active learning scheme of a semester, leaving for future research to determine if this is also true for traditional courses and for other disciplines. In one way or another Brewe's results and collaborators are undoubtedly fascinating. Would it imply that in the near future a well designed and better taught introductory course of physics will fascinate a majority of students? View to believe.",
    "https://upload.wikimedia.org/wikipedia/commons/c/c0/Ir%2C77.jpg": "In an article published in 1980 in Science magazine, a group of researchers from the University of California, Berkeley, led by Luis \u00c1lvarez \u2013 Nobel Prize in Physics 1968 \u2013 advanced a possible explanation for the massive extinction of organisms \u2013 including non-avian dinosaurs \u2013 that is known to have occurred some 66 million years ago in the transition from the Cretaceous period to Paleogene. While there are alternative explanations to explain this extinction, the hypothesis of \u00c1lvarez and collaborators has gained momentum with the passing of the years and is now widely shared by specialists. According to that hypothesis, the extinction occurred by the fall of a meteorite of large dimensions that would have raised a gigantic cloud of dust that spread throughout the planet blocking the light of the sun. With a reduced intensity of solar radiation, the plants lost the ability to carry out the process of photosynthesis by means of which they generate the organic matter that serves as sustenance to the animal species, thus leading to the extinction of those most susceptible. How could \u00c1lvarez and collaborators sustain a hypothesis about an event that occurred tens of millions of years ago? They were able to do so to do so based on the discovery of geological strata. In fact, it happens that this metal is rare on the surface of the Earth but not on interstellar material and this suggests that the iridium found in these strata comes from the outer space. Thus, the impact of a meteorite rich in iridium would have raised a cloud of dust of global dimensions and dispersed that metal on the entire surface of the planet. Thus, indirect evidence of the occurrence of the impact of a meteorite 66 million years ago was given, but there was still a need to locate the site where it would have occurred. Today, it is accepted that it occurred near the village of Chicxulub on the northern coast of the Yucatan peninsula. The impact of the meteorite generated a crater of 180 kilometers of diameter that is currently partially covered by the sea. However, many questions remain to be answered and the meteorite of Chicxulub remains a topical topic of investigation. Thus, it is conjected that immediately after the impact, a heat wave would have occurred that turned the sky into an oven and that the meteorite of Chicxulub remained a topic of current research. This would have been followed by a winter period due to the cloud of dust that blocked the sun's rays over a period of months to years, and by a period of global warming due to the greenhouse effect of the high concentrations of carbon dioxide that were generated by the impact of the meteorite. This is supported by the results of a research published last Thursday, May 24 in Science magazine by a group of researchers from the United States and Tunisia, with Kenneth McLeod from the University of Missouri at the head. The interest of the researchers was to determine the extent and duration of the global warming after the impact of Chicxulub and for this they focused on the study of the concentration of the 18th isotope of oxygen in fossil remains \u2013 teeth, bones and scales \u2013 of fish that suffered such impact. These fossil remains were located in the El Kef region in north-west Tunisia that during the Cretaceous-Paleogen transition was under the sea. his determinations, McLeod and collaborators made use of the fact that the concentration of the isotope 18 of oxygen in the water decreases to the extent that its temperature increases, and that this is reflected in the concentration of that isotope in the organic tissue of the fish that inhabit it. Thus, the researchers were able to determine the changes that the temperature of the planet suffered by the effect of the Chicxulub meteorite from the determination of the composition of oxygen 18 in the fossil remains of El Kef. As a result, McLeod and collaborators find that the temperature of the planet increased by about 5 degrees centigrade by effect of the impact of the meteorite, and that this increase was prolonged by about 100,000 years. It is, of course, difficult to arrive at certainty about events that occurred tens of millions of years ago and the conclusions of McLeod and collaborators are not shared by all specialists. Thus, some say that the amount of greenhouse gases generated during the Chicxulub episode was not large enough to produce an increase of 5 degrees centigrade in the temperature of the planet and that the emission of gases is not shared by all specialists. By volcanism, which is known to have been particularly active at the time, it is the real cause.As it may be, McLeod and collaborators offer hard data \u2013 as Alvarez and collaborators did at the time about the occurrence of an impact of planetary dimensions \u2013 on a substantial increase in the temperature of the planet which took 100,000 years to dissipate. And in this context, they warn about the very long-term effects that the current global increase \u2013 which already almost reaches a centigrade degree with respect to pre-industrial values \u2013 can have on the use of fossil fuels until recently indiscriminate.",
    "https://upload.wikimedia.org/wikipedia/commons/5/5e/Assorted_United_States_coins.jpg": "As we know, lead is a metal with peculiar physical properties. Its specific weight, for example, is significantly higher than that of other common metals such as iron or aluminium. It is also characterized by being a soft metal, resistant to corrosion and melts at relatively low temperatures. Lead is also a toxic metal polluting the environment. Lead has been used for thousands of years and in fact is one of the first metals used by our civilization. The Romans, in particular, two millennia ago, made liberal use of lead and, among other applications, used it to build pipes of the city's water distribution network and in the manufacture of containers to make sweeteners boiling grape wine. This last practice would have caused among the Roman elite diseases by lead poisoning, which some have even wanted to see as the cause of the decline of Rome.In addition to this speculation, however, it does have firm evidence that Romans contaminated the environment with lead waste with their practices of extraction and melting of this metal. Although it is situated many thousands of kilometres from the point where the pollutants were generated, this did not prevent the atmospheric currents from carrying them to the point where they were trapped by the ice. Thus, the Greenland ice sheet, which has grown in thickness over time over thousands of years, has a detailed historical record of the emission of lead into the atmosphere. To read this record, it is sufficient to measure the concentration of lead in the ice in different depths. From, of course, knowing what depth corresponds to each historical time. On the other hand, while investigating the lead pollution that Rome produced throughout its existence has a scientific interest in itself, it should be noted that lead mining was conducted in conjunction with that of silver that was intended for the production of coins. Fluctuations of the emission of lead into the atmosphere by the Romans then account for the rate of acceleration or slowdown of its economic activity. Although in the past a study had been carried out in this direction, in an article appeared this week in the journal Proceedings of the National Academy of Sciences of Greenland, which was published in Greenland. The United States reports the results of an investigation that expands it considerably.This article was published by an interdisciplinary and international group of researchers led by Joseph McConnell of the Desert Research Institute in the State of Nevada in the United States.McConnell and collaborators studied the concentration of lead in the Greenland ice sheet within a thickness of 400 meters corresponding to the years 1,100 before and 800 after our era.This time interval includes the emergence of the Roman Republic and the decline of the Roman Empire of the West.The new study provides information at intervals of two years and accounts for variations in the emission of pollutants over time that correspond to historical events of different nature that occurred in the Mediterranean Sea region.According to McConnell and collaborators, around the year 1,000 before our era, coinciding with the Phoenic expansion towards the west of the Mediterranean Sea, a sustained increase in the emission of lead to the atmosphere began, which continued for eight centuries as mining activities increased in regions to the north and west of the Mediterranean. And in the second century of the Christian era, lead emissions corresponded to intensive mining activities in the Iberian peninsula, under the successive domination of Carthage, the Roman Republic and the Roman Empire. However, short-lived fluctuations occurred that corresponded to wars in the regions where lead and silver mines were located. A longer-lasting decline in the generation of lead contaminants occurred at the beginning of the first Punic War between Rome and Carthage during the years 264-241 B.C. This generation, however, grew during the last years of the conflict when Carthage possibly increased the coinage to pay mercenaries for the war, according to McConnell and collaborators. During the second Punic War between the years 218-201 B. Before Christianity, the emission of lead first decreased and later increased when the Romans stripped away the Carthaginians of lead and silver mines in the south of the Iberian Peninsula.McConnell and collaborators show in their article many other relations between fluctuations in the emission of lead to the atmosphere by activities. mining companies located on the Iberian Peninsula with historical events that historians have well located in time in a period of almost 2,000 years. And since lead mining was associated with silver destined for coin minting, the results also tell us the history of the comings and goings of the Roman economy.Certainly, much more information than we would have suspected was hidden in the polar ices.",
    "https://upload.wikimedia.org/wikipedia/commons/8/86/Mathematics_lecture_at_the_Helsinki_University_of_Technology.jpg": "According to Jo Boaler, a professor of mathematics at Stanford University in the state of California, there is a myth in the United States that students are divided into two groups: those who are gifted to study mathematics and those who are not. Thus, Boaler continues, when a high school student experiences some difficulty with his mathematics subject he concludes that he belongs to the second group and is disinterested by the subject.According to Boaler, this myth, coupled with the conception of mathematics as a set of formulas and procedures to be memorized \u2013 instead of a topic full of ideas, concepts and creativity \u2013 has prevented the teaching of mathematics in secondary schools in the United States from taking a prominent place worldwide. In the PISA tests of mathematics in 2015, for example, students in the United States occupied 38th place among 68 countries.In Mexico the situation is no better \u2013 in fact, if we are to attend to the 54th place that our country occupies in the PISA tests of mathematics \u2013 and we know that there are students who refuse to learn. It is also common for mathematics to be taught as a theme to memorize, which easily becomes somewhat tedious and seemingly meaningless. However, according to Boaler, the division of the world's population between mathematicians and non-mathematicians is artificial, as the ability to learn mathematics is actually common given the plasticity of the brain. Thus, learning mathematics would be facilitated by a change in the way many students conceive their own ability to address the subject. With regard to this, an article published on April 25 in Frontiers in Education by a group of researchers led by Jo Boaler, describes the results of an investigation carried out to precisely find out the extent to which the student's attitude to mathematics affects their learning. Specifically, Boaler and collaborators proposed to determine the impact on high school mathematics students of an online course developed by Boaler and some of his students at Stanford University. This course emphasizes, among other ideas such as that the brain has a great plast It is equally emphasized that mathematics is a matter of great creativity and beauty and that it is everywhere around us.The study was conducted with 1,090 students from 10 high schools in California.Of the total number of students, 439 took the course online while the rest did not.The participating teachers had in their group both participants who took the course and others who did not.In this way, the researchers were able to contrast the effect that the course had on the use of the students.As a result of their study, Boaler and collaborators found a better performance in the mathematics exams of the students who took the course online. Specifically, the average student who took the course had a higher rating than 63% of the students who did not take it.In order to find an explanation for the best performance of the students, Boaler and collaborators measured their involvement with mathematics based on their participation in class discussions, as well as in their willingness to work as hard as possible and not to give up in the face of difficulties. In all the areas evaluated, the students who took the online course outperformed those who did not.Furthermore, Boaler and collaborators were interested in investigating the change of attitude of the students towards mathematics after taking the course online.For this purpose, they interviewed 156 students before and after carrying out the research and found that the course had a positive effect on the students' confidence in themselves to learn mathematics, as well as in their perception of mathematics as an interesting and creative topic.So, according to Boaler's thesis and collaborators, the brain has such a plasticity that we all have the ability to learn mathematics at a high level.The widespread belief that there are people born with a brain not fit for mathematics is not then but a myth that must be discarded. Likewise, the conception of mathematics as a boring topic, with numerous formulas and procedures that must be memorized, must be overcome.Without these obstacles, mathematics would presumably be presented to the common people as a subject, certainly difficult, but interesting, creative and of course that of course, should be overcome. To get to this point in our country, however, the path is random since it would first have to train teachers in the new techniques of learning mathematics. And this does not seem to be a task free of obstacles.",
    "https://upload.wikimedia.org/wikipedia/commons/7/7e/Canicule_Europe_2003.jpg": "The climate specialists have come to the conclusion that the global warming that is experiencing the planet has increased the number of extreme weather episodes of heat or cold. While some deny the veracity of this conclusion, for a good percentage of those who are not specialists in the technical aspects of the climate but who do suffer its consequences, the opinion of the experts does not seem crazy to us. Otherwise, in one way or another, what is undeniable is that cold or heat shocks are very unpleasant and even dangerous. In fact, we know that during extreme weather episodes the number of deaths among the affected population increases. For example, the heat wave that struck France in the summer of 2003, caused about 15,000 deaths. It is also known that in Balgladesh the number of deaths during heat episodes is increased by 20%. Cold blows are equally fatal and in 2003 in India more than 900 people died during a cold wave.The previous numbers are recorded in the introduction of an article published last May 2 in the journal Environmental Research Letters by a group. The purpose of this article is to report the results of a research carried out to determine the incidence of extreme weather events of cold and heat at the global level, and the possibility of predicting their occurrence on days in advance. This last one in order to design strategies to mitigate their consequences.Based on climate data from the National Oceanic and Atmospheric Administration of the United States and the European Center for Medium-Term Meteorological Forecasts, Coughlan and collaborators developed maps at the global level showing the frequency of extreme weather events, both of cold and of heat. Such climatic events are defined as those in which there is a substantial increase or decrease in temperature beyond their usual variability. The developed maps show that extreme heat episodes occur throughout the planet, with the exception of some tropical areas in Indonesia and western South America and Africa. In contrast, there are large areas where extreme weather events are scarce. These areas are located. in the northern part of the South American subcontinent, in central Africa, on the west coast of India and in Indonesia. In general, there are fewer extreme episodes of both cold and heat in tropical regions than in high latitudes. An important aspect of the research carried out by Coghlan and collaborators was that of the global determination of the ability to predict the occurrence of extreme weather events. This ability depends on the availability of meteorological data, the topography of the terrain and the particular technological conditions in each locality. In its article, Coghlan and collaborators include maps showing this capability globally at various levels. The maximum of these levels corresponds to a prediction capacity of a climate event 10 days in advance and is presented, for both cold and heat waves, in eastern European countries, Russia, the Middle East and the central region of the United States and Canada. Prediction capacity in the tropics varies greatly and is very low in Central and High African countries in Brazil. In general terms, researchers find that the predictive capacity for heat waves with 3 to 10 In global terms Coghlan and collaborators estimate that about 5,000 million people live in regions whose heat strokes can be predicted 3 to 10 days in advance and are therefore susceptible to mitigation using, in addition, procedures that do not require so many resources. In Coghlan maps and collaborators our country shows a moderate occurrence of extreme weather events with the exception of the Pacific Ocean coast. On the other hand, the ability to predict heat waves varies greatly, from a high level in the center of the country, to a low capacity in regions of the Pacific coast. The ability to predict cold waves is also variable although more uniform. We are thus a moderately fortunate country as to the occurrence of extreme weather events. At the moment we are not so, however, as to the ability to predict them.",
    "https://upload.wikimedia.org/wikipedia/commons/0/09/Logo_National_Assembly_%281789%29.png": "As we know, the French Revolution led to profound political and social changes in France that led to the abolition of the monarchy and the establishment of the first republic. We also know that the impact of these changes was not limited to France but extended to other parts of the world, including what is now Latin America, and that it contributed significantly to the development of modern democracies. During the first phase of the French Revolution, which occurred during the years 1789-1791, the French system of government was transformed from an absolute monarchy into a constitutional monarchy and among other changes abolished feudalism and the payment of tithes to the Church. These changes were the result of discussions within the Constituent National Assembly, which was composed of more than a thousand deputies representing the clergy, the nobility and the Third State, formed by the unprivileged \u2013 campesinos, artisans, merchants and merchants, among other urban inhabitants. The aim of the assembly was to draw up the first French constitution.With the composition of the Constituent National Assembly and given the significance of the issues dealt with in it, it is not difficult to understand. If we take into account, moreover, the tremendous political and social polarization that France was experiencing at that time because of the crisis of Louis XVI\u2019s monarchy in the light of the new ideas advocated by the Enlightenment, as well as the financial crisis that the government was going through because of its military adventures abroad and the shortage of food for the population. In order to understand the dynamics of the analysis and discussion of the proposals submitted to the Constituent National Assembly by the deputies and their eventual adoption or rejection, an interdisciplinary group of researchers led by Alexander Barron of Indiana University in the United States carried out a study of 40,000 initiatives submitted for consideration by the assembly. The researchers took advantage of the transcripts of the proposals that have been digitized electronically, so that they could make an analysis of texts by computer using sophisticated techniques.Barron and collaborators were interested in determining the novelty of each of the proposals with respect to other submitted earlier, as well as their significance, measured by their survival in subsequent discussions. As a result of their study, the researchers found a great dispersion in terms of these two proposals, as well as their significance, as their impact, measured by their survival in subsequent discussions. There were initiatives with a great novelty but they did not manage to convince the assembly and had little impact. Likewise, there were initiatives that were not innovative but that managed to permeate the minds of the deputies. They find, however, that on average the most innovative initiatives were more likely to transcend than those with less novelty and that, on average, the deputies tended to submit innovative proposals. Typically, according to Barron and collaborators, during the discussions the left-wing deputies defended innovative proposals, while the conservatives opposed them. On the other hand, in order to maximize the impact of an initiative played an important role the oratory skills of the MP who presented it. According to Barron and collaborators, among the most successful in this regard are Jerome Pethion de Villeneuve and Maximilien Robespierre. In particular, in the conditions as held the sessions with more than a thousand deputies, the researchers note that the volume of the voice would have to have been an important factor, since at the time the electrical microphones were not invented. Barron and collaborators found that not all the ideas embodied in the first constitution originated in discussions in the plenary assembly, but within specialized committees formed with members of the assembly. This is perhaps not surprising if we are to consider the great difficulties that would have arisen to transmit and discuss an initiative before a heterogeneous group, and with varied interests, of more than a thousand deputies. Certainly, the discussion of a transcendent matter can be carried out more rationally in a committee of reduced size, which, on the other hand, can lead to results that do not necessarily maximize public benefit. Thus, an open discussion would be necessary. In one way or another, however, nothing is assured if we consider that Robespierre, who belonged to the more radical left wing of the assembly and who was very successful in the public discussion as shown by Barron and collaborators, at a later stage of the French revolution, led the so-called Terror Reign, during which some 40,000 were guillotinized. People.",
    "https://upload.wikimedia.org/wikipedia/commons/e/e4/Table_of_Hydraulics_and_Hydrostatics%2C_Cyclopaedia%2C_Volume_1.jpg": "One characteristic of the development of our civilization from prehistoric times to the present time is the sustained growth of per capita energy consumption. Indeed, a million years ago, the predecessors of our species consumed only the energy that provided them with food. Once they discovered how to use fire to cook food and to alleviate the cold, however, their per capita energy consumption increased accordingly. The same happened with subsequent technological developments, such as agriculture, and the extraction and forging of metals for the manufacture of utensils and tools.The per capita consumption of energy also increased with the appearance of the hydraulic wheel about two thousand years ago and later the windmill, as with the invention of the steam engine towards the end of the eighteenth century, the substitution of fuel wood by coal, and the partial replacement of this last fuel by oil in the first decades of the twentieth century. Finally, we must mention the development of the electricity industry at the end of the nineteenth century which considerably boosted per capita energy consumption. Prehistoric times to the present time the per capita consumption of energy has risen more than a hundred times. In these conditions, taking into account the explosive increase that the population of the world has had, it is not surprising that the increasing use that we have made of energy \u2013 which during the second half of the last century overwhelmingly came from the burning of fossil fuels, oil, natural gas and coal\u2013 has had consequences at a global level. Specifically, that it has caused the climate change that is underway.To mitigate this change, specialists consider that it is necessary to replace fossil fuels with sources of clean energy, including hydroelectric energy \u2013 which takes advantage of water falls, natural or artificial \u2013, biofuels \u2013 for example, bioethanol, obtained from maize or sugar cane\u2013, wind or wind energy, and solar energy. Although the origin of hydroelectric, biofuel and wind energy is ultimately the Sun, it is still a sort of intermediaries in the relationship with our star. Thus, it would be natural to avoid them in the first instance. One way to do this is through the so-called solar panels that convert the Sun's radiation directly electrical energy; with the advantage, moreover, that this is the type of energy that is most useful to us. In the market there are several technologies for the manufacture of solar panels. The one that dominates, however, is the one based on silicon, which is also the material used to build microprocessors and memories for computers. On the other hand, although solar panels have been available for several decades already, their high cost had not allowed their massive use in the generation of energy. This, fortunately, has ceased to be true and the photovoltaic energy \u2013 as is known the energy obtained from such panels \u2013 has drastically reduced its costs and is breaking down strongly in the field of electricity generation. It is worth wondering whether photovoltaic energy is a clean energy. In this regard, we can mention that while the operation of a solar panel does not pollute, during the process of making the panel itself, environmental pollution was generated to a certain degree. In these conditions, to know if in balance the use of solar panels helps the environment, it is necessary to quantify the energy used in the manufacture of a given panel and estimate the time that would take to generate such energy during its operation in normal conditions (energy recovery time).If this time is longer than the estimated time of life of the panel, then the photovoltaic option would not be a viable option to protect the environment. Fortunately, the balance is highly positive because the time of recovery of energy for a silicon panel operating in a region of southern Europe is just over a year, compared to an estimated time of life of the panel of 20 years. This, according to the latest report of the Fraunhofer Institute for Solar Energy Systems in Germany. Thus, a solar panel of silicon during its lifetime will deliver 20 times more energy than that was used in manufacturing it.After several decades of being available in the market, the photovoltaic panels have finally made their arrival in the field of the generation of the photovoltaics. Will they be able to contribute significantly to mitigating climate change? It is difficult to anticipate it, but if we do not, our strongest charter will have failed. And in that case we may have to reverse the trend of increasing energy use that we have sustained over the last hundreds of thousands of years.",
    "https://upload.wikimedia.org/wikipedia/commons/f/f3/Shoal_Bay.jpg": "In these days of the Internet and smartphones many people have made routine use of the service provided by the Global Positioning System or GPS to locate and reach a certain address. While the GPS breakout for these purposes has been sudden, its adoption has been natural among the digital natives. It has not been the case, however, for many of those who were not born surrounded by computers. And much less so for those who passed through this world centuries ago when the GPS would have been somewhat inconceivable. Let us think of the transatlantic navigators \u2013 for example, Christopher Columbus \u2013 who kept their course in the sea by observing the position of the sun and making use of the compass. In this regard, an interesting case \u2013 and surprising as we will see in what follows \u2013 is that of the Vikings, who traveled regularly through the North Atlantic in the X-XII centuries, from Norway to Iceland and Greenland. They even reached the island of Terranova in northern Canada 500 years before Columbus. By this last, according to some authors, the Vikings would be the true discoverers of America \u2013 with permission, of course, of the original occupants of the American continent, who crossed from Siberia to Alaska a long time before and who could protest with all fairness.A remarkable aspect of the Vikings' journeys is that they made them without using the compass, which did not appear in Europe until the 13th century. Thus, they would have been guided by the position of the sun. It is not clear, however, how they would have proceeded on the cloudy days. With regard to the latter, one hypothesis that has been handled for some decades now is that Vikings would have guided their journeys through certain rocks or crystals that have a property known as birrefrigency.This property makes such crystals \u2013 for example, calcite, of which there are deposits in Iceland and therefore it was within the reach of the Vikings\u2013 produce a double image of an object seen through them. This double image is associated with what is known as polarization of light for which there are two possibilities. For further explanation, we must first mention that light is a certain type of wave, such as is produced on a rope to which we fix an end and to The wave generated in this way has a vertical polarization. Likewise, we could shake the end of the string from left to right, from where a wave with horizontal polarization would result. The two images produced by a calcite crystal are associated with the two polarizations of light. That is, the calcite has the ability to separate these two polarizations and can therefore be used as a polarization detector. How does all this connect with the travels of the Vikings? The connection results from the fact that the light of the sky is polarized in the form of circles with the sun in the center. Thus, measuring the polarization of the light of the sky is possible in principle to determine the position of the sun hidden by the clouds. This is what, according to the hypothesis, the Vikings would have used to direct their navigation. To determine the polarization of the light of the sky they would have employed calcita crystals or some equivalent. The hypothesis, however, has detractors who consider that the accuracy with which the vikings may have done their polarization measurements was not good enough. It was not necessarily the case, according to an article published this week in the Royal Society Open Science magazine by D\u00e9nez Sz\u00e1z and Gabor Horv\u00e1th of Lor\u00e1nd University in Hungary. To assess the real possibilities that Vikings could travel between Norway and Greenland without a compass, Sz\u00e1z and Horv\u00e1th simulated via a computer trips between these two destinations, with varying degrees of cloudiness and during the summer solstice and spring equinox. They simulated a total of 1,000 trips lasting three weeks each. They assumed that the sailors fixed the north direction at regular intervals of 1 to 6 hours, determining the position of the invisible sun by means of various types of birrefringe crystals, including calcite crystals. From their simulations, Sz\u00e1z and Horv\u00e1th found that with determinations of the position of the sun at intervals of 1 to 3 hours the Vikings would have achieved success in 90-100% of cases. However, arriving on the island of Newfoundland and in this regard the authors speculate if this was not the reason why the Vikings arrived in American lands. Researchers are, however, cautious and point out that their study must be complemented by others of greater scope.Sz\u00e1z and Horv\u00e1th, in the near future, support with their results the hypothesis that Vikings used sophisticated techniques to determine the position of the sun when it is hidden by the clouds.This certainly is not bad enough to have been done a thousand years ago.And it is, without a doubt, surprising even for digital natives.",
    "https://upload.wikimedia.org/wikipedia/commons/9/90/Schleifpapier_verschiedene_Sorten.jpg": "In an article published in the British journal Nature on 23 January 1896 entitled \u201cOn a New Kind of Rays\u201d, German physicist Wilhelm Roentgen describes the results of his research on the properties of mysterious rays emanating from the Crookes tube with which he was working. This tube was a relatively common device in the electricity research laboratories of the time and consisted of a conical glass ampoule to which the air was extracted and a voltage of several tens of thousands of volts was applied. According to what Roentgen wrote in his article, a tube of Crookes emits radiation of unknown nature \u2013 and which he called X-rays \u2013 which has the property to penetrate and transfer to a large number of materials, including \u201ca book of a thousand pages and a thick block of wood.\u201d He notes that X-rays are even capable of traversing an aluminium sheet or 15 millimetre thick glass. It is not the case, on the other hand, of a plumbed glass sheet \u201cwhich turns out to be much more opaque\u201d. Roentgen also mentions that X-rays are even capable of passing through an aluminium sheet of glass or 15 millimetre thick glass. In this article, Zhang and collaborators can penetrate the organic tissue and include in his article an X-ray of his wife's hand that clearly shows the silhouette of the bones. And with this he captured the popular imagination. As we know, Roentgen's discovery has had an increasing impact on the medical diagnosis insofar as increasingly sophisticated X-ray techniques have been developed, which allow us to see the inside of the body in greater detail. All of this, however, has a cost, because although over time we have found out that the nature of X-rays is the same as that of visible light, we have also learned that they have considerably greater energy than makes them dangerous. Thus, they can cause damage to the organic tissue depending on the dose received, which grows as the detail with which the inside of the body is to be observed grows. In the previous context, there are efforts to reduce the X-ray dose needed for medical diagnosis and in that direction points out an article published this week in the Optica magazine by a group of researchers from the Chinese Academy of Sciences, headed by Ai-Xin Zhang. They report the development of a method that employs a single pixel camera to obtain an X-ray image with ultra-low radiation doses. While for those of us born before the digital camera, the term pixel is novel, young people know that digital cameras are classified by their number of pixels and that the sharpness of the photographs they can take depends on that number. Indeed, in a digital camera, the negative \u2013 which is where the camera lens focuses the image they want to print \u2013 is replaced by a silicon chip formed by a large number of light-sensitive small elements (pixels). Such elements or pixels are distributed in a square mesh in the form of a chess board, and each of them is responsible for generating the part of the photograph that corresponds to it. It is clear, then, that the end of the photograph details will depend on the number of pixels on the camera chip. It is also clear that the camera of a single pixel of Zhang and collaborators cannot generate an X-ray image the same way that the photograph details of the camera. In fact, the photograph that it would generate would have no details at all and more would resemble a photographic negative that would have been uniformly veiled by exposing it to the light. How do Zhang and collaborators manage to print their X-ray photographs? They do so using an ingenious method that consists of taking a large number of photographs, each of them by passing the X-rays through a sand paper filter put to rotate. X-rays when crossing the sand paper generate a changing pattern of lighting of dark and bright areas that is modified as the filter is rotated, so that each \u201cphotograph\u201d that takes the only pixel of the camera is similarly modified. The image is then synthesized by the computer from all the images obtained using a sophisticated mathematical procedure. While the technique described by Zhan and collaborators is not yet ready for use in medical diagnosis, the researchers were able to obtain images using ultra-low doses of X-ray rays with a much higher quality than those obtained with the traditional technique using similar doses of radiation. This, of course, makes it very attractive for applications. The discovery of X-rays by Roentgen was, without a doubt, a spectacular event that certainly captured popular imagination. More than a century after that discovery, the development of increasingly sophisticated techniques to see the hidden at first sight does not perhaps cause the same expectation. Although, we would agree that the possibility of indirectly seeing the inside of the human body through a single pixel camera, a sandpaper and a mathematical algorithm, escapes everything that the popular imagination could have anticipated.",
    "https://upload.wikimedia.org/wikipedia/commons/a/a1/Oceanus-es.png": "In the middle of the Pacific Ocean, between Hawaii and California, is the so-called garbage island, which has a territorial extension almost equal to that of our country. Of course, if we look on the map for an island of this size between Hawaii and California we will not find it, since it does not exist. What does exist is an extension of 1.6 million square kilometers of flotation garbage, mostly plastic materials. The island of garbage, or great waste stain of the Pacific as it is also known, is the result of the accumulation of waste materials that are dragged by the turn of the Pacific \u2013 a sea current in the form of whirlwind caused by the rotation of the Earth. It was discovered in 1997 and is not, for the rest, a unique case, since in other parts of the Pacific Ocean, and in other oceans also, areas of accumulation of garbage are generated. Where does the plastic accumulated in the great stain of the Pacific come from? Given the large amount of plastic materials that we use and quickly discard every day, we might think that the island of garbage is formed, fundamentally, by bottles, vessels, bags, packages, This is not necessarily true, however, according to a study by the organization Clean up Foundation, published this week in Scientific Reports magazine by an international group of researchers, headed by Laurent Lebreton of that organization. Clean up Foundation is a non-profit organization that has received funds to carry out a project that seeks to clean the great stain of the Pacific from garbage. In order to quantify the quantity and sizes of the garbage in flotation in this area, Lebreton and collaborators carried out during the months of July and September 2015 an extensive garbage collection operation using networks of different sizes. To complement this operation, in October 2016 they carried out two flights for the taking of aerial images of the garbage island.From these two data collection campaigns, Lebreton and collaborators were able to quantify the size of the problem. Thus, they calculate that within the area of 1.6 million square kilometers that includes the great stain of peace, they find themselves floating one of these two data collection campaigns, Lebreton and collaborators were able to quantify the size of the problem. 80,000 tons of plastic garbage of all sizes, from small particles of a few millimetres \u2013 micro-plastics, of which they calculate there are some two trillion floating \u2013 to objects greater than 50 centimetres. Naturally, micro-plastics, which result from the disintegration of the original objects, far exceed in number the number of floating objects, still in fragmentation stage. As for the weight of some and others the situation is reversed, and micro-plastics represent just 8% of the weight of the total floating garbage. In addition, Lebreton and collaborators find that, unexpectedly, at least half of the garbage objects collected in the campaign have a marine and non-land origin. In particular, fishing nets represent 46% of the total weight of the garbage collected. In some cases, when their disintegration process had not yet advanced, Lebreton and collaborators were able to find out the origin of an object. Thus, among those collected to which they could identify a written legend, in 30% of cases the language of the legend was Japanese, followed closely by Chinese with 29.8%. It would be expected that the Tohoku tsunami that struck the northern coast of Japan in 2011 would be responsible for the large number of objects of Japanese origin found on the garbage island. In fact, Lebreton and collaborators estimate that from 10% to 20% of the total weight of the floating garbage originated in the tsunami. On the other hand, that 30% of the objects rescued were made in China is not, of course, surprising. In some cases, researchers were also able to determine the year of manufacture of the collected objects. Thus, out of 50 objects with that identifiable date, 1 object was manufactured in 1977, 7 in the 1980s, 17 in the 1990s, 24 between 2000 and 2009 and one in 2010. According to the results of Lebreton and collaborators, half of the garbage they collected has a marine origin, which they did not expect given the amount of terrestrial plastic waste that is dumped into the sea. Thus, they conclude that most of this garbage does not float or that there are mechanisms that fragment it into particles so small that could not be detected in the study. and collaborators find that the 80,000 tons of plastic garbage that they calculate to float in the great patch of the Pacific is 4 to 16 times larger than previously estimated, which would be an indication that the contamination of the planet by plastics is growing rapidly. And this happens in a certain unnoticed, amid the multiple pollutions we have subjected to the planet. So what makes one more stain on the tiger?",
    "https://upload.wikimedia.org/wikipedia/commons/4/4f/Grandfather_Mountain_hairpins%2C_Oct_2016_2.jpg": "Over the past week, the media have reported an article recently published by Richard Jantz of the University of Tennessee in Knoxville in the magazine Forensic Anthropology. This article relates to the fate of the American aviator Amelia Earhart in her ill-fated circumnavigation journey of the world in 1937. As we know, Amelia Earhart was an American plane pilot, famous for having been in 1932 the first woman to cross the Atlantic alone on a non-stop flight, and for having been the first person to fly alone between Hawaii and California in 1935. Following these achievements, Earhart set out for a circumnavigation flight and for this purpose departed on 21 May 1937 from Oakland to Florida in Fred Noonan\u2019s company as a navigator. Florida flew to Puerto Rico and from there to the South American Atlantic coast. From Natal, Brazil, they crossed the Atlantic Ocean to Senegal in Africa, crossed the African continent and flew directly to Karachi. The flight included Calcutta, Yangon, Bangkok, northern Australia and New Guinea, where they arrived on June 29. Continuing with their journey, on July 2, Earhart and Noonan left for Howard\u2019s small island in the middle of the Pacific Ocean, some 4,000 kilometers distant. They never arrived, however, running a fate that is a mystery to date. One possibility is that they had difficulty locating Howard\u2019s island and that they ran out of fuel crashing into the sea. An alternative explanation is that they managed to arrive as shipwrecks to an island near Howard where they would have died from disease or starvation. There are no certains of their fate, however. A 1940 British expedition discovered in the Nikumaroro atoll, about 650 kilometers from Howard, human bone remains that were thought to belong to Earhart. After examining them, however, Dr. David Hoddles of the Fiji Central Medical School, determined that they belonged to a male, European or European-born, mid-European, and complementary person. So in 1998, a group of researchers led by Karen Burns of North Carolina State Unversity wrote a report rejecting these conclusions. Among other things, Hoddles, who consider that he did not have sufficient professional training to give an expert opinion on the bone remains found in Nikumaro. In response, in an article published in 2015 in the Journal of Archaeological Science: Reports, Pamela Cross of University of Bradford in the United Kingdom and Richard Wright of University of Sydney, Australia, they argue that Hoddles was qualified to evaluate the bone remains and defend their conclusions. Thus, the last episode of the controversy is the article mentioned at the beginning of this text recently published by Richard Jantz \u2013 who, by the way, is co-author of Karen Burns\u2019s article \u2013 in which he expresses his disagreement with both Hoddles\u2019 conclusions and Hoddles\u2019s conclusions. In particular, Hoddles disqualifies him by the methods used in his analysis, which certainly were typical of a time when forensic science had not reached the degree of development he has today.The problem for a conclusive identification of these bones is that they are no longer available for his study, as they disappeared after having been examined in 1940. Thus, the only information available to the experts is the measurements of the size of the bones made by Hoddles and the conclusions reached. With a sample of bone remains the controversy could have been resolved by means of a DNA analysis. Without this sample, the problem has been considerably complicated. In fact, in order to try to resolve it, Jantz had to make use of the measurements made by Hoddles \u2013 despite the disqualifications of which he is subjected \u2013 and of estimates of the dimensions of Earharhart bones made from photographs. According to Jantz, there is no evidence to rule out that the bones found in Nikumaroro belong to to Amelia Earhart; and if there are, on the contrary, to conclude that if they are not from Earhart they are from someone with a similar physique. Will we know with certainty one day how Amelia Earhart ended her days? According to experts possibly not, because of the little information available to us, and with this will continue the controversy. In the early years of the aviation the achievements of Amelia Earhart were widely publicized. They were to such an extent that, even today, Earhart is a reason for attention in the media and for a company to do business selling a doll with its effigy. This, of being able to find out, surely would not be unpleasant to her. Contrary to what, without a doubt, Hoddles would say.",
    "https://upload.wikimedia.org/wikipedia/commons/b/b6/Esquema_de_comunicaci%C3%B3n_Shannon.png": "The first day of September 1923 was a bad day for Japan: at 11:58 a.m. an earthquake of magnitude 7.9 followed by a tsunami with waves of 10 meters high hit the cities of Tokyo and Yokohama. According to the Smithsonian Institute website, about 140,000 people died, both in the early moments of the earthquake and in the fires and fire storms that followed.During the confusion that caused the Tokyo earthquake, false rumors spread according to which Koreans living in the city were carrying out acts of looting and causing fires intentionally. Among other falsehoods, Koreans were also accused of poisoning the drinking water wells that supplied the city. As a result, more than 6,000 Koreans were killed by the police, soldiers, or organized groups of Japanese civilians. With the circumstance, moreover, some Japanese ran with the same fate by being confused with Koreans. As we know, the spread of false news, by ignorance or with defined purposes, has been a constant throughout the history of civilization. The results of this study were published this week in the magazine \u201cScience\u201d. Aral and collaborators investigated the number of times a tweet is delayed and the number of people who receive it. Interestingly, the results of this study were published this week in the magazine \u201cScience\u201d. Aral and collaborators investigated the number of times a tweet is delayed and the number of people who receive it. It is still the case today \u2013 although not necessarily with such dramatic consequences in loss of life as Tokyo in 1923 \u2013 with the help of new Internet communication technologies that, among other things, allow the dissemination of false news from sites that appear to be as serious as other reputable media sites. In order to investigate how the dynamics of the dissemination of true information differs from that which is false, three researchers from the Massachusetts Institute of Technology led by Sinan Aral conducted a study with about 126,000 messages retracted on Twitter by 3 million people during the years 2006 and 2017. So, while less than 0.1% of the real news reached 1,000 users, about 1% of the fake news reached the same number of people. Likewise, real news took six times longer than false news to reach 1,500 users. In order to determine whether bots \u2013 or sites where a message is automatically reproduced \u2013 are responsible for the speed of dissemination and penetration of false news, Aral and collaborators eliminated tweets originating in bot sites using sophisticated detection techniques. The results obtained, however, were not modified, implying that the culprits of the biggest dissemination of false news are not computers but humans. All of this is particularly true of false news with political content, which Aral and collaborators find travels faster and reach more Twitter users than any other category of false news. Indeed, researchers find that false political news reaches 20,000 users six times faster than what takes them to reach other false news. To 10,000 receivers.What is the reason that false information travels faster than true information? Aral and collaborators rule out that the explanation resides in the fact that tweeps tend to spread falsehoods have more followers, because they find that just the opposite happens. Instead, they base their explanation on the novelty of the news to be transmitted, which they note is greater for the false news than for the true news, and that it provokes emotions of surprise and disgust that encourage the Twitter user to share them. The novelty of the information and the emotions that they provoke will then be the promoters of the false news, at least according to Aral and collaborators. On the other hand, while false news itself is no novelty, in the present times of virtual worlds, social networks and instant communication acquire a new dimension that is just beginning to be explored. It will thus pass some time before it is clarified how the falsehoods are propagated and methods are developed to combat them. As this happens, the most prudent thing is to apply common sense and think twice before retransmitting a message to cyberspace. everything if the message in question has a political burden.",
    "https://upload.wikimedia.org/wikipedia/commons/0/01/Cesarean_team.JPG": "Although reconstructive plastic surgery has been practiced since very remote times, cosmetic surgery, used to modify the appearance of a part of the body, was only begun towards the end of the 19th century. There is a good reason for it to have been, since the anesthetics used in surgical operations made their appearance only until the mid-19th century. Before this, for someone to decide to undergo a surgical operation would have had a very good reason, much beyond the simple desire to look different.The situation changed when pain-free surgical operations were possible and with this aesthetic surgery expanded and became a business.In particular, in the United States a certain market for nose surgery would have been generated by the desire of the ethnic minorities to look like the bulk of the white population.For this and for other reasons, and according to statistics from the American Association of Esthetic Plastic Surgery, in the year 2016 were carried out in the United States about 150,000 cosmetic nose surgeries.To know how we looked and thus have elements of judgment to take or not the decision to submit to us to These devices give us an objective picture of our physical appearance which, however, corresponds to a certain perspective and which we subjectively evaluate according to it. In other circumstances and from another angle of view, the subjective assessment that we made of our physical appearance might be different.In relation to the latter, it is interesting to note that the widespread practice of self-photographs or \u201cselphies\u201d is producing a curious demand for cosmetic nose surgeries, at least in the United States. In fact, according to the American Academy of Plastic and Reconstructive Facial Surgery, in 2017, 55% of plastic surgeons report receiving requests for nasal surgery from patients who consider their nose to be too large to judge by their photographs \u201cselfie\u201d. In 2016, only 16% of plastic surgeons report having received similar requests, so the demand for nasal surgeries is in rapid growth. The apparent size of the nose in a photograph depends, of course, on the distance to which it is taken. As we know, the things that are closer to the point of observation grow in relative size with respect to the farther objects. Thus, the nose, which is significantly closer to the camera than the rest of the face in a selfie photograph, appears to have a larger size. A quantification of the apparent enlargement effect of the nose was published this week in the magazine \u201cJAMA Facial Plastic Surgery\u201d by a group of researchers from Rutgers University Medical School in New Jersey, headed by Boris Paskhover. According to Paskhover and collaborators, when taking a photograph of a typical face at a distance of 30 centimeters, the nose appears to be 30% larger in size with respect to a photograph taken at a distance of at least 1.5 meters. Thus, as distorted mirrors, the \u201cselfies\u201d produce a distorted image of the face they portray and this the photographer must be aware of. The effect of the \u201cselfies\u201d on the demand for nasal surgical operations is unquestionably surprising, and completely Unexpectedly, as have been other effects that smartphones have produced. In this regard, let us think, for example, of the common and surprising phenomenon that occurs when a group of people are at the same time together and isolated travelling in cyberspace through their cell phones. On the other hand, for the benefit of those who are concerned about the size of their nose in the \u201cselfies\u201d photographs \u2013 which, presumably, would be destined to live in cyberspace \u2013 they would be advised to try to take them at a greater distance. If the latter is not acceptable, the possibility remains to edit them digitally. Or, as an extreme resource, to undergo nasal surgery, which would presumably improve their physical appearance in the virtual world, but would worsen it in the real world. And, at this point, the photographer/cybernaut would have to decide which of the two worlds would have priority. On the other hand, and at the margin of the previous caveats, it seems that the development and combination of anesthetics, nasal techniques and smart phones has given an unexpected twist.",
    "https://upload.wikimedia.org/wikipedia/commons/8/84/Espa%C3%B1a_y_Portugal.jpg": "In 1856, fossil remains were discovered in the Neander Valley, in what is now German territory, which soon became clear belonged to a human species until then unknown. Ten years later, the German biologist Ernst Haeckel proposed the name \u201cHomo stupidus\u201d for this new species, taking for granted its intellectual inferiority.For the luck of Neanderthals \u2013 as we now know the members of the species discovered in the Neander Valley\u2013Haeckel did not succeed with his proposal and prevailed instead the name \u201cHomo neanderthalensis\u201d, published two years earlier by the British geologist William King.From a 19th century European perspective, it is not surprising that Haeckel has prejudged the intellectual capacity of the Neanderthal species and assumed that it would have been by necessity inferior to that of our species. Indeed, Haeckel was racist and held that the European race was superior to all others, which were at an inferior stage of development. Thus, if among the human races, according to Haeckel, there are ranges of intellectual capacity, between species of the species, the However, our ideas about Neanderthals and their intellectual abilities have evolved considerably in their favor, and today it is considered that these were not very different from ours. Thus, Neanderthals could speak, and manufacture tools and body ornaments. They also had the habit of burying their dead, which indicates that they could think symbolically. And if that were not enough, it seems that there were also Neanderthal artists. This is what concludes a study published this week in the magazine \u201cScience\u201d by an international group of researchers headed by Dirk Hoffmann of the Max Planck Institute in Leipzig, Germany, in which they report the date of cave paintings discovered in caves in Spain. Researchers find that the paintings studied were made at a surprisingly distant time, when modern men had not yet arrived in Europe, which was inhabited only by Neanderthals. Hoffmann's research and collaborators took place in three caves: Pasiega, in the north of Spain, near Bilbao, Matravieso in the west, and Ardales in the south, near Malaga. The paintings themselves were not dated but from the lumps of carbonates deposited on them, which were formed after they were made. Thus, minimum ages were determined for the paintings. The date was carried out by a sophisticated technique that measures the compositions of the radioactive elements uranium and thorium in the carbonates, which vary in a characteristic way throughout the time. In La Pasiega the paintings include a figure in the form of stairway whose antiquity is more than 64,800 years. In Maltravieso you can see the silhouette of a hand made by supporting a hand on the wall of the cave and spraying paint through the middle of the mouth. It was found that this figure has an antique of more than 66,700 years. Finally, in Ardales, the wall of the cave has mineral deposits that give it the appearance of a vertical curtain and that have been painted red. In this case, the painting has In all cases, the paintings were made at least 20,000 years before the eruption of modern man in the Iberian Peninsula and this rule out that the authors of them belonged to our species. The inevitable conclusion is that they were made by Neandertals, who were known to be the only humans who populated Spain at the time because of the amount of fossil remains that have been found. Thus, the hand that left its impression in the cave of Maltravieso would have belonged to a Neanderthal that lived more than 60,000 years ago \u2013 which is still fascinating. Thus, it turns out that the intellectual capabilities of the Neanderthals \u2013who could have become known as the \u201cstupids\u201d if Haeckel\u2019s proposal had been successful \u2013 were definitely despised by the European racial prejudices of the nineteenth century. Such prejudices were fueled by the success of Europe in conquering the world in the last centuries. In this context, the fact that our species has survived and that the Neanderthals have been extinguished, was for some evidence more than convincing to demonstrate the inferiority of the latter.However, the results of Hoffmann and collaborators, like those of other researchers, show that things are not so simple, and that while it is true that Neanderthals became extinct some 30,000 years ago, the causes for what this happened are not related to their supposed intellectual inferiority. Thus, there is even one who speculates that if they had not disappeared, Neanderthals might perhaps have reached the Moon.",
    "https://upload.wikimedia.org/wikipedia/commons/3/30/The_War_of_the_Worlds_first_edition.jpg": "As it was broadcast in the mass media, last October an unknown object was discovered by astronomers at the University of Hawaii \u2013 baptized as Oumuamua \u2013 with an unusually elongated form, about 230 meters long and 35 meters wide, and an origin probably beyond the Solar System. Although astronomers finally came to the conclusion that it was an inanimate object, possibly made up of ice and with an external cover of organic material, its peculiar form motivated speculations in the sense that it was an interstellar visiting ship in our solar system. Had this been true, how would we have reacted? Possibly with concern \u2013 not to say panic \u2013 if we were to judge by the public alarm caused eight decades ago by the dramatization of the novel \u201cWar of the Worlds\u201d by the British writer H.G. Wells. As we know, Orson Welles broadcast by radio in the city of New York in October 1938 a dramatization of that novel in which Martians invade the Earth, and although at the beginning of the program it was warned that In an article published last February in the magazine \u201cFrontiers in Psychology\u201d by a group of researchers from Arizona State University, led by Jung Yul Kwon, the results of a study carried out to answer the previous question are reported. In particular, to shed light on what our reaction would be, positive or negative, to the discovery of extraterrestrial microbial life. In a first experiment, carried out with 500 participants, the researchers were asked to imagine a scenario in which the discovery of microbial extraterrestrial life was announced and to report their reactions to it. In the same way, they were asked their opinion about the reaction of the general population. Using specialized software, the researchers analyzed the responses of the participants looking for words that denote positive and negative attitudes to the alleged announcement, finding in both cases a clear preponderance of the first ones. In a second experiment, Jung Yul Kwon and collaborators investigated the reactions of 50 1 participants, not to a hypothetical discovery of extraterrestrial life, but to a news story published by the newspaper \u201cNew York Times\u201d in 1996, announcing the discovery of a meteorite in Antarctica of Martian origin with fossilized remains of an extraterrestrial microbe \u2013 which is, however, a source of controversy. As in the first study, researchers found an analysis of the more positive than negative responses to the discovery of extraterrestrial life.On the other hand, while the article by Jung Yul Kwon and collaborators focuses on extraterrestrial microbial life, it also describes a pilot study carried out to assess the social response, through articles published in the mass media, which in the past has been given to the announcement of discoveries that were related to the existence of extraterrestrial intelligent life. These include the discovery of sources of radiation that were initially thought to be signals transmitted by extraterrestrial beings, as well as the discovery of numerous exoplanets similar to Earth with the conditions of hosting intelligent life. There will, of course, be differences between the perception of the danger posed by alien microbes confined to the planet Mars or an intelligent civilization situated thousands of light years away that little harm could do us, and the anxiety that the presence in the vicinity of our planet of a race of intelligent extraterrestrial beings with the potential to invade us would bring us more negative than positive emotions. Moreover, as the probability that we will be invaded by aliens is practically null, little use has to make considerations about it. In contrast, the discovery of extraterrestrial microbes in the Solar System, which constitutes our neighborhood, does enter the sphere of the possible. And of the pleasant, if we are to believe Jung Yul Kwon and collaborators.",
    "https://upload.wikimedia.org/wikipedia/commons/b/bd/Baena_Liberec.jpg": "The climate change and global warming that our planet is experiencing is a matter of concern both for specialists and for lay people in this area. This is the case, for example, of Jessie Diggins, a member of the United States ski team who is competing in the winter Olympic games that opened last Friday in South Korea. In an interview that appeared a few days ago in the newspaper \u201cNew York Times\u201d, Diggins complains that the snow season on the ski tracks in the United States is becoming shorter as climate change progresses. Having grown up in Afton, a people in the state of Minnesota, Diggins learned to ski as a child and is concerned that their children may not have the same opportunity. There are also experts concerned about the global warming process that could have, in their opinion, disastrous effects on the planet\u2019s climate. As we know, global warming is the result of the growing emission of greenhouse gases into the atmosphere by the use of fossil fuels. It has been proposed that one way to achieve the above is to eliminate subsidies for fossil fuels \u2013 which apply both to their production and consumption \u2013 the price of which will thus be determined by their market value.The reasoning behind this proposal is very simple: if subsidies for fossil fuels \u2013 for example, for gasoline \u2013 are eliminated, they will be increased and their consumption will be reduced.An article published on 8 February in the journal \u201cNature\u201d, however, concludes that things are not that simple.This article was published by an international group of researchers led by Jessica Jewell of the International Institute for Applied System Analysis, based in Laxenburg, Austria.According to Jewell and collaborators, although eliminating subsidies for fossil fuels could result in a reduction in their net demand at global level, and a consequent reduction in the emission of air pollutants, the success would be only modest.In fact, according to researchers, the elimination of subsidies for fossil fuels would result in a reduction at global level of 0.5% to 2% of total dioxide. The reduction in energy demand will also depend on the region of the world to be considered. It will be greater in the countries of the Middle East, North Africa and Latin America, which have high levels of subsidies, but much lower in Europe and the United States. On the other hand, there will be countries, particularly in Africa, where there could even be an increase in the emission of atmospheric pollutants by the substitution of oil or gas by coal, which currently enjoys lower subsidies and whose combustion produces greater air pollution. If Jewell and partners are correct, the elimination of fossil fuel subsidies is not in itself a solution to limit the emission of atmospheric pollutants. In addition, researchers point out that in the non-developed countries such removal should be accompanied by additional measures to protect the population of lower resources that would be particularly affected. On the other hand, in an opinion paper published in \u201cNature\u201d in conjunction with the article by Jewell and collaborators, Ian Parry of the International Monetary Fund argues that fuel prices not only They must pay attention to their production costs, but they must also reflect the consequences of their use, including global warming and other environmental considerations such as pollution deaths, traffic congestions and road accidents.Certainly, given the problems that have resulted from the use we have given fossil fuels, their price should in principle reflect all the calamities it has caused, from endangering the ski fields \u2013 which we would otherwise agree would not be the most serious ones \u2013 to causing road chaos in urban centres and seriously affecting the climate of the planet.In practice, however, it is not clear how to give fuel a fair price in this context, while at the same time providing protection to the population of lower resources in countries like ours. Assuming, of course, that the demand for fuel can be controlled by the price that we assign to it, supposing that it should be evaluated in the light of the results of Jewell and collaborators.",
    "https://upload.wikimedia.org/wikipedia/commons/8/8c/Anesthesia_recovery.jpg": "On October 16, 1846, in an amphitheater at Massachusetts General Hospital in Boston, the first public demonstration of a surgical operation was given using general anesthesia. On that occasion, surgeon John Collins Warren, professor at Harvard Medical School, assisted as an anesthetist by dentist William Morton, removed a congenital tumor from the neck of a patient named Gilbert Abbott. To prepare the patient for the operation, Morton had him inhale ether using a glass device he had designed himself. The operation was a success, and while it was not the first one to be carried out using general anesthesia, it was widely publicized and marked the irruption of anesthetics in the field of surgery. Moreover, ether was not the only substance that was tested as anaesthetic in the nineteenth century; others were also the chloroform and nitrous oxide. The latter \u2013 which is known as \u201cgirant gas\u201d by the laughter it provokes among those who inhale it \u2013 was employed in 1864 by a group of dentists in New York to extract nitrous. The chloroform, for its part, was administered to Queen Victoria to relieve the birth pains of her last two children. Over time, the science of anesthetics became increasingly sophisticated, developing a large number of substances of the most diverse nature to relieve pain in surgical operations. However, even today, more than 150 years after Warren and Morton demonstrated, and when the horrors of surgical operations without anesthesia seem somewhat distant to us, specialists do not agree on what mechanisms are responsible for the action of anesthetics on the nervous system. An interesting article appeared last December in the journal \u201cAnnals of Botany\u201d, aims to shed light on the latter. This article was published by a team of researchers from Germany, Japan, the Czech Republic and Italy, headed by Ken Yokawa of the University of Bonn. It reports the results of an investigation carried out to study the effect of some substances used as anesthetics in the behavior of the University of Bonn. certain plants, among which are the fly-trapping venus and the sensitive mimosa.As we know, the fly-trap venus is a carnivorous plant that traps its living prey by means of a trap placed at the end of each of its leaves. This trap consists of two lobes that close \u2013 like a clam shell \u2013 trapping the insect on its surface. The trap is triggered when the prey touches at least two of the three hairs sensitive to the touch that are found on one of the lobes. The sensitive mimosa, on the other hand, closes its leaves in response to contact with a foreign object. To carry out their research, Yokawa and collaborators acquired the plants chosen in a local nursery. Initially, the plants responded to the stimuli as expected. In the case of the sensitive mimosa, their leaves were closed by touching them lightly with a brush, while the venus fly traps triggered their insect traps after touching two or three of their sensitive hairs. In contrast to the initial tests, after exposure for an hour to the atmosphere with ether, both plants stopped responding completely to the stimuli. Seven hours after removing the sensitive mimosa from the glass chamber recovered their response, while the flycatcher vein was faster and I only need fifteen minutes to do so. Yokawa and collaborators also measured the effect that ether has on the electrical activity of the sensitive hair cells of the fly catcher venus. In order to provoke a reaction from the plant, these cells must generate an electrical impulse, which researchers found is inhibited by the anesthetic. Plants in this way react to anesthetics in a similar way as do members of the animal kingdom, including humans. In this regard, animal and plant kingdoms would not be too far away and from this a question arises: we know that anesthetics can plunge us into a state in which we lose consciousness. Is it the same with plants? That is, do plants have self-consciousness that they lose when they are anaesthetized? Yokawa and collaborators tell us nothing about it and everything is unfortunately left in mere speculation. On the contrary, according to Yokawa and collaborators, what their results do indicate is that, given the similarity of plant and animal responses to anesthetics, plants are very suitable subjects of study \u2013 among other things because they cannot run \u2013 to reveal the mysteries about the mechanisms of action of anesthetics in humans. Something that would surely be surprising for the pioneers of anesthesia in the 19th century.",
    "https://upload.wikimedia.org/wikipedia/commons/4/4b/Montaje_de_la_Ciudad_de_Buenos_Aires.png": "During his visit to Lima last November to compete with Peru for the second and final game of the repechaje series to attend the world football championship to be held this year in Russia, the New Zealand team complained that Peruvians had resorted to dirty tactics to try to stop them. Among these tactics would have included a three-hour delay in the plane that transported them from Buenos Aires to Lima, and also a delay in their transfer from Lima airport to their hotel that would have taken 45 minutes. As a result, New Zealand players would only have been able to fall asleep until 1:30 a.m. In another incident, during the early hours prior to the qualifying game, a group of Peruvian fans threw with great noise and on two occasions fireworks right in front of the hotel where New Zealand players were staying. Although the expectation in Peru for the possible qualification to the Russian world championship was very great \u2013 their last participation in a fair of this kind occurred in 1982 \u2013 it is difficult for Peruvians to have come to the point of deliberately delay an international flight. In the same way, the 45 minutes that it took New Zealanders to transport from the airport to their hotel has probably been more a product of congested Lima traffic than of a deliberate act. Instead, the launching of fireworks in front of the New Zealand players\u2019 hotel did have the purpose of disturbing their sleep and slowing down their performance. In another rather sporty incident, an amateur in the stadium directed a green laser beam to the eyes of the New Zealand goalkeeper during the match with the aim of blinding him momentarily and making him lose his play. The latter, for the rest, is not a unique case and the use of lasers in sports stadiums to disturb players is far from unusual because of the facilities that exist today to acquire compact laser pointers of great power that are easily introduced into sports grounds. One characteristic of laser light is that travels in almost straight line, which allows him to reach large distances with little attenuation. This feature makes her dangerous because by penetrating into the eye she can focus on a small point and damage to the retina. In addition, it has increased to the extent that the powers of laser pointers have done so, which have reached values far beyond what is required by their function as pointers in audiovisual presentations. Thus, the risk is greater as the laser power is higher and in this sense the red pointers, which typically have moderate powers, are the ones that are less risky to involve. It is possible, however, to easily acquire pointers that emit green light with substantially higher powers than the minimum sufficient to cause permanent damage to the retina. And it is precisely these lasers that use the fans to disturb the players in the stadiums. Fortunately, the light of a laser does not travel strictly in a straight line \u2013 it does so to a greater or lesser extent depending on its cost \u2013 and given the great distance it has to travel in a stadium from the rostrum to the court, the amount of energy that could penetrate into the eyes of a player is only a small fraction of the total emitted by the pointer. The risk that this could suffer an eye damage is then proportionally reduced. For example, an article published last December in the journal \u201cDeutsches Arzteblatt International\u201d, published by a group of researchers from Germany and England led by Johannes Birtel of the University of Bonn, presents an analysis of 48 articles in the medical literature describing injuries caused by laser pointers in 111 patients. From this analysis, researchers find that laser pointers are capable of causing serious retinal injuries that may be permanent and result in reduced visual acuity. Birtel and collaborators also included in their article the cases of seven children and adolescents treated at the University of Bonn, who suffered retinal injuries while playing with green laser pointers of different powers. While laser pointers look harmless and can even be taken as toys by children, they are actually devices that may be dangerous if handled inappropriately. One problem noted by Birtel and collaborators is the wrong information \u2013 or lack of it \u2013 provided by the children. manufacturers of pointers on the actual power emitted by their devices. Thus, the actual power of a number of lasers investigated at the University of Bonn differ from the values provided by manufacturers up to a factor of one hundred. Therefore, care should be taken with the handling of laser pointers and use them only when the occasion warrants it. In particular, the pointer that was directed to the New Zealand goalkeeper\u2019s face in the game between Peru and New Zealand was clearly unnecessary, as the Peruvian team \u2013 by the good \u2013 had all to win by its clear football superiority.",
    "https://upload.wikimedia.org/wikipedia/commons/a/a3/Zipolite%2C_puerto_escondido%2C_Oaxaca..jpg": "In a case of interplanetary contamination, the Martians who invaded the Earth in the novel \u201cThe War of the Worlds\u201d by the British writer H.G. Wells were annihilated by the terrestrial microbes, unknown by their immune system and from which, for the same reason, they could not defend themselves. H.G. Wells\u2019 novel was published in 1898, when Mars exercised a great attraction as a possible seat of an advanced civilization. At the end, fortunately for the earthly civilization, although the Martians in fiction had a more advanced civilization than ours, it was not so much so as to anticipate what could happen with a great probability: the existence of terrestrial microbes against which they had no defense. Had they had knowledge of the history of Mexico, the Martians of H.G. Wells would have perhaps been more cautious. Indeed, as we know, in an episode of intercontinental pollution the Spanish conquerors of Mexico brought with unknown microbes in the New World that caused havoc among the native population. The emergence of such microbes was very early and indeed helped the conquerors. In his book \u201cVision of the vanquished: Indigenous Relations of the Conquest\u201d, Miguel Le\u00f3n Portilla cites indigenous testimonies about this attack, apparently because of the bacteria of smallpox: \u201cIt was very destructive disease. Many people died in it. No one could walk anymore, they were lying on their bed. They couldn\u2019t move their neck, they couldn\u2019t move their body, they couldn\u2019t lie down face down, they couldn\u2019t lie on their sword, they couldn\u2019t move from one side to the other. And when they moved, they screamed. Many people were killed by the sticky, flattened, hard grain disease.\u201d So defenseless was Mexico\u2019s native population in the face of the smallpox germs introduced by Spaniards who between 1519 and 1520 died from 5 million to 8 million indigenous people, a significant percentage of the estimated 20 million people made up of the total population. This article was published by a group of researchers from Germany, the United States, Switzerland and Mexico, headed by Ashlid Vagene, and headed by Ashlid Vagene. According to scholars, during the 14th century, Mexico was affected by a series of epidemics of different nature that decimated the indigenous population that fell from 20 million in 1519 to about two million in 1600. Two epidemics, known as cocoliztli by indigenous people, were particularly devastating. The first, which occurred between 1545 and 1550, was estimated to have resulted in between 5 million and 15 million deaths. A second epidemic took place between 1576 and 1578 and resulted in about two million additional deaths. On the other hand, beyond its deadly nature, there is no agreement on what were the pathogens that caused these epidemics.In this regard, an article published this week in the journal \u201cNature Ecology and Evolution\u201d sheds light on the identity of the germs responsible for the cocoliztli epidemic of 1545-1550. According to Vagene and collaborators, there is a high probability that the cause of the epidemic of 1545-1550 was the \u201centeric salmonella\u201d bacteria. They come to this conclusion through the study of the skeletons of cocoliztli victims from a cemetery in the state of Oaxaca \u2013 in which victims of the epidemic are known to be buried \u2013 and in which they found traces of the salmonella genome. For further clarifications, researchers do not say with certainty that this bacterium was the cause of cocoliztli but do consider that there is a great probability that it is.In one way or another, beyond the true identity of the pathogens that ravaged the native population of Mexico as a result of the Spanish conquest, the indigenous population was mermed \u2013literally decimated \u2013 over the course of 80 years, in a population catastrophe of dimensions comparable to those of bubonic plague that struck Europe in the 14th century and produced 25 million deaths. The pathogens of the Old World who became allies of the Spaniards and joined their horses, archabuces and cannons against the Mexicans. Could it have been otherwise? That is, as in the fiction created by H.G. Wells, could the Spaniards have been susceptible to the pathogens of the New World and thus become their enemies? Would this have changed the history of the conquest? The questions are idle, of course, but possibly not absurd and if they are entertaining. After all, we know that foreigners who visit our country are susceptible to suffering various stomach and intestinal diseases due to the phenomenon known as \u201cRevenge of Moctezuma\u201d.",
    "https://upload.wikimedia.org/wikipedia/commons/9/9e/Diqing%2C_Yunnan%2C_China.jpg": "According to a story reported by the media in recent days, Wang Fuman, an eight-year-old boy who lives in a rural area of Yunnan province in southern China \u2013 near the Vietnam border \u2013 has to walk 4.5 kilometers daily to attend school.This would not have been the reason for further comments if not because a photograph released as part of the story shows the child arriving at school with frozen hair and cheeks reddened by the cold.This, because he had to walk for an hour and a half on a cold morning with temperatures below zero degrees Celsius.The photograph of Wang Fuman frozen, which became viral, was taken by his teacher, who circulated it through a social network in China and made it reach a means of communication in that country, which in turn spread it worldwide.As a fortunate consequence, Wang Fuman was given winter clothes, including gloves as part of the dissemination of his history also included a photograph of his hands with cracked skin. On the other hand, while physical exercise may have its positive side \u2013 although the one that Wang Fuman has to perform daily is certainly unhealthy, especially with temperatures below the freezing point of water \u2013 life in physically isolated communities is not desirable. In fact, there is a certain relationship between the level of development and the isolation of a community. A quantification of the isolation of different communities in the world is given to us by an article published this week in the magazine \u201cNature\u201d, published by an international group of researchers headed Daniel Weiss from Oxford University in the United Kingdom. In that article, Weiss and collaborators present, among other data, a global map showing in different colors the time of transfer from any point in the world to the nearest city with a population of at least 50,000 inhabitants. This map has a resolution of one kilometer and was made with data from Google and the \u201cOpen Street Map\u201d project, housed in computers from University College London and Imperial College London University. As might have been expected, the map shows that the transfer times are measured in minutes around In contrast, in some developing countries, notably from sub-Saharan Africa, these times of relocation tend to be considerably larger. A short transfer time, however, does not indicate a high degree of development. Thus, the times of relocation in India, which has a high density of urban centres, are short, while in northern Norway and Sweden, which has a low population density, are considerably longer. Overall, however, if there is a connection between connectivity with urban centres and the degree of development. Indeed, Weiss and collaborators find that while 80% of the world\u2019s population lives less than an hour from an urban centre, the distribution throughout the world is not uniform. Thus, while 90% of the inhabitants of rich countries live less than an hour from an urban centre, in some low-income countries, those concentrated in the region south of Sahara, that figure is just 50%. For the well-being of the population, greater connectivity of non-urban areas with cities would be essential to increase this well-being. In line with this, using data from demographic and health surveys funded by the United States Agency for International Development, Weiss and collaborators find a clear correlation between the time of transfer to the city and the level of income, the level of education achieved and the use of health services.Weiss and collaborators note that the areas of greater accessibility include those with abundant transport infrastructure and/or with many scattered cities, and of this suggest as a strategy that transport infrastructure should be improved and promote a polycentric urban development.According to INEGI, 22 per cent of the country's population lived in rural communities. In these conditions, Mexico would, according to the suggestion of Weiss and collaborators, have to build urban and transport infrastructure to meet the needs for at least 20 million people. Given the conditions of Mexico and China, however, Wang Fuman would be very likely to resolve its transport problems before our compatriots do the same.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d7/Nordhalbkugel_gr.png": "As has been widely publicized by the media, the east coast of the United States is being affected by a severe winter storm that has led to snowfall even to the southern state of Florida. By Saturday night and Sunday morning, the United States climate office has issued a low temperature alert that, combined with the wind effect, will reach apparent temperatures in some places of less than tens of degrees Celsius. And all this, as we know, still affects us, who are placed south of the Tropic of Cancer at considerable distance from the colds of the Arctic. The extreme climate that is affecting the east coast of the United States seems to contradict the global warming process that is affecting the planet. In fact, in a tweet from last December 28, the president of the United States suggested that, in order to face the cold, the east coast of the United States could make use of a little of the good global warming by which \u201cour country, but not others, will pay trillions of dollars as protection.\u201d In fact, according to experts, warming In fact, as an example, it can be mentioned that this mechanism is discussed in an article published last September in the magazine \u201cBulletin of the American Meteorological Society\u201d by an international group of researchers headed by Marlene Kretschmer of the \u201cPotsdam Institute for Climate Impact Research\u201d, Germany. As we know, the temperature decreases in temperate areas of the northern hemisphere are caused by the flow of polar air to these areas. According to Kretschmer and collaborators, on the other hand, the polar jet current circulating in the northern part of our hemisphere serves as a containment barrier for the flow of Arctic air to the south. This current, however, weakens as the temperature of the North Pole rises, which is precisely causing global warming. We can mention, moreover, that while such warming has been the result of uncontrolled greenhouse gas emissions, the polar regions themselves are actively contributing to increasing the amount of solar radiation retained by the Earth; this, insofar as the fraction of its ice-covered surface has been reduced. That is, since an ice-covered surface reflects most of the solar radiation that affects it, as polar ice decreases, the amount of radiation that is referred to space and consequently the amount that is absorbed by the Earth decreases. The study by Kretschmer and collaborators, however, refers to the temperature decreases that have been observed in the northern parts of Asia and Europe and more research is necessary to find out whether the mechanism they have found to explain the cold winters on those continents is equally adequate to explain the cold wave that currently strikes the north of the American continent. In one way or another, however, through the results of Kretschmer and collaborators, it is possible to understand something that we profans seem to be a counter-sense. say, that a process of warming, which is indisputable is happening at a global level and in a more marked way in the polar regions, can originate a polar cold wave. We learn, too, that the Earth\u2019s climate is extremely complicated to understand and that for this purpose our common sense has severe limitations. For someone not expert on climate issues it is then risky to issue opinions on it. Certainly, it is even if these opinions were interested, as is the case with those that point to the convenience of making use of a little of global warming to heat the climate of the east coast of the United States. That the latter is thus proven by the fact of having chosen to comment on the climatic conditions by which it is crossing the east coast of the United States. That is to say, having chosen the current climate of the west coast of that country, that this experiencing temperatures above the usual, would have come to the opposite conclusion.",
    "https://upload.wikimedia.org/wikipedia/commons/0/04/Alcohol_in_Romania.jpg": "This is true for both Mexico and many other countries in the world, although each country has its preferred drinks to give free rein to its joy. In Mexico, as we know, the most popular alcoholic drink is by far beer, followed by tequila. With lower consumption rates we find whiskey, brandy and vodka. In terms of percentages, alcohol consumption rates in Mexico are high, and not only at Christmas times. In fact, according to a survey by the National Institute of Public Health, in 2012 25 percent of Mexican adolescents aged between 10 and 19 years consumed alcohol on a daily or occasional basis throughout the year prior to the date when the survey was conducted. No statistically significant change was observed in this percentage between 2000 and 2012. In contrast, the percentage of adult alcohol users in Mexico is significantly higher and increased significantly between these two years, from 40% in 2000 and 54% in 2012. A very popular alcoholic drink in some countries \u2013 although not in ours, of brewery tradition \u2013 is grape wine in its different versions. Among the leading countries in wine consumption are France and Portugal with an annual per capita consumption of approximately 56 bottles of 0.75 liters. Other European countries, including Italy and Germany are also large wine consumers although in a smaller proportion.On the other hand, while in England the per capita consumption of wine is less than that of the leading countries in the field, it is interesting to bring up an article published in the Christmas edition of BMJ magazine by a group of researchers from Cambridge University, United Kingdom, headed by Theresa Marteau, in which some aspects of wine consumption are analysed in that country. BMJ magazine is a magazine of the British Medical Association that publishes medical research articles with a strict editorial evaluation. In the Christmas issue, however, this magazine also tends to publish lighter articles, which, however, also subject to a strict editorial evaluation. This is the case of the article by Marteau and collaborators reporting the results. of an investigation carried out in order to find out the evolution of the size of wine glasses in England over the last three centuries, and how this evolution has influenced the per capita consumption of wine in that country. According to Marteau and collaborators, the consumption of wine in England quadrupled between 1960 and 1980 and after this doubled between 1980 and 2004, and they wonder if these increases are associated with an increase in the size of the cups in which it is customary to drink it. This would be similar to how the size of table dishes have contributed to a greater consumption of food as reported by other researchers. For their study, Marteau and collaborators obtained data on the size of the wine cups throughout the last three centuries from sources such as the Museum of Art and Archaeology of Oxford University, the Royal House of the United Kingdom, eBay \u2013 former cup auctions \u2013 the catalogue of a glass maker, and the Internet site of the department store with the largest wine cup inventory. From their study, the researchers conclude that in the year 1700 the wine cups had a volume of 66 milliliters, which increased to 417 milliliters in the years 2000 and to 447 milliliters in 2016-2017. Moreover, while until the 90s of the last century the increase was gradual, it accelerated markedly from that moment. Marteau and collaborators recognize that, while the increase in wine consumption in England has occurred concurrently with an increase in the volume of the cups, it is not possible to infer from their data a cause-effect relationship between the two phenomena. They argue, however, that a larger cup houses a greater amount of wine and that this leads, to a greater consumption. That is to say, that the same amount of wine is perceived as less in a large cup compared to a small one. To support the above, Marteau and collaborators bring to the conclusion an earlier investigation carried out in a bar and in which it was found that when serving the wine in larger cups increased sales were increased by 10%. In addition to the fact that later studies confirm or refute the conjecture of Marteau and collaborators, it is certainly surprising to learn that over 300 years the size of the wine cups has multiplied by a factor of seven and that in the 18th century these were barely larger than a traditional tequila cup. On the other hand, it is possible that the same growth trend has occurred with other cups. Tequila, for example, of which there are now giant versions that have appeared in just a few decades. The explosion of sizes could thus be generalized. In this context, it is most advisable to act with the greatest caution in the celebration of the next Christmas holidays.",
    "https://upload.wikimedia.org/wikipedia/commons/c/c2/Brookings_Institute_DC_2007.jpg": "In an article published this week in the Spanish newspaper El Pa\u00eds, Lita Nelsen, who led for 25 years the technology transfer office of the Massachusetts Institute of Technology (MIT), explains that this university \u2013 one of the world\u2019s leading educational institutions in the area of engineering \u2013 obtained from patents that has produced only 4% of its total income. This, contrary to what could have been expected. In fact, the MIT obtains most of its budget of public grants for research projects, followed by college fees charged to its students and donations of private money. Nelsen explains, moreover, that this circumstance is shared by many other universities in the United States. The above is an indication that the scheme of generating resources through technology transfer is complicated, even in institutions with a solid scientific and technological infrastructure. Indeed, Walter Valdivia, of the Brookings Institution in Washington, D.C., reports in a study published in November 2013 that while 13% of universities in the United States generate resources through their patents, the remaining 87% do not generate resources through their patents. As an example, according to data from the Association of University Technolgy Managers cited by Forbes, the University of New York invested $210 million in research in 2006, which generated $157 million in profits \u2013 a 25% \u201closs\u201d \u2013 which placed it in the first place among American universities. The second place was occupied by Wake Forest University with figures of $146,3 million in investment, $60.5 million in profit and a 59% \u201closs\u201d. The next 13 universities considered by Forbes did not exceed in profit 16% of what was invested, The University of California system, for example, invested in 2006, $3.040 million in research and earned $193.4 million in profit, 6.4% of what was invested. A deficit balance between research investment and profits per generation of technology should not, of course, be In contrast, universities are institutions whose substantive functions include education and the generation of new knowledge, and in this sense research is a basic element for the training of new professionals, particularly at the postgraduate level.This is relevant for Mexico, given the pressure that exists in our country for public universities, which are critically dependent on public money, to generate by themselves part of the resources that they need for their operation.In this context, it is not surprising that these universities should seek to bring resources together through the generation and transfer of technology to the industrial sector.This approach is reinforced by the fact that scientific research in our universities is carried out almost exclusively with public funds and therefore it is imperative that it be redicted to a public benefit.While it is not possible to argue in general against these views, from a practical point of view, the difficulty of establishing a resource-generation scheme in Mexico through technology transfer, which is complicated even in the advanced countries that have an educational infrastructure in place, must be addressed from a practical point of view. In fact, since science had a late entry into our country, there has been a slow development of our universities as research institutions. In the last half century, with the creation of CONACyT in 1970, significant progress has been made and research centers and research groups have been created in our universities that are at a level of international competence. There is still much to be done, however, to ensure that our science and technology system reaches the size and maturity that will allow it to have a significant impact on technology transfer processes.In these conditions, it is worrying that the federal government has not devoted more resources to science and technology in Mexico, and that we are still far from reaching 1% of the gross domestic product as investment in science and technology, a goal that has been set at least twice. As a product of the human resources training programme that CONACyT introduced in 1971, a large number of doctors and teachers in science have been trained who are having difficulties in finding employment in Mexico; and those who have managed to take up a place in one of our universities are also having difficulties in obtaining resources to assemble in Mexico. So, many efforts remain to be made to ensure that resources flow to our universities as a product of technology transfer, even if these resources represent only a small percentage of what is invested in research.",
    "https://upload.wikimedia.org/wikipedia/commons/9/9b/National_Association_Against_Woman_Suffrage.jpg": "In her book \u201cRosalind Franklin: the Dark Lady of DNA\u201d, the American writer Brenda Maddox mentions the sexist atmosphere that prevailed at the \u201cKing`s College\u201d in London in the 1950s. In this regard, she notes that, for example, there were two dining rooms in that institution, one exclusively for men and the other for mixed use. Although, according to Maddox, attendance at the men\u2019s dining room was not necessarily something common among all professors and researchers at the University, the history of Rosalind Franklin, who served as a researcher at the \u201cKings\u2019s College\u201d for two years, is understood by some in a context of professional discrimination towards the female sex; discrimination which, moreover, at that time was not unique to the \u201cKing\u2019s College\u201d. Rosalind Franklin was born in London, England, in 1920 and educated as a physical chemist at the University of Cambridge. In 1951, after a research stay in Paris, during which he specialized in the use of X-rays for the study of materials, he incorporated himself as a physicist at Cambridge University. At \u201cKing\u2019s College\u201d where he conducted research that aimed to elucidate the molecular structure of DNA. His X-ray research work was key to Francis Crick and James Watson, then at Cambridge University, concluding that the DNA molecule has the form of a double helix. The story of the discovery of the DNA structure has been involved in controversy as Franklin\u2019s contribution was not recognized at the time fairly. According to that story, the discovery of the DNA structure was based on an X-ray photograph taken by Franklin of the DNA molecule. Violating a basic ethical standard, Maurice Wilkins, Franklin\u2019s co-worker at \u201cKing\u2019s College\u201d, showed that photograph to Crick and Watson who immediately understood its importance. He did, however, before the photograph was made public and without Rosalind\u2019s consent, with whom he did not. By the discovery of the double helix of the DNA molecule, Cricks, Watson and Wilkins received the Nobel Prize in Physiology or Medicine in 1962. Certainly, although he did not succeed. Rosalind Franklin could not have been a beneficiary of this award because by the date four years ago she had died as a victim of ovarian cancer, the episode has been considered by some as an example of gender discrimination in the field of science. In fact, in 1968 James Watson published the book \u201cThe Double Helix\u201d, in which he gives a personal version of the events that led to the discovery of the DNA structure and in which he refers to Franklin in an unrewarding and sexist manner. In response, books have appeared, including Brenda Maddox\u2019s, which try to balance views on Rosalind Franklin, as a person and as a scientist. Sexist prejudices about the type of occupation proper to women, of course, have not been limited to scientific activity or to a particular time. Thus, during the Victorian era \u2013 from which Rosalind Franklin was not very far away in time \u2013 women were largely limited to a role of wives and in some way Queen Victoria, first as a wife and then as a widow, set the example. This week\u2019s article in the journal \u201cScience Advances\u201d, published by an international group of researchers led by Alison Macintosh of Cambridge University in the United Kingdom, reports the results of a research carried out with humers \u2013 upper arm bone \u2013 of 94 women who lived during the period from 5,300 years BC to 850 years AD, covering from the Neolithic to the Middle Ages. The aim of the study was to find out how the appearance of agriculture and sedentaryism modified the thickness of humerus by changing the type of activity and as such grousos is compared to that of contemporary women, both athletes from the Cambridge University rowing team, as well as other high-performing athletes and sedentary people with normal activity. Macintosh and collaborators found that the humers of women who lived between 5,300 years BC and 100 years AD had thicker humers than contemporary women, even in the case of remeras. After that, the thickness of the humerus began to decrease until in the Middle Ages it reached a size equivalent to that of the present. This is an indication that, with the advent of agriculture, women developed an intensive activity that involved a great force in the arms, possibly grinding grains by means of a stone metate.As the technology of the mills progressed, the intensity of this activity decreased and with this the thickness of the upper arm bone.The above shows that in remote times women developed activities that required a great muscle strength, which, to some extent, contrasts with the Victorian conception of the role of women in society. Activities that are, in addition, complement to the intellectual activity exemplified by Rosalind Franklin, equally opposed to Victorian ideas. There is therefore no space, for gender discrimination.",
    "https://upload.wikimedia.org/wikipedia/commons/4/4a/AMI_scheme.png": "In the summer of 1955, the then president of the United States, Dwight Eisenhower, suffered a heart attack while sleeping. Although that attack was misdiagnosed by his personal doctor and it took 12 hours before he was admitted to an emergency hospital, Eisenhower recovered from the problem. And he did so to the extent that the following year he was re-elected for a second four-year term in office, which led to the completion, if not before he suffered a second attack. The heart problems that plagued President Eisenhower during his presidency, gave national visibility to the ideas of Ancel Keys, a physiologist at the University of Minnesota, who held that a risk factor for a heart attack is the high level of cholesterol in blood induced by the intake of foods rich in saturated fats. Not everyone was, however, in agreement with this view. In particular, John Yudkin, a nutritionist at the \u201cQueen Elizabeth College\u201d of the University of London, believed that sugar intake was more dangerous for health than the ingestion of sugar. This, not only for the development of heart problems, but also as a cause of obesity and diabetes.Over time, Keys' views prevailed over Yudkin's and saturated fats became the villain to be avoided, even if suffering from health problems. Thus, a thriving low-fat food industry developed and, to compensate for, rich in carbohydrate content. With the change of diet, however, something turned out wrong if we were to judge by the obesity and diabetes epidemic that has developed in various regions of the world. Indeed, if, for example, we look at obesity statistics in the United States, we will notice that between 1960 and 1980 the number of obese people increased at a moderate rate. In contrast, since 1980, when the US government issued a guide to a healthy diet, that rate increased considerably and the number of obese reached overwhelming numbers. Indeed, according to statistics from the Center for Disease Control and Prevention of the United States, between 2011-2014, two out of three Americans, As a result of the food catastrophe of recent decades, Yudkin\u2019s ideas have resurfaced. Thus, Robert Lustig of the University of California, San Francisco, accuses the sugar of being the real culprit of this catastrophe. It should be noted that even for lay people this makes sense, as humans have evolved by consuming animal fats and it has only been in recent centuries \u2013 a despicable time in evolutionary terms \u2013 that we have added sugar to our diet. As guilty of the food catastrophe, sugar is in this way more suspicious than saturated fats. However, trying solidly the effect that a certain food has on our health is extremely difficult because of the need to carry out controlled experiments over many years. There is also the interference of the different food industries interested in promoting or demonizing certain products for their benefit. In relation to the latter, the week that ends today appeared an article in the magazine Plos One Biology in which research carried out in the decade of the sixties last century by commission of the \u201cSugar Research Foundation Foundation\u201d \u201cThese researches studied the effect of sugar consumption on our health. The reference article was published by a group of researchers at the University of California, San Francisco, led by Christin Kearns. According to research conducted by Kearns and collaborators, the \u201cSugar Research Foundation\u201d \u2013 with leagues with the sugar industry \u2013 funded research conducted at Birmingham University with laboratory rats to determine the effect that a sucrose-rich diet has on triglyceride levels in the blood. Such research found that sucrose feeds generate levels of triglycerides higher than that rich in starches. They also found indications that sucrose diet can produce bladder cancer. When the \u201cSugar Research Foundation\u201d learned the results of the research, still in process, suspended it and never published the results. According to Kearns and collaborators, the \u201cSugar Research Foundation\u201d manipulated the scientific results obtained by researchers at the University of Birmingham to favor the commercial interests of the sugar industry. And with this it would have contributed to the epidemic. Obesity of capital proportions that scares the world. With bitter results.",
    "https://upload.wikimedia.org/wikipedia/commons/b/b0/Wilhelm_R%C3%B6ntgen_by_Nicola_Perscheid_1915b.jpg": "Last Sunday in this same space we commented on the discovery of X-rays by German physicist Wilhelm Roentgen in November 1895 and the impact it had on medical diagnosis and treatment. In contrast to visible light, X-rays have the ability to penetrate organic tissues \u2013 to a greater or lesser extent depending on the type of tissue \u2013 and to produce images of the inside of the body. We also commented on the use of muons \u2013 subatomic particles that have a great penetration capacity in the material bodies \u2013 to investigate the possible presence of oquities inside a stone mole as immense as the major pyramid of Guiza. Thus, X-rays and muons can be used as extensions of our senses to see what is hidden in plain sight.As expected, muons and X-rays were discovered in leading countries in scientific and technological matters and in this regard there is nothing to be surprised. It is interesting to note, however, that very little time after their discovery, both X-rays and muons made presence in our country, particularly in the city of St. Louis Potosi. In fact, within a few months of the announcement of the discovery of X-rays and the diffusion of the X-ray from Roentgen's wife's hand, engineer Luis Espinosa y Cuevas \u2013 brother of Jos\u00e9 Espinosa y Cuevas who was governor of San Luis Potos\u00ed \u2013 acquired and brought to San Luis Potos\u00ed an X-ray machine. Although it is surprising how quickly the X-rays arrived in San Luis Potos\u00ed, this rapidity is partly explained by the fortunate presence of the engineer Espinosa y Cuevas in Germany at the time the discovery of Roentgen was made public. It does not explain it completely, however, and here it is necessary to add his personal interest in the discovery and the desire that this one had an influence in his native country. He agrees with Jos\u00e9 Refugio Mart\u00ednez Mendoza Mendoza, a broad knowledge of the scientific history of San Luis Potos\u00ed, \u201cThe brothers Jos\u00e9 Espinosa and Cuevas and Luis Espinosa and Cuevas, would be among the first engineers to graduate in the Scientific and Literary Institute; these characters would also be among the first students to take up the chair of the At the end of the first decade of teaching at the Institute after its reopening\u201d. Luis Espinosa and Cuevas thus had knowledge of physics, and in this context it is not surprising that he would be interested in X-rays. On the other hand, his training in the field of physics did not guarantee that he had a concurrent interest in employing X-rays to solve problems of a medical nature. In these circumstances and in the absence of more information, his own would be an exceptional case. In one way or another, Luis Espinosa and Cuevas\u2019 initiative to bring to San Luis Potos\u00ed an X-ray machine at this early time place the state as a pioneer of X-rays, not only in Mexico but in all of Latin America. San Luis Potos\u00ed would be like this and the place where the first X-rays were probably performed. San Luis Potos\u00ed also had a relatively early contact with the muons \u2013 which are produced by the clash of cosmic rays that come from deep space with atoms of the atmosphere\u2013 that had been discovered in 1936. This contact occurred in the second half of the 1950s and Gustavo del Castillo y Gama, who, together with Candelario P\u00e9rez Rosales, was the founder of the School of Physics at the UASLP. Gustavo del Castillo arrived at the UASLP in 1955, after graduating as a doctor in physics at \u201cPurdue University\u201d in the state of Indiana, and began a project to build a \u201cmist chamber\u201d to detect muones. This project basically sought to reproduce the camera he had built as part of his doctoral thesis. Gustavo del Castillo succeeded in his company and in record time built the camera and put it into operation. If one takes into account the conditions he encountered in the country in general and in the university in particular, it is surprising that the success of the Castle and this definitely reveals it as a person out of series. Muons and X-rays have undoubtedly been relevant to the scientific development of San Luis Potos\u00ed. On the one hand, the rapid adoption of X-rays and its use as a diagnostic tool is indicative of the high level of development that the Potosin medicine had in the beginning of the 20th century and explains its current level. San Luis Potos\u00ed has gone through difficult times throughout his history, the brilliant work of Gustavo del Castillo as a builder of scientific instruments was indicative of his great potential. Today, 60 years after his foundation, this potential has crystallized to a large extent and the Potosine physics is one of the most developed in the country. What will be the future of scientific research in San Luis Potos\u00ed? It is difficult to specify it but will depend to a large extent on the policies of support to science and technology that are implanted at the federal level to maintain and exceed its current level. In particular, we could not expect a healthy development of maintaining the current scarcity of resources destined for research. If this is the case, we would not do justice to the pioneers of research in the state.",
    "https://upload.wikimedia.org/wikipedia/commons/f/f7/Kairo_Museum_Statuette_Cheops_03_%28cropped%29.jpg": "It was in November 1895 that German physicist Wilhelm Roentgen discovered a mysterious form of radiation \u2013 to which he gave the name of the X-rays because his nature was unknown to him \u2013 with the property of traversing objects, even some that are opaque to visible light. The ease that the X-rays have to penetrate into matter depends, on the other hand, on the nature of the matter. Thus, the X-ray image that Roentgen took from his wife's hand, in which clearly the bones and the ring that he carried on one of his fingers are revealed, proved that the X-rays penetrate much more easily into the soft tissue of the hand than through the bones: And they do so much less through the metal of the ring.The X-rays allow us to see in this way the inside of the body, which is hidden from our eyes. Thus it was evident the enormous potential for the medical diagnosis that these rays offered and it is not difficult to understand that they have attracted an enormous and instantaneous interest, not only among specialists but among the general public. Rogenent even made a demonstration of the x-ray before the kaiser William II. Today we know that, apart from X-rays, there are other forms of radiation that allow us to see beyond our eyes. At some airports, for example, security equipment is used that employs very small energy rays \u2013 unlike X-rays \u2013 to discover weapons or other objects hidden under clothing. In this case low-energy radiation can penetrate through the cloth of clothing and discover what is beneath it.Another form of radiation used to discover what is hidden in view are the so-called muons, which occur when cosmic rays coming from deep space penetrate the atmosphere and collide with air molecules. Muons have the particularity of penetrating relatively large distances into materials such as stone \u2013 in contrast to visible light \u2013 and have been used to investigate hidden objects in natural or artificial structures. A very interesting application of muons was published in advance the week that ends today in the journal \u201cNature\u201d by an international group of researchers headed by Kunihiro Morishima of the University of Nagoya in Japan, and the study of the interior of the pyramid of Keops in Egypt that has not yet been fully explored. As we know, the pyramid of Keops is the largest of those that make up the complex of Guiza near Cairo. It was built 4,500 years ago, presumably to serve as a tomb to Pharaoh Keops, although his mummy has not been discovered until now. It is thought that at the time, the pyramid had a height of 146 meters and for almost 4,000 years it was the record of the highest artificial structure on the planet. It is known that its interior houses three cameras, an underground chamber and two cameras above the level of the ground, that of the king and that of the queen, all connected by a set of corridors. To access the king's camera you have to cross a corridor of 1-2 meters wide, 8 meters high and almost 50 meters long called the Great Gallery. Morishima and collaborators were given the task of exploring the pyramid in search of additional cameras. For this, they placed a series of muons detectors in the queen's chamber and measured the intensity. The idea of the experiment is very simple: if there is an oquedad in a certain direction \u2013 measured from the point where the detector is placed \u2013 the intensity of the flow of muons that arrive at that detector along that direction will be greater than if the oquedad did not exist. That is, the muones traveling in an oquedad will suffer less attenuation than those that travel through a similar volume of stone. Thus, measuring the flow of photons for several directions, Morishima and collaborators came to the conclusion that there is an oquedad just above the Great Gallery, with approximately the same volume. The resolution of their measurements, however, does not allow them to conclude if it is really a new chamber or if it is an oquedad placed by the builders of the pyramid to diminish the weight of the stone placed above the Great Gallery and prevent its collapse. They have the certainty, however, that such an oquedad exists so it is detected by three measurements of muons carried out independently. However, the article and the conclusions of Morishima and collaborators were not to the liking of the Egyptian authorities, who stated that the researchers have not discovered anything, that the publication is premature and that it should not have come to light, and that, in any case, the existence of the oquedad was already known. They have threatened, even, to withdraw the permission of the researchers to continue exploring the pyramid. The existence of a new oquedad in the pyramid of Keops, of course, will have to be discussed with scientific arguments in the framework of new investigations and not with disqualifications and threats to withdraw licenses to continue investigating. Apart from this discussion, on the other hand, we can only marvel at the techniques developed using the scientific knowledge that allow us to see the invisible.",
    "https://upload.wikimedia.org/wikipedia/commons/f/f1/Svidnik_skansen_school_interior.jpg": "For a teacher who did not grow up in the digital age, it is shocking to discover during the class a student \u2013 surely a digital native \u2013 by consulting his smartphone for matters unrelated to the course rather than attending to his explanations. In this circumstance, the teacher will certainly come to the conclusion that this lack of attention will surely have a negative impact on his grades at the end of the course. It is not difficult to agree with the latter that, moreover, it results from applying common sense. The subject, however, has its complexities and nuances as discussed in an article that appeared online last August in the magazine Computers in Human Behavior, published by Daniel le Roux and Douglas Parry of Stellenbosch University in South Africa, in which the results of study are described to determine how the use of multimedia devices in the classroom affects students. Researchers note that the presence of such devices in the classroom prompts the student to a multi-tasking activity that continually changes him from one activity, media or non-media. In this context, le Roux and Parry They were interested in finding out whether the multitasking activity, in which the student continuously changes focus, has a negative effect on his academic performance. And if so, if this effect is the same for all academic areas. A total of 1678 students from the faculties of Agricultural Science, Arts and Social Sciences, Medicine and Health Sciences, Economics, Engineering and Natural Sciences participated in the study, 83% of whom had at the time of the study between 20 and 23 years of age. An online survey was carried out among the participants to find out their multimedia activities online, both in the classroom, and in general. Among the online activities that Le Roux and Parry considered for their study were, social networks, microblogs, the search for information in encyclopedic databases and instant messaging. The results of the study indicate that there is a negative impact on the academic performance of the students of arts and social sciences by the use, both inside and outside the classroom, of all multimedia channels considered. The same is true for students of natural sciences insofar as there is a negative impact on the academic performance of the students of the arts and social sciences by the use, both within and outside the classroom. The students of engineering, and medicine were also negatively affected. In this case, the general use of multimedia channels. In contrast, for the students of economics there was no clear correlation between their academic performance and the use of multimedia channels. The study found that the students most negatively affected by the use of multimedia channels are those of arts and social sciences. They do not give le Roux and Parry a conclusive explanation about what causes the differences between disciplines but suggest three possibilities. In a first line of reasoning, they argue that such differences could be due to the different styles of thinking between disciplines: linear, as opposed to nonlinear, and concrete in opposition to abstract. Social sciences would be characterized by a nonlinear and abstract thinking style that, for some undiscused reason, would be particularly susceptible to be affected by the interruptions involved in multitasking activity. This, in contrast to hard sciences such as physics, whose thinking style would tend to be linear and concrete and more resistant to such interruptions. the least resistance to interruptions in class, not to the student, but to the nature of each discipline: quantitative in the case of hard sciences, and more subject to interpretation in the case of social sciences. Researchers argue that their results would show that the teaching of social sciences is less resistant to interruptions than the teaching of hard sciences.One last explanation has to do with the style of evaluation of the student's use. In the case of hard sciences, the answer to a test problem has to be precise and independent of the criterion of the one who reviews it. In contrast, in the case of social sciences, more interpretative, the evaluation is to a certain extent subjective and dependent on the criterion of teacher. Thus, if a student of social sciences spends the time of class distracting his attention with his phone continuously, he will lose himself from capturing the views of the teacher that are relevant to obtaining good grades at the end of the course. In the margin of explanations, however, native or non-native digital we should agree that the class time is the one in which students are obliged to follow the explanations of the teacher. due to boredom or complexity of the topic exposed, the student has to make efforts not to leave class by taking refuge on his phone.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d9/Pigmented_melanoma_-_cytology.jpg": "According to the universal geography text of the primary school we studied more than half a century ago, the human races were fundamentally distinguished by the colour of the skin. Thus, there were white, black, yellow and red races, the latter in reference to the peoples of the far east and of the American continent, in respective form. It was not difficult to understand the difference between the black and white races if the figures accompanying the text were taken care of, on the one hand, of a person of clear complexion, with a beard well cared for and dressed in the European way and, on the other hand, of a person of very dark and semi-naked complexion. In contrast, with all the corresponding illustrative drawing, it was more difficult to imagine an individual with a yellow face. And do not say red, given that all of us in the classroom were native to the American continent. All of the above, of course, responded to a Eurocentric view of the world, according to which the white race, native to the European continent, was superior to all others that were characterized by a different skin colour. Europe\u2019s undoubted technological superiority over the rest of the world in the 19th century gave arguments to proclaim that the white race was superior to all others. In the present circumstances, however, in which we are witnessing economic and technological ascent from the countries of the Far East, these arguments have completely lost their effectiveness. Certainly, from a technological and economic point of view there are no arguments that support the supposed white superiority. And so it seems that there is neither from the genetic point of view, if we are to believe an article published this week in the magazine \u201cScience\u201d by an international group of researchers headed by Sarah Tishkoff of the University of Pennsylvania. In their article, Tishkoff and collaborators report the results of a genetic study carried out with natives of Ethiopia, Tanzania and Botswana belonging to various ethnic groups. The aim of the study was to identify genes that affect the pigmentation of the skin. As we know, the color of the skin is determined by the presence of the melanin pigment in the epidermis, so that at a higher level of darker melanin is the color of the skin. The dark skin of African peoples has been explained in terms of the level of protection that this skin provides against ultraviolet radiation from the Sun. In Africa this level is high given its geographical location and consequently the skin of Africans evolved towards high levels of melanin. In contrast, the populations that migrated from Africa to the European continent found there lower levels of ultraviolet radiation losing the skin its original dark color in favor of a pale color, advantageous for the production of vitamin D. However, Tishkoff and collaborators consider that this explanation is insufficient because among Africans this color varies greatly, being markedly dark among the peoples of the area comprising Sudan and Chad, and much clearer among the Sans living in southern Africa. Thus, researchers reason that there has to be an additional genetic effect.To determine the color of the skin and of this the level of melanin, Tishkoff and collaborators measured the amount of light reflected by the skin of a group of 2094 African volunteers with a wide genetic and ethnic diversity. As a result of their study, researchers identified 8 variants in the African genome that strongly influence the color of the skin, some darkening it and others clarifying it. Tishkoff and collaborators also found that some genetic variants that determine the color of the skin are present in populations outside Africa. And, in relation to this, and surprisingly, they found two genes that affect the color of the skin, the hair and the eyes in the European population, which are also present and active in the San population of Southern Africa, of relatively clear skin. Such genetic variants would have developed in Africa about a million years ago, when the appearance of our species was still very distant in time. Based on their results Tishkoff argues that using the color of the skin to classify humans has no more validity than to use for this purpose another characteristic such as height. In particular, the African race, characterized by a certain color of the skin, does not exist as a concept, given the great variety of skin tones that is The racists and white supremacists have been and are in this way in a crass mistake. After all, white skin ultimately results from an adaptation to the middle. Indeed, as Sarah Tishkoff points out, if we shave a chimpanzee \u2013 which separated from our evolutionary line about six million years ago \u2013 we will find that it has pale skin, because it does not need melanin to protect itself from sunlight.",
    "https://upload.wikimedia.org/wikipedia/commons/c/c1/Menschenhaar_200_fach.jpg": "In an article published in 1864 in the journal The Quarterly Journal of Science, William King, professor at Queens University in Ireland, describes the characteristics of the fossil remains found in 1857 in a Neander Valley cave in Germany, and concludes that the individual they belonged to had a skull, closer to that of the apes than that of humans. Based on this he suggests that the intellectual capacity of the individual in question was probably similar to that of the apes. In particular, he claims that he would not have had the intellect to conceive of the existence of God or to assume moral obligations. To overshadow his arguments, King points out that it would be difficult to conceive humans with a capacity inferior to that of the Aborigines of the Andaman Islands, who still classify as human by the shape of their skull but that as far as intellect are just above the animals. Thus there would be no possibility for Neanderthals and their skull to deform the human category. Today, 150 years away, we know much more than King about the fossils of the Neander Valley. To begin, we know that they belong to the so-called Nea Man. In fact, the Neanderthals used tools, used fire, were hunters and were covered with clothing. Some specialists even claimed that they buried their dead and that they were able to think in a symbolic way. The Neanderthals subsisted in Europe, which diverged from our species half a million years ago and that some 300,000 years ago migrated from Africa to Europe and Asia. Physically, the Neanderthals were smaller, stronger, and with shorter limbs compared to our species. Thus, they had a reduced chin, a fleeing forehead, and bones of prominent eyebrows. Undoubtedly, Neanderthals had a physical appearance that distinguished them from our species \u2013 and surely we would choose not to meet any of them at night in a dead alley. It is not clear, however, if in intelligence they came closer to the apes to humans as King maintained, since their cranial volume was equal to or greater than ours \u2013 which surely would have surprised them. Some 30,000 years ago when they became extinct as a species for reasons that are not clear. One hypothesis that has been ventured in this regard is that Neanderthals did not survive contact with populations of humans, who arrived from Africa to Europe some 100,000 years ago, because of their supposed intellectual inferiority. An alternative hypothesis, however, is that Neanderthals would not have been able to survive the climate change that affected Europe during glaciation. Whatever has been the cause of the extinction of Neanderthals, specialists now have proof that, at least in some cases, the encounters between Neanderthals and humans were friendly \u2013 or not with a purely destructive intent \u2013. Indeed, we now know that the two species crossed during the time they coincided and that from this crossing, the genome of those with European ancestry contains 2% of Neanderthal genes. Even more, an article published this week in The American Journal of Human Genetics, by Michael Dannemann and Janet Kelso of the Max Planck Institute in Leipzig, Germany, finds that human traits are currently influenced by the American Journal of Human Genetics, by Michael Dannemann and Janet Kelso of the Max Planck Institute in Leipzig, Germany. For his study Dannemann and Kelso used data from more than 100,000 individuals provided by the UK Biobank This data bank was configured by genetic analysis and a questionnaire applied to volunteers about themselves and who have kept record of their health for a long time. Among the traits that researchers found associated with Neanderthal DNA were skin color, hair color, sleep patterns, states of discouragement and smoking. The skin color and sleep patterns of Neanderthals would have been determined by their adaptation to the climate of Europe with major changes in solar lighting throughout the year. In other cases such as smoking, since Neanderthals presumably did not smoke, the association is more difficult to explain. Dannemann and Kelso, on the other hand, did not find an association between Neanderthal DNA and red hair color, indicating that there would have been no red-haired Neanderthals. The great technological progress that Western civilization has achieved \u2013 and now also non-European Eastern civilization \u2013 since its death in 1886, but also because of the out of time that the comments, supposedly scientific but markedly prejudiced, expressed in its article on Neanderthal fossils result. And, of course, it would be necessary to see its surprise reaction when it learns that it itself is 2% Neanderthal.",
    "https://upload.wikimedia.org/wikipedia/commons/7/7d/Apollo_11_Launch2.jpg": "Next Wednesday, October 4, will be 60 years since Sputnik 1 was put into orbit by the Soviet Union, the first artificial satellite in history, which began the so-called space age. The Soviet Union thus advanced for almost four months to the United States, which, after several failed attempts, finally succeeded in orbiting its first satellite, Explorer 1, on January 31, 1958. Soviet success produced a shock effect on the American public which assumed that US technology was superior to that of the Soviet Union. Among other things, the Americans had managed to develop the atomic bomb as part of the war effort during the Second World War, with unprecedented deployment of technology, and this fed belief in its technological superiority. The putting into orbit of Sputnik 1, however, made it clear that Soviet space technology was at those times superior to that of the United States.In relation to the latter, even before the Americans succeeded in orbiting Explorer 1, the Soviets had already successfully launched their second satellite. ika, which thus became the first living being to visit space \u2013 an unenviable honor, by the way, because the Soviets did not at that time have the technology needed to return it to Earth, so Laika also became the first living being to die in space.In the context of the Cold War, the Soviets taking the lead in space matters caused concern in the American public because the rockets used to place satellites in orbit could also be used to bomb American territory. On the other hand, the relative technological backwardness of the United States was attributed to a deficient system of education in science and mathematics, and this prompted the development of new approaches and teaching texts, both at the preparatory school level and at the university level. Committees were formed that included scientists from American universities for the development of texts of teaching physics with innovative approaches. One of these texts, destined for the preparatory school, was developed by the committee \u201cPhysical Science Study Committee\u201d, known as PSSC, which was headed by Jerold Zachariasarias and Francis Friedman of the Massachusetts Institute of Technology, and included the participation of preparatory physics teachers. PSSC was created in 1956 and after Sputnik 1 was put into orbit received a substantial increase in support from the United States National Science Foundation and was given the task of developing a new text for the teaching of physics, supported by laboratory material and film material. The text developed by the PSSC was published in 1960 and may be familiar to those who attended preparatory school in the 1960s. It was not as successful as expected, however, as a text of difficult reading and understanding for the average high school student. Likewise, texts of physics for the university level were developed with a high quality and innovative approach, but they have the same problem and contain materials and approaches that are too advanced for the level to which they are directed. However, and apart from the relative success of efforts to innovate science teaching, as we know the Soviet Union in the race to carry a manned mission to the surface. It is interesting to note that even today the level of physics and mathematics in high school in the United States is not particularly prominent worldwide, and in the PISA tests of the OECD, American students occupy only half-table places. At the same time, there is a remarkable presence of foreign students, mainly from China and India, in American universities in the areas of science, technology, engineering and mathematics, and in some cases foreign students are even majority. Indeed, according to statistics of the Pew Research Center, in the years 2012-2013, 57% of students who received a doctoral degree in an engineering area were foreigners. In areas of computing, mathematics and physics, the corresponding numbers are: 53%, 50% and 40%.Sputnik 1 launch sixty years ago caused a blow to American pride at the same time that generated concern that the Soviet Union in the middle of the Cold War posed a threat of rockets with superior characteristics. In contrast, the low level of teaching in science and mathematics, which was diagnosed as the cause of Soviet superiority at the beginning of the space age, has apparently not had an equivalent evolution, to the degree that Americans today are not apparently interested in high-level preparation in scientific and technological topics.",
    "https://upload.wikimedia.org/wikipedia/commons/0/07/1960_Valdivia_earthquake.jpg": "On the afternoon of Sunday, May 22, 1960, there was the greatest earthquake in southern Chile that has been recorded and that has become known as the Valdivia earthquake. This earthquake reached a magnitude of 9.5 and, in conjunction with the tsunami that followed it, destroyed much of southern Chile. Fortunately, despite its magnitude, the Valdivia earthquake produced only about 2,000 people killed. How large a magnitude earthquake 9.5. To answer this question, it is necessary to first note that the scale at which the magnitude of an earthquake is measured can be misleading, since that scale is not directly proportional to the energy released by the earthquake. Far from this, we have that an earthquake of magnitude 9 releases 32 times more energy than an earthquake of magnitude 8 and 1,000 times more than a magnitude 7. Thus, the Valdivia earthquake was 130 times more powerful than the magnitude 8.1 earthquake that devastated Mexico City on September 19, 1985, with a balance of more than 10,000 people dead. In this way, the devastation that an earthquake can produce depends not only on its magnitude but also on particular situations and circumstances.In the case of the Valdivia earthquake, for example, it was preceded minutes earlier by a smaller one, which alerted the population that was saved outside the buildings that ended up collapsing.In the case of Mexico City, in addition to the great urban concentration that it suffers, the subsoil of the city, which was once part of a lake, enlarged the seismic waves and caused the selective collapse of buildings with heights around 20 floors.Another closer example is the earthquakes of 7 and 19 September last, with respective magnitudes of 8.1 and 7.1. As we know, the impact on Mexico City of the earthquake of 7 September was much less than that of 19 of the same month, despite being 30 times more powerful. This was the result of the difference in distances between the city and the epicenters of both earthquakes. Its epicenter was located just 100 kilometers from Mexico City, in contrast to the earthquake of 7 September that had its epicenter in the Pacific Ocean, near the border of Chiapas and Oaxaca. Apart from the above, the fact is that two earthquakes of great magnitude have occurred in a span of just twelve days and this has attracted the attention of some experts who wonder if there would have been any relationship between them.A preliminary study carried out by scientists of the company Tremblor Inc., which can be consulted on the Internet, however, concludes that the distance between the epicenters of the earthquakes of the past 7 and 19 September is too great for this relationship to have occurred.They were therefore two independent events, although as a result of the interaction of the same tectonic plates.It is necessary to remember, on the other hand, that the earthquakes occur when the efforts generated by the interaction between two tectonic plates are released.In southeastern Mexico this interaction occurs along the coast of the Pacific Ocean, from Michoac\u00e1n to Chiapas, between the North American mainland plate and Chiapas. The latter is moving towards the east at a rate of about 6 centimeters per year, penetrating below the continental plate. The experts also know that the Cocos Plate, after an initial descent, penetrates horizontally towards the continent for about 300 kilometers and from there descends rapidly.One characteristic that distinguishes the earthquake of September 19th is that its epicenter was located away from the coast of the Pacific Ocean, at the point where the Cocos Plate begins its rapid descent to a depth of 50 kilometers, according to specialists. That is, hundreds of kilometers from the point in the Pacific Ocean where the Cocos Plates and North America are located in the Pacific Ocean, and at a stone's throw from the largest urban center of the country. Mexico City is thus an atypical city that concentrates one of the largest populations in the world and a good part of the population of Mexico. A city that is located 2,000 meters high away from the sea, and in a valley surrounded by mountains that aggravate the problem of environmental pollution. And, if not only, in a small part of Mexico. an area of great seismicity and with a subsoil that amplifies the seismic waves, danger that the city apparently does not take over with enough rigor. Otherwise, as it is possible that after the experience of the earthquake of 1985, after last September 19 we find buildings completely collapsed and surrounded by constructions that did manage to stand. By the way, after the earthquake of Valdivia was in danger the organization of the world cup of football programmed to take place in Chile two years later. Fortunately, and surprisingly, Chile managed to superimpose itself to its misfortunes and organized a memorable cup in which it even reached the third place.",
    "https://upload.wikimedia.org/wikipedia/commons/c/cf/Saturn%27s_ring_plane.jpg": "When on the night of January 7, 1610 Galileo pointed his telescope towards Jupiter, he discovered near the planet three small luminous points that he initially thought were stars. It did not take him long to convince himself, however, that the three luminous points \u2013 four, as he later found out \u2013 were satellites that revolved around Jupiter, similar to how the planets revolved around the Sun.Galileo also directed his telescope towards Saturn, which is after Jupiter the second largest planet in the Solar System. While Saturn\u2019s brightness is relatively small by its distance and is not particularly striking by the naked eye, it is the most spectacular planet in the Solar System because it is surrounded by rings. Unfortunately for Galileo, its telescope \u2013 advanced for the time but with a very poor resolution power according to current standards \u2013 did not allow it to identify Saturn\u2019s rings as such and only saw them as two protuberances placed on opposite sides of the planet. Better telescopes produced clearer images and in 1655 the Dutch astronomer Christiaan Huygens described Saturn\u2019s rings as a thin, flat disk surrounding the planet. . The Italian-French astronomer Giovanni Cassini, on the other hand, discovered that this disc is divided into two concentric rings by a dark gap known as Cassini\u2019s division. Today we know that the rings surrounding Saturn have a very complicated structure, with multiple concentric flat rings that reflect the light of the Sun in varying degrees. Our knowledge of Saturn comes from both observations made from Earth and from interplanetary ships that have been sent to explore it. The last of them is the Cassini ship \u2013 named after Giovanni Cassini\u2013, launched by NASA and the European Space Agency and which has just completed its 20-year mission in space on 15 September. The Cassini ship set off for Saturn in October 1997 and after a seven-year journey arrived at its destination. Once there it entered orbit around Saturn to begin exploration of the planet and its surroundings, which lasted thirteen years. Such exploration produced, among many other things, spectacular images of Saturn\u2019s rings seen from different perspectives, which are only possible with a photographic camera placed in The ship also sent images with great detail of Saturn's outer gaseous layer, including the curious hexagonal formation located in its north pole and which rotates on itself every eleven hours. It also devoted the Cassini ship to the exploration of Saturn's satellites and found, for example, that in Enceladus, the sixth largest satellite, there is an ocean of liquid water 10 kilometers deep beneath a surface layer of ice 30-40 kilometers thick. This discovery places Encelad as one of the possible places in the Solar System that harbors microbial life.On board the Cassini ship traveled the Huygens probe \u2013 named after Christiaan Huygens \u2013 which was launched towards the surface of Titan \u2013 the largest satellite of Saturn.After a descent of two and a half hours through the atmosphere of Titan, the Hyugens probe, braking its speed with a parachute, managed to pose gently on the surface of the satellite from where it transmitted images for more than an hour. On September 15, after exhausting all its fuel, the Cassini ship was launched in free fall towards Saturn, disintegrating by friction with the atmosphere of the planet. According to NASA, this maneuver was intended to eliminate the possibility of contaminating Enceladus or Titan with terrestrial microbes and thus preserve them pristine for future research on the origin of life. Thus, one of the most successful spatial explorations, which, according to NASA, produced a huge amount of scientific data whose analysis will take a good number of years. Just four centuries ago Galileo pointed his telescope to the sky and discovered that Jupiter is a miniature solar system with satellites turning around it. This, of course, we know is correct. In fact, it decisively contributed to changing our anthropocentric conception of the world, as it proved that not everything necessarily has to turn around the Earth. Galileo also pointed out his telescope to Saturn and on this occasion did not have such luck, as he could not appreciate the planet in all its spectacularity. The technology of his time did not allow it. In that sense, after he pointed out his telescope to Saturn and on this occasion he did not have so much luck, because he could not appreciate the planet in all its spectacularity. see the spectacular images sent by Cassini from Saturn, we can feel fortunate to be born four centuries later.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d4/Bronze_Marcus_Aurelius_Louvre_Br45.jpg": "Among the common metals, gold undoubtedly has a special place among us; among other things, because of its color and brightness that it does not lose with time unlike other metals such as silver or copper. Gold is known since very old times since it is possible to find it in an almost pure form in nature. It is, on the other hand, a very soft metal that had limited uses in prehistoric times beyond ornamentals. Gold was not the only metal known at the beginning of civilization. Also other metals such as silver and copper that are also found in native form in nature and that, like gold, had decorative and ornamental uses. The latter, given its relative hardness, was also used in the manufacture of weapons and various utensils.The use of copper, however, was limited to the extent that only copper found in native form was available and its more widespread use had to wait for the development of methods to extract it from minerals rich in it.Once it was discovered that heating at high temperature minerals such as malachita and azurita was possible to obtain metallic copper, it was produced. a technological revolution that gave rise to what is called the Copper Age. From this age the Bronze Age was derived about 4,500 years ago, when it was discovered that adding tin to copper greatly increases its hardness and thus its range of applications. It also derived, about 3,000 years ago, the Iron Age that produced an even greater technological revolution. The invention of copper metallurgy thus gave rise to a chain of technological developments that have been key to the development of civilization and one might wonder about the chain of events that gave rise to that metallurgy.Since at the time when the copper metallurgy was developed there was no theoretical knowledge about the nature of the materials involved, the discoveries that led to such development would have to have occurred by chance. It is possible, for example, that someone had thrown malachite minerals into a fire with sufficient temperature to release copper trapped within those minerals. This and other similar observations would have given patterns to reproduce observation through test and error procedures, which could have occurred. It should be noted, however, that in order to release copper it is necessary to reach a temperature that is around 1,100 degrees Celsius, which is not easy to reach in an open fire.One way or another, it is a fact that our ancestors discovered how to extract copper from minerals such as malachite and sour in prehistoric times and in relation to this it is interesting to wonder about the place and time in which this would have happened.Based on archaeological evidence about copper metallurgy, the Copper Age would have started some 7,000 years ago in a region that spans from the Balkans to Iran. This date, however, was questioned by the discovery at Catalhoyuk's Neolithic site in Turkey of what appears to be the slag resulting from the copper mineral smelting process. Such slag is 8,500 years old and would move the date of the beginning of the Copper Age 1,500 years into the past. Catalhoyuk would thus be the cradle of copper metallurgy, from where it would have been dispersed to other sites in Europe and Europe. In order to check or discard this possibility, a group of researchers in the United Kingdom and Germany, led by Miljana Radivojevic of the University of Cambridge in the United Kingdom, carried out an analytical study of the materials found in Catalhoyuk. The results of this study appeared this week in the journal \u201cJournal of Archaeological Science\u201d. Based on their research, Radivojevic and collaborators find no evidence that the materials studied correspond to slags from a copper smelting process. On the contrary, they conclude that they resulted from a certain amount of copper ore deposited in a tomb that was subsequently affected by an intense fire that even charred the corpse. It would thus have been that copper metallurgy had begun some 7,000 years ago and not 8,500 years ago as the evidence of Catalhoyuk suggested. Furthermore, according to Radivojevic and collaborators, the possibility of such metallurgy was opened simultaneously in several sites in Europe and Central Asia. Today, we have a deep theoretical knowledge about metals - we understand, for example, Why gold has that color and why it never loses its brightness-, as well as a large number of materials of all kinds. Based on this knowledge, we understand what are the principles that govern metallurgy of metals and in general the technology of a large number of materials. This has led us to make even materials that do not exist in nature. And all this we have achieved in just 7,000 years, very short time in terms of the evolution time of our species.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d0/Northwest_passage.jpg": "The week that ends today the press reported the transport of a load of natural gas by the Russian ship Christopher Margerie of 300 meters in length between the ports of Hammerfest in Norway and Boryeong in South Korea. Such event would have nothing in particular if it were not because the journey of the Russian ship was carried out by the so-called Pass of the Northeast, which runs from the north of Europe along the Russian Arctic coast and crosses to the Pacific Ocean through the Bering Strait. The trip, moreover, was made without the help of icebreakers ships, since the Christopher Margerie is a ship of special construction for the navigation in ice seas.The route by the Pass of the Northeast represents a saving of 30% in the duration of the journey between Europe and Asia compared to the route through the channel of Suez and therefore it is of great commercial appeal. Previously the Pass of the Northeast was not practicable by the arctic ices that obstructed it. This situation is changing, however, by effect of the global warming, that has reduced the ices ar In a similar situation \u2013 although less favorable in terms of navigability \u2013 there is the Northwest Passage linking Europe with the Pacific Ocean through the Canadian Arctic. Thus, for example, last year we learned that the tourist cruise \u201cCrystal Serenity\u201d was able to make a trip between Alaska and New York sailing through the Northwest Pass taking advantage of the summer thaw. The Northwest Pass was eagerly sought by Europeans from the 16th century. In fact, for some countries such as England that passage was essential because the routes to the south, whether around Africa or South America, were monopolized by Portuguese and Spanish. The Northwest Pass was finally discovered in the 19th century, much further north than originally expected and blocked by Arctic ice. An expedition to search for a waterway along the Northwest Pass that is historically remarkable was the one commanded by Englishman John Franklin that ended in disaster. The expedition under Franklin, which had two ships, The HSM Erebus and the HSM Terror, and 105 men in command of 24 officers, left the west coast of Greenland in the summer of 1845 and enfiled towards the west towards the Lancaster Strait. Difficulties in advancing, however, forced expeditionaries to winter on the island of Beechey where three crewmen died. At the end of the winter the expedition enfiled to the south. With very little luck, however, as in September 1846 the Erebus and Terror were caught by the ice near Prince William Island, forcing the crew to winter for the second time. From here it is not clear which course was followed by the expeditionaries who would have had to leave the ships trapped on the ice and walk south to seek salvation. Unfortunately, they did not succeed and all died in the attempt. In September last year, a team from the private foundation \u201cArtic Research Foundation\u201d discovered the remains of \u201cHMS Terror\u201d submerged about 24 meters in the water, about 100 kilometers south Two years earlier, the remains of the \u201cHMS Erebus\u201d were also found submerged 11 meters in an even more southern position. These discoveries have called into question the version of the abandonment of the ships once they were caught by the ice and opens the possibility that the crew members or part of them would have tried to head south on board them. The story of John Franklin\u2019s unfortunate expedition puts into perspective the situation of the Northwest Pass \u2013 and by extension, the North East Pass \u2013 just 150 years ago when it was, if not impregnable, if with much commercially unviable for the environmental conditions and technological possibilities of the time. Today, the situation has changed markedly, not only because the current technology allows the transit of ships in the Arctic under environmental conditions that were impassable in the nineteenth century, but because the same environmental conditions have been modified by global warming. Attractive and therefore more congested. Experts also anticipate that as the Arctic Ocean is released from ice and the shipping routes expand, mineral resources in the region will be opened up to exploitation that are not commercially viable today. Conditions will thus be created to increase industrial activity and consequently generate greater environmental pollution and Arctic melting. Thus, from the point of view of quality of life, the twenty-first century certainly has many advantages over the nineteenth century. Free transit through the steps of the northwest and north-east, however, is not one of them.",
    "https://upload.wikimedia.org/wikipedia/commons/e/e0/Pythagoras_in_the_Roman_Forum%2C_Colosseum.jpg": "How much do you remember from your high school trigonometry and geometry courses? Surely you remember that, among many other things, we were taught to distinguish between a right angle and one that is not, and that in the first case the angle is defined by two perpendicular lines that intersect at one point. We also learned that a right angle measures 90 degrees and that an acute angle measures less than that. The secondary school trained us, likewise, to identify a right triangle, one of whose angles is straight and the other two sharp.All of this was not difficult to understand and remember. A little more complex were other topics and concepts that form part of the trigonometry courses, including the trigonometric functions \u2013 sine, cosine, tangente, among others. Not to forget, of course, the famous Pythagoras theorem that establishes a relationship between the length of the sides \u2013 catatos \u2013 of a right triangle with the length of its hypotenuse. They allow you to know the value of one of the lengths of a right triangle \u2013 the hypotenuse or either of the two catates \u2013 given the other two lengths and therefore have a huge practical utility. In the layout, for example, of a temple or a pyramid. On the other hand, it is quite possible that if you did not continue using the trigonometric functions at the end of secondary school you have already largely forgotten them. On the contrary, you will surely have no problem to evoke clearly a rectangle angle or an acute angle, since the abstract concept of angle \u2013 generated by the intersection of two straights \u2013 is already part of our culture. It has not always been so, however, and in this regard it is interesting to bring up an article that appeared this week in the magazine \u201cHistory Mathematica\u201d, whose authors are David Mansfield and Norman Wildberger, mathematicians of the University of New South Wales in Australia. In this article a study carried out with the clay tablet known as Plimpton 322, which was discovered in southern Iraq almost 100 years ago. has an age of about 3,800 years and had its origin in the ancient Sumerian city of Larsa near the Persian Gulf. The Plimpton 322 tablet measures 12.7 cm by 8.8 cm and clearly shows that it suffered a fracture, possibly in recent times since it contains remains of a modern glue. It shows four columns and fifteen lines equally spaced of cuneiform signs. These signs correspond to numbers represented in a sexagesimal system, which is the one employed by the Sumerians. Something that has caught the attention of experts since the tablet was studied in the decade of the forties is that from the numbers contained in it are derived triplets of numbers consisting of the Pythagorean theorem. As we know, this theorem states that if we raise to the square the two catheters of a rectangle and add them the result is equal to the square of the hypotenuse. An example of a triplet of this class are numbers 3, 4 and 5. In this connection, it has been suggested that it was used as an aid for the teaching of mathematics. Mansfield and Wildberger, on the contrary, conclude that the Plimpton 322 is actually a trigonometric table which, like contemporary equivalent tables, allows to calculate one of the lengths of a right triangle given its other two lengths. On the other hand, unlike what happens today, the concept of angle did not exist among Sumerian mathematicians and is therefore absent from the Plimpton 322, whose numbers and procedures refer only to the lengths of the sides of a right triangle. In addition, unlike a contemporary trigonometric table, which is approximated to a certain degree, the numbers inscribed on the Plimpton 322 tablet are accurate. Thus, while it is the Greeks who are credited to have invented trigonometry, of being Mansfield and Wildberger in fact, the Sumerians would have been advanced to them for a thousand years, showing an astonishing level of sophisticism. This, in sharp contrast to the Greeks. Of all the above, and assuming that Mansfield and Wildberger are indeed right, would result in trigonometry, a topic that many of us had headaches in high school, being actually something that was invented by the Sumerians, to our dismay, thousands of years ago. Likewise, it would appear that the concept of angle, which seems so natural to us, is not so much so in reality. Indeed, its absence was not an obstacle for Sumerians to develop trigonometry and apply it to the construction of temples, palaces and canals.",
    "https://upload.wikimedia.org/wikipedia/commons/b/b2/Vincent_van_Gogh_-_Self-Portrait_-_Google_Art_Project.jpg": "On July 29th, 127 years after the death of the Dutch painter Vincent van Gogh, who killed himself in 1890 from a bullet in the chest at 37 years old. Despite his relatively brief existence, van Gogh painted the order of 900 paintings. He also painted them during his last ten years of life, because before he devoted himself to painting, he did so to a series of activities of the most varied that undoubtedly reflect the unstable nature of his character. He worked for the branch of The Hague of a Parisian art gallery, also as an assistant in a bookstore in the Dutch city of Dordrecht, as an assistant to a Protestant pastor in England, as a student of theology in Amsterdam and as a missionary in mines in the Mons region in Belgium. Only after settling in Brussels in 1880 was he resolved to devote himself to painting. Even for those we are not familiar with painting, it is evident that van Gogh's painting evolved greatly in a short time. It is sufficient to compare the dark colours of \u201cThe potato canteens\u201d of 1885, with the vivid colors of painting. On the other hand, although there is no accurate diagnosis, it is known that van Gogh suffered from mental sufferings that even led him to be interned in sanatoriums towards the end of his life, and in this regard it is illustrative the anecdote according to which he would have cut an ear with a knife after a dispute with the painter Paul Gauguin. Given these circumstances, there are those who wonder if the drugs that were administered to him to treat his sufferings could have influenced the style of van Gogh as a painter; specifically, in his perception of the colors. Although it is not known with certainty with which drugs van Gogh was medicated, it has been speculated that he could have been treated with a derivative of the plant known as a dedalera, which was used at the time to treat, in addition to cardiac diseases, various neurological and psychiatric diseases. It is known, on the other hand, that an overdose of dedalera produces a change in the perception of colors that acquire a yellow dye, which would be related to the use of various neurological and psychiatric diseases. Another effect of intoxication with a dagger is the perception of circles around a luminous point, an effect that is also visible in some paintings by van Gogh. In particular, this effect is noticeable in \u201cThe starry night\u201d, which presents a nocturnal view from the window of his room in the asylum of Saint-Remi-de-Provence in the south of France, where he voluntarily confined himself towards the end of his days.The hypothesis about the use of the thimble by van Gogh is supported by the painting \u201cThe portrait of Dr. Gachet\u201d, where the painter portrayed the doctor who attended him in his last months of life. In that painting, Dr. Gachet appears sitting on a pensive table, standing out on the table at the bottom of the painting a section of the thimbler. The appearance of a thimbler branch in a painting by van Gogh, although he does not prove his consumption by the painter, does establish his proximity to the plant, to which, curiously painted with a color that does not correspond to a painting by van Gogh, although he does not prove his consumption by the painter, does establish his proximity to the plant, to which, It should be noted, however, that the \u201cDr. Cachet Portrait\u201d was made in 1890, a few months after van Gogh\u2019s death, and that he used yellow with profusion even before he met Dr. Cachet. This, of course, does not rule out that van Gogh would have previously used the drug prescribed by his previous doctors. In addition to the thimble, he has ventured that van Gogh might have had an alteration in the perception of color due to the abuse in the consumption of wormwood liquor that was very popular in Paris among the painters of the time. According to other opinions, however, this is unlikely because of the large amounts of wormwood that he would have consumed before having an appreciable effect. Despite how attractive the hypothesis of van Gogh\u2019s intoxication by dedalera and its impact on his painting, we do not have enough evidence to prove it or refute it. One way or another, on the 127th anniversary of his tragic death, we should thank Vincent van Gogh for the pictures he inherited from posterity \u2013 some fantastic, with a profusion of yellow \u2013 and regret that, in payment, life has treated him so badly.",
    "https://upload.wikimedia.org/wikipedia/commons/5/5b/Amarillos.png": "The electric light began its expansion around the world just over a hundred years ago. To be precise, since Edison commercialized the first incandescent lamps in 1880. Certainly, Edison was not the first to manufacture an incandescent lamp. Yes, instead, he was the first to develop a lamp with a sufficiently long lifetime to be commercially viable. It is remarkable that the design of the incandescent lamps that can still be acquired commercially is basically the same as that of the lamp developed by Edison more than a century ago. Indeed, that lamp consisted of a carbonized bamboo filament that was heated by means of an electric current to the point of generating visible light. The filament was placed inside a glass bulb in whose interior was made empty to prevent the hot filament from being consumed by contact with air oxygen. The electric current of the filament was introduced by means of a metal socket threaded at the base of the glass bulb. in 1906\u2013 and the vacuum inside the glass bulb by an inert gas, the above description corresponds to that of a modern incandescent lamp. The coincidences between the Edison lamps and the modern ones show that the former constitute extraordinarily well-conceived devices, which survived during the twentieth century the competition with other lighting technologies, including fluorescent lamps. Over the years, however, the incandescent lamps have met with an adversary that has proved difficult to beat: LED lamps. And it is that the incandescent lamps, besides virtues, have also defects. One of the greatest is their low efficiency for the production of light, since the electrical energy consumed by 90 per cent becomes heat and in this respect are greatly surpassed by the LED lamps.At first the low efficiency of the incandescent lamps had only relative relevance.With the energy crises that have occurred since the decade of the 70s of last century and the problems of environmental pollution and climate change that plague us, such efficiency has been In these circumstances, LED light sources are having an increasing penetration into the market at the expense of, in part, incandescent lamps.In addition to greater efficiency, LED lamps have other virtues, including their robustness and long duration.There is nothing perfect, however, and these lamps also have their disadvantages.One of them has to do with their high content of blue radiation. Indeed, in its simplest version, a white LED light source consists of a primary emitter of blue light that is covered with a layer of a material that when excited by blue light emits yellow light. The combination of primary blue light and secondary yellow light is perceived by us as white light. The blue radiation emitted by LED lamps is cause for concern by specialists because it has been associated with various health problems. In particular, there is evidence that the use of night lighting with high blue light content delays the production of melatonin that is the substance that it is the substance that it is. In contrast, nocturnal exposure to blue light interferes with the circadian rhythm and the sleep cycle. A study showing the latter was published in the July issue of this year in the journal \u201cOphthalmic and Physiological Optics\u201d by a group of researchers from the University of Houston, headed by Lisa Ostrin. The reference study was carried out with 21 volunteers aged between 17 and 42 years, who were asked to wear yellow lenses that block blue light and part of green light, three hours before going to sleep and for two weeks. Volunteers claimed to have conceived the dream more quickly and had a better quality of it after using yellow lenses. In addition, they experienced an increase in the level of melatonin of 58 percent and had 24 more minutes of sleep. Humans have evolved with sunlight, which certainly has a large content of blue light, but to which we have adapted our circadian rhythm. In contrast, we have been under the influence of light. In comparison to the times of the incandescent focus \u2013 which has a relatively small blue light content \u2013 we are now exposed to higher levels of night blue light, not only by the LED lamps used for lighting, but also by the multitude of devices that use such lamps, including computer screens, tablets and cell phones that we use profusion. Will the LED lamp, as we know it now and given the problems it faces, be a device so successful as an incandescent lamp that it lived among us for over a hundred years? This, of course, only time will tell.",
    "https://upload.wikimedia.org/wikipedia/commons/a/aa/Astronomical_unit.png": "Suppose that an inhabitant of medieval Europe makes a journey until the second half of the 19th century \u2013 perhaps by means of the H. G. Wells time machine \u2013 and there he learns that on September 23, 1846 the German astronomer Johann Galle discovered an eighth planet after following the indications of the French mathematician Urban Le Verrier about its possible location in the sky. Le Verrier\u2019s predictions were based on the disturbances observed on the planet Uranus that suggested the presence of a planet beyond its orbit. Given these results, no doubt our traveler from the past would be convinced that both Galle and Le Verrier were magicians: Galle for using an instrument\u2013the telescope\u2013that allowed him to see invisible things and Le Verrier for their predictive power. Such a conviction would not have been surprising, for the telescope was invented until the end of the 16th century and Isaac Newton\u2019s theory of gravitation, on which Le Verrier based its prediction, was not devised by Newton until the 17th century; that is, several centuries after the time of our so-called visitor. . At present the telescope is no longer surprising and in fact it is possible to acquire one of these instruments even in a commercial center. The predictive power of the one who showed Le Verrier, on the contrary, is astonishing even today. French astronomer Francisco Arago commented that Le Verrier \u2013 who was his collaborator \u2013 \u201chad discovered a new planet with the tip of his pen\u201d and this, which at the time proved amazing, remains it 150 years later. However, we do not think that Le Verrier was a magician. At least not a person with divination powers or hidden powers that could alter the course of natural phenomena and place a celestial body at will in a given position in the sky. In fact, without it is not a widespread belief, we now think that there is no way to alter that course or see beyond what our five senses reveal to us. Moreover, it seems that Le Verrier, even with his obvious mastery of Newton\u2019s theory of gravitational, needed a certain amount of luck to predict the existence of the eighth planet of the Solar System, We now know as Neptune. He did not have this same fate when, animated by his previous success, together with Arago predicted the existence of a new planet between the Sun and Mercury that would explain the disturbances observed in the orbit of the latter. This hypothesis, however, was discarded when it was discovered that Newton's theory of gravitation is not adequate to accurately describe the orbit of Mercury. Likewise, the predictions of the existence of a ninth planet beyond the orbit of Neptune have not been lucky either. Indeed, at the beginning of the 20th century the amateur astronomer Percival Lowell predicted such existence based on disturbances observed in the orbit of Uranus that could not be explained solely by the influence of Neptune \u2013 in contrast to the hypothesis of Le Verrier \u2013 and was given the task of finding it. Infeructuously, however. However, after his death the astronomer Clyde Tombaugh continued with the search for the ninth planet, now successfully, upon discovering Pluto in 1930. that Pluto is too small to be the planet predicted by Lowell. In fact, Pluto was degraded in 2006 by the International Astronomical Union to the category of dwarf planet. Although the existence of a ninth planet in the Solar System has not been proven so far, some astronomers are convinced of its existence. Not based on disturbances of the orbit of Uranus that was discovered in reality do not exist, but on the disturbances of the orbits of some planetoids beyond the orbit of Neptune. In this regard, an article published in the magazine \u201cMonthly Notices of the Royal Astronomical Society: Letters\u201d on 27 June by astronomers from the Complutense University of Madrid, presents new evidence in favor of the existence of a ninth planet. The conclusions of astronomers from Complutense University were based on a study of 28 celestial bodies with very eccentric orbits, which keep them at an average distance to the Sun of 150 astronomical units \u2013 an astronomical unit is the distance between the Sun and our planet\u2013, and found that they are grouped in such a way that it can be explained by assuming the existence of a ninth planet located at about 300-400 astronomical units of the Sun. The stories of the discovery of the eighth planet and the fruitless search of the ninth, illustrates us about some characteristics of the scientific method. On the one hand, it shows us that this method is extremely powerful, to the extent that it allows the discovery \u201cwith the tip of the pen\u201d, of an invisible planet at first sight. On the other hand, it also illustrates that a scientific discovery depends, not only on the preciseness of a given theory, but also requires a certain dose of luck.In balance, however, the usefulness and predictive power of the scientific method is light years ahead of any magical or superstitious practice that, in contrast, has shown little over thousands of years.",
    "https://upload.wikimedia.org/wikipedia/commons/0/01/COP8MOP3_2006_Curitiba_bus_2.jpg": "In the beginning, to the extent that there were few, the cars kept a discreet presence among us. As their number grew, however, that presence, far from discreet, has become overwhelming. Particularly, although not exclusively, in countries like Mexico and in cities like ours, where the number of vehicles has grown dramatically in recent decades. By way of example, in the city of San Luis Potos\u00ed, which is not a unique case, the number of motor vehicles doubles every eight years and has gone from just under fifty thousand in 1980 to almost half a million in 2015.This, according to data from the INEGI.The cars, which have brought us both benefits and problems, have a leading role and a constant presence in our lives.The week that ends today, for example, made headline news due to the initiative of the government of Mexico City to put a maximum limit on the area destined for parking in the construction of new buildings.The objective of this reform is to discourage the use of the automobile.This measure has caused controversy. In the metropolitan area of Mexico City it is excessive and generates a multitude of problems. Those who have criticized the reform, however, argue that it is inadequate because of the poor public transport system of the city that does not constitute an alternative to the private car. It can also be argued that, at best, the reform is insufficient. Indeed, following the same line of reasoning, it could be argued that, in addition to limiting parking spaces, the construction of new roadways should be limited. To support this, it can be noted \u2013 with figures from the INEGI \u2013 that with the construction of the second floors in the outskirts of Mexico City, a significant increase in the rate of growth of the number of motor vehicles circulating in the city, which resumed its normal pace since 2008, would indicate that this growth is limited to some extent by the difficulty to circulate through the streets of the city. This would agree with the fact that the rate of growth of the number of cars in Mexico City is significantly lower than in other cities of the country. In this regard, the traffic problems of the city of Los Angeles in the state of California are legendary. One measure that has been introduced to mitigate these problems is the exclusive lanes for cars in which more than one passenger is travelling and which seek to encourage car sharing. This measure has also been targeted by critics who argue that exclusive lanes end up being underutilized, thus leaving fewer lanes for normal traffic. On the other hand, critics aside, an article published on July 7 in the magazine \u201cScience\u201d offers solid arguments that support the effectiveness of exclusive lanes for shared cars. This article was published by a group of researchers led by Benjamin Olken of the Massachusetts Institute of Technology. It demonstrates the benefits of policies to encourage car sharing, at least for the particular case they studied: the city of Jakarta, capital of Indonesia.Yakarta has one of the largest traffic problems in the world, and to try to mitigate them the government established in 1992 rules to encourage car sharing. In an extreme version: it banned the circulation in some of the main arteries of the city in the peak hours of cars with less than three passengers. Later, in March 2016, and suddenly, the government lifted the ban. This gave Olken and collaborators an opportunity to study in a real case the effect of imposing a rule for car sharing.In their study, researchers made use of Google Maps data to determine in real time, every ten minutes, the circulation speeds through the arteries of the city, before and after removal of the norm. They found that, after this removal, the transfer times increased 46 percent in the peak hours of the morning and 87 percent in the afternoon. They found, moreover, something surprising: the circulation in secondary avenues for which the rule was not applied also worsened. Olken and collaborators consider that this last effect should be the reason for a later study but advance that the affectation of the secondary streets can simply reflect the sudden increase in the number of cars in circulation. It could also be the result of a congestation of the main arteries that diverted. In any case, the results of Olken and collaborators are solid and show that encouraging car sharing could constitute a way \u2013 a bitter medicine \u2013 to relieve traffic congestion in our cities, which will soon suffer a greater crisis. This way would have a stronger livelihood than the one that seems to have discouraged the construction of parking lots; or that of building more circulation arteries that is still a solution of brute force.",
    "https://upload.wikimedia.org/wikipedia/commons/3/31/Bundesarchiv_Bild_183-15911-0002%2C_Chemnitz%2C_Abreise_zum_%22Dienst_f%C3%BCr_Deutschland%22.jpg": "As we know, the handshake, as a body expression it is, plays a relevant social role in certain parts of the world. Proof of this is the excessive attention given to the President of the United States and to his hand greetings in his meetings with world leaders. Indeed, in a quick search on the Internet we find abundant information about it, including collections of videos showing President Trump greeting different leaders of countries on various continents. In those videos we can see that the handshake of the American president may include grips, pulls and shakes. In addition, in some cases the contact time exceeds the limits of the conventional, either by being the handshakes too long, or by having a duration equal to zero \u2013 which means that there was no squeeze. The interest in the greetings of the president of the most powerful country of the world, of course, lies in what they can reveal. The British newspaper \u201cThe Guardian\u201d, for example, wonders whether the way President Trump greets his foreign policy. Thus, a perplexed prime minister of Japan would have hijacked his hand for 19 seconds. , presumably as a gesture to show that it is he who commands.The Japanese Prime Minister, for his part, after getting rid of the greeting made more than evident his discomfort, making a gesture that included a turn of eyes.At the opposite end, during a press conference in the White House, President Trump would apparently have ignored a suggestion from the German Chancellor with whom he holds serious differences, to give himself a handshake.The chancellor simply turned her face and ignored the episode.Given this situation, some leaders have chosen to counterattack.The French President Emmanuel Macron, for example, held with Trump last May in Brussels a battle of handshakes in which he proved victorious, by getting the American to be the first to withdraw the greeting.Even, according to comments from the press, Macron\u2019s grip was so strong that Trump\u2019s hand would have become pale. Certainly, the handshake has a great social symbolism. The role he plays, however, does not have the same importance in all cultures and in this sense a group of Trump\u2019s hand. The study, published in the journal \u201cJournal of Nonverbal Behavior\u201d on 29 June, was conducted with 44 volunteers of Caucasian origin and 44 from Eastern Asia, all residing in the United States. Both groups were composed of 22 men and 22 women. During the experiment, participants were presented with a series of videos in which, in a business environment, two people were about to start a meeting. One person acted as host and the other as guest. The host and the guest could both greet each other and not greet each other by hand before the meeting was started. Both, the host and the guest, reflected the ethnic origin and gender of the participants; that is, they could be, they could be, they could be, they could be, they could be, they could be, they could be greeted and they could not greet each other before the meeting was started. In each case, volunteers were asked to give an evaluation of the host host-host interaction, and if the host seemed competent to them and would be willing to start a business with him. As expected, researchers found that people of Caucasian origin, compared to those from East Asia, evaluated the interaction more positively when they measured a handshake. They found, likewise, that the male participants evaluated the interaction more positively when the host was a man than when he was a woman; this, in contrast to the female participants who did not import the host gender. According to Katsumi, this would reflect the fact that handshake is inherently a Western custom, historically practiced by men in business environments. Katsumi\u2019s study is important for a country such as the United States where multiple cultures live and in which women have fully incorporated into the economy. Thus, the perception of the relevance of handshake would not be the same or among the different ethnic groups \u2013 at least between the two studied. back to the international arena, it should be remembered that Japan is a country where handshake is not practiced as often as in the United States, and hence that the Japanese Prime Minister\u2019s bewilderment at the vigorous greeting of the American President is not surprising. This is not the case, of course, of France and the French President. It might even be asked whether, in the light of Katsumi\u2019s study and collaborators, Presidents Trump and Macron would greet with the same vigor of having been born women. Apart from anecdotes, however, and while handshake is so socially relevant that it even inspires scientific studies, it surprises the way that in recent months it has jumped into the palera, not to say circus.",
    "https://upload.wikimedia.org/wikipedia/commons/0/0e/Fotos_produzidas_pelo_Senado_%2830554309793%29.jpg": "According to predictions of the company CISCO of San Jose, California, by 2020 there will be 5.5 billion mobile phone users, which represents 70% of the world\u2019s population. This figure, if impressive, acquires an additional dimension if we contrast it with the number of people who will have access to other basic services, some certainly more basic than that of telecommunications. Indeed, according to CISCO, the number of people who by 2020 will have access to electricity and running water will be 5.3 billion and 3.5 billion, respectively. That is, by 2020 there will be more owners of mobile phones than users of electricity. And the most striking thing: two billion people will have a mobile phone but no running water in their homes. We have witnessed in the last decades the emergence of cellular phones in our lives. Today, we use smart phones in a wide variety of applications. According to the \u201cPew Research Center\u201d, the most common activity among users of these phones in the United States is the sending of text messages, followed by voice or video communications. . Common activities are also Internet navigation, e-mail consultation, participation in social networks, recording videos and photographs \u2013 with the results of all known \u2013 games and consultation of maps, among others. The uses of smartphones have thus far surpassed the role for which they were originally conceived and hence the great impact they have had on our lifestyle. Smart phones have even changed our behavior. In this sense, it is enough to consider that sometimes we use them to isolate us and ignore people around us. Another unexpected consequence of the bursting of smartphones became the topic of an article published this week in the online magazine \u201cPlos One\u201d by a group of researchers from British institutions headed by Matthew Timmis of Anglia Rusking University. In that article, Timmis and collaborators report the results of a study aimed at finding out how a person who walks down the street to overcome obstacles he encounters and not to have an accident, if at the same time he makes use of a smart phone, according to Timmis in part the idea for To carry out such a study it arose when one morning he observed that a person walking in front of him did it too slowly and doing those. At first he thought that he was in an inconvenient state \u2013 despite the early hour \u2013 until they crossed and realized that he was making use of a smartphone. To carry out his study, Timmins and collaborators counted with the help of 21 volunteers, 16 men and 5 women around the age of 25 and without any motor disease. Volunteers were asked to walk along a corridor of 5.3 meters long. Sometimes the corridor was free of obstacles, while at other times they placed an obstacle made of cardboard and wood and a step of 7.5 centimeters high. Tests were carried out both without a mobile phone, as with volunteers speaking, reading a text or writing a text with a smart phone in their hands. Participants were placed with sensors to determine the direction where they were heading the view along the test and sensors were installed to record their movements. The effect was more marked when writing a text than when reading it. Also, even those who only spoke on the phone did not necessarily direct their eyes towards the obstacle but sometimes did it to any other place. Thus, when using a mobile phone when walking we become more dependent on the peripheral vision \u2013 the corner of the eye \u2013 for the assessment of the obstacles. This, however, and according to Timmins and collaborators, does not make our step any more insecure, because we automatically take a cautious strategy by making more slow and safe movements. By taking a step, for example, we do it more slowly and raising our foot beyond what is strictly necessary.This, however, does not mean, the researchers warn, that the use of a cell phone while walking on the street is free of dangers, because to avoid a threat that appears before us quickly and unexpectedly we may well need all our attention to avoid it.In one way or another, Timmins's research puts on stage \u2013 for example, if I would need it \u2013 the mobile phone, possibly the device that has the fastest and most radically transformed our way of life. So much so that it has even changed our way of walking.",
    "https://upload.wikimedia.org/wikipedia/commons/b/bf/Bird_Diversity_2013.png": "A few days ago the Turkish Ministry of Education announced that the teaching of evolution will be suppressed from the curricula of secondary school. The argument put forward is that students of that level do not yet have the capacity to understand a topic \u201cso controversial.\u201d The initiative has been criticized by those who see in it an attempt to erode the secular character of the Turkish state. The theory that species are not immutable but are in continuous transformation has a strong emotional burden and has been difficult for many to accept. Thus, a cartoon published in 1871 by a satirical magazine showed Charles Darwin, with his characteristic bald and thick beard and with a body of ape! Even today, 150 years after the publication of The Origin of Species, evolution remains \u201ccontroversial.\u201d And certainly, it is not only in Turkey. The concept according to which species are not immutable but are in continuous transformation allows us to find reasonable explanations for the existence of the species we see around us. Otherwise, if we assume that all of them have been immutable. From the moment they were created, we would have to resort to forced and inconsistent explanations. Evolution provides us with a framework to understand the diversity of animal and plant species that inhabit the Earth, as well as the origin of the fossil remains of animals and humans with characteristics different from those of the current species. Let us consider the problem, apparently minor, of finding an explanation to the diversity of forms of the eggs of the different species of birds. Such eggs can have a spherical form, as is the case of owls, or an elongated and symmetrical form similar to that of a zepelin airt. They can also have an elongated but asymmetrical form, as happens with the arao, which is a sea bird that inhabits the north of the European and American continents. In contrast, there are no birds that lay eggs with asymmetrical and short forms that resemble a hot air balloon. If all the eggs have the same function of protecting the chick in their gestation, why do they vary so much in their form? Assuming an anti-evolution position we could answer that they have such or such a form. The answer is likely to be satisfactory to some but not to others who consider that this is not really an answer. In an evolutionary context different explanations have been given. It has been postulated, for example, that an elongated and asymmetrical form causes egg to roll in a circle and is thus beneficial in those cases of birds \u2013 such as Araos \u2013 that lay their eggs on cliffs where they are exposed to roll and fall. It has also been postulated that the shape of the eggs determines how they fit in the nest. An article published this week in the magazine \u201cScience\u201d refutes these hypotheses and advances an explanation of more consistency. This article was published by an international group of researchers headed by Mary Caswell Stoddard of Princeton University. Stoddard and collaborators carried out a study with about 50,000 eggs representing 1,400 species of birds. In their study researchers first assumed that the shape of the egg is not determined by the shell, but by its internal membrane, whose shape is modeled by the forces to which it is based. In addition, assuming that the strength and thickness of the membrane may vary along the oviduct, they could mathematically reproduce the egg forms observed in nature. To obtain an elongated and asymmetrical shape, for example, they varied the thickness and strength of the membrane along its axis. A short and asymmetrical shape, on the other hand, does not occur in nature because the longitudinal resistance of the membrane would vary too abruptly.Once they understood the mechanics of forming an egg, Stoddard and collaborators wondered about the evolutionary force that drives the process and found that the shape of the egg is related to the ability of the bird to fly. Thus, migratory birds that spend a good amount of time in the air, put elongated or asymmetric eggs, while the eggs of non-migration birds tend to be more spherical. Perhaps, migratory birds require narrow pelvis and slender bodies to facilitate their flight and this leads to the development of elongated eggs. The hypotheses handled by Stoddard and collaborators are clearly superior \u2013 in degree of sophistication, reasoning and methodology \u2013 to those that could be elaborated by denying evolution. Certainly, the researchers have not said the last word and their conclusions can be questioned by later studies. They will be, therefore, as in a showcase subject to the permanent judgment of their colleagues. The latter is the characteristic of the scientific method that never pretends to reach absolute truth. It is not the case, in contrast, of those who deny evolution, including possibly the Turkish president, who according to his detractors intends to delay 150 years of education in their country.",
    "https://upload.wikimedia.org/wikipedia/commons/b/b0/Apple_Headquarters_in_Cupertino.jpg": "With the creation of the National Council of Science and Technology (CONACyT) in December 1970, scientific and technological research in our country underwent a qualitative change. Prior to this, scientific research as a profession was practiced in very few places in Mexico. Fundamentally in institutions in the metropolitan area of the capital, with some exceptions. At the beginning of the 1970s, the situation began to change and research began to penetrate the interior of the country. Slowly, however, as a reflection of Mexico's huge backwardness in the matter.Among the factors that slowed down scientific progress in the 1970s and 1980s were, on the one hand, the economic crises that the country suffered, and, on the other, the low salaries that researchers received in our universities and research centers \u2013 partly due to these crises \u2013 that did not allow them to devote themselves exclusively to their profession. A key element in tackling the wage problem was the creation in 1984 of the National System of Researchers (SNI), which, based on the academic merits and results obtained by each researcher, awarded them a scholarship as a salary supplement. Although the SNI has had a remarkable growth in its just over three decades of existence, the number of researchers in Mexico is still very small compared to the size of the country \u2013 in the United States, for example, about six million people are employed in positions classified as science and engineering. Researchers in Mexico, in addition, and in view of the lack of job opportunities in other sectors, have been incorporated mainly into the academic environment, which has substantially increased its level of research. In contrast, little impact has been had by scientific research carried out in Mexico in terms of technology transfer from academia to the productive sector. What is the reason why there is such a weak relationship between the two sectors? In an article published in June 2016 in the journal \u201cTechnology in Society\u201d by a group of researchers from the National Polytechnic Institute headed by Alma Cristal Hern\u00e1ndez Mondrag\u00f3n discuss the point. Hern\u00e1ndez Mondrag\u00f3n and collaborators consider a particular facet of university-company linkage: the creation of new companies based on knowledge They conclude that the development of this type of company has been largely inhibited in Mexico by regulations contained in the Federal Law on Administrative Responsibilities of Public Servants that apply to researchers attached to public institutions that are thus considered public servants. According to the law, as a public servant, the researcher would be placed in a situation of conflict of interest according to the law by creating a company with technology based on its research results, facing possible administrative sanctions and even prison sentences. However, this was true only until December 2015. As from this date, it is no longer the case, as explained by an article published last Tuesday in the newspaper La Cr\u00f3nica de Hoy by the Advisory Council of Sciences of the Presidency of the Republic. In effect, in December 2015, the law on public servants was amended to make an exception to the conflict of interest situation in such a way that a researcher in a public institution can now make use of his research results to obtain a study results. In particular, it could create a technology-based company and be a shareholder in it. The prospect of losing its job or stopping in prison was undoubtedly an effective deterrent for a researcher to moderate \u2013 if he/she does have it \u2013 his/her business impulses. Changes in the law, which make an exception to the conflict of interest, thus remove a major obstacle to the transfer of technology between academia and the company. It is not the only obstacle to remove, however, and there are others that deserve attention. One problem on the horizon is public support for research. The creation of technology-based companies part of consolidated laboratories and research groups and with adequate financial support. For the time being, given the lack of interest of the private sector, such support can only come from the public sector. In the crisis conditions in which the country finds itself, however, funding for scientific research more than is being increased has been reduced and this will certainly not help to encourage the creation of companies from the academy. This is the result of the relatively recent introduction of science in Mexico. After all, it has not yet been half a century since the founding of CONACyT. And little more than three decades since research was professionalized with the creation of the SNI.",
    "https://upload.wikimedia.org/wikipedia/commons/1/14/Antpen-es.png": "One of the news of the week was undoubtedly the decision of the President of the United States to withdraw from the Paris agreement for the reduction of the emission of atmospheric pollutants in order to mitigate climate change. Some have felt that this decision is largely theatrical, because the agreement does not include punitive measures in case any of the signatories did not comply with the agreement. At the same time, however, it has provoked controversy and negative reactions. However, with its decision, the President shows disagreement on a point that the experts consider crucial to the climate health of the planet. Among other things, the presidential decision would imply that the United States will not make any further contributions to the United Nations Green Fund so that developing countries will face the effects of global warming. It should be noted that the United States committed three billion dollars to this fund, of which they have contributed only one billion. Together with the decision of the United States to abandon the Paris pact, this week we learn that an ice plate on the coast of the Antarctic peninsula is about to fracture, which would give rise to a gigantic This, according to researchers from the University of Swansea in the United Kingdom, led by Adrian Luckman, who observed through satellite photographs that between 25 and 31 May last, a crack previously existing in the ice sheet advanced about 17 kilometers, leaving only 13 kilometers to cause a total fracture.Although, according to researchers, there is no evidence that the fracture of the ice plate is due to climate change, it is known that previous ice plate breakdowns on the Antarctic peninsula have been caused by the warming of the ocean and the atmosphere. In this regard, Luckman notes that the Antarctic peninsula is one of the places on the planet where the ocean temperature is most rapidly rising, which certainly would not have helped to stop the formation of the fracture on the ice plate.Huckman fears that the current invoice, which will release 10% of the total ice plate, will leave it to this one. The formation of a gigantic iceberg in Antarctica is a news that no longer causes surprise in these times of climate change. Thus, there is global warming and that this is due to the emission of greenhouse gases into the atmosphere, not only has a strong scientific sustenance, but is accepted by a large part of the public. Yale University\u2019s Climate Change Communications program, for example, finds that 70% of American adults believe in climate change and 53% are convinced that it is due to human activities. Likewise, 49% believe that a majority of scientists believe that climate change is happening and 70% declare their confidence in scientists. On the other hand, 51% of American adults believe that climate change is damaging or harming their compatriots within 10 years, while only 40% believe that it will suffer personal damage. Thus, while a majority of Americans are convinced that climate change is real and that it is due to human activities. The distribution of opinions about the occurrence of climate change depends, of course, on geography. However, with few exceptions \u2013 in the Midwest or the former industrial belt around the Great Lakes, among others \u2013 there is a majority view that it is a real fact. In contrast, in very few places \u2013 around the cities of Los Angeles and San Francisco, for example \u2013 there is a majority view that climate change will cause damage to its person. The effects of climate change are thus thought to be distant and relatively unconcerned, which must be particularly true for the ultra-president\u2019s followers. This is not the case, on the other hand, of climate scientists who think that global temperature increases should be limited to less than two degrees centigrade above their pre-industrial values, as agreed in the Paris Pact. Otherwise, disastrous and irreversible effects on the climate of the planet will occur. ices from Greenland and Antarctica and the waters of the oceans expand by increasing temperature. If this happens, one of the most affected places will be the Florida peninsula, where the Mar-a-Lago mansion is located. That will have been fulfilled that god punishes without a stick or a fourth.",
    "https://upload.wikimedia.org/wikipedia/commons/5/51/Antonio_de_Pereda_-_El_sue%C3%B1o_del_caballero_-_Google_Art_Project.jpg": "As we know \u2013 exceptions aside \u2013 we use the hours of the night primarily to sleep. To sleep, moreover, from six to eight hours of one tug. We are so accustomed to this routine that it is surprising to learn that this is not a widespread practice in all cultures, and that, in fact, it was not in Western culture \u2013 of which we are largely heirs \u2013 but until relatively little time ago. Indeed, as Roger Ekirch of the Virginia Polytechnic Institute has documented, the habit of sleeping in a single stage arose in the nineteenth century and coincided with the industrial revolution and the expansion of night lighting. Previously during the night it was customary to sleep in two stages separated by an interval of a few hours; an interval that was used in the most diverse ways, including that of getting up from bed to chat with neighbors. Actually, thinking better, maybe sleeping in two or more stages is not so surprising at the end of the night, but in some way a natural consequence of the emergence of night lighting. The hours of darkness, however, are more than the necessary hours of sleep and from this it is inevitable that the night will have hours of vigil.Ekirch speculates that part of the insomnia problems that today suffer a good part of the population, which depends on the use of sleeping pills, may be due to the change of sleep regime of two stages \u2013 which would be the natural one and that prevailed until a couple of centuries ago \u2013 to the regime of a stage that we are accustomed to today. Although it is not clear if regarding this last Ekirch is correct, there is the possibility that in the years to come the quality of sleep will worsen by the effect of the global warming that will generate warmer nights \u2013 still more than it has generated so far. This at least according to an article published in the magazine \u201cScience Advances\u201d by a group of researchers of American institutions headed by Nick Obradovich of Harvard University. Obradovich and collaborators note that when the body prepares to start the sleep period decreases its temperature, same as it recovers again In this way, in case a high ambient temperature interferes with the regulation of the body temperature, the sleep-watch cycle will be altered and the quality of sleep will deteriorate. In their research, Obradovich and collaborators first sought to establish that, in fact, there is a correlation between the ambient temperature and the quality of sleep. For this, they used the data of a survey carried out by the Center for Disease Control and Prevention of the United States between 2002 and 2011 to about three-quarters of a million people. To the participants the question was asked: \u201cIn the past 30 days, how many days did you feel that you did not have enough sleep and night rest?\u201d Following this, climatological data of ambient temperature were consulted at the date and place that corresponded to each response. The researchers found that the number of nights with restful sleep was directly related to the deviation of ambient temperature from its normal average value. Specifically, an increase of a centigrade degree in that deviation produced 3 additional nights of bad sleep each month, for every 100 people. Obradovich and collaborators found, In addition, this effect was most marked in the summer months and among people over 65 years of age. They find, likewise, a greater effect among those whose salary does not exceed $50,000 per year compared to those with higher incomes. This latter possibly reflects the cost of maintaining an adequate air conditioning system. In the future, when warmer nights are anticipated by climate change, we could anticipate more sleepless nights. Thus, taking into account the temperature increases that are predicted for the years 2050 and 2099 the number of nights with restless sleep per month would increase by 6 and 14, respectively. However, they do not pretend to Obradovich and collaborators to be precise in this regard, since they recognize that in the future, among other technological advances, more widely affordable means of environmental temperature control could be developed. We certainly do not have a crystal ball to predict what will happen in the future. The changing past offers us more certainty. In particular, it teaches us that the industrial revolution, along with all the benefits that it has brought us, has given us in the same way warmer and intra nights. nquilas.",
    "https://upload.wikimedia.org/wikipedia/commons/7/72/Niccolo_Paganini.jpg": "Since it took its present form in Cremona in the 16th century, the violin climbed into one of the most prestigious musical instruments today. And according to this prestige \u2013 or rather as an integral part of it \u2013 the violin is closely associated with Niccol\u00f2 Paganini and his extravagant history, very typical of the 19th century. As we know, it was such the virtuosity of Paganini as an interpreter of the violin that it was said that he had made a pact with the devil. And, certainly, his cadaveric and extravagant aspect of life did not help to dispel the doubt. Even when he died in 1840 in Nice, the church did not allow him to be given Christian burial. Only four years later it was possible for his remains to be transferred to Genoa with the intervention of the pope. It was not buried, however, but until 1876 in Parma. It also belongs to the violin the legend of Cremona and its famous lutieres \u2013 string instrument constructors \u2013 among which Antonio Stradivari, Giuseppe Guarneri and the Amati family stand out. Cremona\u2019s golden age \u2013 the eighteenth century \u2013 is highly appreciated and reaches values that are measured in millions of dollars. In fact, the price of a violin Stradivarius or Guarneri can exceed 10 million dollars. While a violin of 10 million dollars is a more typical object of collectors or investors, there are also old violins that belong to professional musicians. With regard to the latter, in the year 2010, the theft of a violin Stradivarius to the Korean violinist Min Jin Kim was made public in London. The theft of the instrument occurred in a cafeteria in an oversight of its owner, who had acquired it at a cost of 450,000 pounds sterling. One year after the theft the London police found the thief, more not with the violin, which was not located until 2013, fortunately without major damage. An article published online by the British daily \u201cDaily Mail\u201d last Tuesday refers to the drama suffered by the violinist who considered her instrument \u2013 which at that time it was already cost 1.2 million pounds \u2013 part of itself and indispensable for her musical career. . The penalty he suffered was such that he stopped playing at concerts and fell into the anorexia he had suffered years ago. Although he later overcame his depression, he could no longer recover his violin by having accepted the insurance company\u2019s payment for the theft. With this acceptance the violin passed into the insurer\u2019s hands, and the cost that the instrument had reached \u2013 $2.5 million \u2013 prevented him from negotiating his reacquisition. Cremona violins are commonly considered superior in sound quality to any modern violin \u2013 hence the high prices they reach \u2013 and have been the subject of many studies to try to unravel their manufacturing secrets. There is no unanimous agreement on such superiority, however. Among those who disagree is Claudia Fritz, an acoustic expert, who with a group of collaborators published an article in 2012 in which she reports that professional violinists are unable to distinguish between a modern violin and an old one. As expected, these conclusions were criticized by professional musicians. Thus, the \u201cNew York Times\u201d collected comments from violinist Earl Carlyss who considered that the procedure was In order to determine the quality of an instrument, a violinist needs to evaluate how it is projected in a concert hall. He equipped the tests carried out by Fritz and collaborators to try to compare a Ford and a Ferrari in the parking lot of a supermarket. Fritz's reply and collaborators were given in an article published this week in the magazine \u201cProceedings of the National Academy of Sciences\u201d. In that article, the researchers reported the results of studies made in two concert halls, one in Paris and the other in New York, in which three violinists Stradivarius and three modern violins were compared blindly. In contrast to the first study, the new research collected opinions from both the performing professional violinists and the audience. Comparisons, in addition, were made both with orchestral accompaniment and without such accompaniment. Researchers find results that reinforce and extend their previous findings. Thus, in a blind comparison, both violinists and educated listeners were shown. s, given to choose between a modern violin and a Stradivarius, prefer a modern-made violin. The superiority of Cremona's violins over modern violins would thus be a myth and Min Jin Kim would have suffered for free from the loss of a violin that could have replaced with advantage and a fraction of the cost of the original instrument. Otherwise, nothing of his well-deserved prestige will lose the violins and their fantastic sound by the fact that the myth of Cremona fades. Just as nothing has been lost because, likewise, Paganini's pact with the devil does not pass today from being fiction.",
    "https://upload.wikimedia.org/wikipedia/commons/4/4e/Prise_de_la_Bastille.jpg": "On a cold winter day in Stockholm in 1650, the famous French philosopher Ren\u00e9 Descartes ceased to exist \u2013 and simultaneously to think about it. Descartes had arrived in Stockholm five months earlier invited by the queen of Sweden, who was interested in being instructed in the new philosophy developed by him. It seems that Descartes did not enjoy his stay in Stockholm because of the rigid discipline to which he was subjected by the queen, which demanded him to rise still at night on the frigid winter mornings. And, in fact, so did not enjoy the stay that ended up dying; apparently pneumonia, although there is also a version that he would have been poisoned with arsenic. However, the misfortunes of Descartes did not end with his death. Indeed, it happened that at the death Descartes was buried in Stockholm and with this he would have apparently rested in peace for all eternity. Sixteen years after his burial, however, a group following Descartes de Paris promoted and obtained his remains to be transferred to France. under the supervision of the French ambassador to Sweden, and kept in the embassy with the custody of Swedish soldiers awaiting their transfer to France. The custody of the remains by soldiers would have been apparently motivated by the danger that they would be stolen \u2013 in particular by the English \u2013 given Descartes\u2019 growing reputation as the patron saint of science. This caution, however, proved counterproductive, as we shall see below. The transfer of the remains to France was coordinated by the French ambassador. This was a collector of relics and would have taken the opportunity to stay, with the consent of the Catholic Church of Sweden, with an index finger bone of the almost holy\u2019s right hand. Upon arriving in France in 1666, Descartes was buried for the second time, now in the church of Santa Genoveva del Monte in Paris. It did not stop there, however, because during the French revolution the remains of Descartes were again unearthed and laid in a museum, until in 1818 the Academy of Sciences buried them in the church of \u201cSaint Germain dess dess. Pr\u00e9s\u201d in Paris, where they currently rest. Not complete, however, because when they opened the coffin before burial the academics discovered that the skull was missing. The circumstance in which it disappeared was not clear until three years later, when the Swedish chemist Berzelius found that at an auction of objects belonging to a Swedish scientist named Anders Sparrman, the \u201ccranium of the famous Descartes\u201d was listed as one of the objects that had been offered.Berzelius found out that the skull had been acquired at the auction by the owner of a casino. He interviewed him and managed to sell it to him. Once with the skull in his possession, Berzelius sent him to the Academy of Sciences that was given to search for data that authenticated the remains. Today, after the investigation of the Academy, it is known that these remains passed through many hands. The first owner was the captain of the soldiers who guarded the remains before his departure to France, who would have stolen the skull so that \u201csomething of the great philosopher would remain in Sweden\u201d. The chain of owners of Descartes\u2019 skull was followed by a military officer, a government official, his son-in-law, an overseer, a tax advisor and finally Anders Sparrman. Some owners decorated the skull with legends, which helped French scholars conclude that Ren\u00e9 Descartes had undoubtedly been their original owner. Descartes\u2019 skull is currently housed in the Man Museum in Paris. Apart from the controversies that generated its philosophical ideas in its time, Descartes was a genius and as such he is among those whose brain has been studied after death to try to understand the origin of human intelligence. One of these studies was made public last April in the journal \u201cJournal of the Neurological Sciences\u201d by a group of researchers in France and Holland, headed by Charlier Philippe of the Paris Descartes University. Contrary to other studies \u2013 such as the one conducted with Albert Einstein\u2019s brain \u2013 Philippe of the Neurological Sciences in France and Holland. In spite of this, the tomography images they obtained show in detail the external morphology of Descartes' brain, which was imprinted inside the skull. Unfortunately, as has happened in other cases, researchers find little in Descartes' brain that could explain his exceptional intelligence. So we will have to wait for more research before we glimpse the secrets of the brain of geniuses.Since what differentiates us the humans of other species in the animal kingdom is intelligence, it is not surprising that an exceptional brain awakens us a great fascination. And it awakens us to such a degree that it produces such extravagant and showy stories \u2013 the same as macabres \u2013 as Ren\u00e9 Descartes's and his adventures after leaving the world.",
    "https://upload.wikimedia.org/wikipedia/commons/e/ea/Salaries_and_Unemployment.JPG": "An article published in Sweden in 1869, aimed at inhibiting the emigration of the Swedish population to the United States, warned of the alleged dangers faced by those who ventured to travel to the American country.This article included two contrasting illustrations.In one it presented themselves to an idyllic country, with abundant hunting and fishing resources, and the possibility of resting in a hammock under the shade of leafy trees.In the other, reflecting the supposedly real country, the immigrant was faced with great threats, including the attack by wild wild wild beasts, snakes and natives.The latter are dressed as American Indians, with feathers on their heads and drawing out the heart to the Aztec style of a victim thrown to the ground.It is not clear how this article or other similar ones have had in the spirits of the potential Swedish immigrants to the United States, but certainly did not inhibit the more than a million Swedes who changed their residence to that country during the 19th century and the beginning of the 20th century in the search for the American dream. , Irish, Polish, Greek, Russian and Italian, among other nationalities, who came to the United States in this same period in search of a better life. Not to mention the 16 million Mexicans who emigrated to the United States between 1965 and 2015 \u2013 according to the \u201cPew Research Center\u201d \u2013 also attracted by the American dream. On the other hand, we know that in recent decades the American dream has been blurred to a certain extent. Thus, an article published this week in the magazine \u201cScience\u201d, published by a research group from American universities headed by Raj Chetty of \u201cStanford University\u201d in California, finds that one of the aspects that define the American dream: the aspiration for children to enjoy a higher standard of living than the parents had, has suffered a major shock. Specifically, that article concludes that the proportion of children who at thirty years old have a salary higher than that their parents at the same age had has fallen sharply in recent decades. Chetty and collaborators reached this conclusion after analyzing labor statistics from the United States for children born between 1970s. Since the lack of sufficient data linking parents and children throughout the period of interest does not make it possible to directly compare the salary received by a child with that of their father decades ago, the researchers resorted to indirect methods and to several databases. Thus, they made a combined use of data provided by the United States tax collector's office linking parents and children, born after 1980, and data from the United States census office for those born earlier that year. In the latter case, in the absence of complete data, the researchers had to resort to a hypothesis concerning the stability of the sum of the wages of parents and children over time. According to the authors of the article, however, their hypothesis is sound and is supported by the data available. As mentioned above, Chetty and collaborators conclude that intergenerational social mobility in the United States has fallen dramatically among those born in the period 1940-1984. The decline in mobility, moreover, was not the same throughout the U.S. territory, affecting particularly the middle west. Thus, in the state of Michigan there was a drop in mobility by 48 percentage points, while in Illinois, Indiana and Ohio, that drop was 45 points. In contrast, in the states of New York and Massachusetts, the decline in mobility was approximately 35 points.Chetty and collaborators wonder about the causes of this drastic fall in in intergenerational mobility and the policies that would have to be implemented to restore it to its previous levels.They consider two possible causes: the fall in the rate of growth of the U.S. economy, and a growth of inequality in the distribution of gross domestic product among the population.They dismiss the first cause because they find or even restore the rate of growth of the U.S. economy to the levels of the mid-twentieth century could restore intergenerational mobility.They conclude, on the other hand, that the fall in such mobility is due to the increasing inequality in the distribution of economic benefits among the population. Thus, an increase in the rate of economic growth would benefit In this way, according to Chetty and collaborators, the growing social inequality in the United States is destroying the myth of the American dream. And it is surely doing so with greater effectiveness with which anti-U.S. articles curbed Swedish emigration to that country in the 19th century.",
    "https://upload.wikimedia.org/wikipedia/commons/9/9c/Cover_%28The_Lost_World%2C_1912%29.jpg": "In his 1912 novel \u201cThe Lost World\u201d, Arthur Conan Doyle describes an expedition to a plateau lost in the Amazon jungle by a group of explorers that includes scientists, reporters and simple adventurers. The plateau in question is bordered by high walls, steeped and inaccessible to such an extent that they have isolated it from the world for hundreds of millions of years, making it possible to survive animals long extinguished. Among these animals are pterodactyls and iguanodonts. The explorers found themselves even with a primitive group of monkey-men who make war on them. \u201cThe Lost World\u201d is, of course, a work of fiction. A work very in tune with the time it was written \u2013 a little more than fifty years after Charles Darwin published \u201cThe Origin of Species\u201d \u2013 but that possibly no one would take it as anything more than mere fiction. Surprisingly, however, a paleontological discovery carried out in 2003 on an island of Indonesia makes reality to some extent what Conan Doyle had imagined. Indeed, in September 2003 A group of researchers from Australia and Indonesia discovered about six meters deep in the Liang Bua cave on the Indonesian island of Flores, an almost complete skeleton of an individual who in life would have had about a meter of height. The age of the remains was originally dated to 18,000 years and subsequently extended to 65,000-90,000 years. Because of its short stature, paleontologists originally thought that they were before the skeleton of a child. Soon, however, it was clear to them that it was a small adult individual, with a brain volume that barely reached 400 cubic centimeters, which is almost a quarter of the volume of a modern human brain. The researchers had thus brought to light a tiny human, who lived in a relatively recent time and whose origin for the time constituted an absolute mystery. Moreover, after the original discovery there were similar ones on the same island of Flores, demonstrating that the island was until about 50,000 years ago inhabited by a diminent human race. On the other hand, in parallel with the search for satisfactory answers to the mystery of the island of Flores. Flowers, and for the benefit of public relations, the researchers rightly baptized the newly discovered human group with the nickname \u201cHobbit.\u201d How did the \u201cHobbit\u201d arrive on the island of Flores? This question has generated much controversy among the specialists and contradictory explanations have been offered about its origin. These explanations take into account the fact that the island of Flores has been totally or relatively isolated over the past two million years. In these isolation conditions, some specialists consider that the \u201cHobbit\u201d is actually anatomically a modern human affected by some genetic disorder. In the same line of argument, being a modern human population isolated with limited resources, it would have evolved to a tiny size. Other researchers consider that the \u201cHobbit\u201d are descendants of the \u201cMan of Java\u201d who came from Africa to East Asia about 1.8 million years ago. As the Java Man was taller and had a brain considerably larger than the \u201cHobbits\u201d, the latter would have to have evolved into smaller sizes due to an island isolation effect. They have not, however, This hypothesis is supported by a study published this week in the journal \u201cJournal of Human Evolution\u201d by an international group of researchers headed by Debbie Argu of the National University of Australia. Argue and collaborators come to this conclusion after studying and comparing 133 fossils of skulls, jaws and teeth of a large number of species that lived over the last three million years. From this study, it appears that the \u201cHobbit\u201d, with 100% security, are not modern men with a genetic pathology. Likewise, with 99% of security, it appears that the \u201cHobbits\u201d are not directly related to the Java Man. On the contrary, researchers come to the conclusion that the \u201cHobbits\u201d may have originated in Africa more than 1.75 million years ago and subsequently emigrated to the island of Flores. Thus, according to Argue and collaborators, the \u201cHobbit\u201d until before its disappearance 50,000 years ago could have been a relic with almost two million years old. A relic with which our ancestors lived together. In fact, the extinction of the \u201cHobbits\u201d coincides in time with the expansion of our species in eastern Asia. The discovery of the race of the \u201cHobbits\u201d, who survived in isolation until recent times is certainly fascinating. And, certainly, it shows us that sometimes reality surpasses fiction.",
    "https://upload.wikimedia.org/wikipedia/commons/c/ca/1911_Solvay_conference.jpg": "Last Wednesday, Jos\u00e9 Antonio S\u00e1nchez, president of Radio Televisi\u00f3n Espa\u00f1ola, gave a lecture at the Casa de Am\u00e9rica in Madrid, in which he compared the Aztec Empire with Adolfo Hitler\u2019s Nazi regime. During his talk, S\u00e1nchez quoted Australian historian Inga Clendinnen who would have said that \u201cto regret the disappearance of the Aztec Empire is more or less like to feel sorry for the defeat of the Nazis in the Second World War.\u201d Although the speaker made it clear that he was ignorant on the subject and that his own dissociated himself from having the category of a conference, his assertions and quotations provoked rejection in Mexican media. Excelsior newspaper, for example, called them outrageous. According to Jos\u00e9 Antonio S\u00e1nchez, Spain in America \u201cwas never colonizing, it was evangelizing and civilizing\u201d of a people with barbaric customs. Of course, even assuming that this was true, it would have to be conceded that in its evangelizing and civilizing work Spain sometimes exceeded practices that seemed to contradict it. An example of this is the massacre of the Temple of the Great at treason. During the feast of T\u00f3xcatl by the conquerors under the command of Pedro de Alvarado. It is also the practice of entrustment, through which a certain number of Indians were given to a peninsular for exploitation and, of course, evangelization.On the other hand, despite the atrocities committed by the invaders during the conquest and even though the Europeans of the 15th century were accustomed to the most refined methods of torture, the conquerors were horrified by the human sacrifices that the Aztecs would have carried out prodigalistically. And, above all, by the practices of anthropophagy with the bodies of the sacrifices that provided the Spaniards with an excellent argument to demonstrate the need to subdue, evangelize and civilize the Mexicans. Apart from the scandal of the conquerors for the practice of cannibalism, studies on the transmission of neurodegenerative diseases associated with the intake of contaminated human flesh, as well as evidence of fossil remains discovered in prehistoric sites, show that cannibalism has been present among us since remote times. . It has spread even to the present time in isolated places on the planet. It is not clear, however, whether such practice had a ritual purpose or nutritional purposes. An article published this week in the journal \u201cScientific Reports\u201d leans towards the first possibility. That article, published by James Cole of Brighton University in the United Kingdom, concludes that the calorie content of the human body is not particularly large and that it is not a particularly attractive source of food. Indeed, Cole finds that the muscle mass of a 66 kg body of weight contains about 32,000 calories, compared to 3,600,000 calories of a mammoth, 600,000 calories of a bear and 200,000 calories of a horse. In addition, the calorie content of the human body per kilogram of muscle mass is significantly smaller compared to large animals such as mammoths, woolly rhinoceros and bears. In these circumstances, Cole wonders: what might have been the motivations of our ancestors to hunt their own species rather than looking for larger animals that would provide them, by unit. Taking into account, moreover, that in the first case they would face animals with a similar level of intelligence which would certainly make hunting more difficult. Thus, Cole concludes that the episodes of cannibalism so far discovered probably had a ritual origin.In relation to the Aztecs, the cannibalism they practiced was for nutritional or ritual purposes? In this there is no unanimous agreement, but Bernad Ortiz de Montellano of Wayne State University in Detroit maintains that the Aztecs did not need to resort to cannibalism to meet their food needs since Tenochtitlan produced enough food, in addition to that, as the capital of the Aztec Empire that it was, he received a large number of tributes. Furthermore, the number of sacrifices would not have been sufficient to nourish the privileged 25% of the population that consumed their meat. Thus, just as it would have happened with our distant ancestors according to James Cole, the practice of anthropophagia among the Aztecs would have had a ritual purpose and the sacrifices would not have been simple slaughter animals. In this context, although cannibalism and the flower wars of the Aztecs were a brutal practice, they were nothing more than the massacres and atrocities carried out by the Spaniards during the conquest; nor more than the subsequent submission of the indigenous population. Thus, it turns out that the comparison made by Jos\u00e9 Antonio S\u00e1nchez between the Aztec Empire and the Nazi regime is exaggerated. To say the least.",
    "https://upload.wikimedia.org/wikipedia/commons/b/b6/Soyuz_18_booster.jpg": "The week that ends today we learned from the media that the American company Space X managed to put into orbit a satellite using a recycled rocket; that is, a rocket that had already traveled into space. To recycle a rocket it is necessary to recover it without damage at the end of its mission and for this Space X has developed a technology to pose it smoothly on a platform at sea. This technology allowed to recover without damage the reference rocket \u2013 in fact only its first stage \u2013 at the end of its first mission. It also allowed it to be recovered at the end of the second mission, so that the rocket could be reused for a third trip and potentially for multiple missions.With the recycling of the first stage of the rockets, Space X hopes to obtain significant savings in its launches of satellites into space, given that each launch has a total cost of approximately 60 million dollars, to a large extent for the cost of the rocket. As we know, the satellite age began on October 4, 1957 when the Soviet Union then launched Sputnik 1, the first artificial satellite in history. Sputnik 1 was kept in orbit for three years. months after which he returned to Earth, incinerated by friction with the atmosphere. Sputnik 1 was followed by others of his class, as did the American equivalents. Satellite sending intensified in the following decades, rapidly increasing the number of objects in orbit. Currently, according to the \u201cUnion of Concerned Scientists\u201d, there are about 1,400 operating satellites circulating to the Earth. The number of countries that possess satellites has also grown substantially. Thus, while in 1966 only the United States, the Soviet Union, France, Italy and Great Britain possessed satellites, by 2016 the list had been extended to half a hundred countries, including Mexico, although not all of them have their own ability to access space. The 1,400 satellites in operation are distributed in several orbits at different heights. In low orbits, about hundreds of kilometers of altitudes are located almost 800 satellites, while in the most remote orbit, about 36,000 kilometers of the Earth's surface are located in about 500 satellites. The rest is located in intermediate orbits. There are a large number of objects orbiting the Earth that are the product of our space activities and are classified as space debris. According to NASA, about 20,000 objects with dimensions greater than 10 centimeters are tracked in orbit. Five percent of these objects are active satellites and eight percent are rocket debris. The remaining one is made up of satellites or inactive satellite fragments. Additionally, according to NASA, there are about half a million fragments of the size of a marble or larger, and millions of minor fragments that cannot be observed but that at the speeds they travel, which could reach 28,000 kilometres per hour, can cause considerable damage in the event of a collision. In addition, collisions in orbit can substantially increase the number of space debris fragments. For example, the collision between a Russian satellite and an American satellite in February 2009 produced more than 2,000 fragments that were added to the space debris inventory. Similarly, a test carried out by China in 2007, during which a missile destroyed an inactive satellite, generated more than 2,000 fragments that were added to the space debris inventory. Three thousand new fragments in orbit.Forgotten or lost objects in space are also added to the space debris inventory.In the past days, as an example, the press informed us of the loss in space of a 1.5-meter-diameter shield against meteorites, which would have had to be installed on the International Space Station by two astronauts during a spacewalk. In the corresponding video \u2013 which can be consulted on the Internet \u2013 one of the astronauts can hear that one of the astronauts tells his companion that he does not find the shield, which is seen moving slowly and getting lost in the depths of space. According to specialists, space debris, particularly that small enough that it cannot be tracked \u2013 the product of more than 5,000 launches into space from the Sputink 1 \u2013 represents a growing danger to space missions. On the other hand, the problem may not be solved in the short term. That is, as space travel is covered by rocket recycling programs such as the one he is leading to Space X company, the tendency may be to increase the frequency of space launches more than There will be, for private interests, more incentives to aggravate the problem of space debris than to reduce it. Just as it happens, for example, with climate change, the product of other debris also generated by us.",
    "https://upload.wikimedia.org/wikipedia/commons/9/91/Monsoon_clouds_Lucknow.JPG": "The nocturnal images of the Earth seen from space show profusely illuminated regions that indicate where the largest concentrations of population of the planet are located. Thus, we can see areas of great brilliance around the large Californian cities and the east coast of the United States, as well as around the large European, Japanese and Chinese cities. This contrasts with the illumination of the Sahara desert region in North Africa, indicative of its very low population density.The low population of the Sahara desert, of course, is the result of its excessively dry climate that has resulted in an arid and hostile territory, not attractive to take root. In fact, the popular image of the Sahara desert is that of a moor with little more than sand dunes and storms. This, however, and even though it is hard to believe, was not always the case and there was a time when the Sahara desert was a place with abundant vegetation and fauna that today is only found in regions more south of the African continent. same, about 11,000 years ago, a strengthened African monsoon carried moisture and rain from the Atlantic Ocean to the desert and transformed it into a lush green. The transport of moisture from the ocean to the continent occurred when the earth warmed up more than the sea water by the effect of solar radiation. In these conditions, the air in contact with the earth raised its temperature and ascended generating a region of low pressure, which, in turn, caused a stream of humid air from the sea to the continent. Additionally, as the wet air ascended and its temperature decreased, it had less capacity to retain the water vapor that was precipitated in the form of rain. Thus, the Sahara became a dry and barren territory with abundant plant and animal life that included crocodiles, elephants and giraffes, as well as with a network of rivers and lakes; the latter of such a dimension that they were able to host fish of up to 150 kilograms of weight. The Sahara's green period lasted until about 5,000 years ago when it returned to the desert condition that today boasts the decline of the monsoon's strength. This, in turn, would have been the result of changes in the orbit of the Earth around the Sun and the inclination of its axis of rotation, which would have been aligned 11,000 years ago in such a way as to increase the warming of the Sahara during the summer. Eventually, some 5,000 years ago, the alignment of our planet in relation to the Sun changed again and with this the amount of solar radiation was reduced by impacting on the Sahara. In these conditions the strength of the monsoons decreased and with this the Sahara returned to its original condition. This explanation, however, was questioned by an article published last January in the magazine \u201cFrontiers in Earth Science\u201d, published by David Wright of the National University of Seoul in South Korea. According to Wright, it is possible that the disappearance of the Green Sahara has not been due to natural causes but that human activities have contributed decisivelyWright finds that some 8,000 years ago, when it would have started the decline of the Green Sahara. , populations dedicated to grazing appeared in the Nile region that began to migrate to the west. This coincided with a replacement of the vegetation of the Sahara with scrublands, which is indicative of the beginning of desertification. The loss of the vegetation of the Green Sahara \u2013 by natural causes, or artificial ones for the benefit of grazing \u2013 increased the reflection of the sunlight and with this the earth became less heated and consequently the monsoons weakened. Thus, the area covered by the vegetation and the strength of the monsoons decreased further, until, following a chain of self-strengthening, we ended with the desert of which we are witnessing. Thus, we have the beginning of both, the grazing activities and the process of desertification of the Sahara, would have coincided in time. We cannot say much more, however, as Wright points out, we find at this point the problem of egg and hen. That is, it is not possible to conclude if desertification is the product of grazing, or if grazing was the practice of a population of hunter-gatherers who were forced to change their way of subsistence by the desertification of their habitat. However, open the possibility that our practices have contributed decisively to modifying a vegetable with a rich vegetation, with crocodiles, elephants and giraffes and a network of rivers and lakes, in a desert in a dry and desolate end of 9 million square kilometers.",
    "https://upload.wikimedia.org/wikipedia/commons/4/42/Tokyocity.png": "On the morning of September 1, 1923, an earthquake of magnitude 7.9 destroyed the city of Tokyo, killing more than 100,000 people. The devastation was the result of both the earthquake itself and the fires it caused. In the hours and days that followed, false rumors came from military and police forces, according to which the Koreans living in Tokyo were carrying out robberies and causing riots armed with bombs. They would have even poisoned the drinking water wells of the city; this, according to notes published in local newspapers of the time. As a result of the false information campaign, 6,000 Koreans were lynched, some in an atrocious manner, both by organized groups of the civilian population and by military and police. Among the victims were even Japanese who were confused with Koreans in the midst of the disorder.Irrational behaviors resulting from the recreation of rumours and false news are not unusual. Thus, although in a different context, disinformation and false information campaigns have been launched that seek to discredit scientific facts and provoke irrational responses in the public. As we know, there is a consensus among climate scientists that the planet is gradually warming up, largely due to the emission of greenhouse gases into the atmosphere by human activities. However, there is no lack of doubt about this fact. In relation to the latter and to be precise, it should be noted that it is beyond doubt that the concentration of carbon dioxide \u2013 the main greenhouse gas \u2013 in the atmosphere is growing year after year. Indeed, the measurements of this concentration that the Mauna Loa Observatory, Hawaii, has continuously carried out since 1958 to date \u2013 available on the Internet \u2013 demonstrate this in a strong way. It is clear, too, that this concentration is linked to human activities developed from the industrial revolution. It is also clear \u2013 even though there were those who disagreed in the past years \u2013 that the temperature of the surface of our industry is clearly linked to human activities. The results of the research were published last January in the magazine \u201cGlobal Challenges\u201d. On the other hand, linking the increase in Earth\u2019s temperature with the increase in the concentration of greenhouse gases in the atmosphere and with human activities is a technical issue that can only be addressed by specialists. On this point, however, 97% of climate scientists agree that such a league exists. In contrast, for climate change skeptics, the rise in Earth\u2019s temperature \u2013 if any \u2013 is due to natural causes and not to human causes. And to support this thesis they have launched a campaign of misinformation and false information in order to neutralize the opinion of specialists. To investigate the effectiveness of this campaign and how to neutralize it, a group of university specialists in Great Britain and the United States, headed by Sander van der Linden from Cambridge University in the United Kingdom, conducted a study with more than 2,000 participants through the Internet. The results of the research were published last January in the magazine \u201cGlobal Challenges\u201d. The researchers proposed to determine that false messages had a greater effectiveness among the public and for this they took examples of a real campaign of disinformation. At another stage of the investigation, they proposed to determine the effectiveness of possible \u201cvacunas\u201d against disinformation and false claims. As a result of their work, van der Linden and collaborators found that while disinformation messages have an adverse effect on the perception of climate change, it is possible to \u201cinoculate\u201d the public against false claims by means of messages that alert about the existence of groups interested in discrediting scientific opinions. That is, instead of reacting against a false message once disseminated, it would be necessary to alert the public a priori to the future dissemination of the same, giving details of its possible content. The campaigns of disinformation and false news have defined purposes that in the case of the massacre of Koreans in Tokyo may not be completely clear. If they are, instead, the purposes behind the campaigns against climate change. Here climate scientists expose a problem of urgent solution that demands great changes in the way we use the sources. This affects interests and naturally generates great resistances and disinformation campaigns. In these circumstances and against false news and alternative facts \u2013 so fashionable today \u2013 we only have to vaccinate ourselves and defend ourselves as much as possible.",
    "https://upload.wikimedia.org/wikipedia/commons/3/3f/Rojos.png": "With the introduction and commercialization of electric light at the end of the 19th century the nights quickly lost their blackness and with this our night habits changed considerably. To be precise, it should be mentioned that the blackness of the nights began to be lost throughout the 19th century with the gas lamps. These, however, did not have the potential of the incandescent lights and at the time they were quickly displaced by the electric light.The spirit of the nights without electricity was faithfully captured by painters like the French Georges de La Tour \u2013 17th century \u2013 in paintings that show night scenes in interior illuminated by the light of a candle, with such a poor intensity that it would barely reach to not stumble.All this changed with the electric light and the paintings of the Tour we could put before the image of an American stadium of baseball during the celebration of a night game, with such intense and well distributed lighting that allows players to practice their profession with the incredible precision that it demands. As opposed to the incandescent lamps, which generate light by heating a metallic filament, LEDs produce light by passing an electric current through a semiconductor material. And depending on the chemical composition of that material, it is the color of the light emitted by the LED. The first LEDs were made in the 1960s of the last century and emitted red light \u2013 they also had invisible infrared light. Later, LEDs were made that emitted in yellow or green colors. In these developments, the research laboratories of the United States played a prominent role. An LED of one color, however, cannot be used as a lamp for lighting because for this it is necessary to emit white light, that is, light with a mixture of various colors. In these conditions the revolution in lighting had to wait until the 1990s, when the Japanese Isamu Akasaki, Hiroshi Amano and Shuji Nakamura produced blue LEDs. . Here it should be noted that although blue LEDs cannot be used as lighting sources either, some of the light they emit can be converted into green and red colors. Thus, mixing green and red with the original blue, white light is obtained. On the other hand, while single-color LEDs are not suitable as lighting sources, if they have a large number of other applications, including their use in traffic control screens and traffic lights, to mention one of the most common. There are even applications for LEDs that emit in colors beyond those we can see and this motivates that in different laboratories in the world research projects for the development of LEDs with invisible light emission characteristics are carried out. In relation to this last point, this week a group of researchers from Cornell and Notre Dame Universities in the United States published an article in the magazine \u201cApplied Physics Letters\u201d in which they report the development of an LED that emits ultraviolet light. , among other applications, it can be used to purify water or hygiene food, as well as in devices to detect counterfeit paper money. The technology used to manufacture such ultraviolet LED is extremely sophisticated and involves the manipulation of layers of materials of different chemical composition with atomic thicknesses. Such technology is, of course, possible only within laboratories that have technical and scientific knowledge of border, which has been traditional in many American laboratories. It is, however, interesting to note the ethnic composition of the group that developed the reference ultraviolet LED. A list of its members\u2019 names gives us an indication of it: S.M. Islam, Kevin Lee, Jai Verma, Vladimir Protasenko, Sergei Rouvimov, Shyam Bharadwaj, Huili (Grace) Xing, and Debdeep Jena. From this listing and doing a quick search on the Internet reveals that the group is formed by three researchers from India, two from China, two from Russia, one from Bangladesh and zero from the United States. This latter, which is surprising, is not, however, a In fact, the fact that a majority of members of a research group in North American laboratories are mostly composed of specialists who emigrated to the United States is not uncommon. Thus, restricting the entry of foreign researchers into the United States, as is feared in certain circles, seems to be something that goes against the interests of that country, because while it is true that the United States is a technological leader, such leadership is based on the flow of intelligence from abroad. Thus, the country that contributed the most to give the world electricity, and the one that has played a central role in the development of LED sources, could enter a period of darkness.",
    "https://upload.wikimedia.org/wikipedia/commons/5/5d/1907-07-03%2C_%C2%A1Alegr%C3%ADa%21%2C_Los_de_la_orden_botijil%2C_Medina_Vera_%28cropped%29.jpg": "In recent days we saw published in the media notes with showy headlines talking about the possibility of mammoth resurrection in a couple of years. This, after George Church, who heads a research team at Harvard University dedicated to producing modified elephant cells with mammoth genes, gave a lecture at the American Association for the Advancement of Science congress held in Boston last week. At that conference, Church presented the latest results of her research that turned out to be more modest than published by some media. It was not the case of the British newspaper \u201cThe Guardian\u201d, according to which Church and her team of scientists are two years away from creating an embryo in which mammoth traits will be programmed into an Asian elephant with the aim of \u201cproducing an elephant-mammoth hybrid embryo\u201d, which \u201ccould occur in a couple of years.\u201d This does not agree with the impression created by other media, as according to what Church actually reported, we would still be far from seeing mammoths grazing in Siberia. In fact, Church and collaborators are not at this time worried about resurrecting the mammoth \u2013 extinguished about four thousand years ago \u2013 but about generating the hybrid embryo, which would be closer to that of an elephant than that of a mammoth. And once they had achieved this \u2013 if they ever did \u2013 the road to producing a mammoth-elephant hybrid would still be very long. According to John Hawks of the University of Wisconsin, who is skeptical of the Church project, a formidable problem to solve for the creation of a mammoth-elephant hybrid is that of the subrogated medium or matrix in which the embryo would develop until the end of gestation. One possibility would be the use of an Asian elephant but this is considered unlikely given that the species is in danger of extinction. According to \u201cThe Guardian\u201d, Church considers the possibility of employing an artificial matrix what Hawks considers to be a problem of difficult solution. Moreover, exaggeration in the media as to scientific news is not out of the ordinary. Indeed, since science has originated countless breakthroughs that have changed. In fact, Mars is far from hospitable. To begin with, it has an atmosphere in extreme tenue, it has a very high level of media appeal, such as that relating to the resuscitation of mammoths. A similar situation sometimes leads to overestimation of its real capabilities. Especially if it concerns issues of great media appeal such as the resuscitation of mammoths. A similar situation arises, for example, with regard to the voyages to Mars, which is the planet of the solar system more similar to ours and which is why it attracts much attention. Mars has been a source of speculation about the possibility of its being inhabited. In the 19th century, for example, the Italian astronomer Giovanni Schaparelli observed lines on the surface of Mars that others later interpreted as irrigation channels built by a Martian civilization. Although it was later made clear that these lines were nothing but an optical illusion, Mars continued to be the subject of novels and films. In this context, it is not surprising that there exists a society, \u201cThe Mars Society\u201d, whose objectives are to \u201cEncourage the exploration and colonization of the red planet\u201d, although these objectives represent considerable difficulties. and without any gas that we can breathe, what would force us to live permanently within hermetically closed buildings with artificial atmosphere; or, if we are to go out, to be buried in a cumbersome astronaut suit. But perhaps what would give us the most problem would be the high-energy radiations coming from the Sun and interstellar space that could kill us and from which we would not have protection. We would not thus expect manned travel to Mars in the foreseeable future. And despite this many times in the media such trips appear as something within our reach. With regard to the latter, on 13 February, the newspaper Excelsior headed a note in the following way with reference to a Mexican student: \u201cAt just 20 years old, Yair Pi\u00f1a was chosen by NASA to be part of the story as he was part of the 180th crew to go to Mars; he enlists his journey from the Utah desert.\u201d A quick search on the Internet tells us that training to travel to Mars will take place at the \u201cMars Desert Research Station\u201d located in the southern state of Utah in the The training camp has a certain similarity to what the future colonizers of Mars would find. Except, however, that in Utah you can breathe unlike Mars. And, most importantly, without deadly high-energy radiations. Something like a theme park about Mars without the inconveniences of the real planet.And as for mammoths grazing in Siberia, it seems that we would have to settle for a theme park as soon as possible.And all this should perhaps be reflected by the media.",
    "https://upload.wikimedia.org/wikipedia/commons/1/11/Ammonia-2D-dimensions.png": "As Aristotle maintained, some insects are generated spontaneously from dew, just as some fish and worms do from the mud and rotting meat, respectively. Aristotle\u2019s having held these kinds of opinions is not surprising if we remember that, according to Bertrand Russell, the Greek philosopher also had the belief that women have less teeth than men, without it having occurred to him to prove it by telling either of his two wives. Aristotle had a considerable influence on European thinking over almost two millennia. Not everyone, however, was convinced of the spontaneous generation of living beings. Thus, we can read in Wikipedia that Francisco Redi, an Italian physician and naturalist of the seventeenth century, conducted a couple of simple experiments to refute it. In a first experiment, Redi placed pieces of meat in two jars, one sealed it hermetically to prevent the passage of flies and the other left it open. In the case of the open jar, worms were generated. Thinking that perhaps the result was that the air of the environment did not enter into the closed jar, in a second experiment he placed a piece of meat in a jar that covered with a gauze. The result was that the meat rotted without generating worms, and that the flies, having not been able to reach the meat, had laid their eggs on the gauze. Redi's experiments showed that the worms were born, not by spontaneous generation, but from the eggs of the flies. Not everyone was convinced, however, and touched Luis Pasteur, until the nineteenth century, to bury the idea of spontaneous generation. Although not entirely, however, since the worms of the putrefacted meat turned out to be larvae of fly, it is necessary to wonder how it was that the primigenous fly and its larva was generated. Of course, after Darwin it became clear that the species did not remain immutable in time but that they are in continuous evolution. And in this regard, without invoking a divine creation, the most reasonable hypothesis is that life was generated spontaneously from inanimate matter, following the laws of physics and chemistry, and once the right environmental conditions were given.The results of an experiment carried out in 1953 by Stanley Miller and Harold Urey at the University of Chicago point in this direction.As part of the experiment, Miller and Urey tried to reproduce the environmental conditions of the earth billions of years ago when life would have originated. For this, they mixed water, methane, ammonia, carbon dioxide, nitrogen and water, and subjected the mixture to 60,000 volts electric discharges. As a result, if they did not obtain living matter, if they managed to synthesize amino acids and other organic compounds associated with it. Specialists, on the other hand, also contemplate the possibility that life has originated somewhere else in the solar system and not necessarily on earth, and has been brought up to date. This possibility, of course, does not solve the unknowns about the origin of life, but if it increases the chances that the necessary conditions for its appearance have been given somewhere in the solar system. In relation to this last point, this week\u2019s issue of the magazine \u201cScience\u201d published an article in which results are reported that suggest that in the dwarf planet Ceres, which is located in the belt of asteroids between the orbits of Mars and Jupiter, could count on the conditions conducive to the existence of life. The article was published by an international group of researchers headed by Maria Cristina De Sanctis of the National Institute of Astrophysics, in Rome, Italy. Sanctis and collaborators studied data obtained by the Dawn probe, which is currently in orbit around Ceres, and found the presence of organic matter in a region of about 1,000 square kilometers around the Ernutet crater of 50 kilometers of diameter. Based on the analyzed data and a study of the geology of the area, The researchers conclude that the discovered organic matter does not come from the impact of a meteorite but originates within the same planet. Although the fact of finding organic matter outside our planet is not in itself an extraordinary fact, since it has already been found in other bodies of the solar system, the discovery of De Sanctis and collaborators is relevant, because Ceres has other elements that are indispensable to life. According to Simone Marchi, one of the authors of the reference article, \u201cCeres has evidence of hydrated minerals of ammonia, frozen water, carbonates, salts and now organic materials. With this new discovery, Dawn has shown that Ceres contains the key ingredients for life.\u201d And so, after all, it turns out that spontaneous generation does exist.",
    "https://upload.wikimedia.org/wikipedia/commons/b/bb/Conan_doyle.jpg": "Perhaps the pterodactyls are not as famous or call as much attention as the tyrants or the Brontosaurus, which are among the favorites of the children, but they certainly do not fail to have their charm. Thus, they have, for example, a prominent appearance in Arthur Conan Doyle\u2019s novel \u201cThe Lost World\u201d \u2013 creator of Sherlock Holmes\u2013 published in 1912. They appear also, although perhaps with a less prominent role, in the homonymous film of silent cinema, based on that novel and premiered in 1925. In his novel, Conan Doyle describes an expedition led by a professor Challenger to a lost plateau in the Amazon jungle, in which dinosaurs and other extinct animals had supposedly survived long ago. This included pterodactyls with wings six meters long. In a passage of that novel, when explorers approached a nest with pterodactyl offspring, they were attacked by a flock of adult specimens saving for a short time. The description of the novelist, of the nest emanated \u201ca horrible, mephitic and rancid stench that made us nauseous\u201d, at the same time that the ferocious males, \u201cstopped each one in his own rock, absolutely immobile except for the rolling of his red eyes\u201d, seemed more like \u201cdead and dissected examples than life-filled beings.\u201d Then, the pterodactyls began to fly in increasingly closed circles over the explorers ending up attacking them. But it was towards the end of the novel Conan Doyle granted the pterodactyls a star performance. This developed at the London Institute of Zoology, when, before an incredulous audience of their findings in the Amazon rainforest, Challenger theatrically released a pterodactyl offspring that they had managed to carry there. With such bad luck, however, that the calf managed to escape through a window of the enclosure by losing itself forever.The royal pterodactyls, however, did not have the enormous size that Conan Doyle attributed to them. On the contrary, according to Wikipedia, they did not go beyond measuring a meter and a half with open wings. This is not the case, on the other hand, of the Azd\u00e1rquids, relatives of the pterodactyls and also flying reptiles.This is particularly true of the so-called Hatzegopteryx, whose fossil remains were originally discovered in 1991.According to paleontologist Mark Witton of the University of Portsmouth in the United Kingdom, these animals reached a span of ten to twelve metres \u2013 which is equivalent to the size of a Cessna aircraft \u2013 and a weight of 220 kilograms.According to Witton, Hatzegopteryx lived towards the end of the Cretaceous period \u2013 which began 145 million years ago and ended 66 million years ago \u2013 on Hateg Island, in what is now Romania.During the Cretaceous period, Hateg Island was separated from the rest of Europe by deep waters and in these conditions the fauna itself evolved in isolation. At the same time, the lack of predators would have allowed the Hatzegopteryx to evolve to gigantic proportions. In an article that appeared the week that ends today in the magazine \u201cPeerJ\u201d, Mark Witton and Darrel Naish of the University of Southampton in the United Kingdom, they guess that, unlike other giant azdarchids, of 4-5 meters high and neck close to the three meters long but relatively thin, the Hatzegopteryx would have had a neck of only one meter and a half long but much more muscular. This would have allowed them to exert a force with the jaws considerably greater than that which their most slender relatives could have exercised. Thus, the researchers conclude that the Hatzegopteryx were remarkably well endowed for the larger hunt and, in fact, would have been the biggest predators of the island of Hateg. Surely it would have been terrifying to attack us by a flying reptile of several meters high, more than 200 kilograms of And to be consistent with this, we must also give Conan Doyle the appropriate credit. Although, thinking about it, we may have to wait a little while for more fossil discoveries of Hatzegopteryx, because to conclude that this was such a formidable predator, Naish and Witton leaned only on a single vertebrae of the animal's neck, the only one that has been discovered so far.",
    "https://upload.wikimedia.org/wikipedia/commons/4/4a/Plato-raphael.jpg": "When Moctezuma Xocoyotzin sent a group of messengers loaded with numerous present to welcome the strangers who arrived by sea on the coast of Veracruz, he did so in response to a bad diagnosis of the situation. This bad diagnosis was the result of the magical conception of the world that the Mexica had. Indeed, based on a series of fatal omens, derived from events that occurred before the arrival of the Spaniards, Moctezuma came to the conclusion that the newcomers were gods. Specifically, he believed that he was facing the expected return of Quetzalcoatl; a belief that we know was completely wrong. The erroneous diagnosis of the problem did not help Moctezuma respond to the challenge he faced in the most effective way possible and all the measures that he had taken to stop the Spanish from moving towards Tenochtitl\u00e1n proved fruitless. In particular, the present ones that brought them to welcome them, far from pleasing them increased their greed and their desire to advance into the territory. A good diagnosis at the time of trying to solve a problem; or, putting it in other terms, of the importance of accurately understanding a situation in order to try to predict its future evolution and influence it. And for this it is necessary to strip ourselves of magical conceptions of the world \u2013like those that contributed to the fall of Moctezuma and the Aztec Empire \u2013, replacing them with a scientific conception of the same.On the other hand, even renouncing soothsayers, necromancers and shamans, the prediction of the future is not guaranteed and the degree to which we can achieve it depends on the complexity we face. Thus, it is easier to predict the trajectory of a bullet fired with a certain direction and speed, than to predict the type of change that our currency will have at the end of 2017. Putting it in terms of scientific disciplines: it is easier to predict events in the area of physics than in the area of the economy and in general of the social sciences. We have thus, while physics is a science that has remarkable predictive power, and has allowed by the same thing from gently landing probes on the surface of Mars to the surface of Mars. To build computers, the social sciences are more modest in this sense because their subjects of study are considerably more complex than those of physics. Among the experts, however, there is the conviction that in the not too distant future, using new techniques of analysis and information accumulated on the Internet, it will be possible to reverse this situation. In relation to the above, a special section of this week\u2019s issue of the magazine \u201cScience\u201d is published a series of articles discussing the science of prediction and the current and future possibility of predicting the occurrence of social events of the most diverse nature. These include the outcome of elections, the development of violent political conflicts, and the emergence of transcendent scientific discoveries. In particular, an article written by researchers from the Universities of Pennsylvania and Harvard in the United States headed by Phillip Tetlock, discusses the use of collective wisdom to predict future events. This is done through tournaments in which participants make predictions about the future occurrence of events in a wide variety of economic and geopolitical topics. Participants must give numerical answers to questions. These participants also have defined profiles, including a more open mind to consider their personal opinions as \u201ca hypothesis to put to the test and not a sacred possession.\u201d They also tend to think of the exercise of prediction as a skill that can be cultivated. The best predictors, moreover, tend to have advanced professional degrees and a general knowledge of politics. Although the science of prediction still has a lot of field ahead of them, we certainly have today better tools to analyze situations of a social nature than those that Moctezuma had at the time to evaluate the predicament in which he put it the arrival of the Spanish conquerors. Although, moreover, a greater understanding of their situation probably in the long run of nothing would have served him by the military superiority of the invaders.",
    "https://upload.wikimedia.org/wikipedia/commons/1/1a/Gran_muralla_badalig_agosto_2004JPG.jpg": "If it is a question of dividing walls, the most notable example is perhaps that of the Great Wall of China. It was during the Ming dynasty, which ruled China between the years 1368 and 1644, when the Great Wall was built as we now know it. It is known, however, that it was preceded by other walls of different extensions, which in some cases date back to the third century B.C.E. The versions that preceded the Great Wall were built with stony land or other relatively undurable materials; this, in contrast to the Great Wall of the Ming Dynasty, in which stone and brick were used. Although the purpose of the Great Wall was to defend the empire before the onslaught of the northern nomadic tribes, China was invaded and conquered by the Manchus in the seventeenth century \u2013 earlier, by the Mongols in the thirteenth century \u2013 which had established a dynasty that prevailed until the twentieth century. Thus, the Great Wall, although it was seen by the Manchus in the seventeenth century \u2013 had been by the Mongols \u2013 and had been by the Mongols \u2013 who established a dynasty that prevailed until the twentieth century. It is a solid, impressive and eye-catching construction \u2013 far more eye-catching than the \u201cimpenetrable, physical, high, powerful and beautiful\u201d wall, which is planned to be built on the northern border of our country \u2013 as a defense for the Chinese empire. According to historians, moreover, the Great Wall not only did not resist the military onslaughts of the barbarians of the north, but even in less violent times, far from impenetrable, it was considerably porous. Thus, it seems that soldiers of the garrisons guarding the northern border of China \u2013 which were in considerable isolation and even had to seek for themselves what was necessary to survive \u2013 maintained contact and made friendly deals with the barbarians, their supposed enemies, on the other side of the wall. On the other hand, what is porous in some cases is not so much so in others. Thus, the Great Wall, by establishing a physical barrier between two geographical areas, hindered the genetic flow between populations of plants with habitats isolated by that barrier. An article published in 2003 in the magazine \u201cHeredity\u201d by a group of researchers from the University of Pekin in China, headed by H. Gu. Gu and collaborators studied plant species found in the vicinity of the Great Wall in its section of Juyongguan, about 60-70 kilometers north of Beijing, and found that the wall affected the evolution of plants living in its surroundings. For their study, Gu and collaborators collected, in two places near the wall and on both sides of it, six plant species. At the collection points the wall has a height of 6 meters and a width of 5.8 meters on average. As control samples, they also collected five plant species on both sides of a road in a site far from the wall. At the end of their research, Gu and collaborators found a significant difference between plants of the same species living on one side and another of the wall, which was greater than that found among control samples. For those who are pollinated by the wind. Thus, the height of the wall would be a more severe obstacle for insects, who would have to fly above it, than for the strong winds that blow in Juyongguan. And for animals that do not fly, of course, a physical barrier of six meters or more of height is even more severe and in this there are many criticisms that have been made of the wall that would be built all along the border between Mexico and the United States. In particular, it is alerted to the loss of genetic diversity in animal species by the interruption of the flow of genes across the border, as happened to plants divided by the Great Wall in Juyongguan. A physical obstacle, in addition, restricts the flow of animals and can prevent access to sources of water and food, as well as to their migration routes. According to the Fish and Wildlife Service of the United States, the construction of the border wall \u2013which would have a height between 10 and 20 meters \u2013 would negatively impact 111 species in danger. Animals have little resources to defend themselves from an aggression to their habitat such as the construction of the wall of marras \u2013 or more precisely, its completion, because it is already partially constructed. It is not necessarily the case of us humans, who in one way or another would possibly manage to become porous a wall supposedly impenetrable. And in case of doubt, please consult with the Chinese.",
    "https://upload.wikimedia.org/wikipedia/commons/7/73/Hydraulic_Fracturing-Related_Activities.jpg": "On the website of the new U.S. federal administration, under the heading \u201cA Energy Plan for America First,\u201d it is stated that the incoming U.S. president is committed to \u201celiminating harmful and unnecessary policies, such as the US Climate and Water Action Plan.\u201d This plan establishes policies to tackle global warming with less polluting energy sources from the environment and to bring the country towards a sustainable energy future. In contrast, the document of the new U.S. administration favours the use of fossil fuels, taking advantage of the vast reserves of gas and shale oil existing in the U.S. territory, and no mention is made of clean energy such as solar or wind. It has not been surprising that the change in U.S. energy policy has been known in advance that the new president is not a believer in the existence of a cause-effect relationship between global warming and the use of fossil fuels. This, however, is what an overwhelming majority of climate scientists accept, who argue that the evidence supporting this relationship is very strong. The atmosphere of carbon dioxide \u2013 the main cause of global warming \u2013 shows seasonal oscillations, the annual average of this increase is gradual and each year establishes a new brand. Thus, according to the Mauna Loa Observatory in Hawaii, operated by the National Oceanic and Atmospheric Administration of the United States, the concentration of carbon dioxide in the atmosphere reached an average value of approximately 405 parts per million last December, representing an increase of almost 1% over the level measured a year earlier. Concurrently, according to the same source, 2016 has been the warmest year since statistics were taken. And even with this background evidence, the new US administration does not include at the outset a plan for the development of clean sources of energy, which will necessarily have to prevail in the long term if we are to mitigate and overcome climate change. We must also consider that the techniques used for the exploitation of shale gas and oil \u2013 like the one in the North American subsoil \u2013 are a cause of many disputes. The extent to which oil and gas deposits have been depleted in some parts of the world has had to resort to deposits with an increasing degree of difficulty in their exploitation, and in this context sophisticated extraction techniques have had to be developed. In particular, the technique of hydraulic fracturing, or \u201cfracking\u201d, was developed for the exploitation of shale deposits, as it is known in English. Hydraulic fracturing is applied to deposits in which oil or natural gas are housed in low porosity rocks, which makes it difficult or impossible to flow to the surface. In these conditions, for the exploitation of such deposits a vertical perforation is made until the deposit is reached and then prolonged with horizontal perforation. Water is then injected under pressure, in combination with some chemical agents and sand, in order to fracture the rock of the deposit and in this way release the gas or oil trapped in it. Although the technique of hydraulic fractation has virtues since it allows the exploitation of deposits that are inaccessible with conventional techniques, it is also the object of great controversy due to the possible contamination of the mantles. aquifers \u2013 which are less deep than shale deposits \u2013 by the fluids injected into the well that eventually return to the surface. Additionally, during the exploitation of a shale deposit methane gas \u2013 the main component of natural gas \u2013 is leaked into the atmosphere and it is known that methane is a greenhouse gas that is many times more powerful than carbon dioxide. Thus, the use of gas and shale oil has to be evaluated in the light of possible methane leaks into the atmosphere. The uncontrolled consumption of energy that we have carried out over the past two centuries has led to a deep conflict with the planet. To overcome this, we must carry out a process of replacing fossil fuels with clean sources of energy, a process that will be slow due to need. The more we delay in developing these sources, however, our conflict with the planet will take longer to be overcome. Perhaps it is worth finishing this article with a quote from former President Obama, with which he opens the document \u201cClimate Action Plan\u201d: \u201cIt is our conviction that our obligations as Americans will not be overcome. We will respond to the threat of climate change knowing that if we fail we will betray our children and future generations. Some can still deny the overwhelming judgment of science, but no one can avoid the devastating impact of a raging fire, devastating drought or a powerful storm.\u201d",
    "https://upload.wikimedia.org/wikipedia/commons/d/d5/Conquistador_espa%C3%B1ol.JPG": "An article published by the BBC a couple of years ago states that \u201cFor thousands of years humans have taken the masochistic pleasure of adding chili to food.\u201d In Mexico, where we put chili even in sweets, we would not consider that it is masochistic to season with chili foods. It should be recognized, however, that the reference article is to some extent right, because the taste for spicy varies greatly from person to person, and a very spicy meal that is pleasant to some, could be intolerable to others.Anyhow, there are itchings to itchings and, certainly, there are levels of capsaicin \u2013 the chemical compound that gives the characteristic flavor to chili\u2013 that no one can tolerate. So much so that this compound is the active ingredient of aerosols used to disperse crowds, which irritates the eyes and can cause temporary blindness. Chile, which is assumed to be native to Mexico, has been among us for many thousands of years. The effect of chili fumes on the child\u2019s eyes is evident in the drawing. It was the Spanish conquerors who took the chili to Europe face down and from there it would have arrived in Asia, where it was incorporated into the different regional cuisines. Moreover, with great enthusiasm, so much so that in Asia the use of chili as a condiment can be even more generous than in Mexico. Thus, it is not surprising that it is China and India, the two most populous countries on the planet, the world\u2019s leading chili producers. China\u2019s production is so great and competitive in price, that a large proportion of the chili sold in Mexico is imported precisely from China. It has thus a positive side, if used sparingly, as negative, for its toxic properties. And the good news is such that on the positive side the advantages go beyond its use as a condiment to give flavor to food. At least this is what is stated in a published article. This week in the online magazine Plos One by Mustafa Chopan and Benjamin Littenberg of the University of Vermont in the United States. These researchers carried out a study over 23 years with more than 16,000 volunteers in that country and found that daily consumption of chili decreased by 13% the probability of dying for any cause.The finding of Chopan and Littenberg agrees with an article published in 2015 in the British Medical Journal by a group of researchers from China and the United States, headed by Jun Lv of the University of Beijing.This article reported the results of a study carried out with more than half a million people from 10 regions of China, recruited between 2004-2008.The aim of that study was to determine the effect that the consumption of chili seasoned food has on life expectancy.Like in the research of Chopan and Littenberg, Jun Lv and collaborators found that those who consumed chili almost every day of the week had at the end of the study a 14 percent less chance of dying for any cause, compared to those who declared The same inverse relationship between chile consumption and mortality is observed if they are considered as particular causes of death, such as cancer, heart disease or respiratory diseases, and is stronger among those who do not consume alcohol than among those who do.The results are also valid for both men and women.From their origin in Mexico, chile expanded, first to the American continent and then to the entire planet following the Spanish conquest of the New World.In addition to its use as a food conservative and as a condiment to improve the flavor of the same \u2013 or to mask it in the event that they had broken down \u2013 chile was attributed medicinal effects.The latter is in agreement with the findings of Chopan and Littenberg, and Jun Lv and collaborators.So, it seems that when chile is applied that which little poison does not kill. And on the contrary, it can even be healthy.",
    "https://upload.wikimedia.org/wikipedia/commons/0/0c/CountriesByGDPPerCapitaNominal2018.png": "A look at the world map shows us that, although not exclusively, countries with high per capita incomes tend to be located in cold regions of the planet. This is the case, for example, of countries in northern Europe such as Norway, Sweden and Germany. At the other extreme, the poorest countries are systematically located on the African continent, where average temperatures are substantially higher than those in northern Europe. Is there a cause-effect relationship between climate and economic and social development? This hypothetical relationship, which corresponds to what is known as climate determinism or geographical determinism, has had advocates throughout history, some in good faith and others not necessarily disinterested. Thus, by way of example, geographical determinism was very useful at the end of the nineteenth century to justify the colonization by Europeans of those parts of the planet inhabited by races and civilizations that they considered inferior because of their unfavourable geographical situation.The theses on the influence of climate on the development of civilizations have survived until our days and are of interest to some specialists in the matter that they use. In contrast to the biased views of colonial Europeans a century ago, an article published in the journal \u201cNature\u201d in October 2015 by Marshall Burke of Stanford University, and Solomon Hsiang, and Edward Miguel of the University of California at Berkeley, concludes that environmental temperature is a factor that is directly related to the economic productivity of a country. Climate can thus be regarded as a \u201cnatural capital\u201d, analogous to physical capital and human capital. Researchers came to this conclusion by studying the economic performance of 166 countries between the years 1960-2010 and correlated it with the environmental temperature variations that each country experienced at random over the time of study. No comparisons were made between countries, but that each country compared itself at intervals of two years. Thus, the economic productivity of the 166 countries studied over each two-year period was determined, depending on the average environmental temperature to which they were exposed in those periods.Burke and collaborators found that such economic productivity is maximum for an ambient temperature of 13 years. Under this temperature, economic productivity decreases, and the same thing happens, in an accelerated manner, above it. Why does economic productivity depend on ambient temperature? According to Burke and collaborators, some factors that affect economic productivity are dependent on this temperature. Among these, agricultural productivity and productivity of workers can decrease to higher temperatures. Additionally, high temperatures promote diseases and violent behaviors that can affect productivity, according to researchers. All of this acquires greater relevance in the conditions of climate change and global warming that the planet is going through. According to Burke and collaborators, this change will affect the countries of the world differently. Those who currently have average environmental temperatures below 13 degrees Celsius will increase their economic productivity as global warming advances. In contrast, countries whose average temperature is already above 13 degrees Celsius will see their productivity diminished in the future. Researchers estimate that, given the current trends in global warming, the world\u2019s economic productivity will decrease by 23% in 2100, with If Burke and his colleagues were right, and given that rich countries tend to have lower average environmental temperatures than poor countries today, climate change will lead to greater inequality between the developed and underdeveloped world. Thus, while Norway would have an increase in its gross domestic product (GDP) per capita of 250 per cent in 2100, Nigeria would see a 90 per cent decline in that same year. Mexico will be on the side of the losing countries and its per capita GDP would be reduced by 73 per cent. Thus, global warming, which we would think was democratic and affected all countries equally, would not be so much and would be taught to poor countries that are the least to blame for climate change. That is, and as is often the case, the thinst dog would be burdened with fleas.",
    "https://upload.wikimedia.org/wikipedia/commons/1/16/Central_t%C3%A9rmica%2C_Escatr%C3%B3n%2C_Zaragoza%2C_Espa%C3%B1a%2C_2015-12-23%2C_DD_35.JPG": "Just as the 20th century was the century of the incandescent lamp, so the 21st century will surely be the LED lamp. Indeed, even though the cost of LED lamps is still relatively high, they are becoming increasingly popular and are gradually replacing the incandescent spotlights and fluorescent lamps as sources of light. Given the multiple advantages of LEDs, this replacement is expected to be virtually total in the coming decades. Indeed, a report released last September by the United States Department of Energy predicts that by 2035 99% of the luminaires on the roads and public places of that country will consist of LED sources. As for residential applications, although in this area the penetration of LEDs will be relatively slow, the reference report forecasts that in 2035 90% of the light sources of American homes will be LED lamps. Incandescent lamps are particularly inefficient devices, which convert into light energy just 5% of all the energy they consume, transforming the remaining 95% into heat. In the first half of the 20th century, when neither the energy crisis nor the climate change had been declared, the inefficient incandescent lamps were of no greater concern.In particular, the new crisis conditions generated initiatives to improve the efficiency of lighting devices, which employ 15% of all the electrical energy generated in the United States. One development in this direction is compact fluorescent lamps \u2013 which are now widely used \u2013 that are several times more efficient than incandescent lamps. However, fluorescent lamps are potentially polluting of the environment and their disposal at the end of their useful life must be done with appropriate precautions. Fortunately, LEDs have advantages both over incandescent bulbs and over fluorescent lamps. On the one hand, they are 6 to 10 times more efficient than incandescent sources. On the other hand, compared to fluorescent lamps, they are more efficient and do not present the problem of mercury contamination. In addition to the above, LEDs are compact, resistant and have a longer useful life. However, LEDs are not exempt from criticism. By way of example, according to information in the media on 29 December, a programme to replace 270,000 sodium lamps with LED lamps in the streets of the city of Chicago has been the subject of discussions by those who consider that the brilliance of LED lamps is visually annoying and demand that they be equipped with screens to avoid glare. With regard to the latter, it should be noted that LEDs that emit white light do so by mixing colors and that the resulting light has an appearance that depends on the proportion of blue light that enters into that mixture. Thus, if this proportion is high, a \u201ccold\u201d light will be obtained and otherwise a \u201cwarm\u201d light. On the other hand, there is scientific evidence that associates a high content of blue light in artificial lighting with some health problems, including sleep disturbances, and it is in this context that the critics of LED lamps to be installed in Chicago demand that they have a low proportion of blue light. Such, however, it seems that the virtues of LED lamps more than compensate for their defects and it is not surprising that experts consider that LEDs will be the sources of light that will illuminate us in the decades to come. Not to be ruled out, of course, their replacement by technologically more sophisticated light sources, with even higher luminous efficiencies. Efficis, certainly, that would be more and more distant than those of the incandescent lamps, which flourished in the light. a time of abundant fossil fuels and little concern for the environment.",
    "https://upload.wikimedia.org/wikipedia/commons/4/4f/Paul_Gauguin_111.jpg": "On December 14, New York\u2019s Christie\u2019s house raised a $3.7 million copy of Isaac Newton\u2019s first edition of the book \u201cPrincipia Mathematica\u201d published in 1687. With this, \u201cPrincipia Mathematica\u201d became the most expensive printed scientific work. Edmund Halley, the discoverer of the comet of the same name, encouraged Newton to compile in a book his ideas about the causes of the movement. Halley even paid for the costs of publishing Newton\u2019s book, given that the Royal Society \u2013 which had committed itself to doing it \u2013 was left without funds after paying for the publication of John Ray\u2019s and Francis Willughby\u2019s \u201cFish History\u201d book. Ray\u2019s and Willughby\u2019s book, which contains numerous detailed images of fish and for the same reason had high publishing costs, did not sell well and resulted in an economic failure for the Royal Society. Thus, this scientific society \u2013 the first in history \u2013 was deprived of publishing what is considered the most influential scientific context of the Royal Society. In his work \u201cPrincipia Mathematica\u201d, Newton first enunciates his famous three laws of movement and then uses them to explain the movement of the planets. His theory has proved so successful that even today, more than three hundred years after it was enunciated, it is taught in physics courses, both elementary in the preparatory school, and advanced in the university. Another measure of Newton\u2019s success on the causes of movement is given to us by the fact that they are used to calculate the impulses and trajectories necessary to send ships into space, including the ships destined to other planets in the Solar system. To be able to insert, for example, a satellite into an orbit around Saturn is not a simple task and, in fact, would be impossible without Isaac Newton\u2019s ideas. Apart from formulating a theory about the movement of the material bodies using mathematics developed by him and to use it to explain the paths of the planets \u2013with what gave rise to the discipline of physics as we know it today\u2013, Isaac Newton radically modified our conception of the Universe by postulating the universality of his theory, which would apply so much to earthly objects. According to Newton, the objects we see in the firmament follow the same laws as the objects on Earth and the behavior of the former can therefore be understood by studying the latter.Physics, driven by Isaac Newton with his \u201cPrincipia Mathematica\u201d served as a model for the development of other sciences that have produced technologies that have radically changed our way of life, particularly in the last hundred years.In this context, we might understand that a copy of the first edition of \u201cPrincipia Mathematica\u201d has reached a price of 3.7 million dollars at auction. Actually, thinking twice, this amount is too low if we compare it with the prices that have reached among collectors other books that have been far from having the transcendence of the \u201cPrincipia Mathematica\u201d. Thus, by consulting Wikipedia we find that the printed book that has reached the highest cost of sale is \u201cBayPsalm Book\u201d, published in 1640 in the United States. This book, which was the first published in that country, reached an auction price of 14.2 In Wikipedia we also learn that the written work that has reached the highest selling price is the \u201cLeicester Codex\u201d, which is a compilation of drawings and manuscript texts by Leonardo da Vinci. The Leicester Codex was acquired by Bill Gates in 1994 in 30.8 million dollars \u201349.3 million dollars adjusted for inflation. The pictorial work, on the other hand, can reach even higher selling prices. Thus, paintings painted by Gaugin, C\u00e9zanne, Modigliani, Picasso and van Gogh, among others, have been sold at prices ranging from 150 million dollars to 300 million dollars today; that is, they have been sold at 40-80 times higher prices than the one that reached the copy of \u201cPrincipia Mathematica\u201d auctioned on December 14. The price that a collector is willing to pay for a work produced by the human intellect depends on subjective factors and the rarity of the work. Thus, Paul Gauguin\u2019s painting \u201cWhen You Homes?\u201d was sold in December 14. 2015 in 300 million dollars compared to the 3.7 million dollars reached by the first edition of \u201cPrincipia Mathematica\u201d, of which it is estimated that some 150 copies have survived. Surely, the relative abundance of copies of the original edition of Newton\u2019s summit work influence its \u201clow\u201d auction price. Yet, possibly said low price is an indicator that we are not appreciating in its just dimension the formidable impact that Isaac Newton\u2019s work, and science in general, have had on our lives.",
    "https://upload.wikimedia.org/wikipedia/commons/6/66/Child_with_Smallpox_Bangladesh.jpg": "In his 1898 novel \u201cThe War of the Worlds\u201d, the British writer H.G. Wells describes how the invading Martians of the Earth were defeated by an unexpected enemy: the terrestrial microbes for which they were not immunized. In his novel, on the other hand,Wells did not consider the possibility that the Martians would have arrived with their own microbes, for which we surely would not have had defenses either.This would have resulted in a disaster and decimated the population of our planet.Although the scenario described by Wells is only fiction, it is not far from what can happen in a real situation when two populations that have evolved separately are mixed up. Thus, we have that the indigenous inhabitants of the New World were decimated by the infectious diseases that arrived with the Spanish conquerors and for which they did not have defenses.Although the experts do not agree on the fact that the indigenous population was affected by the infective agents of the Old World, we know that one of these, presumably the viruel, was a factor for the fall of Teno. In his book \u201cThe vision of the defeated\u201d, Miguel Le\u00f3n Portilla reproduces the description contained in the Florentine Codex about the infectious epidemic that broke out in Tenochtitlan prior to the siege by the Spaniards. According to the indigenous testimony: \u201c...first a great plague spread among us, a general illness... About us spread: great destroyer of people. Some well covered them, everywhere in his body spread. In his face, in his head, in his body.\u201d And the indigenous testimony continues: \u201cIt was very destructive disease. Many people died in it. No one could walk, no more lay lying on the bed. No one could move, no one could turn his neck, he could not make body movements; he could not lie down face; he could not lie down on his back, nor move from one side to another. And when they moved something, they screamed. Many died the sticky, harsh disease of grains.\u201d This article was published by an international team of researchers led by Ana Duggande at McMaster University in Ontario, Canada, and concludes that smallpox originated in a relatively recent period, some 400 years ago, suggesting that this virus was not the cause of the epidemic in Tenochtitlan. Duggan and collaborators base their conclusions on a study of the DNA of the mummy of a child, aged between two and four years, found in the Church of the Holy Spirit in Vilnius, Lithuania. The mummy was dated with radioactive coal between the years 1643-1665. well the original purpose of the research did not focus on the smallpox virus \u2013 mummy does not show any evidence of the scars characteristic of this disease \u2013 to the surprise of the specialists, the DNA analysis of the mummy revealed the presence of this virus.In these circumstances, the researchers compared the DNA of the smallpox virus found in the mummy with that of the modern strains and found that they are closely related.A comparison of the differences observed allows finding its evolution in time and determining when they had a common ancestor.They found that this occurred between the years 1588 and 1645, which is consistent with the epidemics of this disease that occurred in Europe during the seventeenth century.If Duggan and collaborators were right, the epidemic that struck Tenochtitlan would have to be caused by an infectious agent different from the smallpox and the same could be said of other even older epidemics that might have been due to this virus.The older solid evidence of the presence of the smallpox, however, is precisely the According to the specialists, more studies are necessary to have greater certainty about the evolutionary history of smallpox, and as a first step we must confirm the results of Duggan and collaborators. This is important, because although smallpox is now eradicated, the more we know about it, the more we can defend ourselves in case it appears again on the scene.In contrast, for the Aztecs, who lived several hundred years before we could have a moderately effective management of disease, little would have been important to know if what they were suffering was a smallpox attack or some other unknown identity virus.",
    "https://upload.wikimedia.org/wikipedia/commons/c/cf/Storck_Harbour_scene.jpg": "The president-elect of the United States announced in previous days that he had managed to convince the United Technologies company not to move forward with his plans to move an air conditioning equipment manufacturing plant from Indiana to Mexico. Although the actual number of jobs involved is confusing, this would have saved around 1,000 jobs in the United States \u2013 same as they would have been lost in Mexico. As we know, this goes according to one of the campaign flags of the President-elect who promised to reverse the process of losing jobs in the United States due to the migration of American factories to our country. The North American free trade agreement has led to an exodus of U.S. companies seeking to take advantage of the low salaries paid in Mexico, a circumstance that has turned us into the twelfth export economy in the world. At the same time, however, it has placed us in a vulnerable situation with respect to the United States, as the current situation makes it evident to us; moreover, bearing in mind that more than seventy percent of our exports are to that country. Foreign investment in Mexico has brought high-technology manufacturing plants. , which has led Mexican products to achieve a high degree of sophistication. A measure of this is given by the economic complexity index (ICE) developed by a group of researchers from the Massachusetts Institute of Technology and Harvard University, headed by Ricardo Hausmann and C\u00e9sar Hidalgo. The ICE measures the sophistication and diversity of products manufactured by a country according to the amount of knowledge needed to manufacture them.According to ICE, Mexico occupied the twenty-second place of economic complexity in the world in 2014, surpassing, among others, Canada, Brazil and Argentina in the American continent. Our country's ICE, moreover, has grown about 30 percent over the last two decades, according to the Atlas of Economic Complexity published by Harvard University. Hausmann and Hidalgo find that the position in the ICE is directly related to the degree of development of a country and to the per capita income of its inhabitants. Thus, at the top of the ICE list are, Japan, Germany and Switzerland, which have equal per capita income. Mexico, with a per capita income close to $8,000 a year, is an exception. This could perhaps be a reflection of the fact that the technologies contained in the products manufactured in Mexico by foreign companies were not developed herein in their places of origin.The specialists assume, however, that the high degree of economic complexity of our country constitutes a breeding ground for accelerated economic development.For this, in any case, we will have to develop capacities to absorb the technologies that foreign investments are bringing to our country, and at the same time develop the capacities necessary to generate their own technologies.As Hausmann and Hidalgo put it, the development of greater economic complexity faces the dilemma of egg and chicken.That is to say, progress is being made towards a more complex economy by developing products in which knowledge and capacities from multiple sources have been integrated.In a given case, not all the capabilities necessary for the manufacture of a certain product could be counted, and at the same time, since there is no industry that manufactures it, there would not be the incentives to develop the missing capacities, especially in a given case. Under these conditions, the strategy would be to create new products based on existing capacities, through the development of a single and new complementary capacity.A fundamental component of the strategy would be the drive of our university education system \u2013 particularly at the postgraduate level and in contrast to a purely technical education \u2013 in areas related to the already established productive plant.Our university research and education centres must develop and already accumulate scientific and technological knowledge, as well as to educate specialists in strategic areas.And they must do so without neglecting the training of professionals demanded by the productive plant.A greater economic complexity based on their own technological resources \u2013 according to our situation as the twelfth exporter of the world \u2013 would certainly be useful to mitigate situations of distress such as those we are going through now, caused by our excessive dependence on the outside.",
    "https://upload.wikimedia.org/wikipedia/commons/a/a8/Beagle_2_replica.jpg": "In the week that ends today, it was confirmed that the end of the European Beagle 2 probe, sent to explore the surface of Mars more than ten years ago, was not as violent as it was thought.As planned, the Beagle 2 probe was released from the mother ship Mars Express \u2013 in orbit around Mars \u2013 on December 19, 2003 towards the Martian surface, on which it was to lie softly two days later. Once it arrived at its destination, the Beagle 2 \u2013 which was shaped like a pocket watch of 1 meter in diameter and 33 kg in weight \u2013 should have opened as a pocket watch and deployed its scientific instruments and its communication antenna, as well as the solar panels that would give it energy. After it was released from Mars Express, however, nothing more was known about the Beagle 2 that it was not communicated with the orbital as expected when it arrived at the Martian surface. The mystery about the fate of the Beagle 2 began to be clarified when NASA released in January 2015 high-resolution images taken by the satelliteMarsReconnaissanceOrbiter \u2013 in orbit around Mars since 2006\u2013 in which the Beagle 2 is apparently shown at its landing site.Although the images see the probe only as a bright spot in which some details are hardly distinguished \u2013 including the profile of what would presumably be one or two of its solar panels\u2013such images give an indication that the Beagle 2 would have survived the descent.All this was confirmed and expanded by a study released this week by the press department of the University ofLeicesteren Great Britain. The study was carried out by a group of specialists from the universities ofLeicestery De Montfort, who studied the images of the Beagle 2 provided by NASA using an innovative imaging analysis technique. Their conclusions are that the Beagle 2 probe landed without damage to the surface of Mars and was even able to deploy the largest part of its solar panels. The reason why the probe did not establish communication once on the surface of Mars is not clear, but one possibility in this respect is that one of the solar panels has prevented the correct deployment of the communication antenna.On the other hand, the European probeSchiaparelli, who tried to land on the surface of Mars on 19 October, did not have the same fate as the Beagle 2 \u2013 if it could be called luck to what was experienced by the latter\u2013 and suffered when landing a collision followed by an explosion that completely destroyed it.This is evident, according to specialists, of images provided by the MarsReconnaisssanceOrbiter. The probe Schiaparelli should have landed on Mars by stopping its fall, first by means of a parachute and then, just before landing, using retro-propulsor rockets. Apparently, a failure in the programming of the probe control computer would have caused the rockets to be lit for only 5 seconds instead of 30 seconds as intended. The failure of the Beagle and Schaparelli probes leaves the United States as the only country that has been able to gently place a probe on the Martian surface, and shows that reaching Mars is not a simple undertaking. And if this is difficult for a mechanical ingenuity, it is to a greater extent for a living organism that, among other obstacles, has to overcome the danger of high-energy radiation from the Sun and interstellar space. In these conditions it does not seem feasible that in the coming decades we could colonize Mars, as it is posed in some instances. And in the best case, without air to breathe, with extreme variations of temperature between day and night, and with continuous bombardment of high-energy radiation, our presence in Mars in the medium term is probably limited to a few scientific or exploration stations. Thus, in order to calm our desires of space travelers we must resort to literary fiction, which allows us to imagine trips, One notable example is the book Martian Chronicles by American writer RayBradbury. In his book, Bradbury recounts the first human expeditions to the planet Mars and its subsequent colonization. While this colonization could not occur as Bradbury describes it, Mars gave the writer the pretext to write a fantastic book that creates for the reader an atmosphere that is not of this world \u2013 and that, as an extra bonus, at the same time reflects problems that are characteristic of terrestrial civilization. Moreover, with everything and the failures that have occurred in the exploration of Mars, we can only admire our ability to place a probe at remote control on the surface of a planet that is just a luminous point in the sky.",
    "https://upload.wikimedia.org/wikipedia/commons/7/70/Pluto_system_2006_es.jpg": "The discovery of the ninth planet of the Solar System, beyond the orbit of Neptune, was announced by the director of the Lowell Observatory in Flagstaff, Arizona, on March 13, 1930. In a note published on March 21, 1930, the journal \u201cScience\u201d reported the fact. The existence of a ninth planet had been predicted by several researchers since the mid-19th century and the discovery made public by the Lowell Observatory seemed to confirm it. The predictions of astronomers were based on the disturbances observed in the orbits of Uranus and Neptune \u2013 7th and 8th planets of the solar system, respectively \u2013 which indicated the existence of a celestial body beyond the orbit of Neptune. The hypothetical ninth planet became known at the beginning of the twentieth century as planet X. It should be recalled that the discovery of Neptune occurred after the French mathematician Urbain Le Verrier predicted its existence from the disturbances observed in the orbit of Uranus. As a result of Le Verrier's success, it was not unreasonable to assume that the existence of a ninth planet could be predicted from the observation of the perturbations of the orbits of Uranus and Neptune.And in this regard, Pluto's discovery would have confirmed it.In time, however, it was clear that Pluto's size \u2013500 times smaller than Earth\u2013 is not large enough to disturb the orbits of Uranus and Neptune.In addition, astronomers found that such a disturbance in reality does not exist and that it was based on an overestimation of Neptune's mass. Thus, while the discovery of Pluto was motivated by the mathematical prediction of the existence of a ninth planet, Pluto actually exists on the margin of such a prediction. However, with Pluto the solar system was made of a ninth planet, which was added to the five known since ancient times: Mercury, Venus, Mars, Jupiter and Saturn \u2013 all visible to the naked eye \u2013 and the Earth. Uranus was also added \u2013 discovered in 1781 by William Herschel using a telescope\u2013 already Neptune.In 2006, however, the situation broke down as Pluto was degraded to the category of a dwarf planet and with this the Solar System was once again left with only eight planets.There are now signs that the situation could take a new turn as the search for the ninth planet has regained strength, now in the confines of the Solar System, beyond the orbits of Neptune and Pluto. Thus, astronomers KonstantinBaygin and Michalel Brown of the California Institute of Technology in an article published last January in the magazine \u201cTheAstronomicalJournal\u201d propose the existence of a ninth planet in an eccentric orbit that would lead to a minimum distance from the Sun at about five times the radius of the orbit of Pluto \u2013 some 150 times the distance from the Earth to the Sun. Further away from the Sun, the hypothetical ninth planet would reach about thirty times Pluto\u2019s distance from the Sun. As for its size, the ninth planet would have a mass about 10 times the Earth\u2019s mass and it would take 10,000 to 20,000 years to complete its orbit. The evidence available to Byagin and Brown to support their hypothesis about the existence of the ninth planet are similar to that which was used in the past and are based on the influence that the hypothetical planet would have on the movement of astronomical objects from the Kuiper band that lies beyond Neptune\u2019s orbit. Among these objects is Sedna, which has a diameter of about 1,000 kilometers and travels in a very eccentric orbit with a maximum approach to the Sun of two times the average radius of the orbit of Pluto. Other objects of the same class, including the so-called 2012VP113, of about 450 kilometers of diameter, discovered in 2014. Byagin and Brown argue that the peculiarities and coincidences in the orbits of these transneptonian objects can be explained by the influence As is normal, not all astronomers agree with the conclusions of Byagin and Brown. Thus, there are those who argue that observations have been made with too small a group of transneptunian objects, and that if carried out with a larger group they would lose their livelihood for the hypothesis of the ninth planet. However, aside from the controversy, there are several groups of astronomers competing for being the first to see the ninth planet. In the years to come we will see if they succeed, like Le Verrier and Galle. Or, if the new history of the ninth planet is a fiasco, as was planet X.",
    "https://upload.wikimedia.org/wikipedia/commons/9/9d/NYC_Montage_2014_4_-_Jleon.jpg": "RayEmmet, the fictional guitarist who appeared in Woody Allen\u2019s film \u201cSweet and Lowdown\u201d \u2013\u201cThe Great Lover\u201d in Mexico\u2013 would have been the second best in the world, only surpassed by Django Reinhardt, the legendary jazz gypsy guitarist of the 1930s and 1940s. In fiction, Emmet recognized Reinhardt\u2019s overwhelming superiority as a guitarist and admired him enormously. So much so that he would have fainted the couple of times he could see it from afar. Reinhardt suffered severe damage to his left hand during a fire, losing to a large extent the use of his little and ring fingers, which forced him to develop a technique to play the guitar using only his index and middle fingers. And the remarkable thing is that, despite this limitation, Reinhardt was a very influential guitarist who, according to the knowledgeable, created a particular style of jazz music. Emmet had other strange additions. One of these was simply to contemplate the passage of trains for a long time. Another was to kill brown rats by shooting.And with regard to this last hobby, as we know victims would not have missed.In fact, brown rats are inevitable guests in urban centres.In New York City, for example, it has come to be considered that they live up to 8 million rats \u2013 different from black rats\u2013, although experts consider this number to be too high and estimate that in New York they live only about two million brown rats; this, however, without counting those that could live underground in the pipes. As for the size of New York ratspards, MattCombs, a doctoral student at FordhamUniversity in New York, considers that rat stories of the size of a cat to be exaggerated and that the weight of the larger ones may not be greater than a kilogram. As for his own experience, Combs\u2013who specializes in studying rat populations even It is clear from a genetic study carried out by a team of researchers from four continents with 314 rats trapped in 30 countries \u2013 that the weight of the largest one that has managed to catch is only about 700 grams.Two million rats are undoubtedly many rats but the small number of them is very bad for other urban centers with worse sanitary conditions, for example Mexico City. No one really knows how many brown rats have their residence in the capital of the country, but the newspaper El Universal in an article some year ago quoted the delegate of the Delegation Cuauht\u00e9moc saying that in Mexico City there were at that time about 45 million brown rats, without there is actually a way to check the figure. Certainly, although in more or less number depending on the place, brown rats are everywhere and we are so accustomed to their company that it is surprising to learn that we have started living with them only until relatively recent dates: in Europe for about 500 years and for 200 years less in the American continent. The team of researchers was led by Emily Puckett of FordhamUniversity and included MattCombs. According to Puckett and collaborators, the brown rats originated in Mongolia and northern China and from there spread around the world. Their movement was through human settlements, including those along the Silk Road. Researchers found several routes of expansion. One towards Southeast Asia, one towards the east of the American continent \u2013 possibly via fur traffickers \u2013 and another towards Europe, where they would have arrived around 1,500 AD. Once in Europe, the brown rat would have expanded around the world traveling aboard the ships of the European expeditions of exploration and conquest. An interesting conclusion of Puckett and collaborators regarding the genetic study of the brown rat population of New York City, is that this population does not mix with the rats that continue to arrive aboard the ships that visit the port of this city. The researchers give this fact is that brown rats are very territorial and once a population of these rats settles in an urban center it does not allow another population of brown rats to do the same. From the above we can conclude that, although it is surprising, we have not always been neighbors of brown rats. It seems, however, that to the extent that urban centers developed and commercial exchange between them was established, it was inevitable that brown rats became forced into our uncomfortable neighbors. So uncomfortable that we find it funny that RayEmmet had by hobby to kill them by bullets.",
    "https://upload.wikimedia.org/wikipedia/commons/2/28/Psittacus_erithacus_-perching_on_tray-8d.jpg": "On 13 September 2007, following the death of Alex, the parrot famous for his intelligence, the British newspaper \u201cTheGuardian\u201d published: \u201cAmerica is in mourning. Alex, the African grey parrot who was smarter than the average of the American presidents, has died at the relatively tender age of 31 years. Alex could count up to six, identify colors, understand concepts such as larger and smaller, and had a vocabulary of 150 words. For his followers, Alex was proof that the phrase \u201cbird brain\u201d must be deleted from the dictionary. Alex was acquired in 1977 at a pet store by Irene Pepperberg, who was at that time a doctoral student at \u201cHarvard University\u201d and later professor of psychology at \u201cBrandeisUniversity\u201d in Waltham, Massachusetts. For thirty years Pepperberg trained at the parrot with the remarkable results mentioned in the note of \u201cTheGuardian.\u201d Certainly, what Alex could do was extraordinary and certainly helped to erode the image of animals as mere automatons whose behavior is the result. Alex\u2019s case is not, on the other hand, the only one that has shown the intelligence of certain animal species. Two weeks ago, for example, the magazine \u201cScience\u201d published an article reporting experiments carried out by an international group of researchers with different species of great apes \u2013 bonobos, chimpanzees and orangutans \u2013 which indicate that these primates are self-conscious and able to understand what other individuals think. They may even be clear that others are wrong, if this is the case. During the experiments, the primates participants \u2013 one at a time \u2013 observed through a television monitor how an individual in a King Kong costume \u201cattacked\u201d one of the researchers to hide themselves under one of two piles of hay. The attacked individual, who was able to see the place where his attacker was hidden, momentarily came out of the scene and returned with a stick to take carelessness, In a second version of the performance, the attacker leaves his hiding place and disappears from the scene while the attacked researcher is absent and does not notice it. On returning to the scene he is heading towards the pile of hay in which he is supposed to find his attacker. To assess the reaction of the primates, the researchers recorded the movement of their eyes during the representations and determined the place where they were heading the view. This place turned out to be in both cases the pile of hay in which the attacker believed that his aggressor was hiding. Primates knew what the attack was thinking. And they also knew that sometimes their beliefs were wrong. Between humans and other higher animal species there would not then be a qualitative but only quantitative difference in cognitive abilities. Given the relationship in terms of the evolution of the species that populate the Earth, otherwise, this should not be surprising. An article published this week in the magazine \u201cNature\u201d by a group of archaeologists from universities in Great Britain and Brazil headed by Tomos Pro. \u201cOxford University\u201d ffitt gives us another indication \u2013 in a different direction \u2013 of our close relationship as a species with others on the face of the Earth. Proffitt and collaborators studied the behavior of capuchin monkeys in the Sierra de Capivara National Park in northeastern Brazil. Specifically, they studied the practice of capuchin monkeys striking two stones against each other, until they fractured them. Although this practice itself might not be something extraordinary, in the case of capuchin monkeys it results in the generation of very sharp stone fragments that are surprisingly similar to those found in archaeological sites belonging to the first humans with an age of two million years. The manufacture of stone tools has been regarded as distinctive of the evolution of human intelligence. Proffitt\u2019s findings and collaborators, however, show that such tools can be manufactured using brains considerably smaller than humans, which, according to experts, would lead to reinterpreting the role that the making of tools had in the development of our species. However, while there is evidence that the first humans made use of their stone tools, the capuchin monkeys do not seem to understand their usefulness and, once manufactured, they leave them aside. As scientific evidence accumulates, the idea is strengthened according to which \u2013 apart from being the dominant species on Earth \u2013 our differences with other species would be more quantitative than qualitative. And not only with species that separate us millions of years of evolution, but also with African grey parrots that we have been isolated from for 300 million years.",
    "https://upload.wikimedia.org/wikipedia/commons/9/94/Tyrannosaurus_Rex_Holotype.jpg": "Only until after the invention of photography in the first half of the 19th century could we count on images which, we can be reasonably sure, reflect the past in a reliable way. Thus, in which it is considered the first photograph of a person, we can know with certainty how it looked in 1838 the \u201cBoulevard du Temple\u201d of Paris. The photograph shows this boulevard with trees on both sides, a three-story building in the foreground, and the silhouette of a person standing on a corner, apparently polishing his shoes. Before the invention of photography the artistic portrait of a person could be altered by desires and subjective factors, either by the artist or the portrayed person. In contrast, a photographic machine is out of objective necessity and reflects the nature as it is \u2013 unless the photographufra retouches that, as we know, are now very easy to perform. It serves as an introduction to the subject that we want to deal with today: the dinosaurs and the aspect that they had in life. 65 million years, we do not have photographs of them or artistic portraits of live models\u2013so they were with subjective alterations\u2013. Yes, on the other hand, we have numerous artistic recreations of these animals based on the scientific data available at the time, although they were made with more or less artistic freedoms.Since we only have fossil remains of dinosaurs, determining from them what their aspect was in life is not an easy task.However, scientists have gradually managed to unravel their secrets, in particular their appearance and lifestyle.While, as something inherent to the scientific method, the image we have of dinosaurs has changed to the extent that new fossils have been discovered and developed more sophisticated ways to study them.One of the most famous dinosaurs is the tyranosaur rex, which according to its fossil remains was more than ten meters long, had a weight of between 5 and 10 tons, huge jaws with teeth up to 30 centimeters long to the root, and carnivorous habits. However, there is uncertainty as to what they would have looked like in life. Did they, for example, have dark, scaly, hard skin as it happens in the film \u201cJurasic Park\u201d? Scientists today are not sure and some consider that they might even have been covered with feathers, at least in certain parts of the body. Otherwise, regardless of the uncertainty about whether the T. Rex had feathers or not, there is solid scientific evidence that other dinosaurs did. It is known, for example, that the velociraptor \u2013 one of the stars of Jurassic Park \u2013 was covered with feathers, which gave it a very different look than the beast imagined by Hollywood \u2013 in addition to having a considerably smaller size. An article published last week in the magazine \u201cCurrentBiology\u201d by an international group of researchers headed by Jakob Vinther of Bristol University in the United Kingdom, shows us how sophisticated the study of dinosaur fossil remains has come. that article, Vinther and collaborators carried out an investigation with remains of a dinosaur the size of a gazelle and with a head reminiscent of that of a cotorra, which lived in northeastern China more than 100 million years ago. The researchers studied what they suppose are the fossilized remains of pigments that gave color to the skin of the dinosaur. Specifically, they were interested in determining the distribution of these pigments on the body of the dinosaur in order to determine what their habitat was. With regard to the latter, it is known that animals living in open spaces have the darkest back than the belly and this helps them to hide from their predators. Indeed, sunlight makes the objects look brighter in the upper part than in the lower part and this gives an impression of volume. Having an animal more coloration in the back than in the belly helps it to lose the contrast of brilliance and with this impression of volume, making it more difficult to distinguish its presence. that the passage from the dark part to the clear part of the dinosaur studied was not as abrupt as in animals living in open spaces. From here they concluded that this dinosaur lived in enclosed spaces surrounded by vegetation, where it did not receive sunlight directly but in a scattered way.Since photographic machines were not invented until about 65 million years after the dinosaurs became extinct, it is certainly not possible to have reliable images of them. In these conditions, to find out how they would have looked in life we have to resort to indirect methods. Specifically, to the scientific study of their fossil remains. And this, by necessity, is a slow process that will undoubtedly produce errors that, however, will be corrected over time.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d3/Bill_Clinton.jpg": "The connection is perhaps surprising, but in the past there was a close relationship between some American universities that today enjoy great prestige, and the practice of slavery against African natives as it existed in the United States in the 18th and 19th centuries.In fact, universities such as Princeton in New Jersey and Columbia in New York were financially supported in their beginnings by rich merchants who had made their fortune through the slave trade between Africa and the United States.And, even more surprising,the relationship of universities with slave institutions was not only passive \u2013 as it would have been if they had simply acted as recipients of the slave dealers\u2019 donations\u2013but at least in one case it was active, receiving the university directly benefits from the property even from the slave trade.This case is the case of Georgetown University, which has been present in the media in recent days.Georgetown University is a Jesuit school founded in 1789 with headquarters in Washington, D.C.It is one of the most prestigious universities in the United States and between its e. Former President Bill Clinton, the current kings of Spain and Jordan, as well as former presidents of Panama, Costa Rica and El Salvador, met with financial problems in 1838.The university went through financial problems and to solve them, it was decided to sell 272 African slaves who belonged to a plantation that the Jesuits owned in the state of Maryland.The profits of that plantation were destined for Georgetown University.At that time, however, the plantation was poorly managed and the profits were not enough.The slaves were sold to southern plantations in Louisiana.The slave sale operation reported an income of about three million dollars and was carried out by two Jesuit religious, former presidents of Georgetown University.A list of the slaves sold can be found on the Internet page \u201cGeorgetown Slavery archive\u201d of the University of Georgetown.In that list they include more than sixty children, one of them two months old, and several elderly.We can imagine the shock that the sale produced among those affected \u2013 and among some of the Jesuits on the plantation that, among other things, They were concerned because there was the possibility that slaves could not hear mass in Louisiana\u2014since it was known that the conditions for slaves on the southern plantations were brutal. We found the details of that sale in an article published in the newspaper \u201cNew York Times\u201d last April. There we read that there were children who were separated from their parents and that the slaves were forcibly taken to the ship that would transport them to Louisiana. Slaves were found to have fled, though some of them were later captured and forced to board. An elderly woman, on her knees, begged to tell her what she had done to deserve that fate.Last week, the president of Georgetown University acknowledged that she was in debt to the descendants of the 272 slaves sold to the southern plantations and that in order to reward them she would give them the same facilities to enter that university as those given to those whose parents or grandparents were students of that university. One by the name of one of the victims of the transaction \u2013 the first that appeared on the shipping list \u2013 and the other by the founder in 1827 of a school for black girls.This week, however, the descendants of the slaves made public that they consider that the offer of Georgetown University is not enough to repair the facts that occurred 180 years ago, and they ask for the establishment of a reparation fund for the huge amount of $1,000 million dollars, which, on the other hand, is not clear how it will be used. Georgetown University is therefore receiving a punishment deserved for its sins of the past. It is possible, on the other hand, that the $1 billion demanded are excessive and that something closer to the $3 million obtained from the sale of slaves is more realistic. Moreover, and regardless of the arrangement reached by the victims' convictions with Georgetown University \u2013 and while it is true that slavery was seen 180 years ago with different eyes \u2013 it is difficult to understand that Jesuit religious from the Maryland plantation have managed to combine their convictions with the practice of slavery. .",
    "https://upload.wikimedia.org/wikipedia/commons/e/ee/Iridium-4_Mission_%2825557986177%29.jpg": "As reported by the media, last Thursday an explosion in Cape Canaveral, Florida, destroyed a rocket from the North American company SpaceX that was on its launch platform. With the explosion, which shook nearby buildings and left smoke clouds in the sky, a $195 million communications satellite was lost on board the rocket. \u201cSpaceX\u201d is a private company founded in 2002 that offers commercial space cargo services. Among other customers, SpaceX works for NASA with which it has signed a contract for the resupply of the International Space Station (IEI). In this connection, it should be remembered that after NASA discontinued its space shuttle program in 2011, the agency was left without its own capacity to send cargo into space. It depends on others to do so. The company \u201cSpaceX\u201d plans to carry out in the immediate future also manned missions to the IAE under contract with NASA. Under these conditions, last Thursday\u2019s accident must have been a cause for concern for this. So, in order to reduce the importance of the accident \u2013 which occurred during the filling maneuvers of the rocket fuel tanks \u2013 \u201cSpaceX\u201d referred to it euphemistically as \u201canomaly on the takeoff platform\u201d. Last Thursday, on the other hand, it is not the first accident that \u201cSpaceX\u201d suffers. In June 2015 a rocket from this company exploded in the air two minutes after takeoff. That accident, however, was preceded by six successful launches. The founder of the \u201cSpaceX\u201d is ElonMusk, who has also been an accident from other companies such as PayPal, Solar City and Tesla Motors, this last manufacturer of electric cars that can be equipped to travel in a semi-autonomous way. In this regard, let us remember that last May one of the Tesla Motors cars had an accident on a Florida road where the driver died when the car crashed, which was travelling with the auto pilot activated, against a cargo truck that closed his way. The accident occurred when the automatic system of the vehicle could not distinguish the silhouette of the truck against the clear sky already opened questions about the viability of the cars without driver in the immediate term. Musk is a promoter of extravagant projects like the hypothetical means of transport \u201cHyperloop\u201d, which consists of a tube of little more than two meters of diameter in whose interior it travels, levitated by an air mattress, a capsule with28 passengers. The capsule is driven electrically and to decrease the friction with the air to the tube is extracted air until reaching a moderate vacuum. In these conditions, according to Musk, one could travel between the cities of Los Angeles and San Francisco in less than 35 minutes, at a speed greater than 1,100 kilometers per hour. Through \u201cSpaceX\u201d, Musk also drives a project to carry out a manned mission to Mars in the year 2024, which is felt impossible by the enormous technological obstacles presented and the risks that the travelers would run, including the radiations of high energy coming from the Sun and the interstellar space that are not suitable for the year 2024. Some of Musk's projects are clearly fanciful and possibly have a public relations purpose rather than serious intentions to carry them out. In contrast, as far as projects to carry cargo into nearby space are concerned, \u201cSpaceX\u201d has been successful and with its offer it has managed to push down costs to place loads in orbit. In addition, in order to further reduce these costs, \u201cSpaceX\u201d is carrying out tests to re-use rockets, which have traditionally been destroyed at each launch. For this purpose, the company is carrying out tests to get these rockets back to ground in a controlled way and are gently laid on the ground. This is extremely complicated, because far from the way NASA ferries landed planning, the rockets \u2013as they do not have wings to plan \u2013 have to descend vertically making balance and aided by the engines.In videos that it is possible to find on the Internet we can see how complicated and spectacular this happens when it succeeds \u2013and even when it fails, but in a different way\u2013.The first soft descent into the firm ground of a \u201cSpace\u201d rocket can be found on the Internet. X\u201d occurred last December in Florida. Later, in the month of April this year, \u201cSpaceX\u201d managed to land a rocket on a marine platform. In both cases, the maneuver was certainly spectacular. Almost seven decades have passed since the launch of the first artificial satellite by the then Soviet Union. Since then, we have witnessed memorable space events including the first manned space trip and the first manned trip to the Moon. We witnessed the appearance and subsequent disappearance of the overwhelmingly expensive space shuttles. And with all this, we still have room to admire the incredible precision with which a rocket of hundreds of tons of weight can be brought back to earth.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d7/H%C3%A0bit_Saludable.jpg": "Each version of the summer Olympic Games has had extra-sportive features for which it is remembered. During the Munich Games in 1972, for example, the Palestinian terrorist attack on the Olympic Village occurred, resulting in the death of 11 members of the Israeli delegation, including five athletes. We can also mention that the Moscow Olympic Games in 1980 were attended by only 80 countries because of the boycott organized by the United States against the Soviet Union; and that four years later, in retaliation, the Los Angeles Olympic Games did not come to the Soviet Union seconded by countries of the communist bloc. Recently, the magazine \u201cSportsIllustrated\u201d did a favor to the Mexico 68 Olympiad by placing it on the list of the worst in history. The reason: the height of Mexico City of more than two thousand meters, with an atmosphere more tenuous than at sea level and therefore with less oxygen. This, which negatively affected the resistance tests, had a positive effect on tests where air resistance is an important factor. Perhaps the most notable example is the The Olympic Games in Rio de Janeiro, which come to an end this Sunday, have not been the exception in terms of extrasport events that will remain for history.In fact, the Rio de Janeiro games have been marked by a series of circumstances and problems of the most diverse nature; from the economic and political difficulties that Brazil is going through, to the controversial doping scandal that, with one exception, marginated Russian track and field athletes from the games, including the Garrochista Yelena Isimbayeva, who has been twice an Olympic champion, three times a world champion, who has held the world record of her trial since 2004, and who has never given positive evidence in tests. In the last few days we have learned of another extra-sport scandal that took place in the framework of the Rio Olympics and that involved four members of the United States swimming team, all gold medalists.The group of swimmers included RyanLochte who has won a total of 12 Olympic medals in swimming tests for the United States, just behind Michael Phelps.The reference incident, widely spread by the media, took place the morning of last Sunday when the athletes returned to the Olympic village on board a taxi at six o'clock in the morning, after a night of juggle.Needing a toilet, they asked the driver of the taxi to stop at a gas station. There, the swimmers peed in the street and caused destruction in the establishment, apparently instigated by Lochte. This confronted them with the managers, one of whom pulled out a gun to calm the vandals. Lochte, not happy with his performance, invented the story that they had been assailed by Lochte. According to the athlete, they were forced by the assailants to get out of the taxi and lie down on the floor. By refusing, Lochte would have been in the head.The swimmer probably considered that in the United States his story would be credible given the image that the Americans have of Brazil \u2013 perhaps not entirely wrong, but very probably exaggerated \u2013 as a disordered and unsafe country.Lochte's story, however, soon came down when the Brazilian police, after an investigation, made public what had really happened.The anger it provoked in Brazil is more than understandable and the head of the civil police of Rio de Janeiro declared that the Cariocas deserved an apology from swimmers for spreading fanciful facts that stained the image of the city. In the United States there were also reactions in the press that condemned the action of swimmers. The newspaper \u201cNew York Times\u201d, for example, quotes Brian Winter, editor of the magazine \u201cAmericasQuarterly\u201d, who believes that Lochte fed the story of Lochte. among Brazilians \u201can image of the Americans as gringos who treat their country as a third-class destination for \u201cspring break\u201d, where the police can be lied to without suffering any consequences.\u201d Rio\u2019s games will thus go down in history not only because of the remarkable sporting performance of some athletes, but also because of the performance of some others in outdoor activities to their sports specialty that certainly demand less preparation effort. Otherwise, the party that the American swimmers ran is far from unusual. As we can read from Wikipedia, as we can read, in their entry into the Olympic village of Munich 1972 \u2013 which took place in the early hours \u2013 Palestinian terrorists would have been helped by American sportsmen who were going on a party and who were returning to the village at that time. Americans would have thought that, like them, terrorists were trying to enter the village in a furtive manner.",
    "https://upload.wikimedia.org/wikipedia/commons/e/ef/World_Map_Gini_coefficient_with_legend_2.png": "In a statement issued this week by the Greek Ministry of Culture, it is reported that a group of Greek and American archaeologists discovered a 3,000-year-old skeleton at Mount Lykaion in southwestern Greece.This unleashed speculation that the discovered skeleton could correspond to that of a victim sacrificed to the god Zeus. Greek authors of antiquity, including Plato, pointed to Mount Lykaion as a site where human sacrifices were practiced.Until the discovery announced in previous days, however, no direct evidence had been found to indicate it.In this sense, according to the British daily \u201cTheGuardian\u201d, David Gilman Romano of the University of Arizona, one of the authors of the discovery of Mount Lykaion, notes that although there is no certainty that it is indeed a human sacrifice, the place where the remains were found is not a cemetery but an altar of sacrifices. Furthermore, he mentions that the skeleton lacks the upper part of the skull and that the body was placed between two rows of stone aligned in the east-west direction, With the pelvis covered with stone plates.The possibility that it is a human sacrifice could not then be discarded.JanBremmer of the University of Groningen in Holland, for his part, is not convinced that the skeleton discovered on Mount Lykaion corresponds to a sacrifice and mentions that the image of Greece as the cradle of philosophy, democracy and rational thought in the Western world does not agree with the barbaric practice of human sacrifices.However, as we know the reason is not enough to avoid atrocities if there are profits in between.And in this regard, an international group of researchers led by Joseph Watts of the University of Auckland in New Zealand, affirms that human sacrifices had an additional function to that of appease the wrath of the gods: to promote and preserve social stratification.The researchers offer their arguments and conclusions in an article published last April in the journal \u201cNature\u201d.Watts and collaborators carried out a study of93 traditional cultures that from a common origin in Taiwan were distributed in a large geographical area, from the Polynesia to Madagascar and from Hawaii to New Zealand.The peoples investigated developed a great cultural diversity over time and formed from egalitarian societies to highly stratified societies.They also occupied a wide range of habitats, from small atolls to continental territories.In the cultures studied, in addition, the practice of human sacrifice was widespread.In this context, the purpose of the research was to determine the relationship that existed between this practice and social stratification.In their study, the researchers determined the existence or absence of human sacrifices in each culture and classified them as egalitarian, if wealth and social status were not inherited between generations, moderately stratified if wealth and social position were inherited but had the possibility to change within a generation, and highly stratified if wealth and social status were inherited and had no or little possibility of change within a generation.The 93 societies studied were divided into 20 egalitarian, 46 moderately stratified and 27 highly stratified. Watts and collaborators found evidence that it existed in 40 of the cultures studied, representing 43% of the total. With regard to the frequency of this practice in relation to social stratification, they found that it existed in 5 cultures of the 20 egalitarian (25%), in 17 of the 46 moderately stratified (37%), and in 18 of the 27 highly stratified (67%).In addition to the above, Watts and collaborators sought to find out who was first, whether human sacrifices or social stratification.From the evolution of the societies studied found that human sacrifices promote social stratification and help maintain it once it has developed.In this context, the function of human sacrifices was to maintain social inequality through terror that inspired the possibility of becoming one more victim; having realized that the victims of such sacrifices were commonly people with a low social rank. Human sacrifice was a murder with religious justifications that sought to influence the will of the gods that were thought to trigger the greatest misfortunes on the world. They conceived themselves more in the realm of the natural than in the supernatural, human sacrifices lost their justification and tended to disappear.Or perhaps only to transform themselves, replacing their religious justification with a more suitable one, as circumstances require.",
    "https://upload.wikimedia.org/wikipedia/commons/e/e1/Chemicals_in_flasks.jpg": "The document \u201cThe State of the Climate in 2015\u201d published this week in the \u201cBulletin of the American MeteorologicalSociety\u201d, which contains contributions from scientists from a large number of countries compiled by the \u201cNationalOceanic and AtmosphericAdminstration\u201d of the United States, confirms what several instances advanced at the beginning of this year: 2015 was the warmest year in history. In 2015 the global average temperature exceeded pre-industrial levels by 1 degree centigrade. Concurrently, the average concentration of carbon dioxide in the atmosphere \u2013 the main cause of global warming \u2013 measured at Mauna Loa station, Hawaii, first overflowed the 400-part barrier per million. This value must be compared to the 280 parts per million that prevailed before the industrial revolution. The effects that, according to specialists, produces global warming include the melting of the ice layers in Greenland, which is contributing to increasing the level of the oceans and which in the medium term could flood low areas around the world. . An article published this week in the journal \u201cGeophysicalResearchLetters\u201d points to another potential consequence\u2013unexpected\u2013 of the melting of Greenland\u2019s ice sheet. This article was published by an international research group headed by William Colgan of the \u201cYork University\u201d in Canada, and it discusses the potential disappearance of the ice layer in Greenland that could expose military installations built by the United States in the 1950s in the context of the Cold War. In 1959 the \u201cArmyCorp of Engineers\u201d of the United States Army built \u201cCamp Century\u201d, an underground complex in northwestern Greenland, some 200 kilometres from the North American air base of Thuley at 1,300 kilometres from the North Pole. The North American presence in Greenland followed the signing in 1951 of an agreement between the United States and Denmark to defend Greenland \u2013 which was and remains Danish territory \u2013 from a possible attack by the Soviet Union. \u201cCamp Century\u201d, which the American army described as a \u201ccity under the ice\u201d, comprised 3,000 metres of tunnels perfored in the ice. At a depth of about 8 meters, the largest of which had a length of 350 meters and a width and a height of almost ten meters.The facility had the capacity to permanently accommodate 200 soldiers.In addition to rooms and research laboratories, it had latrines, hospital showers with operating room, medical clinic, hairdresser and a capillary; as well as a theatre, library, shops and recreation space, among other amenities.They received energy from a portable nuclear reactor and supplies from the Thule air base. Officially, and so it was handled before the Danish government, the purpose of \u201cCamp Century\u201d was to study construction techniques in the Arctic, explore the practical problems associated with the use of a portable nuclear reactor, and conduct scientific studies of the Arctic ice layer. \u201cCamp Century\u201d, however, was also used to explore the possibility of building a site in the Arctic for the launch of missiles. Thus, in 1962, the project \u201cIceworm\u201d was proposed to build an installation under the ice, with 4,000 kilometers of tunnels. in an area of 130,000 square kilometers, which would deploy 600 nuclear missiles capable of reaching the Soviet Union. The \u201cIceworm\u201d project, however, was never approved because it was found that the constructions of \u201cCamp Century\u201d were unstable by the movement of the ice sheet. Such conditions, \u201cCamp Century\u201d was abandoned without more concern than to remove the nuclear reactor from the site. All other facilities of the complex, including 10,000 tons of building materials, 200,000 litres of diesel fuel, radioactive waste, huge quantities of waste water and chemical contaminants in unknown quantities, were left at the site assuming that they would be buried forever by the accumulation of snow. What was taken for granted fifty years ago, however, cannot be guaranteed today and it is possible that \u201cCamp Century\u201d will eventually emerge to the surface as the ice disappears due to climate change. This at least according to Colgan and collaborators who conclude that by the end of this century the accumulation of ice will cease to compensate for losses and hence the thickness of the ice layer decrease. Who will be responsible for remedying \u201cCamp Century\u201d once it emerges to the surface, if it ever does? According to Colgan and collaborators, it is not clear who would have to do so on the basis of the agreement signed by the United States and Denmark that it is ambiguous about it. What is clear, however, is that in his case the injured will be Greenland \u2013 which did nothing to deserve it \u2013 and that he is increasingly seeking greater independence from Denmark. Certainly, we will not live long enough to witness the outcome of the matter. Yes, we have lived what is necessary to verify that with \u201cCamp Century\u201d reality surpassed fiction.",
    "https://upload.wikimedia.org/wikipedia/commons/f/f1/Mars_mission.jpg": "The images that have sent us from Mars the different probes that NASA has placed on the surface of that planet show it as a desolate, dry and stony place, not suitable for any higher life form. Actually, the conditions for life on Mars are worse than those that we could intuit from the images of its surface. Mars, for example, has a very faint atmosphere with a density that is just one hundredth of that of our planet and that is, in addition, composed of 95% carbon dioxide. In this way, there would be no oxygen to breathe and we would have to live in enclosed spaces or buried in a special suit. Being further away from the sun than our planet, the average temperature on the surface of Mars is less than 55 degrees Celsius. Besides, because of the tenuousness of the Martian atmosphere, the variations of temperature between day and night can reach 100 degrees Celsius on the equator of the planet. It is therefore not Mars an attractive place to visit. Except, of course, for those few with enough spirit of adventure. There are many serious reasons for this; one of them has to do with the radiations to which anyone would be exposed who would attempt to travel there \u2013 on a journey that would take him something like nine months. Indeed, interplanetary space is a very dangerous place, full of high-energy radiations from the Sun and external sources to the Solar System.These radiations produce alterations in the organic tissue that cause diseases, including cancer.And despite all the foreseeable obstacles, since the beginning of the space age, in the fifties of the last century, proposals and projects to travel to Mars have been recurrent. Wikipedia, for example, lists more than half a hundred initiatives in this sense in the last sixty years. Today, NASA plans to carry out a manned mission to Mars in the thirties of this century and there are initiatives in that direction by private organizations for even earlier dates.Until now, the only astronauts that have traveled under conditions. As we recall, through this project NASA managed to place the first human on the surface of the Moon in July 1969. A total of 24 astronauts participated in this project, which for the first time carried travelers outside the magnetosphere that protects our planet from high-energy radiation from space. During his trip to the Moon, Apollo astronauts lost this protection and were exposed to such radiation. With regard to the above, an article appeared this week in the journal \u201cScientificReports\u201d, a group of specialists from research centers in the United States, headed by Michael Delp of Florida State University, suggests that the astronauts of the Apollo project of the sixties and 1970s were affected to such an extent by the high-energy radiation in the course of their missions that ultimately led to their death. Delp and collaborators carried out a statistical study on the causes of death of NASA astronauts who have passed away to date. They included 7 astronauts. The study found that of Apollo astronauts, 43% died from cardiovascular disease, while 29% died from cancer. As far as astronauts who traveled only to low orbits are concerned, the respective percentages are 11% and 31%, figures that are very similar for those who never traveled to space. That is, while the probability of dying from cancer was the same among all astronauts, regardless of whether they were so far away from Earth, Apollo astronauts died from cardiovascular diseases with a frequency 4-5 times higher than the rest of astronauts who never left the magnetosphere. One problem with the results of Delp and collaborators is that they were obtained with very small samples, particularly with regard to Apollo astronauts. To support their statistics, however, researchers were able to support their statistics. They carried out an experimental study with mice who were subjected to simulated conditions of absence of gravity and high-energy radiation, which caused damage to the walls of the blood vessels of the animals. Many plans exist to send a manned mission to Mars, some more serious and others with surprisingly short deadlines. It would be missing whether high-energy radiations \u2013 as well as other obstacles that are equally formidable \u2013 have nothing else.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d1/Thumbnail_technical_series_1996-01-01_1.gif": "According to a report from German television in December 2014, 99% of high-level Russian athletes employ prohibited substances to increase their performance.Furthermore, according to the testimony of the Russian athlete YuliaStepanova, they do so as part of an official policy for the preparation of Olympic athletes.One year after the German television report, the International Anti-Doping Agency (WADA) recommended that the Russian track and field team be excluded from the Rio de Janeiro Olympics to be held next August. According to WADA, coaches, officials of the Russian track and field federation, officials of the Russian anti-doping agency, and others, organized efforts to \u201cpromote doping and make it possible for such efforts to succeed, including concealing certain positive cases of doping.\u201d Furthermore, it is clear that \u201cthe federal government was not only complicit in the collusion but that it was all a state-driven regime.\u201dTo win an Olympic medal with the help of a prohibited substance that can be detected, cooperation is needed, of course, Athletics Association (IAAF) which, according to WADA, did nothing to deal with cases of doping and allowed the participation in the 2012 Olympics of athletes who should have been disqualified at first instance. In addition to the fact that some senior IAAF officials would have received bribes to hide the cases of doping. Last June, IAAF made the decision to exclude the participation of the entire Russian track and field team of the Rio Olympics on the grounds that \u201cRussian athletes cannot return convincingly to international competition without undermining the confidence of their competitors and the public.\u201d In response, the Russian president stated that it is unfair for those athletes who compete without drug use and that he does not accept a collective punishment, which would be equivalent to putting a whole family in jail for a crime committed by one of its members. Russian athletes, on the other hand, are not the only ones who resort to doping to increase their performance. In relation to this point, a report from German television and the British newspaper \u201cSunday Times\u201d made The study found that the data of 146 athletes, who between 2001 and 2012 won world championships or Olympic medals \u201355 gold \u2013 give rise to suspicion that they used substances to increase their performance. Although 80 of these 146 athletes are Russian, the data indicate that these are not the only ones who doped. Otherwise, the use of prohibited substances in sports competitions is not a new phenomenon. In the 1904 San Luis Misuri Olympics \u2013just the third of the modern era \u2013 a case of doping with strychnine was recorded, an unexpected stimulant that today we would be more associated with mystery novels than Olympic games. The episode occurred during the marathon race, which is also remembered for the number of strange episodes that occurred during the marathon. The chronicle of the race can be found on the website of the \u201cSmithsonianInstitution\u201d. 1904, one of them, Fred Lorz, for his work as a mason, had to train at night. Likewise, two members of the Tsuana tribe of South Africa, who were there for reasons different from those of the marathon and ran without shoes, participated. The same thing as a Cuban, Felix Carbajal, who worked as a postman in his country and who, upon arriving in the United States, lost all his money playing dice and had to travel on foot and asking for lifts from New Orleans to St. Louis.Once the marathon began, Lorz took the lead but was soon overtaken by Hicks.A few miles to finish the race, Hicks was exhausted and his auxiliaries provided him with a dose of strychnine and clear egg, which they repeated, adding brandy, a few kilometers from the finish. He was disqualified, of course, but not before he was about to receive the gold medal from President Roosevelt's daughter. In the end, the winner was Hicks, who entered the half-dead goal. Thus, Hicksla won the gold medal from the San Luis marathon, helped by a cocktail of strychnine, egg white and brandy.A lot of time has passed since 1904 and the Olympics have certainly undergone a huge transformation, both qualitatively and quantitatively. Thus, if more than a century ago he gave the case of an athlete who won a gold medal with the help of stimulants, it is inevitable that today \u2013 with the enormous amount of money and political interests involved in the Olympics \u2013 doping is not in any way unusual. Neither among Russian athletes nor among those of other nationalities.",
    "https://upload.wikimedia.org/wikipedia/commons/f/f5/PSM_V75_D415_Arthur_Smith_Woodward.png": "The purpose has never been clarified, nor have the culprits been fully identified, but just over a century ago there were those who or in England had the occurrence of falsifying fossils and making them pass through the remains of an ancestor of ours. We refer to the so-called Piltdown Man, whose remains were allegedly found between the years 1908-1912 in a gravel mine near Piltdown, a village in the south of England. History began in 1908, when a mine worker would have located some fragments of a fossilized skull, same as he had reached Charles Dawson, an amateur archaeologist, who gave himself the task of exploring the site in search for more fossils. Later, he was joined in the search by Father Teilhard of Chardin and Arthur Smith Woodward, a professional paleontologist of the British Museum, succeeding in finding more skull fragments, a jaw with two molars and a canine tooth. The peculiar feature of the fossil remains is that, while skull fragments reminded of a modern man, the jaw had the characteristics of a simian. At that session they expressed their conviction that the fossil remains of Piltdown, a corresponding link lost between our species and our ape ancestors.Although controversial, Smith Woodward's and Dawson's views were well accepted and supported by prominent British paleontologists.The support was such that in 1938 it was erected on the site of the supposed discovery of the Piltdown Man a memorial to the event.In 1953, however, it became clear that everything had been a deception and that the skull belonged to an anatomically modern human while the jaw was of an orangutan.The remains had been trickly altered to disguise the fact that they did not perpetuate the same individual.One of the ways in which the reason why the Man of Piltdown was able to survive for four decades, invokes the fact that while on the European continent there were abundant fossils that attested to the evolution of the human species, in England these In the words of evolutionist biologist and scientific divulgator Stephen JayGould, \u201cEngland did not know anything about its oldest ancestors. France, on the other hand, enjoyed a superabundance of Neanderthals, Chromanons and their associated tools and art. French anthropologists enjoyed passing through the noses of the English this exaggerated disparity of evidence. Piltdown could not have been better designed to turn the tortilla around. It seemed much earlier than the Neanderthal.\u201d Although at the end of the dayPiltdown did not contribute to the English could turn the tortilla over to the French, this week a discovery was made known with which they could do something about it; although in a different context and with considerably more limited reach.This discovery was carried out in Peterborough, located about 120km north of London, site of a human settlement of the Bronze Age. On the site of Peterborough archaeologists found that about 3,000 years ago a set of shacks were set on fire \u2013 by accident or vandalism. The huts, which were built on piles above the surface of a river, collapsed and sank with everything inside them.For archaeologists \u2013but obviously not for their inhabitants, even though they saved their lives \u2013 the fire, carbonization and subsequent sinking of the huts were a great luck, since it allowed the preservation for three thousand years of their remains with everything inside.Thus, the researchers found buried in the river bed numerous ceramic objects, from small cups to plates and containers to store food. They also found wooden objects, as well as metal objects, including chisels and pliers. One thing that archaeologists highlight is the discovery of remains of fabrics that were preserved by the charring they suffered.In addition, the distribution of objects found in the different spaces of collapsed houses gives an indication of how they were used.The archaeologists also discovered remains of food and containers with remains of food. In one case they even encountered a dish with their spoon, submerged it in the charred content.All of this provides valuable information about the eating habits of the Bronze Age.Thus, Peterborough's site constitutes a time capsule that gives us a vision of the world 3,000 years ago.So the British have their own version of Pompeii.A version that is even 1,000 years older than the city buried by Vesuvius.It seems that with Peterborough the British will be more fortunate than they were with Piltdown.",
    "https://upload.wikimedia.org/wikipedia/commons/1/14/Am_Anfang_schuffF_GOtt_Himel_vnd_Erden.jpg": "One event that was widely broadcast in the media this week was the arrival of Jupiter from NASA\u2019s Junode probe. Juno was launched to this planet in August 2011 and after traveling 2.8 billion kilometers reached its destination on July 5. The probe has the mission to study closely the planet that is the largest planet in the solar system and, among other things, to find out what its internal structure is. Once in the vicinity of Jupiter, Juno maneuvered to enter orbit. NASA chose an eccentric polar orbit that minimized damage to the measuring instruments and solar panels of the probe by the radiation belts that surround Jupiter. Juno is expected to carry out a total of 37 orbits, each lasting fourteen days, and to approach up to about 4,300 kilometers above the surface of Jupiter. At the end of the mission, NASA will bring down to the probe in a controlled manner to the planet\u2019s atmosphere, where it will disintegrate by the enormous pressures and heat that will be held. Jupiter today ended up attracting a lot of public attention and in a way became a celebrity.What, for the rest, should not have taken away the dream from the planet, as it is not the first time it occurs.In fact, of the giant planets\u2013Jupiter, Saturn, Uranus and Neptune\u2013, Jupiter has been the most studied by the US space agency.Previously to the Juno mission, seven probes were sent by NASA to the vicinity of Jupiter.Of these, the longest time devoted to it was Galileo, which remained in orbit around the planet between 1995 and 2003.The others have explored it only in passing, although they have provided a lot of information.The first was the Pioneer 10 that in December 1973 approached about 130,000 kilometers of Jupiter on its way to interstellar space.The Pioneer 10 sent to the Earth photographs of Jupiter that exceeded in resolution those moments had been obtained from our planet.On the other hand, NASA has not been the only one to take an interest in Jupiter. for thousands of years and before being identified as such. And there are reasons for it: in the firmament it appears as the second brightest star, only after Venus. We know, of course, that Jupiter is not a star and that if we see it as a luminous point is only by the distance to which it is found. In antiquity, although the interstellar distances were not known, neither Jupiter nor any of the four other planets visible at first sight \u2013Mercury, Venus, Mars and Saturn \u2013 were considered ordinary stars, as they moved in the firmament following more complex paths than those of ordinary stars. So much so that the Greeks called them errant stars and the Romans gave them names of gods. And among the Roman gods, Jupiter was the one of the highest hierarchy. Jupiter has played central roles throughout history. At the beginning of the 17th century he contributed in a decisive way to bring down the supposition of geocentric prejudice prevailing then, according to which the Earth is the center of the universe and as such as all the objects we see in the firmament rotate to ours. Although the apparent movement of the Moon, the Sun and ordinary stars does not contradict this assumption, the same cannot be said with respect to the planets, which move most of the time in one direction, but also sometimes move in the opposite direction.To explain the complex movement of the planets \u2013 within the geocentric prejudice \u2013 Claudio Ptolemy almost two thousand years ago employed a complicated model according to which the Earth was immobile in the center of the universe and the planets revolved around a point that in turn revolved around the Earth. At the distance the Ptolemeoluce model quite artificial. It nevertheless enjoyed great influence for more than a millennium until it was found in the sixteenth century with Nicholas Copernicus, who advocated for a model with the Sun occupying the place of the Earth.The function of the geocentric model occurred in 1610 when Galileo Galilei pointed out a rudimentary telescope of its construction towards Jupiter and discovered a luminous disk with three bright spots in its vicinity.In a second observation days later, the original points had changed position and a fourth had appeared. Galileo correctly deduced that the luminous points were satellites orbiting around Jupiter, the now known as Galilean satellites in his honor. Thus, Galileo demonstrated with hard data that not all objects of the firmament necessarily have to orbit around the Terra and thus removed from our planet the special place that had been wrongly assigned to it. As a consequence, it was natural to assume that terrestrial phenomena are governed by the same physical laws that govern celestial phenomena and this opened the way for the development of the science of mechanics that would serve as a model for the development of other scientific disciplines. Thus, Jupiter, the planet that NASA now tries to know more thoroughly, played a star role, rather than a star \u2013 at least not an ordinary star \u2013 in the development of Western civilization.",
    "https://upload.wikimedia.org/wikipedia/commons/e/e5/North_face_south_tower_after_plane_strike_9-11.jpg": "As was widely reported by the media, last Tuesday a terrorist attack at Istanbul airport, Turkey, left at least 44 people dead, including two suicide bombers.This fact adds to the growing number of terrorist incidents in the world, which multiplied by a factor of nine between 2000 and 2014, according to the database on global terrorism hosted at the University of Maryland.According to this database, nearly 33,000 people globally died from terrorist acts in 2014, including 6,200 attackers. Those killed by terrorism, on the other hand, were not distributed equally throughout the world and 78 per cent of the total occurred in only five countries: Iraq, Nigeria, Afghanistan, Pakistan and Syria, with Iraq being the worst spared by recording approximately 10,000 deaths.In contrast, in the United States,18 people died in 2014 as victims of terrorism.The vast majority of terrorist attacks in the world take place in this way in a few countries and this contrasts with the disproportionately focused media attention given to the terrorist incidents that occur in developed countries. in Paris with the result of 137 people killed, but we may not remember with the same ease those who took place on 20 September of the same year in two locations in Nigeria, with the result of at least 145 fatal victims.However, in the past few years the number of victims of terrorism has been relatively small in developed countries, particularly in the United States, where the deaths from terrorism in 2014 were just 0.06% of the total number of deaths from traffic accidents, there is interest in studying the phenomenon of terrorism in order to anticipate its attacks.With regard to the above, on 17 June a group of researchers in the United States, headed by N.F. Johnson of the University of Miami, published in the magazine \u201cScience\u201d an article in which they report the results of a study carried out in the hope of understanding the process by which terrorist groups are formed, as well as the conditions conducive to their activity as such.The study was carried out with information obtained from the Internet, which is the means of communication that promotes the integration and coordination of the above groups. Johnson and collaborators assumed that, rather than following the Internet messages of all those who occasionally had mentioned, for example, the Islamic State (ISIS), we must follow the self-formation and evolution of support groups \u2013 to which they refer as \u201caggregated\u201d \u2013 to such a terrorist organization. Each of these aggregates is formed by a group of followers of a certain Internet page, who \u201coften discuss online operational details, such as funding routes, technological knowhow and how to avoid attacks by drones.\u201d To carry out their study, Johnson and collaborators focused on pages hosted on Vkontakte, which is a social network similar to Facebook, based in Russia and 350 million users globally. Vkontakte allows several languages and in the same one the pro-ISIS pages have longer survival time than Facebook. The network is also used by ISIS to disseminate propaganda among the Russian language population.To carry out their research, Johnson and collaborators first identified added Johnson and collaborators point out that these add-ons live in a virtual environment where they find predators \u2013 cyber police, individual hackers, or network administrators \u2013 and are subject to an evolution that may include fusion with other aggregates or their disappearance. In the latter case, the add-on can re-incarnate with another name. By studying the creation of new aggregates, researchers found that, in a particular case, the occurrence of a terrorist act by ISIS was preceded by an increase in such activity. By studying the movement in the social networks of support groups, a certain terrorist organization could then anticipate the imminence of an attack.Not everyone agrees, however, and there are those who point out that Johnson and collaborators are actually not predicting anything and that the In order to establish a connection between a terrorist act and the increased activity of its support groups on social networks, it would then be necessary to demonstrate this in more cases. Moreover, the peculiar geographical distribution of terrorist activity, which is concentrated in a few regions of the planet, suggests that it is due to objective causes, partly associated with the social inequalities that prevail in the world, and that in order to prevent terrorist attacks it might be more effective to try to mitigate them.",
    "https://upload.wikimedia.org/wikipedia/commons/1/15/Transmetro_en_Ciudad_de_Guatemala.jpg": "According to the World Health Organization, a million and a quarter people die every year from traffic accidents around the world. Motor vehicles contribute, indirectly, to more than 2% of the deaths that occur annually at the global level.The car, a relatively recent invention that has had a great influence on our lifestyle \u2013 and death to some extent also \u2013 is in the process of undergoing a substantial transformation.This, in relation to the development of autonomous vehicles able to travel without the intervention of a driver.This type of vehicles, which can in principle respond more quickly and accurately to emergencies, would lead to a substantial reduction in the number of deaths from traffic accidents.As we know, there are several companies that are experimenting with prototypes of cars without a driver.The best known example is that of Google, which has been testing several vehicles equipped with sophisticated systems for the perception of their surroundings and the control of their movement autonomously.According to Google, their driverless cars have traveled more than two and a half miles without a driver in the states of California and Texas, and although they have had some shocks, these have not been responsible for their own. This had actually been the case until last February, when a Google car closed its way to an urban bus in California. Google recognized that the accident was his car. The crash occurred when the autonomous car intended to turn to the right for which it moved to the right end of the street. Before reaching the corner, however, it encountered an obstacle which forced him to open to his left without taking into account the urban bus approaching him at low speed. Google explained that the vehicle control software assumed that the bus would stop and leave him, which did not happen over the collision. In relation to this, Google claims to have made changes in the control software to take into account this type of eventuality. According to some opinions, autonomous cars are already a reality and will not pass many years before it is common to see them on the public road. Some technical and other problems will, however, have to be solved before this happens. One of these problems is the subject of an article published this week. In the magazine \u201cScience\u201d by researchers from France and the United States led by J.F. Bonnefon of the University of Toulouse, Bonnefon and collaborators address a problem related to car programming to avoid accidents in which people\u2019s lives are put at risk. Researchers consider the following situation. Suppose an autonomous car finds that a group of pedestrians is going through its path and in order to avoid running them down has the option of violently turning what would lead it to crash a wall and possibly kill its occupants.What should the car do?Priorize the lives of pedestrians or those of its occupants?Bonnefon and collaborators carried out an Internet survey with approximately 2,000 people looking for an answer. Respondents lean for a utilitarian solution that minimizes the number of victims. For example, if pedestrians are more than one and only the driver travels in the car, the \u201csoftware\u201d should make him turn and crash in the wall, possibly killing the driver. In contrast, the occupants are several and the pedestrian only one, the car must maintain its route.The majority opinions, however, correspond only to a version of \u201cdo God\u2019s will on my compadre\u2019s mules\u201d, because when the interviewees were asked if they would buy a car with a \u201cutilitarian software\u201d, programmed to kill him or some family member in a given case, most answered that they would not. Thus, a car programmed in this way would surely be a commercial failure.How should an autonomous car be programmed? In the first instance a programming with a utilitarian approach should be made mandatory. Paradoxically, however, as researchers point out, this would not help to decrease the number of fatalities due to traffic accidents by delaying the adoption of cars without a driver.Many problems must be solved before we have cars without a driver on the public road, including the moral disjunction regarding their programming to handle life-threatening situations, and for which Bonnefon and collaborators do not offer a solution. Car without a driver are still years ahead.And Even further away they are in our midst because of the urban disorder that reigns in the country. Indeed, if in the orderly streets of California there was a collision between an urban bus and car without a driver, what will not happen in the unordered traffic of our city?Certainly, the technical problems to solve to adapt a car without a driver to our environment seem formidable.",
    "https://upload.wikimedia.org/wikipedia/commons/f/fe/M%C3%A9xico_City_at_Night_2005.jpg": "How long has it been since you last saw the Milky Way? Unless you have recently traveled to the countryside, it is possible that several years have passed since you had the opportunity.In the new generations we may even find people who have never seen the Milky Way and the thousands of stars that can be seen by the naked eye on a dark night. And all this because of the increasing pollution by artificial electric light in urban centers, which makes it increasingly difficult to observe the details of the firmament.We are thus rapidly losing awareness of the world around us, which contrasts with the times before the expansion of electric light, when the nights were dark and the firmament and its stars were part of daily life. In this regard, an international group of researchers, headed by Fabio Falchi of the Institute of Sciences and Technology on Luminic Pollution inThiene, Italy, published on June 10 in the magazine \u201cScienceAdvances\u201d an atlas on light pollution globally. According to this article, approximately 83% of the world\u2019s population, and more than 99% of the world\u2019s 99% of the world\u2019s population, published in the magazine \u201cScienceAdvances\u201d an atlas on light pollution globally. It is also found that the Milky Way is hidden for one third of the world's population, as well as for 60% of Europeans and 80% of Americans.Falchi and collaborators also offer detailed information by country.Thus, the most polluted country is Singapore, followed by Kuwait, Qatar, the United Arab Emirates and Saudi Arabia.At the other end, eighteen of the twenty least polluted countries are located in Africa; the first place is Chad, followed by the Central African Republic and Madagascar.With respect to our country, although it is not in the group of twenty most polluted countries, a look at the light distribution maps included in the reference article shows areas of great luminosity.The most intense, of course, corresponds to the metropolitan area of Mexico City, with Puebla and Cuernavaca as satellites. Also, Guadalajara and Monterrey-Saltillo stand out, as well as La Laguna. Quer\u00e9taro, Aguascalientes and San Luis Potos\u00ed.We know that light pollution is just one of the many global emergencies that our planet suffers. Atmospheric pollution by the emission of greenhouse gases is another, as is pollution of the oceans by non-biodegradable materials, congestion of the Earth's spatial vicinity by artificial satellites, or pollution of the stratosphere by chemical compounds that destroy the ozone layer that protects the Earth from ultraviolet radiation from the sun, to mention a few. Such pollutions, which have a global range, are ultimately the product of the industrial revolution that occurred two centuries ago and have occurred in an extremely short time; short in comparison with other characteristic times of our passage through the planet. Indeed, the period of time \u2013 measured in thousands of years \u2013 that has elapsed since the invention of agriculture is a very small fraction of the time \u2013 measured in hundreds of thousands of years \u2013 that took our species to evolve to its present state from our immediate ancestor \u2013 common to the Neandertal species. As the paleontologist Stephen JayGould points out in the essay \u201cLamarck\u2019s Shadows\u201d, included in his book \u201cThe Thumb of the Panda\u201d, the rapid times characteristic of our cultural evolution \u2013 with all its positive and negative consequences, including the rapid pollution of the planet \u2013 are a reflection of the fact that this evolution has a Lamarckian nature. Jean-BaptisteLamarck explained the evolution postulating that species develop new physical characteristics as a way to adapt to the environment in which they live, which they inherit from their offspring. Lamarck\u2019s evolution thus results in a very efficient process, capable of producing substantial changes in a short time. Cultural evolution follows Lamarck\u2019s rule. Scientific or technological development, for example, can be inherited to a next generation by some oral or written means. The inherited development can be modified and transmitted to the next generation, evolving in this way efficiently. . The natural selection mechanism postulated by Darwin \u2013 which is largely accepted for animal species \u2013 is in short-term inefficient contrast and needs long periods of time to produce substantial changes. The short time in which we have generated major changes on the planet, compared to the time it has taken us to evolve as a species, can then be understood in terms of the differences between the models of Lamarck and Darwin. Which, of course, of little comfort serves us. In particular, it would be better for us to put a brake on light pollution before we forget that the sky has stars.",
    "https://upload.wikimedia.org/wikipedia/commons/1/15/Giordano_Bruno.jpg": "On February 17, 1600, Giordano Bruno was executed at the stake accused of heresy by the Roman inquisition. A monument in the Roman square \u201cCampo deiFiori\u201d \u2013the place of execution\u2013commemorates the event. Among other heretical opinions, Bruno argued in favor of the existence in the Universe of a multiplicity of worlds populated by intelligent beings. Although for scholars it is not clear to what extent this particular belief of Bruno influenced the sentence pronounced against him, the same one went against the current religious orthodoxy and deprived us of our privileged place as the only intelligent species of the universe. Today, four centuries after Bruno\u2019s execution, the possibility that there may be extraterrestrial worlds populated by intelligent beings, even more advanced than we are, is widely accepted. So accepted that it has given rise to serious \u2013 if indeed controversial \u2013 initiatives to discover some of these hypothetical worlds. In one of these initiatives, since the sixties of the last century, the firmament has been searched for signs. However, despite all efforts, no evidence has been found of the existence of extraterrestrial intelligence \u2013 in fact, not even of microscopic life outside our planet. Thus, the expectation regarding the existence of extraterrestrial life advanced by Bruno is still still being confirmed.On the other hand, today we know that we do not occupy a special place in the Universe as the only intelligent species. And this we find out, not looking in interstellar space, but searching for the past of our planet. In fact, we know that our species is the result of an evolution that took millions of years and that we were not always what we are today. There were even times when the process of evolution led to two different human species living together, for example, paleoanthropologists know of the existence of Neanderthals, a human species different from ours, but with a similar degree of intelligence, with which we lived for tens of thousands of years until its extinction some 30,000 years ago. Another example that has taken specialists by surprise is the Man of Flores, a human species until recently unknown that would have lived in Flores, an island of the Indonesian archipelago until about 50,000 years ago.The species of the Man of Flores was tiny, barely a meter tall, and because of this circumstance has become known as \u201chobbit\u201d.No one knew of the existence of the \u201chobbits\u201d until September 2003, when a group of researchers from Australia and Indonesia discovered a skeleton of that species in LiangBua, a cave on the island of Flores. The skeleton belonged to an individual \u2013possibly female \u2013 of 1.06 meters of stature, 25 kilograms of weight and a brain with a volume of 380 cubic centimeters \u2013 about a third size of the brain of our species.Although it was originally dated to 18,000 years, today it is known that the age of the restsosocila between the 100,000 and the 60,000 years.Some specialists have suggested that the skeleton of LiangBuacresponde to that of the one of the This article was published by an international group of researchers headed by Gerrit van der Bergh of the University of Wollongong in Australia. In his article, van der Bergh and collaborators report the discovery of the lower part of the jaw and a molar of an individual, 20 percent smaller than the man of Flores and who seems to be his ancestor. The discovery was carried out in a place called Mata Menge on the island of Flores, about 75 kilometers from LianBua,The amazing thing about the finding is that the remains are 700,000 years old. According to the new discovery, the LiangBua skeleton does not correspond to a modern human with a pathology, as its ancestors inhabited the island of Flores for more than 700,000 years, when our species did not yet exist. According to van der Bergh and collaborators, the Flores man comes from a primitive human species that arrived at the island of Flores for more than 700,000 years. a Flores a million years ago and once there evolved towards a smaller body because of the shortage of food on the island. They consider, however, it is necessary to have new fossils to reach a more solid conclusion. While obtaining information from the remote past is not a simple task, today it is clear that on the path that has followed our species in its evolution until the present moment, on more than one occasion we have lived with species close to ours that finally became extinct, perhaps by our influence. Had not the Neanderthal or the Man of Flores been extinguished, would they have helped Giordano Bruno to release the bonfire? We cannot know, but given our tendency to racial discrimination, it is possible that it would have made no difference.",
    "https://upload.wikimedia.org/wikipedia/commons/7/7e/Francisco_de_Goya_y_Lucientes_-_Witches_Sabbath_-_Google_Art_Project.jpg": "The figures vary according to the source, but between the 15th and 18th centuries around 50,000 people in Europe, for the most part women, were condemned and executed \u2013 some at the stake\u2013accused of witchcraft. Since the 17th century, executions for this reason began to decrease to disappear in the next century. This, because the rational conception of the world was imposed on the magic vision of the world, which was the basis of the trials against witchcraft. There is no agreement among experts on the causes that led to witch-hunting in the 15th to 18th centuries, but some speculate that the so-called witches and witches prosecuted were actually scapegoats of the civil and religious authorities, who were presented as indirect responsible for natural and economic disasters. Thus, witches and witches were supposed to obey the forces of the demon, true guilty of the misfortunes of the people, and therefore deserved to be punished. With regard to this interpretation, Emily Oster of \u201cHarvard University\u201d, in an article published in 2004, notes that witch-hunting coincided with the cooling period of the land known as \u201cLittle Ice Age\u201d, which occurred between the 16th and 19th centuries. This period produced cold winters in Europe and a drop in agricultural production that brought famines and social instability. It is perhaps interesting to do a digression here to mention that Antonio Stradivarius made his famous violins with trees grown during the Little Ice Age; violins that, according to some specialists, owe their sound quality precisely to this circumstance.Returning to the agricultural disasters produced by the cooling of the planet, we can point out that, given the magical conception that was held at that time about natural phenomena, it is not difficult to understand that the common people could easily have come to be convinced that they were being attacked by the devil, as well as by witches, their intermediaries in this world. They played 500 years ago, they certainly haven't disappeared from the planet.So, many of us associate a witch with a toothless old woman, dressed in black and flying during the night mounted on a broom.Streetypes aside, we know that there are practicing witches in the world, although not with the supernatural abilities they claim and that would be peculiar to their supposed nature.It is possible that today's witches are not exposed to the same dangers that some centuries ago, which included that of being prosecuted, and sentenced to die at the stake.This, however, does not mean that they are not at risk, mainly in those places in the world where belief in witchcraft is still rooted in the population.We can mention, for example, that in a tea plantation in Jalpaiguri, in northeastern India, five women were tied up, tortured and murdered in 2003, falsely accused of having practiced witchcraft against a inhabitant of the town who died suffering from a bad stomach. This, at least, according to Boris Gershmande of the \u201cAmerican University\u201d in Washington, DC, who studied the influence of belief in witchcraft in 19 African countries south of the Sahara, in which belief in witchcraft is widespread. According to the results of his study, published in last May\u2019s issue of the journal \u201cJournal of DevelopmentEconomics\u201d, Gershmandocumenta with solid data and confirms what other researchers had raised: that belief in witchcraft has a negative social effect which constitutes a brake on economic progress to increase mistrust among the population and negatively impact the attitudes of cooperation and camaraderie. In contrast to witchcraft, Gershman does not find an equivalent social impact on other supernatural beliefs among those found in hell, reincarnation, miracles and evil spirits. Witchcraft thus seems to be alone as a belief in the supernatural that promotes antisocial attitudes. 15th-XVIIIth centuries. This conception admitted the possibility that a certain natural phenomenon \u2013 a person\u2019s illness, for example \u2013 was caused by a supernatural force \u2013 the devil through an inhabitant of this world. Today we know \u2013 or at least have no proof of the contrary \u2013 that this is not so and that all the phenomena we can observe have a natural cause. And that even belief in witches \u2013 which survives among us persistently \u2013 could have a rational explanation.",
    "https://upload.wikimedia.org/wikipedia/commons/6/68/Idioma_griego_antiguo.png": "At an international congress held this week in Thessaloniki, Greece, to commemorate the 2,400 years of the birth of Aristotle, Greek archaeologist KonstantinosSismanidis claimed to believe that he had discovered the tomb of the Greek philosopher at Stagira, his birthplace in northern Greece. This, after a search that spread over two decades. That someone dedicates twenty years of his life to searching for the tomb of Aristotle, more than two thousand years after his death, is a sign of the enormous and lasting intellectual influence that this philosopher has had on Western civilization over more than two millennia. As it is also the case that this week an international congress has been held in his honor. Certainly, Aristotle is one of the most influential people in history and as such it is not surprising that his name is familiar to us \u2013 and that it is even active as his own name. And all this despite the time that has passed since his death and not having played a political or military role, roles that make it easier to transcend people. With the fall of the Western Roman Empire, Aristotle had little influence in the Europe of the beginning of the Middle Ages.The situation changed in the lower Middle Ages when Aristotle was rediscovered by being translated some of his works from ancient Greek into Latin or Arabic into Latin.In the 13th century, some Aristotelian ideas were reconciled with the doctrine of the church and incorporated into it by Thomas Aquinas.Despite the persistence of Aristotle throughout history, however, not everyone has a positive view of his intellectual legacy.British mathematician Bertrand Russell, for example, was very critical of the negative role that in his opinion \u2013 through the church \u2013 the Aristotelian ideas have played in the development of science in Europe in the 16th and 17th centuries. Among other aspects, Bertrand Russell reproves the little importance that Aristotle gave to observation, which we know is a fundamental element of the scientific method. In his book \u201cThe Impact of Science on Society\u201d, Russell writes: \u201cObservation versus authority: For modern and educated people it seems obvious that questions of fact should be verified by observation and not by consulting authorities of the distant past. But this is an entirely modern conception that hardly existed before the 17th century. Aristotle claimed that men had more teeth than women; although he was married twice, it never occurred to him to verify this statement by examining his mouth by his wives.\u201d As Russell points out, in his work \u201cHistory of Animals\u201d Aristotle also states that the bite of the shrew is dangerous for horses, especially if the muse is pregnant and that an elephant\u2019s insomnia can be cured by rubbing the animal\u2019s shoulders with salt, olive oil and hot water. In the field of physics and astronomy, some ideas that Aristotle was holding are equally known and that science\u2019s observation and experimentation proved to be wrong. Aristotle stated, for example, that in the absence of an impulse an object in motion would lose its Today we know that this is wrong, thanks to Galileo Galilei.Aristoteles identified four causes to explain the changes that we observe in the world.Two of these causes are the efficient cause and the final cause.Science recognizes only the first of these.The second, which should have disappeared from our sight a good time ago, remains, nevertheless, still in force.The final cause is employed by those who defend that the world and its evolution are the product of an intelligent design that seeks a certain end and outside of the physical laws.We have thus Aristotelian ideas even living among us.More than two thousand years after they were stated and despite the many incontrovertible evidence that what really works for us is the scientific method.To convince us of this last, it is enough to think about the multiple technological applications of science, among which are modern medicine, the Internet and interplanetary explorations, to put only three examples.So, using the scientific method we now know, for example, that madness is not the product of demonic possession and that to cure it we do not have to submit it. We also know that the celestial bodies move according to the laws of physics \u2013 the same ones that follow the objects on our planet \u2013 and not driven by gods as Aristotle maintained. Certainly, using the scientific method we now understand that many things that we once believed to be true are actually false.What is more difficult to understand is that there are still those who are not convinced.In addition to the above, what is remarkable is that, at 2,400 years away, in one way or another, we are still talking about Aristotle.",
    "https://upload.wikimedia.org/wikipedia/commons/2/22/Al_Azhar1.jpg": "On August 1, 1859, Vicente Chico Sein, then governor of the state, gave life to the Scientific and Literary Institute of San Luis Potos\u00ed \u2013 an immediate prior to the UASLP \u2013 and entrusted him with the mission of providing preparatory and professional education in the state. The Institute fulfilled its function, surviving even the misfortunes that our country crossed in the next half century. At the beginning of the decade of the twentieth century of the past century, however, it was under the critical eye of those who considered that their graduates had a low professional quality and that they would do better to close it. In a speech delivered during the graduation ceremony of students of the Scientific and Literary Institute in February 1921, Governor Rafael Nieto, referring to the many enemies of the Institute, said: \u201cMany of those enemies argue that higher education is a luxury in the mezquinity of our economic environment; that if we are not in a position to even moderately attend elementary and primary education of the State, it is absurd to spend a good part of our budget on the formation of an ar intellectual isthocracy; that the rickets of our economic resources only allow the Institute a precarious and petty life, and therefore, only mediocre professionals who are going to swell the ranks of the intellectual proletariat can leave it.\"Today, when it is evident the critical role that higher education has in the development of a country, it is surprising that there is anyone who dares to soften this type of argument, even though obviously they had a political background. In response, Rafael Nieto argued: \"It is true that it is a reprobable anomaly that we have a professional establishment more or less well cared for and that we neglect elementary and primary education instead. The remedy is not, however, to suppress the good but to correct the bad.\" As a solution, Nieto decided to make the Institute an autonomous institution with respect to the state government and thus to remove it \"from the vaivenes of politics.\" The new university was born in this way \u2013 January 10, 1923 \u2013 the Autonomous University of San Luis Potos\u00ed, the first with this character in Mexico. This situation prevailed until the 1950s when, among other research initiatives, the Institute for the Research of Desert Zones (1954) and the Institute of Physics (1955) were founded. In the 1950s, however, the resources available to the University were not sufficient for research to flourish. At the federal level, while there was the possibility of obtaining funds for research, they were meagre and intermittent. Thus, in childhood, scientific research at the UASLP went through difficult times. The situation began to improve as the 1970s emerged when the federal government recognized that science and technology were two indispensable elements for the development of the country and substantially changed its policy in this regard. Thus, in 1970, CONACyT was created, with the mission of promoting the scientific and technological development of the country, and in 1984 the National Research System (SNI), which complemented the salary of researchers and The change in policies in support of science and education in Mexico has not stopped and continues to wind in the stern; in addition, it has become one of the best institutions of higher education in the country, both for its educational programmes and for its research capacity. More importantly, the progress of the University has not stopped and continues to wind in the stern; in an accelerated manner. Thus, over the last four years, under the rectorate of the master in architecture Manuel Ferm\u00edn Villar Rubio, the University has increased by more than fifty percent the number of its professors who are members of the SNI, created two new research institutes and expanded its state coverage with two new campuses: Tamazunchale and Salinas de Hidalgo.The change of the University, on the other hand, has not been limited to the quantitative. Centro Universitario de la Artes, which brought the artistic activities closer to the students of the various careers offered by the UASLP. And in this order also created the Bachelor's degree in contemporary art, which will begin to operate in the next academic cycle, and which represents an educational offer qualitatively different from that offered so far by the University. Thus, almost a century after the Scientific and Literary Institute was subjected to unsupported criticism, the immediate future of the UASLP looks bright. Far from the gloomy panorama that its detractors were trying to show.",
    "https://upload.wikimedia.org/wikipedia/commons/0/01/An%C3%BAncio_na_Av._Nossa_Senhora_de_Copacabana.jpg": "In a black commercial ad that appeared in 1965 on the cover of a magazine, Raquel Welch, the then famous Hollywood star, waits for us: \u201cI can\u2019t afford to be skinny\u201c, to then clarify: \u201cWhile filming movies for film or television is exciting and with many rewards, it also involves a relentless daily routine of long hours of work, from early morning to late evening. This often forces us to suspend food or dinner.\u201d Thus, the actress would have had trouble keeping the figure. Whoever has seen one of her films from the 1960s, however, will agree that Raquel Welchlogr\u00f3, in some way, solve his problem. How did she explain it herself in the advertisement of marras: the secret was a food supplement, tonic and pills, to increase the appetite and nutrients necessary to maintain the weight.At these times, in which fashion is to lose weight \u2013 not lift it \u2013 an advertisement like that of Raquel Wel Welchnos is surprising. It illustrates us, however, about the vaivenes that she has In classical Greece, and judging by the sculptures that have come to us from that time \u2013 the Venus of Milo, for example \u2013 the ideal body tended to be robust. This, in contrast to the fashion of ancient Egypt where the ideal body was rather thin. As the 20th century emerged, aesthetics demanded robust bodies \u2013as much as women lay in corsets to wear wasp waistbands. The 1920s brought an androgynic fashion in which women lost their waist. To recover it again in the 1950s, with Marilyn Monroe as one of its representative figures, and lose it again in the 1990s. In contrast to the fluctuations of fashion, the weight of the inhabitants of many countries of the world, including ours, is increasing continuously, and in an alarming way. A measure of the overweight of a person gives its body mass index, which is obtained by dividing its weight in kilograms by the square of its height in meters. A normal weight is defined by a body mass index between the meters. 18.5 and 25. An index between 25 and 30 defines overweight, and one greater than 30 to obesity. Thus, a person of 1.75 meters of height and a weight of 75 kilograms has a body mass index of 24.5, close to the upper limit of the interval that is considered normal. If that same person weighed 95 kilograms his index would be 31, which places him within the obesity range.On the other hand, considering specific cases, Raquel Welch would have had in the sixties a body mass index of approximately 19, a little lower than that of Marilyn Monroe. Thus, both were in the normal low range, despite the perception of them. This is not the case, unfortunately, of the majority of the population of the United States, since according to official sources, about seventy percent of Americans are overweight and of these approximately half are classified as obese. In Mexico, according to data of the Organization for Economic Cooperation and Development, the figures are not very different.A number of diseases, including cardiovascular diseases and diabetes, are associated with overweight and medical recommendations are treated to us. A research paper appeared this week, however, finds that the body mass index for which there is a lower mortality rate, for any disease, falls within the range corresponding to overweight. The reference article was published in the journal \u201cJournal of the American Medical Association\u201d by a group of researchers from the \u201cCopenhagenUniversity Hospital\u201d in Denmark. The article reports the results of a study carried out to correlate mortality, for any disease, with the body mass index. Data from three different periods were investigated: 1976-1978, 1991-1994 and 2003-2013, from more than 100,000 volunteers extracted from the general population of Copenhagen. The researchers found that for the period 1976-1978 the minimum mortality was given for a body mass index of 23.7, which is within the range considered normal. For the period 1991-1994, however, the index was increased to 24.6 and for the period 2003-2013 to 27. The latter value corresponds to the range considered overweight. only would not be harmful, but they would allow us to increase our life expectancy. As the authors point out, however, theirs is a study carried out with a specific type of population, white Danes, which might not be valid for other ethnic groups. Besides it would have to be confirmed by other independent studies. On the other hand, a body mass index of 27 means just a few kilos of more than the 25 index. Therefore, the bells should not be thrown on the flight and, in case of doubt, we should continue to take care of our weight.We should do so in order to take care of our health by following rational scientific studies. Not to meet the demands of fashions, which are quite capricious and changing, beyond all rationality.",
    "https://upload.wikimedia.org/wikipedia/commons/e/ec/Principia.jpg": "In a colloquium on the history of professional physics in Mexico, in which I participated a few weeks ago in the capital of the country, one of the speakers characterized the development of this discipline in Mexico as a random process in which things have taken place, not as a result of a scientific policy orchestrated at the federal level, which would have moved it forward step by step, but as a result of sporadic personal initiatives that have been successful in finding failure; all this depending on the circumstances they have faced. Given the little interest that science has aroused among our top authorities, it is not surprising that it has arrived in the country with a considerable delay. Indeed, as we know it today, science originated in Europe in the 16th and 17th centuries and began to show all its technological potential in the 19th century. In Mexico, in contrast, it was until 1970 \u2013 when CONACyT was created \u2013 that the federal government formally recognized \u2013 albeit with ups and downs in later administrations \u2013 that science and technology are unique elements for the development of the country. In Mexico, the resources with which they were given were modest and did not keep any proportion with the country\u2019s needs. Thus, Mexico remained alien to the scientific progress of the world until very recent dates. Certainly, there are objective reasons that explain it. For example, the climate of violence and political instability that characterized our country during much of the 19th century was certainly not the best breeding ground for the development of a Mexican science. The explanation is, however, only partial if we consider that Japan achieved, from the second half of the 19th century, a remarkable scientific development in very unfavourable circumstances, not radically different from those prevailing in our country. It is thus inevitable to make comparisons.As it is known, after the expulsion of the Spanish and Portuguese in the first half of the 17th century, Japan deliberately isolated itself from the world for more than two hundred years and only maintained a very restricted contact with Dutch and Chinese.This isolation had an abrupt end in the 1950s of the 19th century, when the country was forced to open up to trade with the United States under the threat of the cannons of In 1858, following the diplomatic efforts of Perry and other envoys of the United States government, Japan signed with the United States the \u201cTreaty of Friendship and Trade\u201d with which it resumed its trade relations with the West. Japan\u2019s claudication in the face of the threats of the United States was forced by the great technological disparity that existed between the two countries. And this claudication was not a minor matter, since the fact that the country was forced, faced with the threats of a foreign power, to change a policy that it had maintained for more than two centuries, caused the fall of the feudal regime that existed until then in Japan and the establishment of a central government headed by the emperor. In order to prevent in the future new threats from the outside, the new Japanese government gave itself to the few years the fall of the feudal regime that existed in Japan and the establishment of a central government headed by the emperor. We can also assess the relevance of the educational reforms introduced in Japan by the Nobel Prize in Physics awarded to HidekiYukawa in 1949. Yukawa was a physicist trained in Japanese universities in the 1920s and 1930s, and at the time of receiving the Nobel Prize he was a professor at Kyoto University. That is, the reform of the Japanese education system reached the point that, in the course of a few decades, a world-class scientist could be trained and border research could be carried out in Japanese institutions.While it is not possible to establish a close parallelism between Mexico and Japan, two countries with substantial differences in geography and culture, we can point out that in the nineteenth century the two countries suffered equally from political upheavals and aggression by more technologically advanced countries. And yet, the course that followed science in Mexico was very different from the course that followed in Japan: today the latter is at the cutting edge of technology, while Mexico suffers from considerable backwardness.If we are to learn from the Japanese experience \u2013 and that of other Asian countries \u2013 everything would not be lost and we could well overcome our scientific backwardness in a period of time measured in decades.This, if we get to work hard and in a coordinated way.",
    "https://upload.wikimedia.org/wikipedia/commons/9/92/Hemispheres.png": "It is not difficult to convince us that our ancestors, hundreds of thousands or millions of years ago, were subjected to all kinds of threats that put their survival at risk, including the possibility of being devoured by a predatory animal, which was certainly not the least of their worries.They were thus forced to have an eye on the cat and another in the doodle at risk ending up in the jaws of a tiger sabre teeth or some other predator.Apparently, the saying \u201cto throw one eye at the cat and another at the doodle\u201d had its origin in the need, in times past, to protect the meat hung in the doodle \u2013 iron instrument with tip in the form of a semicircle, which serves to have something hanged, according to the dictionary of the Royal Spanish Academy \u2013 against the bludges of the cat of the house.As it has been, and whether we apply it to the protection of food or the preservation of life, the saying points to the same need: that our brain should deal with two things at once, if it is too bad to find it Of course, the consequences of neglecting the scribble and losing the food reserve are not comparable to those that might come from an unexpected encounter with a leopard or a hungry bear. After all, although without food we would inevitably go through hunger, if we were eaten by a lion we could not enjoy the food even if we had it.A permanent waking state in anticipation of the attack of a predator was thus useful for the survival of our ancestors.And this, we know, was not exclusive to our species and equally important to other animals.So, we have to be able to develop mechanisms to keep a vigil even during the sleep when the perception of the surroundings is greatly diminished.How was this problem solved?According to specialists, developing two ways of sleeping.A first form with the two brain hemispheres in deep sleep, and a second with one of those hemispheres in deep sleep and another in an intermediate waking state, which is known as a unihemispheric dream.So, it is known that crocodiles can sleep, if they perceive a danger, with an open eye, with a deep sleep The open eye also points in the direction in which the animal perceives the threat. An article published in 1999 in the journal \u201cNature\u201d reports the results of an experiment carried out with a group of collar ducks that show that these animals sleep in a state of semi-vigility, with an open eye, in response to the perception of a dangerous situation. In the experiment four groups of four ducks were formed each and placed in line. The ducks placed at the ends of each line were in a more exposed position compared to those placed inside it. As a result, researchers found that the ducks of the ends slept with an open eye almost three times more frequently than the ducks of the center. A measurement of brain activity showed, in addition, that sleeping with an open eye is accompanied by a reduction of deep sleep activity in the cerebral hemisphere connected to the open eye.The crocodiles and ducks, among other animals, can sleep in a state of semi-vigility. Although we know that we do not practice unihemispheric sleep, according to MasakoTamaki \u2013Brown University \u2013 and collaborators, the so-called \u201ceffect of the first night\u201d, for which many people sleep restless the first night they sleep in an unknown place is a manifestation that one of the cerebral hemispheres is more vigilant than the other during sleep, as a result of the lack of familiarity with the room. Tamaki and collaborators come to this conclusion in an article published this week in the magazine \u201cCellBiology\u201d, in which they report the results of a sleep study in an unknown environment carried out with 35 volunteers. The researchers found that there was an asymmetry in the activity of a certain region of the brain hemispheres during the first night of the experiment and that this asymmetry correlated with the difficulty of falling asleep. They also found that the cerebral hemisphere that showed less deep sleep activity responded more to certain external stimuli and caused a greater physical response by the volunteer. On the other hand, the asymmetries observed the first night disappeared on subsequent night. In their results, Tamaki and collaborators conclude that the restless sleep that some experience the first time they sleep in an unknown place constitutes \u201can act of survival in an unknown and potentially dangerous environment, which keeps a hemisphere partially more vigilant than the other and which awakens the sleeper when unknown external signals are detected.\u201d Or, in other words, an act in which we keep an eye on the cat, since we need to sleep, and another in the doodle, in anticipation of some eventuality. Although, of course, this only figuratively, because unlike crocodiles and ducks, we sleep with both eyes closed.",
    "https://upload.wikimedia.org/wikipedia/commons/e/eb/A_Portrait_of_Global_Winds.png": "In September 2014, a team composed of public and private organizations from Canada, discovered at the bottom of the Victoria Strait, in the Canadian Arctic, the remains of the ship HMS Erebus sunk in 1847. This ship, together with the HMS Terror, was part of a British Arctic exploration expedition led by Sir John Franklin. This expedition, which left England on 19 May 1845 with a crew of 24 officers and 110 sailors, was intended to discover a navigable route between the Atlantic and Pacific Oceans through the Canadian Arctic. Far from fulfilling its objective, however, Franklin's expedition had a tragic end. The Erebus and Terror were last sighted by whalers around the end of 1845 in Baffin Bay. Both ships would have been trapped in the ice in September 1846 forcing the crew to winter for two consecutive years in the Arctic, dying some, including Franklin. At the end, the survivors tried to walk to an inhabited place, all of the company. The search for a route between the North Atlantic and the Pacific, known as the Northwest Pass, had been an obsession for the British for several centuries. Had there been such a route, it would have considerably shortened the sea route between Europe and the Far East. However, it did not exist because of the arctic ices that closed the passage to the ships of the time.Today, the extent of the arctic ices is decreasing due to the effect of climate change and this has opened to navigation the Northwest Pass during the summer. If the current rate of warming of the planet continues, experts predict that in the not distant future the Northwest Pass could be navigable all year round. And it does not seem that this rate will decrease; indeed, in the last months we have seen record increases in temperature. Thus, according to Japan's Meteorological Agency, the average temperature of last March exceeded 1.07 degrees Celsius at the average temperature of the 20th century. And for the last February, the corresponding figure was 1.04 degrees Celsius. In both cases, the average temperatures are 1.07 degrees Celsius. The data provided by NASA confirm that the months of February and March last were particularly warm. According to this agency, the temperatures of February and March last were 1.71 and 1.65 degrees Celsius higher than the average of the period 1951-1980. In annual terms, the year 2014 had an average temperature of 0.57 degrees Celsius higher than the average of the period 1961-1990, which made it the warmest year since 1850 when the climatic records began. 2015 in turn exceeded 2014 in this respect, recording a temperature anomaly of 0.75 degrees Celsius above the average of the period referred to. In addition to the above, experts expect 2016 to exceed 2016 as the warmest year since 1850. If the prediction of climatologists is fulfilled, for the third consecutive year the temperature of the planet will increase. While experts note that the temperature increases observed in recent years are partly due to the El Ni\u00f1o phenomenon \u2013 which has a cyclical influence on the climate \u2013 its main year will increase. It is climate change due to the emission of greenhouse gases into the atmosphere and that even without the El Ni\u00f1o phenomenon there would have been record temperature increases.In support of this view, according to data from NASA 15 of the last 16 warmest years since records occurred since 2001.As for the ice coating in the Arctic, this has been the lowest observed since records were held in 1969.For all of the above it is foreseeable that the extent of Arctic ice will decrease gradually.In fact, specialists contemplate that in the medium term the Northwest Passage will be navigable all year round.When this happens, curiously the expectations \u2013 at the expense of the health of the planet \u2013 of those who hundreds of years ago and with no greater objective base firmly believed in the existence of a passage between Europe and Asia through the North Atlantic. And if for some the search for this step did not prove to be a lucky company, at least they will have the comfort of thinking ahead in their time.",
    "https://upload.wikimedia.org/wikipedia/commons/0/0f/Beringia_at_Arctica_surface.png": "As is well known, the Spanish conquest of Mexico 500 years ago had a devastating effect on the native population that was reduced by 90% over the course of a century.This, due to the ill-treatment and unhealthy conditions that the conquerors imposed on the indigenous, but above all because of the diseases that the first imported into Mexico and for which the natives did not have biological immunity.The infectious diseases imported by the Spanish, in particular smallpox, have been partly responsible for the fall of Tenochtitl\u00e1n in the hands of Cort\u00e9s.And what happened in Mexico, recorded in accounts of the time, had counterparts throughout the American continent. An article appeared this week in the magazine \u201cScienceAdvances\u201d takes a look at the population catastrophe that our continent suffered with European conquest from a novel point of view: the one that offers us population genetics. This article was published by an international group of researchers from Australia, United States, Peru, Mexico, Bolivia, Chile and Argentina, headed by Bastien Llamas de \u201cTheUniversity of Adelaide\u201d, Australia. , Flames and collaborators report a mitochondrial genetic study carried out with 92 mummies and skeletons, with antiques between 500 and 8,600 years, coming from archaeological sites in Peru, the United States, Mexico, Bolivia, Chile and Argentina. It is known that mitochondrial DNA is inherited only through the mother \u2013 that is to say, inherited genetic information does not mix with that of the father\u2013 and this opens a window to reconstruct the genetic history of ancient remains through the maternal route. In the case reported by Flames and collaborators, mitochondrial DNA allowed us to glimpse the genetic history of the studied skeletons, taking place in the time until the first group of American settlers began their journey to the New World and isolated from other groups in Siberia. Additionally, the mitochondrial DNA technique allows us to determine when it was that human groups that have remained isolated for a long time had a common ancestor, and in this sense, Flames and collaborators conclude that the groups that The prevailing opinion among the experts was that the first settlers of America crossed from the eastern end of Siberia to Alaska, through Beringia, the land bridge that formed between Asia and America during the last glacial period. Until about 16,000 years ago, however, the ice layers that covered the north of the American continent prevented transit to the south, so that Bastien and collaborators speculated, based on their results, that the first inhabitants of America could have been isolated in the east of Beringia up to 9,000 years ago, before the ice recoil allowed them to travel to the south, possibly by a maritime route along the Pacific coast. On the other hand, according to Bastien and collaborators\u201call ancient mitochondria lineages detected in this study are absent from the present-day groups, suggesting a great rate of extinction.\u201d that European colonization caused a substantial loss of pre-Columbian lineages. The genetic study of Llamas and collaborators coincides in this way with the stories of population catastrophe in the American continent in the 16th century. The situation that occurred in the world 500 years ago, in which a portion of the planet that was isolated by something like 20,000 years was invaded and overwhelmed by another more technologically advanced portion, was unprecedented and not visible that could be repeated in a foreseeable future. For this we would have to wait for an undetermined time until other worlds outside the solar system were discovered that we could conquer \u2013 if it was not that we were conquered earlier. On the margin of the above, we could ask ourselves what would have happened with the conquest of the New World if the microbes instead of helping the Spaniards had been on the side of the Native Americans. As they were on the side of the Earthlings in the H.G. Wells novel \u201cThe War of the Worlds.\u201d This would have balanced the technological superiority of the conquerors. It was not so, however, with the result known . That is to say, the saying that the leanest dog is loaded with fleas is fulfilled.",
    "https://upload.wikimedia.org/wikipedia/commons/3/38/Gregor_Reisch%2C_Margarita_Philosophica%2C_1508_%281230x1615%29.png": "Given the applications that have been derived from the different sciences, it would seem that the obvious answer is that we should.There is the case, however, of people or groups of people under certain circumstances, not only deny scientific evidence, but use it to affirm prejudices against it, as we discussed in what follows.The scientific boom that we live has its origin in the Europe of the sixteenth and seventeenth centuries.One of the relevant scientists of those centuries \u2013 and those that followed them \u2013 is Isaac Newton.Among many other things, Newton developed a mathematical theory with which he could explain why planets move around the sun following ellipses.This theory has been highly successful, and among many other applications has been used by NASA, with obvious success, to launch and direct the spaceships that have visited other planets.The great achievements of physics inspired the development of other sciences.The success that they have achieved, however, has depended on the complexity of their subjects of study.The simplest \u2013 with everything and how complex they may come to be. They are the ones who study physics \u2013planets, atoms, solid materials, etc.. More complicated are those of biology \u2013 living beings\u2013, and even more so of psychology; not to mention sociology, which studies groups of humans. Thus, while physics and biology have had phenomenal successes that have resulted in modern engineering and medicine, sociology is more modest in this regard. However, given its implications, it is of great interest to study applications of the human behavior sciences to social development. In the week that ends today, one of these applications \u2013 in political science \u2013 was discussed in an outreach article published on the Internet site \u201cTheConversation\u201d by John Cook and Margaret Crane of the \u201cUniversity of Queensland\u201d, Australia, and refers to a possible technique to employ to derail Donald Trump in his career towards the presidency of the United States. Cook and Crane note that, according to the website \u201cPolitifact\u201d, 78% of the claims made by Trump fall into the categories of 1) false to a large extent, 2) false. Or 3) emphatically false, and only 3% are classified as true.The level of support of Trump's followers, however, has not declined because of the falseness of their statements and, on the contrary, has been strengthened.According to psychologists, the causes that motivate this apparently irrational behavior are equivalent to those that move those who deny scientific evidence if it contradicts any belief of their own; in which case, instead of weakening that belief they strengthen it.A typical example is climate change that is supported by a majority of climate scientists and that, however, has its legion of non-specialists who reject it. Thus, Cook and Crane consider that it would be ineffective to try to change the opinions of those who support Trump by demonstrating the falseness of their claims, and that it would be smarter to focus the batteries on the indecisive, trusting that they have a mind open enough to react objectively to the evidence.For this, a theory of inoculation that psychologists have developed to combat scientific denial would be used. By exposing the person to a weakened form of the \u201cdisinformation virus\u201d, in order to develop \u201cantibodies\u201d to combat the disease in full. For this, the facts as they are are are presented first, immediately the related myth and finally the techniques used by the myth to distort the facts are explained. Such techniques include the use of false experts and the simplification of complex problems \u2013 such as the one related to the wall Trump wants to build on the border with our country, which is impossible to realize as costly and would be useless according to some experts\u2013. They also include the presentation of individual opinions as representative of the contrary opinion of an entire collective, and the use of conspiracy theories such as those employed by those who deny climate change, affirming that scientific almism support is in fact the result of a plot by a majority of scientists who have agreed to deceive the lagent. Would the theory of inoculation work against Trump? Cook and Crane not be sure about the complexity of the political arena in which it would apply. The prediction of behavior of a human group is their own. In this case Cook and Crane point out that there are elements that make it even more complicated, including the dissatisfaction of people with the political establishment in the United States.For now, what if it is inoccultible is that1) despite the proven value of scientific knowledge \u2013 measured according to its applications \u2013 there is one who closes his eyes when he confronts objective evidence contrary to his beliefs and 2) that everything is used if it is a grid.",
    "https://upload.wikimedia.org/wikipedia/commons/5/5b/A.Cortina-Jos%C3%A9_Aparicio.jpg": "How many are fifty years in the history of the world?Although half a century is a relatively short period of time \u2013 even less than the life expectancy of a person today \u2013 it is long enough for substantial changes to occur in the world during the first half of the 20th century.During the first half of the 20th century, for example, two world wars occurred that altered the global balance, marking the decline of Britain as an imperial power and the rise of the United States and the Soviet Union as dominant countries. Likewise, during the second half of the 20th century we witnessed the confrontation between these two countries in the form of the Cold War, just as at the end of the same period with the dissolution of the Soviet Union.This last left the United States alone as a dominant power at the global level.In the field of local history, in the past few days I dedicated myself to reviewing some aspects of the history of the Autonomous University of San Luis Potos\u00ed throughout the last half century; in particular, the history of the emergence and consolidation of physics in our university. \u201cHistory of the emergence of professional physics in Mexico\u201d, organized by UNAM in honor of Dr. Jorge Flores Valdez, who was one of the creators in 1984 of the National System of Researchers. Physics arrived in San Luis Potos\u00ed in 1955 by Gustavo del Castillo and Gama, who a year earlier had obtained a doctoral degree in physics from\u201cPurdueUniversity\u201d, Indiana, United States.Once back in Mexico and towards the end of that year, del Castillo got the UASLP to create both an Institute of Physics and a School of Physics and invited Candelario P\u00e9rez Rosales \u2013also a graduate of \u201cPurdueUniversity\u201d\u2013 to join efforts to start the operation of the latter. Thus, the school began courses on March 5, 1956 with 9 students, and with Gustavo del Castillo and Candelario P\u00e9rez Rosales as teachers of physics and mathematics, in respective form. As Candelario P\u00e9rez writes in his book \u201cPhysica at dawn\u201d \u2013issued by the UASLP\u2013the local press reported on the event with the following eight columns: \u201d Today San Luis will form his own physicists. The new faculty is born with the best auspices. Mexico\u2019s progress requires a large number of physicists.\u201d The auguries of the press, however, took a long time to crystallize, because although physics in our university initially counted with two off-series promoters, Gustavo del Castillo and Candelario P\u00e9rez, these were possibly ahead of their time since the UASLP in the decades of the fifties and sixties was not yet in a position to host and grow a field in which teaching and research are strongly linked. Since we do not have the space here enough to tell in detail about the development of physics in our university, it suffices to mention that in 1978 four full-time researcher places were created for the Institute of Physics and that this was a key event, since one of the problems that physics had in its beginnings at UASLP was precisely the lack of full-time places. Years later, in 1983, the PhD program in physics that had its first graduate in 1986 \u2013 Pedro Villadi\u00f1or Gonz\u00e1lez, with a thesis directed by Jes\u00fas Ur\u00edas Hermosillo\u2013, which meant the first doctoral degree in physics awarded in Mexico by a university outside the metropolitan area of Mexico City.Since 1984, and taking impetus with the creation that year of the National System of Researchers, physics at UASLP has grown gradually and the University today has consolidated itself as one of the most important research centers in this discipline in Mexico. Moreover, the development of research in the UASLP has not been limited to physics and many other fields have also had remarkable growth. One measure of the strength of the UASLP in the field of research is the number of its professors who are members of the National System of Researchers and who today reach 464. An additional measure of this strength gives us the speed with which this number is growing. Thus, in the four years that correspond to the period of the Rector, master in architecture Manuel Ferm\u00edn Villar Rubio, this number grew by more than fifty percent. MY first contact with the UASLP occurred in 1967 when I entered as a student to the At that time the University had a very poor infrastructure and resources to operate in extremely limited. Today we can see a drastic change. So, and to give just one example, in fifty years the UASLP has gone from being an institution in which even an electric typewriter was an unthinkable luxury, to being a university that has sophisticated research laboratories. Gardel sang that twenty years are nothing, which is clearly not a universal truth. In the case of the UASLP the last fifty years have been so much that today it is unrecognizable.",
    "https://upload.wikimedia.org/wikipedia/commons/9/94/Text.jpg": "Was the world created by God or was it created alone?In addition to the fact that the question is unclear, the majority overwhelming opinion among scientists is that there is no way to find out; there is not at least one using the characteristic methods of their profession.Thus, it is not surprising that an article published in the scientific journal PlosOne last January, in which repeated references are made to the \u201cCreator\u201d \u2013 so, with initial capital \u2013 has provoked a series of negative comments; so negative that even the editor of the magazine decided to remove it from it in previous days.The reference article was published by three Chinese researchers headed by Ming-JinLiude the University of Science and Technology ofHuazhong, Wuhan, China, and it describes the results of a research on the biomechanics of the human hand. Specifically, it describes a research aimed at making clear how the fingers and fallangs of the human hand coordinate with each other to perform all the different and complex functions that are characteristic to them \u2013 and that differentiate us from other species. For this purpose, the researchers put together a group of volunteers, 15 women and 15 men, who were seated on a table with their right arm resting comfortably near the edge of the table and were asked to perform 33 manual tasks. These included from holding with force rods of different diameters, to acting scissors or taking objects delicately with index fingers and thumb. In order to follow in detail the movements of the fingers and their phalangs, the volunteers used special gloves equipped with electrical resistances that allowed to record the changing angles of the joints of the fingers. Thus, the researchers recorded the complex movements that the human hand can perform and the coordination that exists between the different fingers to perform each task. In the article in which they describe the results of their study, however, the researchers included on several occasions references to the Creator, who would have designed hands capable of carrying out movements of great complexity. In the summary of the article, for example, they included the following sentence: \u201cThe explicit functional connection between the architecture and hand coordination indicates that the biomechanical characteristics of the architecture of tendons that connect muscles and joints is a design of the Creator to carry out a multitude of daily tasks in a comfortable way.\u201d They also make comments in the same direction on two more occasions in the main text of the article.The negative reaction to the unfortunate comments of Min-JinLiu and collaborators was directed more to the magazinePlosOne than to the authors of the article and was initiated by James McInerney of the \u201cUniversityof Manchester\u201d who called that magazine a joke for not taking care of the texts it publishes. Related to the latter, it must be noted that to be accepted by a scientific journal, an article must go through a critical review by other experts not involved with the research. For some reason not determined, however, the referees of the article, like the editor of the magazine, did not detect the use of inappropriate language employed by the authors and would have accepted it for publication without comment.In a subsequent message, McInernye wrote that his original comment was strong because the creationism had been a fastisicism As we know, there have been conflicts between science and religion since the 16th century when the first began to take its present form and began to question the view of the world offered by religion.While over time the roughness between science and religion has become more fluid as their respective fields of action have been demarcated, the conflicts have not disappeared altogether and, for example, have survived in the form of the creationist movement.It is not clear whether Min-Jin Liu and collaborators are adhering to this movement and this is what would have motivated his references to the Creator\u2013which are unnecessary and do not contribute to the article,if it is not advertising, so be this negative\u2013The authors, on their side, defend themselves by pointing out that English \u2013 language in which they wrote the article\u2013 is not their native language and that for them the word Creator does not have the connotation that has been given to it and they consider that the word \u201cNature\u201d is closer to what they wanted to say. research has the right to express itself as they think it most appropriate, at the same time that the editor of a scientific journal has the obligation and prerogative to accept or reject a text based on its content and the editorial policies of the magazine in question.In these circumstances, PlosOne, which is supposed to be a high profile scientific forum with rigorous editorial evaluation, appears as the only culprit of the incident.As easy as it would have been to have asked Min-JinLiu and collaborators to remove any inappropriate reference in his text \u2013 or to clarify what they would have meant.",
    "https://upload.wikimedia.org/wikipedia/commons/a/a5/Franz_Kafka_Die_Verwandlung_1916_Orig.-Pappband.jpg": "As we know, Franz Kafka\u2019s short story \u201cThe Metamorphosis\u201d begins when Gregor Samsa, his central character, wakes up one morning turned into a monstrous insect. Although the author does not provide detailed information about it, some in the past have assumed that Gregor was transformed into a sort of giant cockroach. Vladimir Nabokov, the author of \u201cLolita\u201d, however, did not agree with this interpretation. According to this author, the insect\u2019s bulging back and belly as described by Kafka, indicate that it was a beetle and that in the only thing he remembered the cockroaches was in the brown color of his body. Analyzing passages from the story, Nabokov even determines that the insect was about a meter long. The morphology of the bug in which Gregor was transformed, however, is not relevant to Kafka\u2019s story. In fact, as Nabokov points out, his transformation was not complete, since he was still lying on the bed, when he was still unaware of such transformation, Gregor opened and closed his eyes thinking that he was halluculating, and \u201ca normal beetle has no eyelids and therefore cannot open and close its eyes\u201d; it would then have been a \u201cscarab with human eyes.\u201d On the other hand, aside from the entomological discussion around Grego rSamsa, it is worth commenting that cockroaches \u2013 of real size \u2013 with everything and how repugnant they turn out to us, also have their remarkable aspects. In particular, as we know, cockroaches can move very quickly and transit through extremely small crevices. We also know that they are extremely resistant and can survive a flatton without apparent damage. And all this can inspire applications, as we will see below. In an article published on 8 February in the magazine \u201cProceedings of the National Academy of Sciences\u201d by Kaushik Jarayam and Robert Full, researchers at the University of California, Berkeley, we describe the results of a study carried out with cockroaches native to the United States. The purpose of that study was to evaluate the ability of cockroaches to transit through narrow slitches and limited spaces vertically. . Through high-speed filming, researchers found that the cockroaches studied, with a height of approximately 12 millimetres, are able to cross a 3-millimeter-high slit in a fraction of a second, compressing their bodies at 40-60%. The procedure used by cockroaches to travel through the opening is complex and involves a series of steps. First, the cockroach explores with its antennas the space around it in search of an escape route. Once it detects a slit introduces its two antennas and decides whether the space beyond it is a viable route. In the positive case, it repeatedly and quickly introduces the head through the slit and begins to introduce the rest of the body, first the chest and then the abdomen, helping with a rapid movement of legs. During the passage of the chest through the narrowest slits it is when the animal experiences the greatest compressive forces, at the same time that the movement of the legs is severely limited. It is at this stage that the cockroach is most exposed to failure in its attempt to cross the slitch.Jarayam and Full also studied They found that cockroaches were able to move at a speed of about half a metre every second, even in spaces with 6 millimetres of height \u2013 half the height of the animal \u2013 and that only for lower heights reduce this speed.This implies that even with the severely deformed body and under great compressive forces, the cockroach's legs do not lose their ability to drive it.In order to determine what degree of compression forces a cockroach can withstand, the researchers subjected them to different tests and found that they can withstand forces of up to 900 times their weight without suffering damage.Croaches base their remarkable abilities on an external cover \u2013exoskeleton\u2013 formed by rigid parts, allowing it to give strength to the legs, and that it is at the same time flexible and capable of suffering great deformations without suffering damage. Inspired by cockroaches, Jarayam and Full designed and built a robot capable of compressing their body in 54% and suffering compression forces of 20 times its weight, which could slip through. The cockroaches are not well-known and we may not find many who sympathize with them. Even Gregor\u2019s family was horrified by their appearance, which although not necessarily a cockroach, was not too different either. Perhaps, however, we could find some fans among those who serve as a source of inspiration.",
    "https://upload.wikimedia.org/wikipedia/commons/6/67/Cercopithecus_mona_01_MWNH_520_1.jpg": "In 1856, the remains of a human skeleton, including the upper part of the skull, two femurs, bones of the two arms and part of the pelvis, were discovered in a mine of the Neander River valley.The meaning of the discovery was not immediately understood and only later the specialists realized that it was a different species from ours.The individuals of this species, with similarities but also differences with us, are now known as Neanderthals, by the place where their remains were first recognized.Nanderthals certainly shared some characteristics with us \u2013 starting from standing upright \u2013 at the same time that they were different. Anatomically, although they were not taller than us, they were more corpulent, with a bulkier chest and in the form of a barrel, and also thicker and shorter bones of arms and legs.In addition, they lacked chin, they had wide nose, a skull less high than ours and bones of very prominent eyebrows. This image is more favourable to us than 150 years ago, when the Neanderthals were little more than hairy apes with a minimum of intelligence. Among other things, we now know that they made and used tools, buried their dead, developed hunting strategies and painted their bodies of colors.It is even known that they had on average a brain bigger than ours \u2013 although it has not been proven, for example, that they had the ability to speak.Neanderthals, indeed, have considerably increased their status among us in recent decades.And they have done so to such a degree that they are now recognized as distant cousins of us, from whom we have evolved half a million years ago.However, and to be distant cousins, however, the physical appearance of Neanderthals was different from that of modern men with whom they lived until about 40,000 years ago.This, at least, according to the reconstructions of the anatomy of Neanderthals. Neanderthals carried out by specialists who show them as individuals with whom we might not like to meet on a dark night in a dead end.The latter, however, apparently was not shared by some ancestors of ours, contemporaries of Neanderthals. Indeed, through genetic studies carried out with fossil remains, it has been found that modern humans, with the exception of Africans, share genetic information with Neanderthals.This has been interpreted as evidence that both populations crossed some 50,000 years ago, presumably in the Middle East, once modern humans left Africa for Europe and Asia. Thus, if this hypothesis were true, our ancestors, far from avoiding or waging war on Neanderthals, would have crossed them.An article appeared this week in the magazine \u201cNature\u201d goes even further and suggests that contacts between modern and Neanderthal men occurred on several occasions and for a considerably longer time than was previously thought.In particular, they occurred some 100,000 years ago, possibly in the Middle East, between one This article was published by an international group of researchers led by Martin Kuhlwilm of the Max Planck Institute of Evolutionary Biology in Leipzig, Germany. Kuhlwilm et al. base their conclusions on a genetic analysis of a fragment of Neanderthal bone discovered in a cave in the Altai mountains in Siberia. This analysis shows that, although this first group of modern men who left Africa ended up dying out, a small fraction of their genes survived as part of the Asian Neanderthal genome. In contrast, a genetic study of European Neanderthals carried out by the same authors did not show an equivalent contribution of modern man genes. Over the last few years, evidence of the crossing of the Neanderthal population with our species has accumulated. This, it was thought, would have occurred after these latter migrated from Africa to Europe and Asia about 60,000 years ago. Kuhlwilm\u2019s results and collaborators suggest that contacts between both species actually occurred much earlier, at least 100,000 years ago. To take into account, however, that the crosses between our species and those of the Neanderthals is not something that is unanimously accepted by the experts. Thus, an alternative explanation to what was found by Kuhlwillm and collaborators is that in reality the fragments of genome that would provide evidence of the crossing between Neanderthals and modern humans, is actually part of the original genome common to both species before they were separated half a million years ago. Otherwise, if the explanation of Kuhlwillm and collaborators was true, it would be shown that, in fact, in tastes genders are broken, and that our ancestors, in terms of choosing a partner, had a quite liberal attitude.",
    "https://upload.wikimedia.org/wikipedia/commons/9/99/PenasBlancas%2C_part_of_the_Bosawas_Reserve%2C_Jinotega_Department%2C_Nicaragua.jpg": "According to the experts, the orangutans separated themselves from the evolutionary line that led our species some 12 million years ago. Although this seems a very long time, in relatively small evolutionary terms. As a consequence both species share some physical characteristics. In particular \u2013 together with the other two great apes, gorillas and chimpanzees\u2013human and orangutans possess a higher degree of intelligence that distinguishes them from other less evolved species. At the same time \u2013 and in this we will have to coincide \u2013 there are great differences between the orangutans and humans that have to do with our greatest brain development. Thus, while the orangutans are able to use tools, they are relatively simple, without any comparison with the degree of technological development that humans have reached. Another difference that has traditionally been thought to exist between orangutans and humans is our ability to speak, which would not have the first ones. This article discusses the case of Tilda, a female orangutan currently confined in the zoo of Cologne, Germany. Tilda is capable of articulating consonants and vowels with a rhythm that resembles that of the human voice. She also does so on specific occasions, as when she demands food from her carers, Tilda was captured in Borneo in 1967 at the age of approximately two years. Tilda is not known to have been her until 8 years after her capture, when she was acquired by a private collector. After this, she was a guest of several zoos in Switzerland and Germany until she stopped in Cologne. Lameira and collaborators think that at some point during the eight years she remained hidden, Tilda was trained to participate in some kind of spectacle and that from this training resulted her ability to articulate sounds.According to Lameira and collaborators, her results show that orangutans do not have respiratory, neurological or articatory impediments to emit vocal sounds and consonant to a frequency proper to human language. With this, in some way the gap between humans and orangutans is narrowed. An article published this week in the magazine \u201cBehavioralEcology and Sociobiology\u201d narrows this gap even further. In that article it is shown that the orangutans are able to agree with the aim of, with advantage, giving a deadly tunda to another orangutan. The work was published by an international team of researchers, with Anna Marzec of the University of Zurich as leader, and in it describes an episode of violence led by a couple of orangutanesen against a female orangutan. The episode occurred in the natural reserve Mawas on the island of Borneo.The participants in the incident were Kondor, a young female who started the attack, Ekko, a male who accompanied her in the assault, and Sidony, the victim, a female of advanced age who was in the company of her son, even dependent on her.Kondor and Sidony had already had at least one violent encounter: years ago,Si Dony was seen beating and biting Kondor, who had approached a son of that. Moments before the attack described by Marzec and collaborators, Kondor and Ekko met Sidony, and although Ekko approached the latter, he showed no interest in her; on the contrary, he walked away to mate with Kondor. This one, however, suddenly interrupted him and threw himself at Sidony followed by Ekko. Sidony was thus attacked by the pair of orangutans who acted accordingly: while one attacked the other prevented him from fleeing, or both of them attacked simultaneously. Kondor instigated each attack while Ekko inflicted the greatest damage. The assault lasted for 33 minutes and was only interrupted by the appearance of Guapo, a male orangutan who came between the two females every time Kondor attempted to attack and eventually escort Sidony out of the scene. The attack, however, proved fatal for Sidony, who died days later to The incident documented by Marzec and collaborators shows that a female orangutan is capable of manipulating a male and instigating a deadly attack against another orangutan female with whom she had previously had problems. Thus, it turns out that the orangutans are capable of carrying out actions that we would have previously thought are only human-like. We should not, however, preempt ourselves to demonize all orangutans by a pair of ruffians who might well not represent the whole species. In any case, in the event of doubt, in the event of encountering an orangutan - male or female - the most prudent would be to undertake the flight as soon as possible.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d1/Tendencia_alcista_bajista_lateral.jpg": "Today, the graphs showing how a certain amount varies over time are not unusual to us. In the past few weeks, for example, we have seen published in different graphic media showing us how the dollar-weight exchange rate has increased, with small fluctuations, to reach at some point the 19 pesos per dollar. Likewise, it is not difficult to find graphs that indicate that over the last year the price of the barrel of the Mexican oil mixture has plummeted from a price close to 100 dollars to reach some time a value below 20 dollars.As we know, an image says more than a thousand words and this is particularly true of the graphs.By means of a graph we can visualize the trend that holds a certain variable amount and estimate that it is what we could expect for the future.For example, in the particular case of the increasing and decreasing trends, in respective form, of the dollar-weight exchange rate and the price of the Mexican oil, we can perhaps come to the conclusion that things don't look too well for us this year. This has not always been the case, however. Graphing a certain amount as time passes \u2013 the price of oil, the price of the dollar, the life expectancy over the last century, or the position of a planet in the firmament over the course of the year, to give some examples. \u2013 has required a certain capacity of abstraction that has taken us millennia to develop. The specialists had so far thought that it was not until relatively recent dates that we managed to develop this capacity. Specifically until the fourteenth century as a result of the work of a group of thinkers established in the \u201cMertonCollege\u201d, Oxford, known as the \u201cOxford Calculators\u201d. An article published this week by MathieuOssendrijver of Humboldt University in Berlin, Germany, in the magazine \u201cScience\u201d \u2013 and which won the cover of the magazine \u2013 comes, however, to a different and surprising conclusion. According to Ossendrijver, the astronomers of Babylon of the 350-50s before our era had already developed a mathematical technique to calculate the position of the planet. Jupiter that precedes the work of the Oxford Calculators for almost 1,500 years.If we look at the sky on a clear night we can see that the stars move along a simple path always in the same direction. The planets, in contrast, follow a more capricious path, sometimes moving in one direction and sometimes in the opposite direction. Given this complication, for ancient astronomers it was more difficult to describe the movement of a planet than that of a star. Astronomers in Babylon, however, managed to overcome this difficulty by using Jupiter speed charts for different times. Ossendrijver comes to this conclusion after studying over several years several clay tablets with cuneiform inscriptions coming from Babylon, which are sheltered in the British Museum.To conceive a graph describing how Jupiter's speed changes \u2013 and not its position, as it would be more natural \u2013 a considerable abstraction capacity is necessary.According to Ossendrijver, the Babylonians also knew how to make use of that graph to calculate the position of the planet at a given time. the latter corresponds to the discipline known as integral calculus, developed by the European thinkers in the seventeenth century. The mathematical knowledge and abstraction that had reached the Babylonians in some way was lost and had to be rediscovered a long time later in Europe. It would not even have come to the Greeks, who would not have conceived graphs with the degree of abstraction achieved in Babylon. The fact that the Babylonians more than two thousand years ago have been able to conceive abstract graphs and have understood some basic concepts of integral calculus \u2013 which even today is not a simple subject, as any student of science or engineering careers can attest \u2013 is surprising. As much as we cannot expect that the capacity of abstraction has been a general rule among the population of Babylon, as it is not \u2013 although it is more widespread \u2013 even today in the world. Indeed, as Ossendrijver comments, it is not even clear if abstract graphs were of ordinary use among Babylonian astronomers.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d2/Voyager.jpg": "On September 6, 1977, the Voyager 1 space probe was launched from Cape Canaveral with the primary mission of studying the giant planets Jupiter and Saturn, as well as Titan, the largest satellite of the latter. Once completed its primary mission, the Voyager 1 spacecraft continued a space trajectory that has led it to enter interstellar space. At this moment the probe is located at a distance such that the signals it emits take about 17 hours to reach the Earth. Voyager 1 is also known because it carries on board a phonographic disc of gold-coated copper with 115 images of the Earth, as well as messages in 55 languages and music recordings from various parts of the world, including a piece of Mexican music \u2013The Cascabel of Lorenzo Barcelata in mariachi version. All this with the aim of telling about our existence and our culture to the hypothetical aliens who might happen to encounter the ship in a remote future. This would have been due to the pretension of the promoters of the project \u2013 headed by Carl Sagan of CornellUniversity \u2013 not to present us to extraterrestrials as an aggressive civilization and given to conflicts.On the other hand, as part of the project \u201cThelastpicture\u201d, in November 2012, a silicon disk was launched into the space attached to a communications satellite in which a hundred images of the Earth were encrypted. The purpose of the project was not so much to make known to the extraterrestrials of our existence, but to create a time capsule that preserved our memory on a geological time scale. In relation to the latter, the impellers of the project \u201cThelastpicture\u201d note that at the height at which communications satellites orbit \u2013 about 36,000 kilometers \u2013 there is no friction with the atmosphere so that these satellites will remain in orbit indefinitely \u2013unless by accident they collide with a meteorite or suffer some other percancer. In contrast to the Voyager project, \u201cThelastpicture\u201d has no reluctance to show our violent behavior and includes a photograph of a nuclear explosion, as well as soldiers during the First World War wearing gas masks. Moreover, aside from any attitude of pretending to hide or make explicit our warrior vocation to the hypothetical extraterrestrials or earthlings of the remote future, it is interesting to ask us about the origin of this vocation. At this point, specialists do not agree. Were groups of nomadic hunter-gatherers violent? Or is our violent behavior a product of sedentaryism that brought the invention of agriculture, as a way of defending a territory or a food deposit? With regard to this, an article published this week in the magazine \u201cNature\u201d by an international group of researchers headed by Marta Miraz\u00f3nLahr of\u201cCambridge University\u201d The United Kingdom reports a study carried out with skeletons of at least 27 individuals, who were found semi-buried in Nataruk, near Lake Turkana in Kenya. The skeletons correspond to hunter-gatherers, both men and women, who died about 10,000 years ago. Ten of the skeletons are well preserved and this allowed to determine that they belonged to individuals who had a violent death.Some by blows to the head and others by invoices produced by projectiles or cutting instruments. Likewise, the disposition in which the remains of two individuals were found suggests that when they died they were tied to their hands. The skeleton of a fetus or a newborn was also found along with the remains of their mother. Miraz\u00f2nLahr's discoveries and collaborators suggest that violence existed among groups of hunter-gatherers and that it is not necessarily related to sedentarism. The same researchers, however, offer an alternative explanation, according to which 10,000 years ago the life among hunter-gathers had some of the elements of sedentarism. In any case, they conclude, \u201cNataruk\u2019s dead are a testimony of the age of intergroup violence and war.\u201d So, one way or another, it turns out that war has accompanied us for a long time, either as a result of our evolution as a species, or as an intrinsic element of our social organization. In these conditions should we hide our true nature from aliens?Since the probability that someone will find in a distant future any of the messages sent into space is virtually zero, this question is perhaps idle. And it is, above all, because sending messages into space in a bottle is not a fun activity.",
    "https://upload.wikimedia.org/wikipedia/commons/6/65/%D0%9A%D0%B0%D1%80%D1%81%D0%BA%D0%BE%D0%B5_%D0%BC%D0%BE%D1%80%D0%B5_%D0%A1%D0%92%D0%9F.jpg": "The Siberian city of Norilsk has a world record: it is the closest city to the North Pole among those with a population greater than 100,000 inhabitants. In fact, Norilsk is located above the Arctic polar circle, at a latitude around 68 degrees. Given what we know about Siberia, we might suspect that Norilsk is suffering from very crude winters. A consultation of the Internet site \u201cWeatherChannel\u201d confirms our suspicions: the temperature forecast for today Sunday will be around 27 degrees Celsius below zero, with a thermal sensation \u2013 due to the wind \u2013 of 37 degrees Celsius below zero. For those living in the tropics it is possible that Norilsk is not an especiallyattractive city to live in. And not only because of the low winter temperatures that can reach fifty degrees Celsius below zero, but because being located beyond the arctic circle it suffers during the winter of little sunlight \u2013 including month and a half of polar night \u2013 and this presumably predisposes us to depression. In spite of all the above, it is not necessary to judge the living conditions in Norilsk under our particular tropical optics and with certainty there will be those who enjoy the Siberian climate. Thus, according to the British newspaper \u201cTheDailyTelegraph\u201d, \u201cit does not seem that the inhabitants of Norilsk smiled less than those of other Russian cities.\u201d Indeed, some even like the winter for the opportunity that provides them to go hunting and fishing.On the other hand, it would also be interesting to recognize, that although there is a large majority of people in the Lord\u2019s vineyard, to have the freedom to do so, they would choose to live a climate more benign than the one that reigns in northern Siberia. And this is possibly as valid today as in the remote past.In this context, it is interesting to comment on the discovery of the remains of a mammoth carried out in the Bay of Yenisey in the Sea of Kara, some 300 kilometers north-west of Norilsk and at 72 degrees latitude. Such a discovery would have nothing in particular except because the remains of the mammoth are 45,000 years old and The discovery is reported in an article published this week in the magazine \u201cScience\u201d by a group of Russian scientists led by Vladimir Pitulko from the Russian Academy of Sciences in St. Petersburg. As we know, there is an agreement between specialists that our human species originated in Africa and that from there it emigrated to Asia, and later to Europe, Oceania and America. With regard to our continent, specialists also agree that the first settlers crossed from Siberia to Alaska through the land bridge that then existed in what is now the Bering Strait. It is not clear, however, when the latter happened, if it was after the period known as the Ultimate Glacial Maximum \u2013 which extended from 26.500 years ago to 19,000 years ago \u2013 or before that period. According to Pitulko and collaborators, their discovery can help solve the point, as it shows that there were human groups that They lived in northern Siberia at an early age, which had the opportunity to cross the Bering Bridge before the Last Glacial Maximum. The results of Pitulko and collaborators also show that our ancestors 45,000 years ago had already developed all the necessary technology to, not only hunt large animals, but to survive the inclement conditions of northern Siberia. In the particular case of the mammoth hunters of Yenisey Bay, we cannot know if they were for any reason forced to advance north or if they went there in search of food; or whether they were a group of adventurers who enjoyed hunting and fishing in the middle of the Siberian cold, as do their modern counterparts in Norilsk. In one way or another, advancing north turned out to the essential dessert to populate the American continent.For the rest, all of us who would not consider Norsilsk among our options as a place of residence \u2013 even though we have at our disposal an arsenal of technologies to survive in the Arctic \u2013 can only be grateful to live 45,000. years later, no need to hunt mammoths or endure extreme colds.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d7/Alletemp.jpg": "As we know, life expectancy at the global level has grown steadily over the last 150 years, to over 80 years in the case of countries with the highest figures in this area.According to the World Health Organization, Japan with the longest population is the country, where life expectancy at birth for women and men is 87 and 80 years, respectively \u2013 the respective figures for Mexico are 73 and 79 years.This contrasts with the average life before the Industrial Revolution that was around 40 years.The increase in life expectancy is the result not only of medical advances in the prevention and treatment of infectious diseases, but also of an improvement in the hygiene conditions of the population.This latter includes the development of water distribution systems and the disposal of human waste in cities, as well as the improvement of personal hygiene habits.We could expect that the poor infrastructure of Europe\u2019s cities in terms of pipes and systems for the disposal of human waste in the centuries prior to the Industrial Revolution were not the best to prevent the epidemics that devastated Europe; particularly the epidemics. It is interesting, on the other hand, to know that these conditions of hygiene were a step backwards from those existing in the Roman Empire at the beginning of our era. Indeed, it is known that Rome at that time had a system of pipes and distribution of running water, as well as of public toilets and latrines, and that this \u2013 the same as the engineering involved \u2013 was lost in Europe in the centuries following the fall of the Western Roman Empire. It could be expected that the benign sanitary conditions of the Roman Empire would have led to a decrease in infectious diseases among the population. To find out if this was really what happened, PiersMitchell of Cambridge University in the United Kingdom made a compilation of the evidence that has been discovered in various archaeological sites \u2013 septic fossils, public latrines and human burials \u2013 about the presence of human parasites in Imperial Rome; this, with the aim of making a comparison with the parasites that have been found in the same places but in Mitchell published his results this week in the magazine \u201cParasitology\u201d. Mitchell\u2019s analysis included studies carried out in archaeological sites that are currently located in Italy, Austria, Germany, France, Egypt and Israel, among other countries. To his surprise, he found that not only did the Romans suffer from intestinal parasites, but in some cases the incidence of infections was even greater than that of other times, in principle less advanced health. Among the most common parasites suffered by the Romans were intestinal worms, trichocephalus, amibas and tapeworms, these last by the consumption of fish without sufficient cooking. Mitchell notes that the evidence found indicates that the incidence of the infection during the Roman Empire was probably greater than the corresponding incidence, in the same places, during the bronze and iron ages. To explain his discoveries, Mitchell ventured several hypotheses. In one of these he considered that the Roman habit of taking baths in public facilities had provoked the Intestinal parasite transmission. This is because the water in the baths was not frequently renewed and kept a floating layer of dirt, the product of the previous bathers.Mitchell also notes that the transmission of parasites could have been due to the fertilization of the agricultural fields using sewage, which would have been a Roman custom.An additional hypothesis, this one, to explain the infection with tapeworms, refers to the Roman hobby by a fermented sauce known as \u201cgarum\u201d, made from raw fish, salt and herbs. Mitchell adventure that the trade in this salsa would have caused the spread of the infection by tape, throughout the entire empire. Examining combs and textiles of the time, Mitchell does not find either that the hygiene of the Romans would have freed them from external parasites, such as lice and fleas. These could have been the way to transmit diseases, particularly bubonic plague, which is known to be stricken the empire in the time of the Emperor Justinian.Apart from hygiene, it would have been necessary at that time, something more would have been necessary for such a practice to have been to have been the disease, particularly bubonic plague, which the empire, which was known to be the empire. Taking into account what happened in the last one hundred and fifty years, it is not difficult to understand that it lacked the Romans: an understanding of the origin of diseases. For Roman doctors the diseases were the result of an imbalance between our four humors: black bile, yellow bile, phlegm and blood, and to combat them it would have to be restored this balance. Moreover, for them parasites were generated spontaneously. And in all this, today we know, they were absolutely wrong. Hygiene is necessary but not enough.",
    "https://upload.wikimedia.org/wikipedia/commons/a/a3/CHUNXILU.jpg": "A recent visit to the University of Science and Engineering of Sichuan, Zigong, China, in some way and unexpectedly transported us in time; specifically, until the mid-sixties of the last century, when the university was founded under very particular circumstances that it is interesting to comment.As we know, the sixties were prodigal in various events of great significance to the world.In particular, it was a period in which the arms race between the United States and the Soviet Union intensified, the so-called Cold War.And it was precisely in the context of the Cold War, shortly after China became the fifth member of the nuclear club, which was founded the university referred to earlier.One element present in the year of 1965 was the permanent threat of a nuclear holocaust.The United States and the Soviet Union were engaged in a nuclear weapons accumulation race that was intended to deter the adversary from starting a nuclear war, even though it would not be annihilated.In this context, both countries had enough nuclear bombs to destroy the world several times. It was also in the 1960s \u2013 specifically in October 1962 \u2013 that a third world war was about to be unleashed during the so-called Cuban missile crisis.The climate of nuclear war threat that prevailed in the 1960s was recreated by film director Stanley Kubricken in his black humor film, \u201cDr. Strangelove or: How I learned to stop worrying and loving the bomb\u201d made in 1964. In the film, an American general is determined to provoke a nuclear confrontation with the Soviet Union and succeeds in taking off a squad of nuclear bombers with the mission to attack Soviet cities. At the last hour it was possible to order the return of all the bombers, with the exception of one of them with whom communication could not be established and whose mission could be completed.The third world war began.In the 1960s we were also witnesses of the first Chinese nuclear test that occurred in October 1964. China joined the United States, the Soviet Union, France and Great Britain as the fifth member of the club of nuclear nations.It should also be remembered that while China developed its nuclear bomb with the help of the Soviet Union, in the 1960s both countries were separated. China was thus isolated and under threat from the two dominant nuclear powers.In this context, the year1965 witnessed the creation in the province of Sichuan, in southwestern China, of the institute that would eventually become the University of Science and Engineering of Sichuan; this, as a branch of the East China Chemical Technology Institute based in Shanghai.The mission of the new institute was to contribute to the development of Chinese nuclear weapons technology.Consequently with these objectives, the headquarters of the new institute was built in a remote place in the deep south of China, some 40 kilometers from the city of Zing in the province of Sichuan.A bust of Marie Curie in one of the campus gardens, for the rest, leaves no doubt the technical vocation of the same.The last decades of the twentieth century saw the city of Zing in Sichuan. However, outside the United States and Russia, which together, according to Robert Norris and Hans Kristensen in an article published in the \u201cBulletin of the AtomicScientists\u201d in the July/August 2010 issue, had in 2010 an inventory of the order of 20,000 nuclear weapons, all the other countries of the club totaled just 1,000 such weapons. On the other hand, although in recent decades the inventory of global nuclear weapons has been substantially reduced from the peak reached in 1986, the development of more modern weapons has not actually stopped. Given this circumstance, opinions have been poured in the last few months to the effect that a new Cold War is under way. William Perry, who was Secretary of Defense in the administration of Bill Clinton, analyses in an article published in the \u201cBulletin of AtomicScientists\u201d on 8 December the possibility of a new reversal of the Cold War between the United States and Russia. , and does not rule it out because today \u201cthe relations between the two countries are as bad as they were in the dark years of the Cold War.\u201d Thus, if expert opinions are true, we would be in danger of having a reissue of the madness that we live for five decades and that had us on the verge of a catastrophe. It is also possible that in reality the danger has never disappeared since, according to expert opinions, the development of new, more sophisticated nuclear weapons has never stopped. Thus, perhaps we should cross our fingers so that we do not have to look nostalgicly at the outdated nuclear weapons of the distant decade of the sixties.",
    "https://upload.wikimedia.org/wikipedia/commons/6/69/Hux-Oxon-72.jpg": "Yesterday Saturday morning, and after some delays, the draft agreement was released to the countries participating in the Paris climate summit. On the boat there were soon mixed reactions. There were those who considered that the agreement implied the end of the fossil fuel era. More commonly, the opinions were that it was a toothless document that little forced the countries that generate the most greenhouse gases. In particular, it is commented that the commitment according to which the developed countries will contribute $100,000 million annually to the non-developed countries to combat the environmental problem, is mentioned only in the preamble to the document and does not result in this binding and only voluntary way. One reason for the latter is the adverse position of the United States Senate to sign a formal commitment in this regard. In fact, there are American senators who deny that global warming exists and in these circumstances a binding agreement would have a very low probability of being approved by the American Senate. Paul Krugman, Nobel Prize for Economics, in an article published in the New York Times on 4 December, he made an appeal against Republicans in the U.S. Senate and \u201cAnd the orthodoxy of denying climate change doesn\u2019t just say that scientific consensus is wrong. There are distinguished members of Congress who support conspiracy theories claiming that evidence for climate change is the product of a gigantic fraud perpetrated by thousands of scientists around the world. They do everything they can to threaten and intimidate individual scientists.\u201d Consensus on global warming has been generated through scientific studies carried out over several decades. In an article published by Thomas Peterson and collaborators in the \u201cBulletin of the American Mechanical Society\u201d in September 2008, an account of scientific literature is given in this regard. An interesting point is that in the 1960s it was not clear whether the planet was getting warmed up or cooled, and this context published research articles that defended both one point of view and the other. However, according to Peterson and collaborators, the dominant point of view was that the planet was being cooled, and this context was published. At the same time, precise measurements of the concentration of carbon dioxide \u2013 the main greenhouse gas \u2013 in the atmosphere, carried out over several years, demonstrated that this concentration was gradually increasing. Thus, a connection was established between global warming and the emission of carbon dioxide into the atmosphere, a fact that is now widely accepted by the scientific community \u2013 albeit not unanimously. The Earth\u2019s surface, including its atmosphere, is a very complicated system whose behavior is not easy to understand, even with the most sophisticated scientific methods. Climate change has thus been exposed to anti-scientific and/or interested interpretations and explanations. In this sense, the newspaper \u201cThe Guardian\u201d, in an article published this week revealed a covert operation carried out by the organization \u201cGreenpeace\u201d which exposed two academics willing to write supposedly scientific articles under commission. In a first case, \u201cGreenpeace\u201d, simulating to be a representative of a gas and oil company of the oil of the atmosphere. Middle East, he contacted William Happer, who is a professor of physics at \u201cPrinceton University\u201d and a climate change skeptic, to write an article explaining the benefits of increasing the concentration of carbon dioxide in the atmosphere. Happer was willing to do so by paying $8,000. In a second case, \u201cGreenpeace\u201d, pretending to be an employee of a consulting company in Indonesia, he contacted Frank Clemente, who is a retired professor at \u201cPennsylvania State University\u201d, with the aim of writing an article dealing with the benefits of using coal as fuel. Like Happer, he agreed to write a 10-page article by paying $15,000. Given these two cases, one may ask about the frequency with which similar cases have been given in which he seeks to dismiss the problem of climate change in response to economic interests that would be affected by a reduction in fossil fuel consumption. Returning to the Paris climate summit, at the plenary meeting held on Saturday afternoon. The text of the agreement issued hours earlier was approved by all delegates. This gave rise to great optimism and the hope that climate change has entered a path of solution. This, although some consider that the agreement lacks teeth. As it may be, a positive point is undoubtedly that climate change has been unanimously recognized as a real problem, contrary to anti-scientific and interested opinions.",
    "https://upload.wikimedia.org/wikipedia/commons/9/97/DCmontage2.jpg": "At the end of 2012, the states of Colorado and Washington in the United States legalized the use of marijuana for recreational purposes, opening the possibility that such legalization would spread to other states in that country, although not at the federal level. Currently, apart from Colorado and Washington, marijuana is legal in Alaska, Oregon and the District of Columbia, and it is expected that it will soon be legalized in 11 other states, including California and New York. At the country level, Uruguay became in 2013 the first to legalize the production and sale of marijuana. In this context, as we know, at the beginning of this month the Supreme Court of Justice of our country authorized four people, members of the SMART organization, the use of marijuana for recreational purposes; this, in the midst of a debate about the desirability of such a drug being legalized in Mexico, a matter that is highly controversial. Among other facets that are inherent, the addictive and widespread use of marijuana is a matter of public health with a social cost. In this sense, an article appeared this week in the magazine \u201cPsychological\u201d Medicine, published by researchers from research centers in Italy and England, headed by Silvia Rigucci of La Sapienza University in Rome, suggests that the use of the highly potent variety of marijuana known in English as \u201cskunk\u201d, causes structural changes in the brain of consumers. It is known that the use of this potent drug is associated with the occurrence of episodes of psychosis. Specifically, researchers find evidence that \u201cskunk\u201d marijuana causes micro-structural changes in the white matter of the callous body, which is known to be particularly affected by the active substance of the drug. It is important to note that white matter contains nerve fibers that have the function of sending signals between the two cerebral hemispheres and whose damage could affect communication between them. Rigucci and collaborators came to their conclusions after studying, by techniques of magnetic resonance, the brain of 56 patients who had suffered episodes of psychosis and 43 healthy volunteers. In both groups there were both consumers and non-users of marijuana. Specifically, of the 56 patients and 43 volunteers, 37 and 22 were marijuana users, respectively. According to Dazzan, \u201cthe frequent use of high-power marijuana is significantly associated with an alteration of the micro-structural integrity of the callous body\u201d; this, compared to those who either do not use marijuana, or consume the less powerful version. They find, moreover, that these alterations were similar in all users of \u201cskulk\u201d, whether or not they have suffered psychotic episodes. They do not find, on the other hand, a difference between those who started using high-powered marijuana before the age of 15 years with those who started its use later. In statements to the British newspaper \u201cThe Guardian\u201d, Paola Dazzan of the Institute of Psychiatry of King\u2019s College in London and one of the authors of the reference article, he mentions that from their results it cannot be said with certainty that the use of high-powered marijuana leads to brain damage. On the contrary, it may well be that those addicts to \u201cskunk\u201d actually are because they suffer from this damage for some other reason. There would be an uncertainty between cause and effect. However, according to Dazzan and Besides the uncertainty, what can be said is that those who regularly consume high-power marijuana \u2013 whose use would be increasing \u2013 \u201chave a brain different from those who do not use it or who consume a less powerful variety.\u201d Certainly, the work of Rigucii and collaborators on the effect of \u2013 \u201cskulk\u201d on the brain will have to be confirmed, and if necessary validated, by independent investigations. One way or another, however, highlights one of the aspects of the complex problem we face because of the widespread use of marijuana \u2013 and drugs, in general \u2013. Problem that is overwhelming by its multiple facets and, no doubt, difficult to settle. And with controversial proposals of solution, of course.",
    "https://upload.wikimedia.org/wikipedia/commons/5/56/Famous_Italians_Mosaic.png": "This week the Italian highest court finally acquitted four Italian geophysicists and two seismic engineers accused of manslaughter for the death of more than 300 people during the earthquake in April 2009 in the city of L \u0301Aquila in central Italy. The six scientists, together with Bernardo De Bernardinis, who at the time served as deputy director of the Italian civil protection department, had been sentenced in 2012 to six years in prison for failing to correctly inform the population of L \u0301Aquila of the risks they faced due to the possible occurrence of a earthquake. As was announced at the time, the seven specialists formed part of a committee that met in L \u0301Aquila on 30 March 2009 to assess the seismic situation of the city, which had suffered numerous small and medium-scale tremors in the previous months. That committee was convened by the Italian civil protection department. According to the judge who condemned the scientists, the residents of L \u0301Aquila were entrusted with the statements that De Bernardinis made. In contrast to De Bernardinis' statements, however, on the morning of 6 April 2009, six days after the meeting of the committee of experts, an earthquake struck L'Aquila by surprise and killing 309 of its inhabitants.The seven specialists convicted in 2012 appealed the sentence, resulting in acquittals in November 2014; with the exception of De Bernardinis who, however, saw his sentence reduced from six to two years in prison.In the end, after a challenge by the prosecutor for the acquittal, the Supreme Court of Justice of Italy acquitted scientists this week in a definitive way.Although it is known that earthquakes are the result of efforts that are generated between two tectonic plates when sliding against one another, the prevailing opinion among specialists is that the scientific knowledge that is counted today is not detailed enough to anticipate them with a certain degree of precision. predicting an earthquake was an argument of defense of the accused scientists, because, according to expert opinions, the occurrence of small and continuous tremors could increase the probability of a major earthquake, this one is small and it is more likely that the earthquake does not occur in the short term.In fact, the judge who condemned the specialists in the first instance did not accuse them of not having been able to predict the earthquake of L \u0301Aquila, but of having failed in the communication of their expert opinions to alert the population about the risk to which they were exposed. In this context, the Italian justice does not exonerate and finds guilty De Bernardinis, who handled the public relations and declared \u2013 even before the meeting of the committee \u2013 that the series of small tremors that had felt in L \u0301Aquila in the previous months in fact were a positive sign since they helped to relieve the accumulated tension in the subsoil. According to testimonies of inhabitants of L \u0301Aquila who lived the earthquake, this statement reassured them and caused them to lower their guard. \u201cScience\u201d magazine on 28 October, says that an Italian judge decided to bring Guido Bertolaso \u2013 a doctor by profession \u2013 to trial, who was the organizer of the pre-earthquake scientific meeting. At that time, Bertolaso served as director of the Italian civil protection department and De Bernardinis was his second on board. According to \u201cScience\u201d, Bertolaso\u2019s trial was based on a telephone call he made referring to the committee\u2019s meeting in L\u2019Aquila as \u201ca media operation he was organizing to shut down a technician from a nearby laboratory who was making alarmist predictions that had caused panic among the population.\u201d Bertolaso also mentioned what the expert committee should say to the population: \u201cthat the small tremors that were happening were positive as they discharged the energy and made a major tremor less likely.\u201d In his telephone conversation Bertolaso would have referred to Giampaolo Guliani, who had made predictions about the imminent occurrence of a large earthquake in L\u2019Aquila. Guiliani based his predictions on measurements. All this allows us to see that the unusual case of the L \u0301Aquila earthquake trials originated, ultimately, by the decision of a public official to silence \u2013 through a committee of experts \u2013 an amateur scientist who alarmed the population with catastrophistic predictions. And possibly everything would have worked for him, because the probability of a major earthquake occurring in the short term was small. He did not take into account, however, the opinions of mother nature.",
    "https://upload.wikimedia.org/wikipedia/commons/c/c5/Indianocean.PNG": "One of the victims \u2013 apparently non-fatal \u2013 of the terrorist attacks last Friday in Paris, France, is the United Nations climate change conference, which is scheduled to take place in that city from November 30 to December 11. While there are doubts about their realization in the current circumstances, the French Prime Minister, according to Reuters, assured that the conference will be held as planned. It is hoped that the Paris climate conference will reach agreements between nations that limit the emission of greenhouse gases to the atmosphere.As we know, a majority of climate experts argue that the increase in the concentration of such gases in the atmosphere, resulting from the use of fossil fuels, is leading to an increase in the average temperature of the Earth's surface and to a climate change that could be catastrophic to not put a stop to it.As a preamble to the climate summit, at the beginning of this week the UN World Meteorological Organization announced that in the first months of this year the concentration in the atmosphere of carbon dioxide \u2013 the most significant greenhouse gas \u2013 was maintained by the UN's This represents an increase of almost 50% over the level that prevailed before the Industrial Revolution. Concurringly, the United Kingdom\u2019s meteorological office released data showing that, from January to September last, the average global temperature increase over the period 1850-1900 was greater for the first time to a degree centigrade. This means that we are halfway to reach the limit of increase set by experts, which is two degrees centigrade with respect to pre-industrial levels, above which a global climate catastrophe would occur. One of the effects of the rise in the Earth\u2019s temperature is the rise in the level of the oceans, due to the melting of ice masses in the poles and the expansion of water by the rise in temperature. While, given the complex nature of the phenomena that determine it, it is difficult to specify what the rise in the sea level will be in the coming decades, the experts estimate that it will reach by the end of the twenty-first century a value in the range between a few tens of centimeters and about two metres; However, because the increase in the concentration of carbon dioxide in the atmosphere has taken place in an extremely rapid manner, specialists consider that beyond the twenty-first century there could be a substantially greater increase to two metres in ocean level. In this connection, they note that the level of the ocean 125,000 years ago, when the Earth's temperature was approximately the same as today and the concentration of carbon dioxide in the atmosphere was 285 parts per million, the sea level was six to nine metres above the present level. Three million years ago, on the other hand, when that concentration was approximately the same as the present one and the Earth's temperature was one to two degrees Celsius higher than the temperature today, the sea level could have been as high as twenty metres above the present level. This would indicate that the speed at which climate change has taken place has not allowed the planet to strike a balance, which would take it hundreds of years to achieve. On the other hand, it would flood coastal areas all over the world. A map prepared by NASA and available on the Internet tells us, for example, that given this increase, South Florida would be completely submerged, as would the coastal regions of our country, particularly those of the Yucatan peninsula. And what about the Maldives in the Indian Ocean south of India, which would be completely submerged. Fortunately for our generation, the global climate change we are experiencing is a relatively slow process, of which we are barely aware and whose final conclusion we will not be able to bear witness. Possibly, future generations will not be equally fortunate, although it is foreseeable that they will be more aware of the problem and will have greater technological tools to solve it. Let us hope that the very unfortunate events in Paris will not soon lead to a meeting in which a serious problem for the world will be tackled. However, it would have to be recognized, the experience of previous meetings does not give much hope that the problem of climate change will be met with an effective solution in the medium term.",
    "https://upload.wikimedia.org/wikipedia/commons/4/45/Carlos_Fuentes%2C_Paris_-_Mar_2009_%2811%29.jpg": "\u201cHey you, Pimpis, who says the Light City. Where, I say? They would like to have Insurgentes\u2019 lighting for a holiday.\u201d So says Junior, one of the characters in the novel \u201cThe Most Transparent Region,\u201d when it refers to the lighting of Paris in the 1950s and compares it to the lighting of Mexico City at the same time. When Carlos Fuentes published in 1958 \u201cThe Most Transparent Region\u201d had spent just eight decades since Edison and other entrepreneurs started commercializing the incandescent lamps. As a result of this commercialization, the electric light quickly expanded, in both private and public spaces, to cities throughout the world \u2013 including Paris and Mexico City. Today, the incandescent lamps, which so much changed the world and survived for more than a century, are in the process of disappearing. This, because they have been overcome by other types of light sources, mainly by the LED lamp \u2013 the acronym of the English expression \u201cLight Emitting\u201d. Diode\u201d \u2013 which in comparison is considerably more durable and efficient. More precisely, while the life time of an incandescent lamp is around 1,000 hours \u2013 one year, keeping the lamp lit an average of three hours a day \u2013 the estimated life time of an LED lamp is 10 to 50 times larger. Likewise, while less than 5% of the electrical energy consumed in an incandescent lamp becomes luminous energy, in a LED lamp the corresponding figure is 6 to 8 times larger. It does not thus have the incandescent lamp way of competing with new LED sources in the field of lighting \u2013 even though the latter\u2019s cost is for the relatively high moment \u2013 and its destination is necessarily that of extinction. It should be noted, moreover, that the uses of LED lamps are not limited to lighting, but also include applications such as traffic lights, automobile lamps, television screens, indicator screens and decorative lights. On the other hand, the technology of LED lamps is completely different from that of incandescent lamps, both in The core of a LED \u2013 where the light is generated and whose chemical composition determines the emitted color \u2013 contains valuable chemical elements such as gallium and Indian, which are not part of the incandescent lamps. In the case of white LED lamps, in addition, the core contains elements such as europium and terbium. Given the value of all these materials and the explosive growth that the LED lamp industry is experiencing, the experts have given themselves the task of searching for innovative methods to recycle the materials with which they are manufactured.In relation to this last point, in a press release issued this week by the Fraunhofer Institute in Germany, it is announced that researchers from that Institute have developed techniques to separate the different components of a LED lamp \u2013 in particular its core \u2013 without destroying them. Once separated, the components can be processed individually. This, specialists, will make the recycling of LED materials economically feasible. For the time, according to experts, when the industry of LED lamps is still in its initial phase of growth, the volume of material is expected by specialists. To recycle is still insufficient to make the process of reuse economically viable. Under these conditions, recycling companies are only storing waste. In the future, however, to the extent that industry grows and a growing proportion of incandescent lamps is replaced by LED lamps, the recycling process will be feasible.Possibly it will not be long before this happens.The speed at which artificial light is changing on our planet is even visible from space.For example, in two photographs taken from the International Space Station \u2013 which can be consulted on the Internet \u2013 it is shown to the city of Milan, Italy, in two recent moments: in 2012, when the city centre was illuminated with incandescent lamps, and in 2015, after those lamps were replaced with LED lamps. The images we can see are contrasting: while in 2012 the centre of Milan was illuminated with the characteristic reddish light of incandescent lamps, in 2015 that color had changed to the blueness of LED lamps. In addition, in 2015 some areas of the city are shown with considerably more The night lights of the cities of the world have changed dramatically over the last century and it seems that they will continue to do so. Although it is not clear whether the change will be for good or for bad, the light levels that we will have in the future will surely go up. And they will be even bigger than those of Mexico City in the 1950s.",
    "https://upload.wikimedia.org/wikipedia/commons/b/b8/Daylightsavings.jpg": "As we know, last Sunday the winter schedule came into effect and we had to delay our clocks for an hour. We have more sleep time, which, however, we do not all take advantage of, because some of the change of schedule caused some of us to get out of control throughout the day that seemed to us longer than usual. Otherwise, the change from summer time to winter time always causes less discomfort than the reverse change that occurs in spring, when we advance one hour the clocks and we have to get up earlier. While one of the main purposes of the summer time is to save energy by having one more hour of natural light towards the end of the day, there are those who believe that this does not happen and that, on the contrary, changing the time has negative effects on our health. It has been observed, for example, that in the days after the summer time comes, the mortality rate for heart problems increases, as well as for traffic accidents.To be changing our circadian rhythm abruptly twice a year does not seem to be the best for health and one can ask A search on the Internet gives us the answer: the first to propose such a practice in a formal way was a New Zealand entomologist named George Hudson; he did so during a presentation he made at a session of the Wellington Philosophical Society in 1895. Why might an entomologist have an interest in making a proposal to establish a summer schedule? It seems Hudson, following his vocation as an entomologist, was engaged in hunting insects at the end of the afternoon after his work day. The lack of sunlight, however, made it difficult for him to do so and reasoned that the problem could be solved by starting the day officially earlier, so he proposed that the clocks be brought forward two hours during the summer. This advance, on the other hand, would have benefits not only for him, but for all those interested in doing activities in the open air in hours close to sunset. Hudson\u2019s proposal was not well received and was a reason for numerous criticism and even mocking of those present at the society session, one of whom suggested that \u201cthe clocks could be handled with different hands\u201d. Over time, however, this proposal was viewed with better eyes, to the extent that Germany introduced it in 1916, during World War I, with the aim of saving fuel.The measure was subsequently followed by other countries, including the United States.The practice of changing the hour twice a year has many critics and there are now proposals to eliminate it. Russia, for example, introduced summer time in 2011 on a permanent basis. To justify the measure, according to the newspaper \u201cThe Guardian\u201d, the then Russian president argued: \u201cIt is irritating, people get up earlier and do not know what to do with the overtime. Not to mention the unhappy cows and other animals who do not know that the clocks have changed and do not understand why they come to milk them at different times.\u201d Summer time was not well received by the Russians and since last year was changed by winter time; also permanent, however.There are proposals in the United States to eliminate the changes of time twice a year and implement summer time on a permanent basis. This view is supported by an article in the magazine \u201cThe Review of Economics and Statistics\u201d, published by Jennifer Doleac and Nicholas Sanders, of the University of Virginia, and of the College of William and Mary, respectively. This article presents a study carried out with criminal statistics in the United States, with the purpose of determining how the change of schedule affects criminal activity. They find that since the change in the summer hours the activity of robberies throughout the day is reduced by 7%, while in the afternoon hours, when there is more light, this percentage is 27%. The reason for the above is that with higher levels of light the wrongdoers refrain from committing their crimes because of the risk of being identified. Furthermore, they do not transfer their criminal activity to hours in the morning when there is less light. The previous one is therefore an additional argument against the time changes, in case any were missing, and there would be a chance that we would witness their disappearance in the not-too-distant future. Hopefully, if this happens, summer time, which does not seem to be adequate for the latitude in which we find ourselves, will not be implanted in our country \u2013 by imitation.",
    "https://upload.wikimedia.org/wikipedia/commons/c/c3/Byzantine_imperial_flag%2C_14th_century_according_to_portolan_charts.png": "Over the last century, the life expectancy of the population has more than doubled globally. One factor contributing to this increase was the development of antibiotics, which were available to the public since the second half of the decade of the forties, at the end of the Second World War. By the use of antibiotics, it was possible to fight bacteria that in the past caused pandemics of great proportions and decimated the population of the world. A bacterium of sad memory in this sense is the \u201cYersinia pestis\u201d, which causes bubonic plague, a disease that is transmitted by the bite of infected fleas. The first pandemic of which is reported to be caused by the \u201cYersinia pestis\u201d is known as the Plague of Justinian, which devastated the Byzantine Empire in the sixth century of our era and during which 40% of the inhabitants of Constantinople would have died. The plague continued intermittently thereafter until approximately 750 of our era. In the centuries that followed, the bacteria \u201cYersinia pestis\u201d intermittently caused other epidemics, although of lesser proportions. It was attributed, for example, to have been the infectious agent behind the \u201cGreat Plague of London\u201d of the years 1666-1667, in which 100,000 people would have died, a quarter of the London population. By the way, because of that plague the University of Cambridge had to be closed temporarily. This forced Isaac Newton, who was a student in it, to take refuge in his family home in the village of Woolsthorpe. His forced stay outside of the university, however, did not prevent Newton from continuing his research work. Far from that, during the last two years at Woolsthrope Newton developed some of his most important discoveries, including the law governing the movement of planets. Returning to more mundane events, the \u201cYersinia pestis\u201d made a third star appearance in 1855, this time in China, spreading later to other parts of the world. The pandemic lasted until the middle of the 20th century and only in China and India killed 12 million people. Today, although antibiotics keep it under control, the \u201cYersinia pestis\u201d is still active among us and can be transmitted by contact with infected rodents. Thus, according to the Center for Disease Control of the United States, so far this year 15 people in that country have been infected by that bacterium, in four cases with fatal results. These numbers, however, are small, so that the once fearsome bacteria do not represent more danger today. On the other hand, while the \u201cYersinia pestis\u201d is no longer of care, it can still make news. And in fact, a scientific article appeared this week in the magazine \u201cCell\u201d claims that this bacterium has lived among us for quite longer than it was believed. This article was published by an international group of researchers headed by Simon Rasmussen of the Technical University of Denmark. The purpose of the study was to identify traces of the bacteria \u201cYersinia pestis\u201d in the skeletons, which would indicate that they belonged to individuals who died victims of the plague. They studied a total of 101 skeletons, of which 7 gave positive results. Of these, in two cases they were able to generate the complete genome of the \u201cYersinia pestis\u201d. The oldest remains in which the presence of the bacteria could be identified belonged to an individual who died 5,000 years ago. It is possible, however, that at that time the bacterium was not as contagious as it was during large pandemics. This is because, according to Rasmussen and collaborators, it lacked the gene that the current version allows him to stay in the digestive tract of fleas. In these conditions, fleas could not be an infection route and the disease would have been transmitted by direct contact with the blood or by the disease. The saliva of the infected person, which makes it less contagious. Once a person was infected, however, the mortality rate was very high. Thus, according to Rasmussen and collaborators, we have lived together \u2013 usually in a rather uncomfortable way \u2013 with the \u201cYersinia pestis\u201d for several thousand years. And as a result of such coexistence, according to some sources, some 200 million people would have died. Today, the bacteria do not represent a major problem, far away they seem to us those times in which we could have died in the course of a few days because of a disease whose origin was left in the most complete darkness. The experience should have been chilling. Although apparently it was not so much for Isaac Newton.",
    "https://upload.wikimedia.org/wikipedia/commons/6/6d/ESA_Headquarters_in_Paris%2C_France.JPG": "Being Mars the planet of the solar system most similar to the Earth \u2013 and the nearest second on average \u2013 has often been a source of speculation about the possibility that it could harbor some form of life, even intelligent. In this sense, at the beginning of the last century the American astronomer Percival Lowell was convinced that the lines that the Italian Giovanni Schiaparelli had observed with his telescope in 1877 on the surface of Mars were channels that Martians would have built to transport water from the polar caps to the desert regions in the equator of the planet. Following his belief, Lowell spent a lot of time trying to confirm it until he was convinced otherwise.Marte has also been present in fictional novels. That planet is, for example, the place of origin of the extraterrestrials who invade the Earth in the novel \u201cThe War of the Worlds\u201d by the British writer H.G. Wells, who would have been inspired to write it in Lowell\u2019s ideas. Similarly, the science fiction writer Ray Bradbury in his book \u201cCr\u00f3nicas Marcianas\u201d gives for her. However, despite our fascination with Mars, the physical conditions that prevail on its surface are not at all friendly to the higher life as we know it. Thus, the photographs that bring us NASA probes from the surface of Mars show an extremely arid and rocky place, without the slightest trace of life. We know, moreover, that the Martian atmosphere is extremely thin and composed fundamentally of carbon dioxide and virtually no oxygen. We also know that, given its distance from the Sun, the surface of the planet is very cold, with an average temperature of less than 55 degrees Celsius and a variation between day and night that can reach 100 degrees Celsius. An additional danger to life on Mars is high energy radiation from space that we know can cause cancer. Unlike the Earth, Mars does not have a magnetic field that diverts such radiations, which continuously bombard its surface. The thinness of the Martian atmosphere \u2013possibly the result of cosmic bombing \u2013 does not help to attenuate such radiations, as it does not do with ultraviolet rays. Mars is not a hospitable place, at least not as it is our planet, and no one expects it to be able to harbor life beyond its microbial version. In this sense, a study carried out by the explorer \u201cCuriosity\u201d that is located since August 2012 on the surface of Mars, showed encouraging results. It has not discovered \u201cCuriosity\u201d microbes on Mars, but clear signs that at some point in its geological history there were stable rivers and lakes of water on its surface; and, as we know, water is an essential element for the development of life. This study was published this week in the magazine \u201cScience\u201d by an international group of researchers headed by J.P Grotzinger of the \u201cCalifornia Institute of Technology\u201d. This group analyzed photographs sent by \u201cCuriosity\u201d of sedimentary deposits inside the Gale crater on Mars that revealed the geological history of that area of the planet. Researchers found inside the crater material deposits that were probably dragged up to there by rivers of water, as well as ro-layers. In this way, and from being Gortzinger and collaborators in the right way \u2013 the same as other researchers who have come to the same conclusion \u2013, in the past Mars was a considerably wetter place compared to the present, pointing to the possibility that in the past there would have been favorable conditions for the development of life. Water, on the other hand, is only one of the essential elements for life. Additionally, it is also necessary to have the chemical elements that make up the molecules of life and the sources of energy to synthesize them, be the latter of solar or geothermal origin. And, of course, it is necessary to have an environment that is not toxic to life, as is currently the Martian surface, continuously bathed with cosmic radiations of high energy. For the development of life, it is necessary to combine several factors and to find out if these factors occurred the past on Mars, as well as to detect the possible presence of life, past and present, in that life, past and present. the European Space Agency plans to send the ExoMars missions to Mars in 2016 and 2018, while NASA plans to send the Mars 202 mission for the same purpose. We cannot at the moment know if it exists, or existed in a remote past, life on Mars. It is possible that, on the other hand, with a little luck we do not have to wait long before finding out if the European and American missions planned for the coming years succeed. In any case, if it found some Martian way of life, it will be simple, far removed from the intelligent life imagined by Lowell, Wells and Bradbury.",
    "https://upload.wikimedia.org/wikipedia/commons/c/ca/Cyclist_on_speed_hump.jpg": "There is widespread agreement among specialists that physical exercise has beneficial effects on health and that sustained, medium-intensity physical activity helps to prevent, and even reverse, modern diseases such as obesity, type 2 diabetes and cardiovascular problems. This has led many scientists to argue that physical exercise is the preferred method for preventing and treating such diseases, a product precisely of the sedentary lifestyle that we currently have. One obstacle to this is that many patients who have been prescribed a certain exercise regimen do not carry it out as they should, especially if they have to do it at home. In relation to this, according to data from different sources, less than 50% of patients who initially agree to perform a certain physical exercise routine maintain their commitment in the long term. Certainly, physical efforts can be exhausting and we tend to avoid them. Unless we are firmly convinced of their usefulness. For those who are not \u2013 or are mortal enemies of the gym \u2013 there is fortunately good news: in different laboratories in the world, research is being carried out to develop \u201cpillies\u201d In this way, if they ever become available to the public, we may be able to go to a pharmacy and buy a bottle of pills equivalent to \u201c5 hours a week\u2019s walk at an accelerated pace.\u201d In such a situation, even those who spend eight hours at work sitting at a desk \u2013 in addition to a considerable amount of time at home in front of television \u2013 could have the condition of athlete, and only for the exception are they exercised. In this case, exercise pills would be very attractive \u2013 and a great deal of business for those who make them \u2013 helping to increase the quality of life of those who are opposed to exercise. The fact that there are pills to be used in development in several research laboratories around the world is certainly a very good news for some. On the side of this one, however, there is also a bad one: it is not expected that exercise pills will be ready for use in the short term, as well as experts do not consider that they will be able to completely replace actual physical exercise. Shunchang Li and Ismail Laher, the latter of the \u201cUniversity of British Columbia\u201d, Canada, are critically examining the various chemicals that are candidates to develop exercise pills, and discussing the benefits that they might have in comparison to actual exercise. This article is entitled \u201cThe Exercise Pills: On the Line of Exit\u201d and is about to appear in the magazine \u201cTrends in Pharmacological Sciences.\u201d According to Laher, the need for exercise pills has already been recognized for some time and at this time is an achievable goal. Pills under study are at an early stage of development and focus on obtaining stronger and faster skeletal muscles. Laher notes, however, that the benefits of physical exercise are not limited to the development of muscles, but that it also impacts cognitive function, while contributing to greater bone strength and improved cardiovascular function. Thus, according to Laher, \u201cit is not realistic to expect exercise pills to be able to substitute for cognitive function. At least not in the immediate future.\u201d Although at the time when such pills are available \u2013 assuming that this is the case \u2013 they will benefit those who are allergic to exercise, Laher foresees that they will have their greatest impact among those who are disabled for some reason to perform physical exercise. In particular, he believes that people suffering from paralysis due to a spinal injury will find themselves among the most benefited, given the deterioration in cardiovascular and muscular functions that their relative immobility brings them. Thus, according to Laher, in the not yet determined future, we will be able to have some of the benefits of physical exercise without exercise itself, simply by ingesting the right pills. This certainly sounds attractive to many. For others, this is a bit absurd. This last one, since we would be using a high-tech product \u2013 exercise pills \u2013 to replace an activity \u2013 walking and running \u2013 that we know how to do very well from time immemorial.",
    "https://upload.wikimedia.org/wikipedia/commons/c/cb/Concesionario_de_Mercedes-Benz%2C_M%C3%BAnich%2C_Alemania%2C_2013-03-30%2C_DD_28.JPG": "Last Friday, September 18th, the government office responsible for environmental protection in the United States (EPA) sent a statement to the Volkswagen company accusing it of having sold in that country, since 2009, diesel-powered cars \u2013 including models of Jetta, Golf, Passat, and Beetle \u2013 that violate US environmental protection laws.This, as we know, triggered a scandal of large proportions and media coverage that threatens sanctions of many billions of dollars for VW. Specifically, the EPA accuses Volkswagen of having introduced a \u201cswitch\u201d in the engine control software of its cars, which commutes the operation of that engine between low- and high-emission modes of pollutants.All this, with the purpose of passing the tests applied by the EPA for the sale of cars in the United States. The VW diesel engine control software is sophisticated enough to find out when the car is subject to a test \u2013 by the position of the steering wheel, the speed of the car, the time it lasts on the engine, and even by barometric pressure \u2013 and switch to the low-emission mode. . This is important, since in the high mode VW cars could emit nitrogen oxides in quantities up to 40 times higher than those permitted by the environmental standard. In contrast, in the low mode these pollutants would be within that standard. Of course, the question is why, if cars are able to operate in a mode of low emission of pollutants and comply with the environmental standard, there is a second mode of operation with substantially higher levels of pollution? The answer is that in the low mode of the VW diesel engine is less than in the high mode. Thus, operating cars in the least polluting mode would compromise its competitiveness in the United States market. As part of the media scandal articles have been published that include opinions about how it will affect the VW company in particular and the figure \u201cMade in Germany\u201d in general. In relation to this, the EPA statement of September 18 it specifies that the fine for each marketed unit is $37,500. If we multiply this amount by the number of VW vehicles sold in the The United States since 2009, which is about 500,000 \u201311 million globally \u2013 turns out that VW would have to pay in fines around $18 billion. In addition, it could face lawsuits from the owners of its cars because used vehicles have fallen in price because of the scandal. If these and other sanctions were applied, the economic impact on the VW could be of great proportions. As for the impact of the VW brand image, in an article published in the magazine \u201cMarketing\u201d, Sven Reinecke of Universitat St. Gallen in Switzerland considers that the scandal through which the VW passes will be overcome given its status as a company of great prestige, and that the dismissal of its CEO a few days ago is the first step in this direction. Only that in the near future other similar scandals arise is that the integrity of the company could be put in jeopardy. As for the prestige of the figure \u201cMade in Germany\u201d, Reinecke states that there is no possibility that it will be affected, since the image of a nation tends to remain unchanged for a long time. Regarding, it notes that Germany is not only associated with quality, beer, cars, cleaning and punctuality, but also with Hitler and World War II. Moreover, the VW is not the only company that holds the image of its country. On the other hand, for some time it has been suspected that several diesel car manufacturers use software such as the one used by the VW to overcome environmental standards. Thus, a study published by the non-governmental organization \u201cTransport and Environment\u201d indicates that companies such as BMW, Citroen, Opel and Mercedes Benz, manufacture cars that exceed the permitted emission limits of pollutants. In this regard, the VW is not, then, a unique case. The fact that there are several that do so, of course, is no consolation and does not take away any responsibility from the VW company for having deceived its customers by selling cars without the promised characteristics in terms of emission of pollutants \u2013 which we know are harmful to health. It will be a long time before the scandal we are dealing with today is forgotten.",
    "https://upload.wikimedia.org/wikipedia/commons/4/46/Johannesburg_CBD.jpg": "Perhaps millions of years ago \u2013 a more precise date is yet to be defined \u2013 the bodies of a group of homininos \u2013 our immediate ancestors and their close relatives \u2013 were deposited or thrown to the bottom of a cave near Johannesburg, South Africa, in a hole known as a Dinaledi camera. This camera is located at a depth of about thirty meters and at a distance of eighty meters in a straight line from the current entrance to the cave. The Dinaledi camera is difficult to access. It is accessed in complete darkness, from an an antechamber located about 21 meters deep. Once in the antechamber, you have to climb 15 meters to the top of a steep block of stone, and then go down to the bottom of the Dinaledi camera, passing through a vertical opening of just 20 centimeters wide.It is not clear what was the intention of those who carried the bodies of the homininos to a hidden place where they were discovered.What is known is that the remains belong to a species of the genus Homo until now unknown. International group of researchers led by Lee Berger of the \u201cUniversity of the Witwatersrand\u201d in South Africa in two articles published this week in the magazine \u201ceLife\u201d. Berger and collaborators were the discoverers of the fossil remains of the Dinaledi chamber. The discovery was carried out during two expeditions carried out in November 2013 and in March 2104, which produced 1,550 fossil bones corresponding to at least 15 individuals of all ages, from neonates to elderly individuals. The skeleton reconstructed from fossils found shows a rare mixture of modern and primitive characteristics. It indicates, for example, that an adult male had a height of 1.50 meters and a brain the size of a gorilla. It also shows that he had hands adapted for the handling of tools, at the same time as appropriate curved fingers to climb trees. This would indicate that while the homininos found in the Dinaledi chamber used tools, they also lived part of their time in the trees. Given these characteristics, Berger and collaborators consider that they have discovered a new species of Homo. How was it that the fossil remains of the Homininians were to stop at the bottom of the Dinaledi chamber? For the time being this is a mystery. Thus, although in the past there might have been other entrances to Dinaledi\u2019s chamber different from the present one, according to Berger and collaborators it is unlikely that these would present similar difficulties to access it. They exclude, for example, that there might have been a vertical entrance \u2013 by which the Homininians might have accidentally fallen. If the difficulties to access the chamber had always existed, including having to travel a long narrow passage in complete darkness, it is difficult to find motivations why the Homininians would have voluntarily penetrated the chamber of Dinaledi and there had been death. Thus, the researchers ruled out that the Dynaledi chamber had been used as a dwelling by the homininians, who would have had to have penetrated it using artificial light \u2013in addition to the fact that there were no signs of occupation of the camera. \u2013 they also ruled that these would have been. It is also difficult to understand what would have motivated the predator to penetrate a cave in complete darkness and with many obstacles, also carrying a prey of appreciable dimensions.As the most likely explanation, Berger and collaborators consider that the hominins whose remains were found in the Dinaledi chamber entered to die there or were deliberately taken dead as part of a certain ritual. If this were true, such primitive hominins as the Homo naledi would have had patterns of complex behavior that normally associate with more evolved individuals. As usual, not all specialists agree with the conclusions of Berger and collaborators and there are those who doubt that they have discovered a new species of the genus Homo. They also question the hypothesis that the new species was capable of behaviors with a certain degree of complexity. Some even claim that the \u201cHomo naledi\u201d and its mortuary practices are more directed to mass media than to the scientific community.And, as always, only additional studies and discoveries can shed light on the matter and eventually resolve the controversy. In particular, the fossils of the Dinaledi chamber have not been dated and we do not know if they are hundreds of thousands or millions of years old. So we will have to wait for these additional studies to find out more about the homininos buried in the Dinaledi chamber. Although it is possible that we will never be able to reveal their secrets.",
    "https://upload.wikimedia.org/wikipedia/commons/1/17/Natsume_Soseki_photo.jpg": "One of the most dramatic is that of Hachiko, the Japanese dog who waited for nine years for the arrival of his dead master at a Tokyo metro station. According to history, Hachiko used to expect the arrival of his master every day, who was a professor at Tokyo University, at the subway station at the end of the day. One day the professor died at the university of a stroke and the dog waited for him at the station. Surprisingly, Hachiko did so for nine years, throughout which he went daily to wait for the train where his master would arrive. In remembrance of Hachick\u00f3\u2019s loyalty, the Japanese raised a bronze statue with his effigy at the entrance of the metro station where he watched uselessly for a good part of his life. Given the affective ties that can develop between humans and dogs, it is not surprising that there are So many people who adopt them as pets \u2013 and in some cases even as family members\u2013. On the other hand, it is striking that cats, who have not shown to humans the same loyalty as dogs, surpass the latter in popularity as pets, both in the United States and in Europe.The apparent attitude of indifference \u2013 or at least less attention \u2013 of cats towards us compared to dogs, has led some to qualify the former as useless and malevolent beings, which they like to torment smaller animals, and those who would not even worry about alerting the owners of the house in which they cohabit in the eventuality that a thief had been introduced \u2013 which is a virtue of dogs. Popular belief, according to which with cats we do not unite the same type of affective ties that unite us with dogs, finds scientific support in an article published this week in the online magazine PLOS ONE by Alice Potter and Daniel Simon Mill of the University of Lincoln in the United Kingdom. to determine the degree to which a young child is attached to his mother, Potter and Mill find that cats show independence from those who care for them. Potter and Mill's experiments were carried out with 20 cats and their respective owners. The tests consisted in observing the reactions of animals to the absence of their master and/or the presence of a stranger. They found that while cats vocalize more in the presence of strangers, they do not show other signs that reveal anguish due to the absence of the master, with which they prefer to interact, but to which they do not conceive as \u201ca focus of safety and protection in a dangerous world.\u201d Cats, compared to dogs and human babies, have a greater degree of independence from their caregivers, which would be in agreement with their nature as solitary hunters.Our ability to communicate with cats is, of course, limited and we do not have the assurance that it is what they actually thought during the experiment, when the master was not present or when they were in the company of a stranger. In fact, in a study prior to Potter and Mill \u2013 cited as In his article \u2013 we conclude that cats do form affective ties with their masters, which indicates the difficulty of penetrating their minds. We certainly cannot penetrate the brains of cats. Unless we enter the world of fiction, where we can find, for example, the book \u201cI am a cat\u201d, by the Japanese writer Natsume Soseki \u201cI am a cat\u201d is a novel written in the first decade of the 20th century that has as a protagonist and narrator a cat; a cat held so little appreciation for its owners \u2013 and for all those who lived in its neighborhood \u2013 that did not even have a name. Throughout the novel, the nameless cat describes its relationship with humans \u2013 which you can boast was not at all good \u2013 and gives a critical view of what it sees around it. While Natsume Soseki\u2019s novel is fascinating, we cannot expect it to shed any light on the functioning of the minds of cats \u2013 and yes, on Japanese society a hundred years ago. mention a story, with a cat as the protagonist, that somehow balances in our minds the negative aspects of the apparent indifference of cats \u2013 according to Potter and Mill \u2013 towards humans.",
    "https://upload.wikimedia.org/wikipedia/commons/2/2c/James_Watt_by_Henry_Howard.jpg": "The steam engine, perfected in Scotland by James Watt, was a key element in the development of the Industrial Revolution which, as we know, was born in England some 250 years ago. Next to the Watt machine, another fundamental part of such development was coal, used as a fuel for its operation. With the Watt machine and coal, the era of the use of fossil fuels began, which, over the years, diversified to include oil and natural gas. The Industrial Revolution has been considered the most important event for the development of civilization after the invention of agriculture. Next to its many positive aspects, however, the Industrial Revolution has also had negative consequences. One of these has to do with the environment. Specifically, with atmospheric pollution with greenhouse gases resulting from the burning of fossil fuels. The week that ends today was lavish in news related to fossil fuels and pollution that in one way or another they produce in the environment. On the one hand, during its participation in the \u201cNational Clean Energy Summit\u201d in Las Vegas, Nevada, the Last Monday, August 24, President Barack Obama expressed himself for renewable energies, particularly solar energy, as a means to tackle the problem of global warming. He said in his speech President Obama, \u201cWe are here because we believe that there is no challenge that poses a greater threat to our future than climate change.\u201d He also stated that \u201cSolar energy is cheaper than conventional energy provided by service providers\u201d and that it is not time to withdraw federal support for renewable energy projects. While there are those who doubt that global warming is a real problem, the case is that the average temperature of the planet is experiencing an upward trend \u2013 despite the supposed \u201cpause\u201d that, according to some would be experiencing the Earth\u2019s climate. Thus, according to the National Ocean and Atmosphere Adminstration (NOAA) of the United States, 2014 was the hottest year on average since record and it is possible for 2015 to overcome it in this regard. Likewise, according to NOAA, last July has been the hottest since 18th. 80, with an average temperature of 0.81 degrees Celsius above the average temperature of the same month throughout the 20th century. The week that ends today also brought us news regarding fossil fuels in another direction. Specifically, in the form of an article published by specialists of the \u201cUniversity of Missouri\u201d in the United States, headed by Susan Nagel, which examines the potential health risks associated with the hydraulic fracture technique for the extraction of oil and natural gas. The hydraulic fracture technique requires the injection into the subsoil of large quantities of water and chemicals at high pressures, in order to fracture the underground rock in which oil or natural gas is trapped, which thus flows to the surface. This made it possible to exploit deposits that were previously considered inaccessible. In the United States, the hydraulic fracture has been so successful that through its use approximately half of its current production of oil and natural gas. There is, however, a controversy over the potential effects on human health that the chemical substances injected in the subsoil have. For 250 years, we have made use of the energy accumulated in fossil fuels over hundreds of millions of years. We have done so with the use of water sources that allow the population living in the vicinity of the wells exploited by hydraulic fractures to be exposed to these substances. One possibility is that they can contaminate aquifers because part of the injected fluids re-emerge to the surface. According to Nagel and collaborators, about 1,000 chemicals are used in the hydraulic fracture technique and some of these are adverse to health. In particular, these researchers are concerned about substances known or suspected to interfere with the hormonal functioning of the body. With this in mind, they carried out a review of more than one hundred published articles that study, on the one hand, the possible ways of dispersing pollutants, and, on the other hand, the effects that these substances have on the hormonal functioning of the body. Based on this review, Nagel and collaborators conclude that activities related to the hydraulic fracture \u201cmay potentially disperse complex mixtures of chemicals that interfere with the endocrine system and can potentially damage human development and reproduction.\u201d So much enthusiasm that we end up affecting the health of the planet. And now, if the suspicions of Nagel and collaborators were correct, we would be endangering even our own health.",
    "https://upload.wikimedia.org/wikipedia/commons/a/ae/Tzompantli_Tovar.jpeg": "On Thursday, August 20, specialists from the National Institute of Anthropology and History (INAH) announced the discovery of the remains of what they consider was the great Tzompantli of Tenochtitlan. These remains were located at a depth of two meters in the center of Mexico City, behind the back of the Metropolitan Cathedral. The research that led to the discovery of the great Tzompantli, which was associated with the Temple Major, lasted from February to June of this year.As we know, a Tzompantli \u2013 or zompantli, according to the Royal Spanish Academy \u2013 was a structure in which the heads of prisoners of war were exposed victims of ritual sacrifices. To fix the heads they were practiced parietal holes and were decked in wooden beams supported by vertical poles, so as to form a wall. The remains of the great Tzompantli discovered consist of a rectangular platform of 45 centimeters high, a width of six meters and a length that can be estimated to reach 34 meters. They were also found in the nucleus of the platform. 35 skulls arranged in a semicircle, joined by a mixture of lime, sand and tezontle gravel. They consider the experts who, in addition to the skulls found, there are many others to discover. Moreover, although the wooden elements of the Tzompantli did not resist the passage of time and the humid conditions of the terrain, the researchers discovered the holes in which the posts that supported the beams of the structure were placed. According to the specialists, the practice of the Tzompantli, which was extended along Mesoamerica, was due to the particular cosmovision of the pre-Hispanic peoples who lived in this region and had religious motivations. According to that cosmovision, the sacrifice of humans and other animals was essential to keep the world in operation. In the words of Miguel Le\u00f3n Portilla, commenting on the religiosity of the pre-Hispanic peoples: \u201c...that religiosity implied the belief that the blood of the sacrificed strengthened the life of the gods, in particular of the Sun. the continuation of the present cosmic age, we would say that human beings were redeemed from their cosmic destruction.\u201d Although the practice of human sacrifices historically occurred in other parts of the world, the apparent \u2013 albeit controversial \u2013 prevalence of it in Mesoamerica has led some to maintain manichean positions with respect to pre-Columbian civilizations \u2013 and to mitigate these positions has not helped, of course, that human sacrifices were associated with cannibalism practices. In response to the negative views regarding our predecessors, Leon Portilla notes that, as in pre-Columbian cultures, humans were redeemed from their cosmic destruction through human sacrifice, according to Christian theology \u201ca human and divine sacrifice is the origin of the redemption of all men and women on Earth.\u201d Apart from the moral qualification of the Mesoamerican population, we can say today that while the memory of the Tzompantli has survived through the sugar skulls that are made around the day of the dead \u2013 among other manifestations \u2013 the cosmovision of the peoples\u2019 So, although the magical visions of the world have not disappeared in the world, it would possibly be difficult for us to find someone who thought that to win a battle, children would have to be sacrificed. As presumably the Cholultecas would have done when in Cholula they intended to set up a trap for Cortes \u2013 which, by the way, ultimately resulted in disaster, as they were massacred by the Spaniards and their Tlaxcaltec allies. Today it is clear to us that the sacrifice of a child cannot condition the outcome of a battle. Nor is it possible to predict with certainty the outcome of a battle \u2013 unless it is among very unequal contenders \u2013 or the future of the world. It is not possible even by using scientific methods \u2013 let alone magical approaches. We have reasonable certainty, thanks to the research of scientists, that the Earth's climate is changing and will change more in the future; to what extent it will, we do not know for sure.The worldview of the Mexica, which this week was news thanks to the announcement of the discovery of the great Tzompantli of the Greater Temple, was clearly wrong however elaborate it may have been. Likewise, its predictive power was largely null, as is the predictive power resulting from any magical approach of the world. Those who died sacrificed to give their energy to the Sun \u2013 some possibly willingly, but others surely under protest \u2013 then did so in a sterile manner.",
    "https://upload.wikimedia.org/wikipedia/commons/e/ed/Kepler-452b_artist_concept.jpg": "After the arrival of the \u201cNew Horizons\u201d probe in the vicinity of Pluto on July 14, last week, we learned from the press about two more developments regarding deep space. On the one hand, NASA announced the discovery of the planet more similar to ours than we have been told about. This planet, which has been called Kepler-452b, is located at a distance of 1,400 light years from Earth. It has a diameter that is about one and a half times the diameter of our planet and orbits, with a period of 385 days, a star similar to the Sun. Furthermore, according to NASA, there is a good possibility that by its size Kepler-452b is a rocky planet. The discovery was published last week in the magazine \u201cAstronomical Journal\u201d by a team of researchers headed by Jon Jenkins of the NASA Ames Research Center. Kepler-452b receives approximately the same amount of solar radiation as the Earth, which places it within the \u201chabitability zone\u201d of its star. According to Jenkins and collaborators, this area is defined as as the region around a star where water, in an open space, can exist in liquid form on the surface of the planet. At a distance beyond the habitability zone, moving away from the star, solar radiation is reduced and water freezes; leaving that zone in the other direction \u2013 towards the star \u2013 the increase of solar radiation causes water to vaporize. Since liquid water is essential to sustain life as we know it, only in planets within the habitability zone of their respective stars could we expect it to exist \u2013 or have existed in some remote time \u2013 life with a certain degree of complexity. In the case of the planet Kepler-452b, there has been enough time for this to happen, as Jenkins and his collaborators estimate that this planet and its star were formed some 6,000 million years ago; that is, about 1,500 million years before our solar system. Last week also brought to us the news that Russian magnate Yuri Milner \u2013 who made his fortune with internet businesses \u2013 launched the initiative \u201cBreakhrough Listen\u201d that will allocate 100. The announcement was made at a press conference at the Royal Society in London. The initiative was supported by several scientific personalities, including the well-known physicist Stephen Hawkins. According to the website of \u201cBreaktrough Listen\u201d, the radio telescopes of Green Bank, Virginia and Parkes Observatory in Australia, will look for radio signals that denote intelligent life in a million stars of the Milky Way and in 100 nearby galaxies. In addition, the optical telescope of the Lick Observatory, in San Jose, California, will search for possible messages transmitted through a laser beam. For more than fifty years systematic efforts have been made to detect radio signals that reveal the existence of extraterrestrial life, with negative results to the present. According to its promoters, the initiative \u201cBreakthrough Listen\u201d is the greatest effort ever made to find extraterrestrial intelligence and will go far beyond what has been done so far. Thus, the initiative envisages exploring a region of the sky 10 As for the sensitivity of the instruments to be used, according to the electronic site of \u201cBreakthrough Listen\u201d, if a civilization in one of the nearest 1,000 stars emits a message with a power equivalent to that used by the radar of an ordinary plane, such a message can be detected by the radio telescopes of the project. Likewise, a hypothetical message transmitted from a nearby star can be detected using a laser beam of just 100 watts \u2013 the power of one of the incandescent foci recently discontinued. Will the project be successful in throwing a torrent of data and inundating the small community of scientists currently engaged in the search for intelligence outside our planet; community that will receive in one day as much information to analyze as it received in a year in its early days. Will the project \u201cBreakthrough Listen\u201d succeed with its 100 million dollars of support? There is no way to anticipate it, so to begin, we do not know if there are aliens. Milner himself assumes that it is likely that the project \u201cBreakthrough Listen\u201d with its 100 million dollars of support? Hawkings, however, affirms that in an infinite universe there must be life apart from our own and that we must give ourselves the task of searching for it. That there are worlds similar to ours in the Universe that could have originated intelligent life is something that is supported by findings such as that of planet Kepler-452b. Only the future, however, by detecting an interstellar message, could confirm it with certainty. On the other hand, in one way or another, the \u201cBreakthrough Listen\u201d project will have an impact, if not interstellar, yes at least at the level of this world, because the purchase of time from the radio telescopes of Green Banks and Parkes for purposes of the project will save them from a possible closure due to lack of funds for their operation.",
    "https://upload.wikimedia.org/wikipedia/commons/c/ca/Percival_Lowell_observing_Venus_from_the_Lowell_Observatory_in_1914.jpg": "In March 1930 the press of the world spread the discovery of the long-sought ninth planet of the Solar System. The discovery was carried out by the young American astronomer Clyde Tombaugh at the Lowell Observatory in Arizona, after a year of patient search. The new planet was baptized as Pluto \u2013 Pluto, for greater precision\u2013, the Roman god of the underworld. The name was suggested by Venetia Phair, an 11-year-old English girl interested in Greek and Roman mythology. Although in an interview published in 2006 by the BBC, Venetia Phair mentions that she does not remember if when she made her suggestion she was thinking about the \u201cdark and menacing Hades\u201d \u2013 the Greek version of Pluto \u2013 the name was suitable for a planet found in a cold and dark region of space, in the confines of the Solar System from where the Sun looks just like a very bright star. Pluto is not alone but accompanied by a satellite, discovered in 1978 by the American astronomer James Christy. This satellite, which is unusually large in relation to the size of Pluto, It circulates to the planet every six days always showing the same face. To complete the grim image of Pluto and its surroundings, this satellite was baptized as Caronte, the boatman of Hades who was in charge of transporting the dead to the underworld through the river Aqueroente. The week that ends today, 85 years after its discovery, Pluto is again news. This time by the arrival of the probe \u201cNew Horizons\u201d of NASA to its vicinity. Pluto is about 6,000 million kilometers from the Earth and has a relatively small size \u2013 its volume is just 0.6% of the volume of the Earth \u2013 so today we don\u2019t know much about it. At its maximum approach, the \u201cNew Horizons\u201d was located about 12,000 kilometers from Pluto, capturing images and scientific data that specialists expect to considerably expand the knowledge we have about the planet and its satellite Charonte. Although few images of Pluto and Charon have been released in which it is possible to see on the surface of the planet. Pluto mountains of ice with altitudes that reach 3,500 meters. In this respect, it should be noted that on the surface of this planet the average temperature is less than 230 degrees Celsius and that at this temperature the ice has a great hardness. The images transmitted by \u201cNew Horizons\u201d of the surface of Pluto also show an extensive bright area in the form of a heart. An approach of this area discovers an icy plain of nitrogen and methane, with polygonal areas of about twenty kilometers long, bordered by channels in appearance not too deep. NASA has also released an image of Caronte that shows fractures in its surface that extend over 1,000 kilometers, as well as a canyon that is estimated to have a depth between 7 and 9 kilometers.One thing that has surprised specialists is the small amount of impact craters observed on the surface, both of Pluto and Charon. This implies that the traces of impacts since the formation of Solar System have been concealed by geological processes. Both Pluto and Caron would be of this geologically active mode. The source of heat inside both bodies that sustains this activity, however, is for the moment a mystery for specialists. In the first half of the 19th century Urban Le Verrier in France and John Couch Adams in England independently predicted the existence of an eighth planet in the Solar System, with an orbit beyond the orbit of Uranus \u2013the seventh planet. This prediction was based on the disturbances observed in the orbit of Uranus that indicated the presence of a massive body undiscovered until that date. The eighth planet \u2013which received the name Neptune \u2013 was discovered by the German astronomer Johann Gottfried Galle in 1846. Galle discovered Neptune guided by Urban Le Verrier, who indicated to him the place of heaven in which he should seek. Similar to the eighth planet, astronomers predicted the existence of a ninth planet, the so-called Planet X, based on apparent irregularities observed in the orbits of Urano and Neptune, and the discovery of Pluto in 1930 seemed to give them reason. It is now clear, however, that Pluto's mass is not large enough to produce the supposed perturbations of the orbits of Uranus and Neptune; perturbations that, on the other hand, we know today are not real. Thus, Pluto, which was originally thought to be Planet X, is actually too small and has nothing to do with it. Even more, we now know that Pluto is not even a planet, as it was degraded from this category by the International Astronomical Union in 2006 which now classifies it as a dwarf planet.Even a degraded category, however, according to specialists, Pluto is an extremely interesting object of study.It is the most distant planet \u2013 dwarf or well-grown \u2013 with which we have made contact.",
    "https://upload.wikimedia.org/wikipedia/commons/1/10/Vesuvius_from_Pompeii_%28hires_version_2_scaled%29.png": "In the course of two years, during 1982-1984, the soil of the port of Pozzuoli on the west coast of Italy rose by almost two meters. Among other consequences, this phenomenon caused that the waters of the port did not have enough depth to accept vessels of great draught. Although this phenomenon did not prove unusual, since it is known that the land in Pozzuoli has suffered elevations and descents since the times of the Romans, the speed with which it was given \u2013 authorized to the occurrence of a earthquake of magnitude 4 \u2013 caused alarm, forcing the evacuation of 40,000 people in prevention of a possible eruption. It is not difficult to understand that there has been an alarm because of what was happening in Pozzuoli, if we remember that this city is located in an area surrounded by volcanoes, and a little more than fifty kilometers from Mount Vesuvius, the same one that buried the cities of Pompeya and Herculano when it erupted in the year 79 of our era. On the other hand, although in the episode of 1982-84 the soil of Pozzuoli suffered a great deformation, it was remarkably resistant to the fracture. . The reason for this has been a mystery. At least it was until this week when an explanation in an article appeared in the magazine \u201cScience\u201d. This article was published by Tiziana Vanorio and Waruntorn Kanitpanyacharoen of Stanford University in the United States. According to these researchers, the Pozzuoli subsoil contains a layer of resistant and ductile material similar to concrete, which gave it the strength necessary to withstand the efforts suffered in 1982-84. To reach this conclusion, Vanorio and Kanitpanyacharoen studied samples of the subsoil in the Pozzuoli area taken to a depth of 2.9 kilometers. They found that near the surface the subsoil contains a layer of volcanic ash rich in silicon oxides and aluminium \u2013 known as pozolana\u2013. At a great depth, on the other hand, there is a layer of rocks containing calcium carbonate and that chemical reactions of minerals in this layer with other constituents generate calcium hydroxide \u2013 one of the components of the cement \u2013 which flows to the surface. the calcium hydroxide with the layer of pozolana is generated a layer of concrete and it is this layer that gives it its particular resistance to the subsoil of Pozzuoli. According to Vanorio, the concrete thus generated in a natural way, is similar to that manufactured by the Romans two thousand years ago using the same volcanic ash of Pozzuoli \u2013Puteoli for the Romans\u2013 although with a different source of calcium. The Romans used their concrete in constructions such as the Roman Pantheon and the Roman Coliseum. The pozolana was also used in the construction of ports on the shores of the Mediterranean Sea, including Alexandria and Cesarea. It was in Puteoli, according to Vanorio, where the Romans carried out the discovery of the procedure to manufacture the concrete using the volcanic ashes of the locality, and suggests that the inspiration to achieve this came to them through the observation of the hardening that the poolana experiences to the contact with water. Already in the year 25 before our era, the Roman architect Vitruvius recommends poolana for the preparation of the structural mortar. If Pozzuoli had not existed, the Romans would not have built the Roman Pantheon, with its dome of more than forty meters of diameter, which has resisted for 19 centuries the inclementness of time, as well as other notable architectural works. Roman concrete technology is thus fundamentally empirical, the result of an accidental discovery \u2013 and, of course, of a great capacity for observation \u2013 in contrast to the current science-based technologies based on a systematic search with the guidance of scientific knowledge of natural phenomena, while remaining dependent, however, to some degree, on accidental discovery. Interestingly, the article by Vanorio and Kanitpanyacharoen in some way places us in one place on our planet, Pozzuoli, in two periods separated by 20 centuries. As regards the present time, through complex and profound underground explorations and complicated chemical elucubrations, the article teaches us what is the composition of the subsoil of Pozuoli. zzuoli and what are the possible causes \u2013 the natural formation of an underground layer of concrete \u2013 for which the threatening phenomena occurring underground have not been as deadly as we might suppose. On the other hand, it reminds us that Pozzuoli would have been the origin of the Roman technology of concrete, developed surprisingly 20 centuries ago, and which produced works that even today draw attention.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d5/Geodynamo_Between_Reversals.gif": "In the first half of the last century physicists discovered that the Earth suffers a continuous bombardment of high-energy particles. And that these particles, which have been called cosmic rays, are generated outside the solar system, in places that have not yet been clearly identified. The characteristic energies of cosmic rays are very large and incompatible with life as we know it. In fact, these rays are one of the greatest obstacles to the realization of the publicized mission manned to Mars, during which astronauts would be exposed to a continuous bombardment of energy. Cosmic rays can even be harmful to inanimate objects, as is the case of computer processors controlling space missions. On our planet we are protected from cosmic rays by the Earth's magnetic field, which diverts them to space, as well as by the Earth's atmosphere, which absorbs those who manage to enter. Some cosmic rays, however, manage to reach the surface of our planet in the form of secondary rays generated when primary rays collide with air molecules. At sea level, secondary rays are formed mostly. The muons are particles that can penetrate relatively large distances in the matter and this has given rise to an interesting application: the obtaining of images \u2013tomographs \u2013 of various objects in which their internal structure is revealed. This application is the subject of an article published this week in the journal \u201cScience Advances\u201d, published by a group of researchers from the United States, headed by J.M. Durham from Los Alamos National Laboratory. As we know, by means of X-rays we can obtain an image of the inside of the human body projected in two dimensions. This is possible because the different parts that make up our body absorb X-rays in a differentiated way. Thus, those parts that absorb more X-rays appear in the x-ray with less exposure compared to those that are more transparent. X-rays also allow to obtain tomography, which reveal the inner structure of the objects and not only their projection in two. As with X-rays, it is possible with muons to obtain images of two dimensions of three-dimensional objects, with the difference that muons penetrate the matter much more than the former. This allows to study large-scale objects, as well as large-density objects. Thus, muons have been used to investigate the interior of pyramids and volcanoes, to cite two cases. According to Durham and collaborators, muons can also be used to obtain tomography of opaque objects, not susceptible to being studied by means of X-rays. In their publication this week, researchers demonstrate that muons tomography allows, for example, to obtain a three-dimensional image of the interior of a metal valve indicating whether it is in open or closed position, or an image of the interior of a metal pipe showing corrosion problems. Muons tomography, according to Durham and collaborators, has advantages over other techniques. It can be used, for example, to assess the corrosion status of pipes in nuclear power plants without disrupting the operation of the plant, or to inspect components embedded in concrete. In contrast, given the low density of muons that impact on the Earth's surface, the time required to obtain a tomography scan is measured in hours. Thus, muon tomography could not be used for a rapid assessment of an installation. Another disadvantage of this technique is its poor resolution \u2013 the images obtained are blurred \u2013 compared to X-ray or ultrasound techniques. We have thus that muon tomography has advantages over other techniques for obtaining three-dimensional images from inside an object, advantages that are based on the ability of muons to penetrate and \u201csee\u201d the inside of material objects and leave them before being absorbed. It also has disadvantages, which are possible to be reduced in the future as technology is advanced. However, it is interesting to note that muon tomography, like all advanced technologies of our days, is based on scientific discoveries. , which in their case were carried out in the first half of the 20th century. Without these discoveries there would be no muon tomography, and the mere idea that by means of invisible rays we could know what an opaque object has inside, would have been discarded as impossible. Or proper to some occult practice.",
    "https://upload.wikimedia.org/wikipedia/commons/3/37/Watervapor_cup.jpg": "After seven months of hibernation, the Philae probe of the European Space Agency gave signs of life last weekend and with this was revived the confidence that the scientific goals set for the Rosseta mission, of which Philae is a part, can be reached. The Rosseta mission aims to study in close proximity to that comet as it approaches the Sun and enters into activity. For this purpose, the Rosseta spacecraft, with the Philae probe on board, reached the comet on August 6th last year at a point between the orbits of Mars and Jupiter, accompanying it since then on its journey to the Sun. In addition to the above, as we may recall, last November Philae departed from the Rosseta ship and lined up towards the surface of the Churymov-Gerasimenko comet, with the purpose of staying there throughout the mission and obtaining, first hand, data from the comet and its \u201clight\u201d on his journey to the Sun. Philae failed, however, a controlled descent and to the whole mission, but This limited the amount of solar radiation that the solar panels of the probe could receive to recharge their batteries, forcing them to enter a state of hibernation.In these conditions, it was only left to those responsible for the Rossetta mission to cross their fingers so that later, when the comet was closer to the Sun, the solar radiation would have enough intensity to recharge the batteries of the probe and the latter could leave its state of hibernation. Fortunately, this was what happened last weekend, when the Rossetta ship was able to establish communication with Philae for 85 seconds. For what purpose was a spaceship sent to follow the Churymov-Gerasimenko comet in its path to the Sun? With regard to this, scientists consider that the composition of the comets reflects the composition of the nebulae from which the Sun and the planets were formed 4,600 million years ago and, according to the European Space Agency, the study, in close proximity to it, In particular, one of the questions that scientists intend to solve with the Rossetta mission is the one concerning the origin of water on Earth. As we know, water is an element of fundamental importance to us and without which life as we know it could not have developed. We also know that water on Earth has a cycle through which it first evaporates from lakes and oceans, then condenses into the atmosphere forming clouds and finally precipitates in the form of rain starting the cycle again. All this is taught to us in school. We rarely, however, wonder how water first originated on our planet.According to the European Space Agency's website, water would have existed as part of the nebula from which the Earth was formed. The high temperatures that once prevailed on the surface of our planet, however, would have evaporated and sent it to space. Thus, the current water on Earth should have come from outside. One hypothesis in this regard is that water arrived transported on asteroids and comets that have collided with our planet over time. One way to check this hypothesis is by comparing the proportion of heavy water characteristic of terrestrial water, with the corresponding proportion of water of asteroids and comets. \u2013It should be remembered that the water molecule is made up of two hydrogen atoms and one oxygen atom and this is true both for ordinary water and for heavy water; in the latter case, however, the hydrogen atoms that constitute the water molecule are hydrogen isotopes heavier than ordinary hydrogen. According to the above, if the water of lakes and oceans had originated in comets such as Churyumov-Gerasimenko, the terrestrial water and the water of that comet should have a similar proportion of heavy water. A first result obtained by Rossella after analyzing the water of comet Churyumov-Gerasimenko is that its proportion of heavy water is three times higher than the corresponding proportion of water on Earth. This constitutes evidence against the cometary origin of water. In the coming months, as the comet Churyumov-Gerasimenko approaches the Sun, reaching its peak point on August 13, Rosseta will have a privileged view of the process of \u201con\u201d the comet Churyumov-Gerasimenko at a distance of a couple of hundred kilometers. With the information they get, experts will be able to answer more questions about the nature of the comets. At the same time, it seems that the Philae probe will be able to follow the process of \u201con\u201d the Churyumov-Gerasimenko still closer than Rossetta: no more or less than a distance of zero kilometers, from the same surface of the comet. In the next two months we will know what results from all this, that in the first instance it seems to be excellent news.",
    "https://upload.wikimedia.org/wikipedia/commons/2/22/Kuchenmaistrey.jpg": "We would certainly agree that to run into a chimpanzee who cooks his food would be very surprising, because, as far as we know, humans are the only species on this planet that does. None of the great apes does, let alone other species further away from us. This would indicate that the cognitive skills that are necessary to develop the practice of cooking food \u2013 which we have led to levels of great sophistication \u2013 are exclusively human. An article published this week in the magazine \u201cProcedings of the Royal Society B\u201d by Felix Warneken and Alexandra G. Rosat of Harvard University, however, would indicate that this is not strictly true, and that chimpanzees, a species close to ours, share with us, in addition to the taste for cooked food, some of the skills that have led humans to develop the art of cooking.According to Warneken and Rosat, the practice of cooking food developed by our distant ancestors required several cognitive skills. that the piece of raw meat that we have before us can be placed on a hot grill and with this substantially improve its flavor. It also required the ability to abstain from eating raw meat as soon as we have it at our disposal \u2013 especially if we are hungry \u2013 and to wait for it to be cooked to do so. And it required, of course, the ability to control the fire.To find out to what extent the chimpanzees possess these skills, Warneken and Rosat carried out a series of eleven experiments with semi-cautive chimpanzees of the Republic of the Congo in Central Africa. These experiments sought, among other objectives, to check whether chimpanzees prefer cooked or raw food, or, if they had a food in hand, before eating it they would be willing to get rid of it and place it in a \u201cstufa\u201d to cook it. The \u201cstufa\u201d in this case consisted of a plastic container with a double bottom in which a slice of cooked potato is hidden. To \u201ccooked\u201d a raw slice, the experimenter The experiments confirmed results previously obtained by other researchers in the sense that chimpanzees prefer cooked foods to raw foods. They also demonstrated that chimpanzees are able to understand, with a minimum of experience, the process of transformation that a certain food undergoes by placing them in the \u201cstufa\u201d and generalizing this knowledge to other foods. Likewise, they were able to store raw foods for cooking and subsequent consumption, resisting the temptation to account for them immediately. If chimpanzees share with us the psychological skills that have led us to develop the art of cooking, Warneken and Rosat wonder why those did not achieve the same. An obvious answer, they point out, is because chimpanzees do not control the fire. There may be more reasons, however. One of these is that a typical food of chimpanzees are fruits, for which the Since chimpanzees have the psychological skills necessary for the development of the kitchen, and these were presumably present in our distant ancestors, even before the adoption of the fire, Warneken and Rosat speculate that the cooking of the food was quickly given after this adoption. They point out, even to an opportunistic use of natural fire to cook food. In this regard, they point out that it is known that chimpanzees in their natural habitat actively seek, to consume, seeds that have been roasted by forest fires. It seems, according to Warneken and Rosat, that although chimpanzees possess the set of psychological skills necessary to develop the art of cooking \u2013 including understanding the process of transforming food by cooking, as well as patience to resist the temptation to eat a raw potato before waiting enough time to cook it\u2013, they have not done so perhaps because this does not present enough advantages for them. Or, well, perhaps, because they have not discovered how In one way or another, chimpanzees do not cook \u2013 yet the findings of Warneken and Rosat \u2013 and this would have relegated them to a secondary role in evolution compared to our species. This, because cooked foods would have provided us with greater energy resources for the development of a larger brain. Thus, cooking would have made a difference.",
    "https://upload.wikimedia.org/wikipedia/commons/6/60/Myoglobin.png": "Chocolate is without doubt a food with a great reputation and charm and to which it is attributed, justified or unjustified, a great deal of nutritional properties and benefits. Perhaps this is why the press release issued last March in Germany by the Institute of Diet and Health, according to which the daily consumption of bitter chocolate helps to control the weight was received with great enthusiasm. This statement was widely disseminated by the press all over the world, including the German newspaper \u201cBild\u201d which dedicated a front page to it. In the above-mentioned statement the results of a study, led by Johannes Bohannon, of the Institute of Diet and Health of Germany, which aimed to investigate the effects that chocolate consumption has on 18 health indicators, including body weight, cholesterol and sodium levels, protein level in the blood, sleep quality and general well-being. To carry out the study, which was extended for three weeks, Bohannon and collaborators divided the volunteers involved into three groups. Two of the groups were subjected to a low carbohydrate diet and the third, which served as a control group. In addition, one of the diet groups was given to consume 42 grams of bitter chocolate every day. Each participant's weight was measured daily during the 21 days of the test. It was found that those who followed their normal diet increased and randomly reduced their weight, without modifying it on average. Those who were subjected to a diet, in contrast, lost on average 5 pounds throughout the study. In addition, those who consumed chocolate made it 10% faster, at the same time that they improved their cholesterol levels and their sense of well-being. The conclusion of the study, published in the journal \u201cInternational Archives of Medicine\u201d, was that the consumption of chocolate accelerates the loss of weight among those subjected to a diet. Thus, chocolate, in addition to all the virtues that we attribute to it derived from its flavor, would constitute a beneficial food for our health. The result could not be better. No, if it were not because the article published by Bohanonn and collaborators is a fraud, as he himself made known in a blog published last Wednesday. Johannes Bohannon is actually John Bohannon. hannon, who works as a reporter for the magazine \u201cScience\u201d. The same one that two years ago carried out a project to expose those scientific publishers who publish articles without the proper editorial rigor by paying a fee. On that occasion, Bohannon wrote versions of an article on the discovery of a new drug to treat cancer, which suffered from obvious scientific failures and sent to 304 online magazines, of which 157 accepted it. Bohannon\u2019s new article-fraud on chocolate, as he relates it in his blog, was the result of an initiative by two German television reporters who intended to produce a documentary on the science-scrap of the food industry. To this end they approached Bohannon \u2013 who is not an expert in nutrition but in molecular biology \u2013 and together decided to carry out the study reported in the article. This study was carried out with a group of 15 participants, recruited with a payment of 150 euros. The number of participants in the study was too small to reach a conclusion. The recipe for this was to measure a large number of parameters \u201318 in total \u2013 in a small group of participants, which made it likely that one of these parameters \u2013 not necessarily body weight \u2013 would appear to be correlated with the consumption of chocolate, without this being the case. This could be verified by carrying out the study again, which was not done, of course.The article was published in a magazine that is on Bohannon's list of publishers who publish fraudulent articles, without it having been previously reviewed by experts who would surely have rejected it because of their lack of scientific rigor.Once the article and the press release were published, the information went into the media and expanded widely throughout the world.What does all this teach us? According to Bohannon, among other things it shows the \u201cincredible laziness\u201d of some science reporters who do not take the work of verifying the truthfulness of scientific statements; which, on the other hand, could have been published in unserious journals that did not show us the \u201cunbelievably serious\u201d of some science reporters who did not. they take the trouble of carrying out a rigorous review by experts of the material they publish. What they do, of course, by paying a fee that in some cases is considerable. It tells us, moreover, that not because they are written the scientific statements are necessarily true. They are not, of course, if they originate in a fraud. And they might not be so even if they come from an investigation would be, because, by nature, the results of science are always subject to review.",
    "https://upload.wikimedia.org/wikipedia/commons/4/4b/16_wood_samples.jpg": "In 1921, Danish archaeologists discovered near the village of Egtved in Denmark, in a tomb of almost 3,400 years old, an oak-wood coffin containing the remains of a teenager aged between 16 and 18 years old. The teenager was baptized as the \u201cYoung Egtved\u201d, and although her body survived only the hair, nails, teeth, part of the brain and some skin \u2013 the bones had apparently disappeared, due to the acidic environment in which the body was found \u2013 the finding is notable for the degree of preservation of the clothes she was buried in and would have worn in life. The teenager was buried in a wool blouse with sleeves up to her elbows, leaving her abdomen uncovered, and a short skirt of ropes giving her two laps to the waist. A wool belt held a bronze medallion that, according to experts, would have represented the Sun. Dressed in this way, the Young woman of Egtved would have had a strangely modern appearance. Egtved\u2019s young woman died during the front. the summer of the year 1,670 before our era, and when he died he had a height of 1.60 meters. He had a high social position and it is possible that he participated in ritual dances for the medallion he carried. It was not native to the place where he was buried and had traveled hundreds of kilometers before dying, possibly to his place of origin. When he died he had little to have returned to Egtved, where he lived permanently. How do we know so much of someone who died thousands of years ago? It is not difficult to conclude that the young woman died in the summer, since remains of flowers were found inside the coffin. As for her stature, although her bones had disintegrated, the silhouette of the Young woman of Egtved was clearly delineated in the cow's skin on which she lay in the coffin, which allows us to know precisely what her height was when she died. Likewise, we know precisely the year in which she died from an analysis of the rings of the wood with which the coffin was made. We know, moreover, that the thickness of a ring depends on how favorable or unfavourable the climate of that year was for the growth of the trunk. Thus, by studying the thickness of the rings of a tree it is possible to determine the time in which it lived. Knowing where the Young woman of Egtved was in the months before a death is a little more complicated. An international group of researchers led by Karin Frei of the National Museum of Denmark, however, managed to find out, by analyzing the relative content of two isotopes of the strontium chemical element, in the teeth, nails and hair of the Young woman of Egtved, making use of the fact that this content depends on the geographical place. The results of the research were published last May 21 in the journal \u201cScientific Reports\u201d. The strontium is absorbed by living beings through water and food. In particular, according to Frei and collaborators, the strontium is fixed during the first 3-4 years of life in the molars, which they carry on the molars. Thus the information of the place where the person lived in his early childhood. An analysis of the strontium content of the Molars of the Young woman of Egtved made it clear that it was not born in the place where he died, since the relative composition of isotopes of this element does not correspond to that of that place, and possibly to a region of the south of present Germany. Based on this discovery, Frei and collaborators speculate that possibly the Young woman of Egtved would have been born hundreds of kilometers south of where her tomb was found, and that it may have ended away from her place of origin by having been given in marriage to establish an alliance between power centers in Denmark and in the south of Germany.Frei and collaborators also analyzed the strontium content of the hair, which they cut in four segments in order to analyze the changes that occurred over a period that could span up to 23 months. They found that in the oldest segment the composition of strontium is consistent with that of southern Germany, indicating that the Young woman of Egtved lived for some time in that area. However, the composition of strontium is similar to that of Denmark, from which it is concluded that the young woman moved from the south to her place of residence. Finally, in the younger hair segment, which corresponds to a few months before her death, the composition of strontium is again the one that corresponds to the south of Germany. Thus, in the course of about two years before her death, the Young woman of Egtved would have moved repeatedly, for hundreds of kilometers, between her place of residence in Denmark and her place of origin in the south of Germany. Thus, if the results of Frei and collaborators were correct, the Young woman of Egtved is surprisingly modern, not only in her way of dressing, but also in her great mobility.",
    "https://upload.wikimedia.org/wikipedia/commons/9/93/Herakles_and_Telephos_Louvre_MR219.jpg": "According to a recurring fantasy in the last century, cavemen had the habit of beating their women with a claw and dragging them by the hairs to the cave in which they lived. All this having as a framework a landscape of abundant vegetation, smoking volcanoes in the distance, and gigantic dinosaurs with dorsal fins, long tails or affiliated teeth. How close or distant is this fantasy of what really was the world that our ancestors inhabited? As far as we have coincided in time with dinosaurs there is nothing further from the truth, for they disappeared from the face of the Earth 65 million years ago, when on the planet there was not yet even the slightest trace of Homo sapiens. With regard to the cave that served as a room, the species does not seem to be true if we consider that cavemen would have been nomads, hunters-gathers, who did not live in a fixed place \u2013 seen in this way, the name of cavemen is in a certain wrong way. This article was published by a group of researchers at University College London, headed by Mark Dyble. Although perhaps no one would believe that in a widespread and daily manner caverners treated their women with blows that could kill them \u2013 which would have led to a shortage of women and thus new births \u2013 the fantasy of the half-glodyte dressed with furs dragging a woman through her hair reflects a stereotype according to which primitive men were violent and macho. According to Dyble and collaborators, however, before the emergence of agriculture and sedentarism, gender equality existed in primitive societies, so that this stereotype would be incorrect. British researchers came to their conclusions after studying two modern groups of hunter-gatherers, the Palanan Agta of the Philippines and the Mbendjele of the Congo in Central Africa, as well as a group of farmers, the Paranan One objective of the research was to determine the degree of consanguinity that exists among the members of these groups, which are formed by approximately twenty individuals. According to Dyble and collaborators, it is known that the members of a social group have the tendency to admit as new members people with whom they are related. In fact, however, and in an apparent paradox, the groups also include members without any blood bond with their peers. In line with this, Dyble and collaborators find that in the groups of hunter-gatherers studied 14% of members are not related to the other members of the group. Researchers resolve the paradox noting that in the groups of hunter-gatherers the decision to admit a new member can be taken by both men and women, which increases the number of non-sanguineous people who could be admitted. This eventually leads to the incorporation into the group of members without kinship thus increasing their heterogeneity. The apparent paradox is, thus, the natural result of the In contrast to the groups of hunter-gatherers, among the groups of farmers studied the percentage of members without any relationship of kinship with the other members is only 4%; this, as a reflection of greater inequality between men and women when deciding the admission of a new member.Dyble and collaborators assume that the gender equality observed in nomadic groups of hunter-gatherers studied was the norm among primitive groups and suggest that such equality played a fundamental role in the social development of humanity.In particular, by promoting the development of heterogeneous groups, sexual equality promoted contact and cooperation between individuals beyond the borders of consanguinity, as well as the exchange and perpetuation of technological innovations.If we are to attend to the conclusions of Dyble and collaborators, gender equality is not a recent invention. Far from this, it would have been in force in the past among our hunter-gather ancestors, then lost for some reason. caverners armed with a club dragging a woman by her hair, in addition to pitiful, would then be just that: cartoons with no greater connection to reality.",
    "https://upload.wikimedia.org/wikipedia/commons/1/1f/IWM-MH-9922-Crossley-Armoured-Car.jpg": "In an article published last May 1 in the journal \u201cScience Advances\u201d by a group of researchers led by Vipan Parihar of the University of California in Irvine, it is reported that mice subject to high-energy radiation, such as those to which future astronauts would be exposed on an interplanetary journey, show damage to the central nervous system, as well as a reduction in their cognitive abilities. This would be particularly critical for the crew of a spaceship that would have to make autonomous decisions in unforeseen situations, which would require all of its intellectual capacity; without neglecting to consider, of course, that damage to the central nervous system would leave astronauts with sequelae for life. The results of the study of Parihar and collaborators add a further obstacle to the realization of a trip to Mars in the near future; in particular, to the mission that NASA has proposed for the year 2035, not to mention the \u201cMars One\u201d project of a Dutch private company, which aims to colonize Mars in the next decade.The solar system is a dangerous place, full of high-energy radiation coming from a Dutch company. These radiations are incompatible with life, and if it has prospered on Earth, it has been due to the protection afforded by the atmosphere, which absorbs radiation, as well as the magnetic field surrounding our planet, which diverts them. Since none of these protections would be available in the course of a trip to Mars, a manned spaceship must have adequate anti-radiation shielding. To shield a spaceship, however, means adding weight to it, which in turn increases the cost of launching it into space. In this regard, it should be noted that at present, according to NASA, the cost of placing an object in orbit is about $10,000 per kilogram. And, of course, to bring it to Mars, that cost is even greater. This reflects the great amount of energy that must be provided to an object to leave our planet. In order for this to happen, it is necessary to accelerate it upward until it reaches such a speed as to counter the Earth's attractive force. As we know, if we throw a stone up, it would eventually return to the ground after having reached a certain height. This height will be higher as soon as the speed we initially printed to the stone is higher, and at this point one wonders how big that speed would have been so that the stone would no longer return to the ground. The answer is known \u2013 or should have known it \u2013 by any student who has passed an elementary physics course: the minimum speed to escape the gravity force of our planet is approximately 40,000 kilometers per hour. This speed is extraordinarily large compared to the speeds we are used to. In particular, it is clear that we could not even remotely throw a stone up with our arm with enough force to escape from the Earth. It is more, nor Nolan Ryan, the big league pitcher famous for his fast ball, could have done it, even in his best times, because he was barely able to throw the ball at a modest 160 kilometers per hour \u2013 if he did it regularly. In practice, to put one object into orbit, or to send it to another. The high cost of putting an object into orbit is associated with the volume of rocket fuel needed to overcome the Earth's attraction, which grows, of course, with the weight of that object. Critics of NASA's plans to carry out a manned mission to Mars in about two decades point out that the problem posed by the high-energy radiation to which astronauts would be exposed on a return trip, the duration of which would be measured in years, is not solved by the high cost of shielding the spacecraft against such radiations. These, in addition to its well-known carcinogenic potential, can cause neurological damage to the crew, if we are to attend to the results of the Parihar research and collaborators.For the above and other factors, space is certainly a dangerous and incompatible place with life. Much more dangerous and beyond our reach than we might possibly think in the first instance depending on the technological advances that have enabled manned missions to the Moon \u2013 which, in fact, is in the vicinity of the Earth compared to Mars \u2013 as well as the sending of remotely controlled robots to the Martian surface. In this context, it is possible that, at least in the coming decades, interplanetary manned journeys will be nothing but fantasies, at best in the field of science fiction.",
    "https://upload.wikimedia.org/wikipedia/commons/7/79/Himalayas.jpg": "As the days go by, the number of fatal victims of the earthquake that occurred in Nepal on Saturday, April 25th will increase in the next few days. According to the latest report by the Nepalese government, the number of deaths from the earthquake exceeds 6,800. This number, however, will surely increase in the next few days as isolated villages are reached in the mountains. In a statement issued by the \u201cUnited States Geological Survey\u201d, 15 hours after the earthquake, it was estimated that there were 52 per cent chance that the number of fatal victims would be at least 10,000, a figure that we now know was not far from reality. In fact, it falls short, according to other more pessimistic estimates. For example, the geophysicist Max Wys, affiliated with the \u201cInternational Center for Earth Simulation\u201d in Geneva, Switzerland, estimates the number of fatal victims at 57,700. This estimate is proportional to the magnitude of the earthquake, which reached a magnitude of 7.8 on the Richter scale, as well as with the number of inhabitants in the affected region. According to Wyss, in the region that experienced seismic shocks with an intensity on the scale of Mercalli equal to or greater than 6 \u2013 which would have caused serious damage to poorly constructed houses \u2013 22.8 million people live. Wyss also finds that 7 million people live in the area that experienced an intensity 8 on the same scale. The earthquake had an epicenter at a point located about 80 kilometers north-west of the capital Kathmandu. As we know, the north of the territory of Nepal is crossed by the Himalayan mountain range, which has nine of the ten highest mountains on Earth. The Himalayan mountain range was formed by the collision of the tectonic plates of India and Eurasia that began about 65 million years ago. Today, the plate of India continues its movement to the north, sliding below the Eurasia plate at a speed of two centimeters per year and raising with this the Himalayan mountain range. This earthquake, moreover, had the peculiarity of occurring in an area known as the central seismic gap, which extends for 700 kilometers from Kathmandu in the east to the Indian state of Uttarakhand in the west, in which no major earthquake had taken place in a long time. According to French geophysicist Laurent Bollinger, the last time an earthquake would have occurred in that area was in 1344, and while in this regard there is no unanimous agreement, it is accepted that the time has elapsed since the previous earthquake is measured in hundreds of years. Given the absence of centuries of earthquakes in the region of the central seismic gap and the consequent tensions accumulated throughout this time, specialists have considered for decades that the occurrence of a major earthquake in that region was inevitable. In this regard, to mention only a recent study, an article published on 12 March by a group of researchers in universities in Australia and India comes to the same conclusion. ; this, on the basis of geological studies carried out in Uttarakhand. And now, after a long pause, the expected earthquake finally arrived; although, according to Laurent Bollinger, not with sufficient intensity \u2013 which is certainly fortunate \u2013 to completely relieve the accumulated tension for centuries. Thus, Bollinger hopes that large-scale earthquakes will occur in the future; when these will occur, however, cannot be determined by current science. If we cannot predict with certainty when an earthquake will occur, we could in principle mitigate its effects. According to experts, the high number of fatalities resulting from the earthquake of April 25th \u2013 and typically from others occurring in underdeveloped countries \u2013 is associated with the deficient housing construction techniques, which would even have worsened by the shortage of timber for construction prevailing in Nepal. In an article published in 2013 in the journal \u201cScience\u201d by Roger Bilham of the \u201cUniversity of Colorado\u201d and Vinod Gaur of the \u201cCentre for Mathematical Modelling and Computer Simulation\u201d \u201c in Balgalore, India, they refer to this problem. In their article \u2013 which they significantly headline: \u201cBuildings as weapons of mass destruction\u201d \u2013 Bilham and Gaur point to the two fundamental problems that are against efforts to mitigate the effects of an earthquake in underdeveloped countries: the lack of resources for the purchase of adequate building materials by a large part of the population, and the lack of anti-seismic building codes or their lack of implementation through corruption practices. As we know, both problems are difficult to solve. To begin to solve them, however, it might be worth realizing that a house or building badly built in a seismic area is indeed a deadly weapon.",
    "https://upload.wikimedia.org/wikipedia/commons/1/1c/Wells_-_The_Invisible_Man_-_Pearson_cover_1897.jpg": "Imagine that at will we could become invisible. What advantages or disadvantages would a skill like this represent to us? A particular vision in this regard is provided by the British writer H.G. Wells in his novel \u201cThe Invisible Man\u201d \u2013which might not be among the best of that author\u2013 in which he explores some aspects of invisibility. The protagonist \u2013invisible \u2013 of that novel, by the name of Griffin, is a scientist who manages to discover a substance that makes transparent to whoever ingests it and uses it in himself. The apparent power that gives it invisibility causes Griffin to lose ground and seeks to conquer the world by means of terror. In the end, however, terror turns against him and has an unfortunate end, dying struck by the neighbors of the people. While Wells\u2019s method of achieving invisibility is unlikely to be realized and does not transcend beyond the realm of science fiction, there are currently ongoing scientific researchs that are seeking to develop technologies to make it a reality. We can see an object that reflects and reaches our eyes. Thus, one way of making an invisible object is to avoid reflecting light. ; that is, manipulating the light so that it opens and surrounds the object and then unites again as if that object had not existed. In a work carried out a couple of years ago, a group of scientists managed to make relatively large animals invisible \u2013 a goldfish and a cat \u2013 using mirrors to manipulate the light. We can then contemplate that in the future \u2013 still uncertain, however \u2013 techniques can be developed to make us invisible, such as in H.G. Wells\u2019 novel, but using very different physical principles. In these circumstances, some have wondered what the effect of a hypothetical invisibility on our social behavior will be. An article appeared this week in the magazine \u201cScientific Reports\u201d helps to answer this question. This article was published by Swedish researchers, attached to the Karolinska Institute, headed by Arvid Guterstam. As a first step in their research, Guterstam and collaborators developed a way to induce in healthy people the illusion of being invisible. To carry this out, the researchers placed the volunteer with their head bent down, as if they saw towards their body. The purpose of the arrangement was to deceive the volunteer to take the image he saw in the viewfinder, generated by the cameras in front of him, as the real image that his eyes saw. The illusion of invisibility occurred by means of tactile stimuli in the volunteer body, which were applied simultaneously with identical virtual stimuli in the invisible body, which were captured by the cameras. Thus, the volunteer received the tactile stimuli in his body, while at the same time seeing through the viewfinder the simultaneous image of the same stimulus applied to the invisible body. It created the illusion that he was invisible. Once Guterstam and collaborators managed to create in the volunteers the illusion of invisibility, they were able to study how this affects the perception that we have of ourselves. They found, in particular, that invisibility reduces the anxiety that some people experience when speaking in public. . How would invisibility affect our social behavior? In \u201cInvisible man\u201d the protagonist was so disturbed with his invisible body that he reached extremes of madness. We would not expect an invisible man of the future to attempt to conquer the world. However, it is likely that from the impunity that would surely lead to invisibility would not be anything positive. Suffice it to point out the aggressiveness of the language employed by some people in the exchanges of comments that are given on the Internet, sheltered, if not by a body invisibility, yes by the invisibility that gives them virtual space. On the other hand, the technologies necessary to achieve an invisibility equivalent to that reported by H.G. Wells would be of such complexity that it is unlikely that they will come true in the medium term. Thus, while the study of Guterstam and collaborators is certainly valuable to specialists, their conclusions will not fortunately be tested in practice in the years to come.",
    "https://upload.wikimedia.org/wikipedia/commons/e/e3/Coat_types_3.jpg": "How, when and where did the domestic dogs that now occupy such a special place among us originate? Although the experts do not have definitive answers to these questions, a genetic study finds that the domestic dog descends from a kind of grey wolf, now extinct, that would have originated in a time before the beginning of agriculture, when our ancestors were still hunter-gatherers. The domestic dog would have thus lived among us for tens of thousands of years, during which period it would have undergone a drastic transformation, from the wild and ferocious animal that would have been in its origins, to a noble and friendly animal \u2013 if not always, as we have sometimes noted with fear \u2013 with which we can easily establish a cordial relationship. This latter even in a more expeditious \u2013 or at least more frequent \u2013 manner than with other animals closer to us, as is the case of chimpanze and other great apes. What is the reason why we humans have such a close relationship with dogs? A group of Japanese researchers, headed by Miho Nagasawa of Azabu University in Japan, believe that they have found it, according to the According to the Japanese researchers, the close relationship that exists between a dog and its owner has a biochemical basis and is associated with the secretion of the substance oxytocin, in both, dog and owner, as a response to their mutual interaction. It should be noted that oxytocin is a substance associated with the establishment of affective bonds between humans, in particular the mother-child bonds that form during the first months after birth. Thus, according to Nagazawa and collaborators, the mechanism responsible for the bonds of friendship between a dog and its owner is based on the same substance that is associated with the establishment of affective bonds between humans. Japanese researchers reached this conclusion after observing a voluntary group of 30 people \u201324 women and 6 men \u2013 interacting with their pet dog \u201314 males and 15 females. Nagasawa and collaborators measured the levels of oxytocin in the urine of the owners, both before and after interacting visually with their dog, and found that The dogs, simultaneously, experienced an increase in their level of oxytocin. A similar experiment carried out with wolves did not produce the same results, despite the fact that the owners of the pet wolves had raised them since they were puppies. In another experiment, the Japanese researchers administered oxytocin to a different group of dogs before establishing contact with their owners and observed an increase in the extent of visual contacts between them and their pets. This led to an increase in the level of oxytocin in the former, although the effect was only observed with female dogs. Thus, the owners of the dogs experienced an increase in their level of oxytocin as a response to that administered to their pets.Humans and domestic dogs, certainly, we have travelled together a very long road, whose duration we do not know with certainty but which is measured in tens of thousands of years. Along this way we have developed solid affective bonds despite belonging to different species. These ties and their age are evident in the photograph included in the article published by David Grimm in the number of thousands of years. Along this way we have developed solid affective ties despite belonging to different species. This week of the magazine \u201cScience\u201d \u2013 in the section dedicated to dogs \u2013 in which the skeletons of a person and a puppy dog are shown together, which have an age of 12,000 years. The particularity of the case is that the human skeleton has the skeleton of the puppy in its hands. Moreover, the article by Nagasawa and collaborators shows us reliably that the ties we have developed with domestic dogs are solid and lasting. So much so that it is possible to find a rational explanation for them.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d1/Europe_to_South_American_in_3_Days_Poster_%2819482266291%29.jpg": "Would you fly on a plane piloted by a robot? Probably your answer would be no, regardless of whether they showed you with statistics that this would not be more dangerous than flying in the conventional way. The explanation to your very likely negative may have Mary Cummings, who was a military pilot and is currently a professor at Duke University, when she states that \u201cThe reason you want a pilot in the cabin is because you share the same fate with you, so that if the plane is about to collapse, you feel better knowing that there is a human in the front seat who will do everything possible to save your own life.\u201d This, of course, would not apply to what happened with the German airliner \u201cGermanwings\u201d plane that last 24 March, according to the most widespread version, was deliberately crashed by its co-pilot \u2013 at that time in command controls \u2013 killing its 144 passengers. As we know, co-driver Andreas Lubitz would have locked himself in the cockpit of the plane, taking advantage that the pilot had gone to the bathroom, to make the plane lose height. The incident of the Germanwings plane adds to that suffered by the 370 flight of \u201cMalaysia Airlines\u201d which disappeared on 8 March 2014, without any certainty being known to date what happened to it, although there are indications that it was deliberately diverted from its route by the pilots. As a result of the \u201cGermanwings\u201d disaster, several airlines around the world have arranged for two crew members to remain in the cockpit of their aircraft on a permanent basis. Thus, unless the two people in the cabin agreed, the likelihood of repeating the case of \u201cGermanwings\u201d would be considerably reduced. Another possibility that has been handled to avoid a similar disaster is the replacement of the co-pilot by an automatic flight system, or by means of a remote operator. The removal of the co-pilot \u2013 and the pilot\u2019s long-term \u2013 would be a continuation of the trend that has been observed for decades to reduce the number of crew members in the cabins of the pilots. Commercial aircraft insofar as their communication and flight control systems were sophisticated. Thus, while in the early days of commercial aviation, in addition to the pilot and co-pilot, a flight engineer, a navigator and a radio operator were in the cockpit, the last two disappeared since the 1940s of the last century, while the flight engineer became unnecessary in the 1980s. According to this trend, the next to disappear would be the co-pilot. In this regard and according to an article published this week in the New York Times newspaper, the United States Department of Defense research agency will begin this year to test a robot that will be placed in the co-pilot\u2019s place and that will be able to perform many of its functions. Among other things, it will be able to talk to the pilot, manipulate the controls of the plane, and even be able to take full control of it and perform landing and take-off maneuvers. Another option to replace the co-pilot, explored by NASA, is its replacement by means of a ground operator, which would be in charge of several aircraft in simultaneous flight. Air traffic automation is very attractive given the size of the aviation industry, not everyone agrees that such automation can be carried out in the short term. Thus, according to the National Academy of Sciences of the United States \u201c...civil aviation is at the border of undergoing revolutionary changes in its capabilities and in its operation associated with automatic systems. These systems, however, raise serious questions that have no answer for now, about how to integrate all revolutionary technological advances into a national airspace governed by rules that can only be changed after lengthy deliberations to reach consensus.\u201d The United States Academy of Sciences considers that there are technological and regulatory barriers to increasing the use of automatic systems in civil aviation in the United States. It considers, for example, that automatic systems are limited in their sensory, perceptive and cognitive capabilities to operate without human intervention. It also considers that the automation of air space requires that humans and machines work together in new and different ways that have not yet been identified. and that for now we will not be faced with the dilemma of boarding or not boarding a plane piloted by a robot. That it may not kidnap us, but that, even with its good intentions, we would not have enough confidence.",
    "https://upload.wikimedia.org/wikipedia/commons/1/11/Francis_Bacon%2C_Viscount_St_Alban_from_NPG_%282%29.jpg": "As is well known, the paintings of the later stage of the Greco often show elongated human figures. This led some to propose the hypothesis that the painter suffered from astigmatism, a defect that, due to supposed corrective lenses poorly designed, would have made him see the elongated objects in the vertical direction. This hypothesis, however, has a logical flaw, since assuming that the Greco actually had this visual defect, in painting his models he would have had to have done it with the correct proportions, because otherwise the figures in the picture would have seemed doubly elongated. Thus, we can initially discard the hypothesis of the Astigmatic Greco. This, however, is strictly valid only if the Greco had painted from models. If, on the contrary, he had done it from memory, the hypothesis would have to be put to the test. This was what Stuart Anstis of the University of California in San Diego, who carried out a series of experiments with volunteers who asked them to draw a square looking through an optical device that shaped their vision. This was the first time that the volunteers reproduced without deformation the square they copied, while in the second they drew an elongated rectangle vertically. This latter apparently supports the hypothesis of Greek astigmatism. Additional experiments, however, denied it. In fact, in a second series of experiments Anstis convinced one of the volunteers to use for several days the optical device deforming the vision, at the same time that, repeatedly, it drew squares of memory. As a result, although initially the voluntary drew rectangles vertically elongated, little by little corrected this elongation and the course of two days was drawing perfect squares overcoming artificial astigmatism. If the Greco had been astigmatic his painting would not have revealed it. The conclusion is that the Greco painted elongated figures for aesthetic reasons and not for a visual problem. What is true for El Greco would not be true, however, for other painters and the latest issue of the scientific journal Scientific American contains an article in which some examples are given in this regard. Among other painters with visual problems, this article mentions Rembrandt, Monet and Degas. One particularly interesting case is that of the controversial British painter of the 20th century Francis Bacon, who is known for his paintings of mutilated or severely deformed faces and human bodies \u2013 in contrast to the inanimate objects that appear in these paintings without deformation\u2013. The reaction that the ordinary spectator experiences to Bacon\u2019s paintings is that of rejection. Thus, Margaret Thatcher referred to Bacon as \u201cthat man who paints those frightening paintings\u201d. In fact, according to what Bacon explained, what he sought with his paintings is that the viewer experienced a \u201cshock\u201d. In an article published in 2013 in the magazine \u201cFrontiers in Human Neuroscience\u201d by Semir Zeki and Tomohiro Ishizu of University College London, they find that Bacon\u2019s paintings are so disturbing because they point directly against the concept we have of a human face or body and produce a neurological response significantly different from that produced before normal faces and bodies. This concept is inherited or well acquired at a very early stage of life and is therefore independent of the cultural baggage of the spectator. The visual shock of Bacon\u2019s paintings would then be universal. Regardless of the conscious intention of horrifying the viewer, one may wonder about the unconscious motivations or circumstances that led Bacon to paint in such an unconventional way. In this regard, an article published in August 2014 in \u201cFrontiers in Human Neuroscience\u201d by a group of researchers from France and Switzerland, headed by Avionam Safran of the Sorbonne University, ventured that Bacon suffered from a visual perception disorder known as dysmorphous. The conclusion of Safran and collaborators is based on Bacon\u2019s testimonies. In the words of the painter, \u201cWhen I look at you speak I see an image that changes constantly: the movement of your mouth, your head, in some way; it moves all the time. I tried to capture this in painting.\u201d Bacon\u2019s painting is certainly difficult to digest for the uninitiated. This does not, however, prevent it from reaching stratospheric prices in the art market. It suffices to point out that the triptych \u201cThree Studies of Lucian Freund\u201d, painted by Bacon in 1969, was sold at auction in 2013 at $142.5 million. This places the work in the eighth place among the paintings that have reached a higher price at auction. Nothing despicable for a work resulting from a supposed neurological problem.",
    "https://upload.wikimedia.org/wikipedia/commons/0/0b/Tlaxcala_-_Palacio_de_Gobierno_-_Indianerkrieger_2.jpg": "With the expansion of the Aztec Empire during the 15th century, the territory inhabited by the Tlaxcaltecs, which were never dominated by the Aztecs, ended up surrounded by enemies. On the other hand, a widely used material in Mesoamerica was the obsidian, with which ornaments, knives and arrowheads were manufactured, among other utensils for daily life and weapons for war. Since the Tlaxcaltecs were surrounded by non-friendly peoples, one wonders how they obtained obsidian to meet their needs, since there were no deposits of this mineral in their territory. An article appeared this week in the journal \u201cJournal of Acheological Science\u201d answers this question. This article was published by an international group of researchers headed by John Millhauser of the State University of North Carolina in the United States, and which includes specialists from the Center for Research and Advanced Studies. M\u00e9rida, Yucat\u00e1n and the College of Michoacan. According to Millhauser and collaborators, the Tlaxcal Millhauser and collaborators based their conclusions on a study carried out with obsidian objects found in Tlaxcala. Of these, 14% have a characteristic green colour that denotes their origin of mines in the region of Pachuca. The origin of the remaining 86% could not be determined visually. For this purpose, a technique based on X-rays was used, which without ambiguity reveals the place of the mine from which they come. Only 14% of the obsidian employed in Tlaxcala comes from the area of Pachuca contrasts with what happened with the Aztecs, who obtained 90% of their obsidian precisely from that area. This leads researchers to assume that the pre-Columbian trade of obsidian was affected by the political situation in Mesoamerica, which would have made it difficult for Tlaxcaltecas to have access to the most common sources of obsidian. In the words of Millhauser, \u201cThe popular conception of an all-powerful Aztec Empire before the arrival of El Pared\u00f3n was close to the border of the Aztec-dominated region and that, apparently, the Tlaxcaltecs would have been able to transport the obsidian in a systematic way. Millhauser wonders why the Aztecs \u2013 who were openly hostile to the Tlaxcaltecs \u2013 did not intervene to prevent it. One possibility, according to Millhauser, is that the Aztecs had considered that the latter was an effort that would not be worth doing, given that the obsidian was not scarce and that had the Tlaxcaltecs been blocked from the mine of El Murion, they might have found some other source of obsidian. In any case, the fact that the Tlaxcaltecs had at their disposal a source of raw material with which they could manufacture weapons right on the border of the enemy territory, would imply that, after all, the Aztecs were not as powerful as it was commonly assumed. Cortez is exaggerated. The region was a politically and culturally complicated place.\u201d Millhauser\u2019s study and collaborators then taught us that although the expansion of the Aztec Empire in the 15th century ended up surrounding the Tlaxcaltecs and encapsulating them territorially, they somehow managed to maintain a flow of obsidian, which they used widely as determined by archaeologists. For this they used non-conventional sources, different from those commonly used by Aztecs. Obsidian, among other things, allowed the Tlaxcaltecs to manufacture weapons to defend themselves from their enemies and maintain their independence from the Aztec Empire. Weapons that, on the other hand, used when they allied with Cortez to defeat the Mexicans. Although these would have been of little use to defend them from the firearms of the Spaniards, much more evolved. Or, in other words, with regard to the weapons of war, iron kills obsidian.",
    "https://upload.wikimedia.org/wikipedia/commons/a/ae/Mapa_de_desempleo_por_pa%C3%ADses.png": "According to figures from the U.S. Centers for Disease Control and Prevention, two million Americans are infected each year with antibiotic-resistant bacteria, some 23,000 of which die as they fail to overcome the disease. The same source estimates that the corresponding costs amount to $20,000 million per year in medical care, in addition to $35 billion for productivity losses. Antibiotic-resistant bacteria represent, thus, a serious public health problem for our neighbor in the north. And, of course, not only for our neighbor in the north, since antibiotic resistance is by nature a problem that does not respect borders, although its particular magnitude varies according to the country in question. The mechanism that generates antibiotic-resistant microbes is a natural consequence of their use, either for the treatment of diseases in humans or for the poultry and livestock industry. Thus, the development of a new antibiotic can be followed by the emergence of resistant bacteria. Consistent with the above, experts have associated the increase of antibiotic-resistant bacteria in humans. A study published this week in the online magazine PLOS ONE, however, concludes that, while antibiotic abuse is a cause of the development of resistant bacteria, it is the quality of government and corruption of each country's own. The study was carried out with 28 European countries by a group of researchers in Australia, led by Peter Collignon of the National University of Australia. The countries with the lowest degree of microbial resistance and the least corruption are Sweden and Denmark. At the other extreme, the most corrupt countries are Lithuania, Latvia and Bulgaria, which are among the most resistant to antibiotics. How can there be a relationship between antibiotic-resistant bacteria and the level of corruption of a country, which is in the first instance unlikely? According to Collignon and collaborators, disorder due to a low-quality government produces, on the one hand, a lack of control in the use of antibiotics \u2013 both in humans and animals, spreading in the latter case through the food chain\u2013, while at the same time results in poor treatment of infectious diseases. All this would combine to create an environment conducive to the development of antibiotic-resistant bacteria. Sanyaya Senanayake, one of the co-authors of the reference study, offers a concrete example in this regard: \u201cE-coli bacteria is commonly found in humans and animals. We know that in certain agricultural sectors antibiotics are used in animals and this results in resistance to them, and that such resistance can be transmitted to humans in various ways, including transmission through food products. We believe that in countries with high levels of corruption there is less likely to be strict monitoring of how these antibiotics are used and how they are discarded, with the possibility that rivers and other parts of the environment being contaminated.\u201d Collignon and collaborators also find that there is no correlation between the percentage of people in the population with a university education and the generation of antibiotic-resistant bacteria and, surprisingly, that private medicine produces more resistant bacteria than public medicine. They do not have a clear explanation for the fact that there is no correlation between the percentage of people in the population with a university education and the generation of antibiotic-resistant bacteria and, surprisingly, that private medicine produces more resistant bacteria than public medicine. But the researchers offer a hypothesis in the sense that doctors in the private sector have less restrictions on the use of antibiotics, both in type and in volume, than those in the public sector.As we know \u2013 and we check every day \u2013 when compared with other countries in the world our country does not get off well in terms of corruption rates. Indeed, according to Transparency International, Mexico ranks 103 out of 175 countries in the Corruption Perception Index, with a score of 35 points out of 100. The first place in that index is occupied by Denmark \u2013 which occupies the second place in Europe in terms of the prevalence of antibiotic-resistant bacteria \u2013 with 92 points, while in the background Somalia and North Korea. Thus, if it is possible to extend to our country the results of Collignon and collaborators \u2013 obtained using statistical data from European countries \u2013 Mexico would have the dubious honour of being a good producer of antibiotic-resistant bacteria. This would be the bad news. The good news is that our country could in any case reverse the situation, because according to the reference article, The resistant bacteria in the past do not affect the resistance of the bacteria in the present. That is, a possible high level of microbial resistance in the present would not be an obstacle to improving the situation in the future. Given the case, everything would be in which we proposed it.",
    "https://upload.wikimedia.org/wikipedia/commons/2/20/Zeus_Otricoli_Pio-Clementino_Inv257.jpg": "It seems that, although he is not of this world, Ganymede shares some characteristics with us. This, according to an article published online this week in the journal \u201cJournal of Geophysical Research\u201d by an international group of researchers headed by J. Saur of the University of Cologne in Germany. This probably requires some clarifications that we offer in what follows. To begin with, we will note that by Ganymede we do not refer to Ganymede, the Trojan who was kidnapped and taken to Olympus by Zeus according to Greek mythology, but to the Jovian satellite that was discovered 1610 by Galileo Galilei. When in that year Galileo pointed his telescope towards Jupiter he discovered four luminous points orbiting the planet \u2013 the latter was known to be because the points changed from one day to another around Jupiter. One of those points was Ganymede; the other three corresponded to the also Jovian satellites Io, Europa and Calisto. Of the four satellites discovered by Galileo, Ganymedes is the largest. In fact, Ganymedes is the satellite. We will also note that Ganymede is an inhospitable world in which we could not survive without artificial means. Still, it is possible that he will share with our planet one of the characteristics that distinguish him: the conditions for the development of life as we know it. Ganymede was the subject of the short story published by science fiction writer Isaac Asimov in 1940, entitled \u201cChristmas in Ganymede\u201d. This story is about the mining of this satellite by a private company that used the native Ganimedeans, called \u201cstrucs\u201d \u2013 because they remembered ostriches for their appearance\u2013 as semi-slave labor. The company during the story is experiencing problems as one of the miners spoke with the asses about Santa Claus and these, who possessed a certain degree of intelligence that even allowed them to speak English badly, refused to work unless they visited Santa Claus on Christmas giving them gifts. They also made use of an old wooden sled that had been taken to Ganymede a long time ago when it was thought that its surface was covered with snow, and eight native animals that vaguely remembered reindeer.The problem had apparently been solved, after considerable difficulties in bending and mooring the sled to the supposed reindeer, until the miners realized that the Ganimedean year \u2013 the time that the satellite takes to complete an orbit around Jupiter \u2013 is only 7 days and that the strucks expected Santa Claus to visit them with this periodicity.The conditions on the surface of Ganymede are, of course, not suitable for native astros or rhines to exist, nor for humans to survive with just a mask and a tank of oxygen as occurs in the Asimov account.On the one hand, although there is apparently an atmosphere of oxygen in Ganymedes, this is too tenue.On the other hand, given that Jupiter It is about five times farther from the Sun than our planet, the solar radiation received by Ganymede is very weak and, consequently, the temperature of its surface is extremely low, so much so that it can reach the least 180 degrees Celsius. Thus, the Asimov story \u2013 which is not, of course, but a humorous account \u2013 has no physical sustenance. It shows, however, that Ganymede is a strange world in which Christmas would have to be celebrated with an unusual frequency. And yet, despite its differences with the Earth, according to the work of Saur and collaborators quoted at the beginning of this article, Ganymede has under a thick layer of surface ice an ocean of salt water that in volume is greater than all the water existing on Earth. It bases this conclusion on the behavior of the Ganimandean auroras \u2013 similar to the northern auroras that occur on our planet\u2013, which are influenced by the rotation of Jupiter. A study through the Hubble space telescope of the changes experienced by these auroras in the extent to which Jupiter rotates, shows that there must be a vast ocean of salt water with a depth of 100 kilometers beneath the frozen surface of Ganymede In a way that coincides with the verification of the existence of an ocean of salt water in Ganymede, an article published this week in the magazine \u201cNature\u201d comes to the conclusion that also in Enceladus, the satellite of Saturn, there is an underground ocean in which, surprisingly, temperatures can reach 90 degrees Celsius. Thus, we have that, unexpectedly, two frozen and distant worlds are more likely to maintain some form of life than that of our neighbor Mars, apparently more Earth-like \u2013 at least in the images that have reached us from its surface \u2013 but extremely dry and safely desolate. What form of life will exist in Ganymede in case there was one? We will not know until we get there, but we would probably not find any structings or reneeds.",
    "https://upload.wikimedia.org/wikipedia/commons/3/3d/Estructura_del_ADN.jpg": "Titan, Saturn\u2019s largest satellite, shares some characteristics with our planet. By way of example, we can mention that the Cassini probe, which has been orbiting Saturn since 2004, found that Titan\u2019s surface is sown with liquid lakes, some of them large in size, even larger than those of the Great Lakes on the border between the United States and Canada. It is also possible that on the surface of Titan rivers run \u2013 or have run at some remote time \u2013 as happens on the surface of our planet. Another coincidence is that Titan, like the Earth, has an atmosphere formed mostly of nitrogen. It is possible, however, that we do not find many more coincidences between the two worlds, Titan and Earth, separated by more than a thousand million kilometers of interplanetary space. In fact, Titan\u2019s lakes are not of water but of methane and ethane. They could not be of water, because the temperature on the surface of Titan is less than 180 degrees Celsius and at this temperature the water cannot be frozen. Titan is a world inhospitable, incompatible with life as we know it. At the same time, however, the discovery of Titan's lakes has caused experts to speculate about the possibility that some form of life exists on this satellite, although different from that we know it. If that were the case, the Titanian organisms would somehow have the same relationship with liquid methane as terrestrial organisms have with water. An article published this week in the online magazine \u201cScience Advances\u201d speculates in this direction using sophisticated arguments. This article was published by James Stevenson and Paulette Clansy, from Cornell University's School of Chemical and Biomolecular Engineering, in the State of New York, and by Jonathan Lunine from the Department of Astronomy of the same university. According to Stevenson and collaborators, Titan could have evolved a particular way of life, adapted both to its atmosphere \u2013 almost entirely composed of nitrogen \u2013 and to those of the same university. This, unlike life on Earth, which is based on liquid water and temperatures above zero degrees Celsius. A fundamental element for life on Earth is the membrane that surrounds cells and isolates them from the aqueous environment. Stevenson and collaborators consider that the appearance of this membrane would have been a first evolutionary step that gave rise to life on our planet. A similar circumstance could have occurred in Titan, and in this sense these researchers speculate that, without a membrane similar to that of terrestrial organisms would freeze and could not function in Titan, there are other viable possibilities for a cell membrane adapted to the conditions of low temperatures there.In relation to this, Stevenson and collaborators proposed a membrane based on nitrogen, abundant in the atmosphere of Titan, instead of phosphorus and oxygen that form part of the cellulars of organisms on Earth. By complicated mathematical calculations, they demonstrated that the proposed membrane would behave in the temperatures of Titan in a manner similar to those of the membranes of terrestrial organisms. This would indicate that, despite their inhospitable conditions, an exotic way of life could have flourished in Titan.This, of course, is only speculation, although supported by sophisticated arguments.In Stevenson's words and collaborators: \"The availability of molecules with the ability to form cell membranes does not by itself prove that life is possible. This, however, directs our search for metabolic and reproductive chemical processes that could be compatible under low temperature conditions.\"To know if there is, or ever was life in Titan we may have to go there with the right search tools. More specifically, we may have to send a probe there with the analytical capabilities that the case merits, because, at least in the medium term, the fact that one of us can tread on the soil of Titan after traveling more than a billion kilometers seems difficult, if not impossible. This, however, does not prevent us from blowing up the imagination and speculating about exotic forms of life in equally exotic remote worlds. Stevenson \u2013 who is a graduate student at Cornell University \u2013 to conduct his study was partly inspired by science fiction writer Isaac Asimov who, in a novel published in 1962, wrote, precisely, about non-water-based life.",
    "https://upload.wikimedia.org/wikipedia/commons/0/08/Ginza_area_at_dusk_from_Tokyo_Tower.jpg": "What characteristics do the ancient Tenochtitl\u00e1n and the current Mexico City have in common? It is possible that not many, although some will be. The most obvious, of course, is that Tenochtitl\u00e1n occupied a space that is currently part of Mexico City and in this sense that is antecedent of the latter. An additional common characteristic is that both Tenochtitl\u00e1n and Mexico City are among the largest cities in the world in which they developed. On the other hand, in absolute terms, Mexico City is a city of gigantic proportions that has no proportion with Tenochtitl\u00e1n, neither in population nor in urban area. Technologically there is also a great difference between the two cities. Thus, for example, while in Mexico City there is currently a massive system of public transport driven by electric energy, in the ancient Tenochtitl\u00e1n transport is made by means of canoes and water channels. Many other differences can be cited between Tenochtitl\u00e1n and the present city of Mexico, differences in technological, social, economic, political or cultural order. According to these researchers, the productivity of a city can be described by the same mathematical law, according to which this productivity increases in the average that increases the size of the city. Ortman and collaborators came to this conclusion from a study of the productivity of different pre-Hispanic populations around Tenochtitl\u00e1n. Since the possessions of the inhabitants of these populations disappeared a long time ago, the researchers took as a measure of such productivity to the volume in cubic meters of public buildings built in one year, as well as to the size of the dwelling houses. They found that productivity in the pre-Hispanic populations increased with the size of urban conglomerates in the same way as does contemporary urban productivity. This is certainly to call attention and in this regard Ortman states: \u201cFor me, the idea that the same processes that generated a place like the city of New York were operating in small populations in other parts of the world in ancient times is interesting to understand.\u201d Moreover, the fact that the productivity of a city in ancient times depends only on its size has interesting consequences for understanding the relationship between social organization and Thus, as Ortman points out: \u201cWe grew up fed by the idea that thanks to capitalism, industrialization and democracy, the modern world is radically different from the world in the past. What we find here is that the forces that determine the socioeconomic patterns in modern cities precede them.\u201d We would thus have that the productivity on which the relative well-being of an urban population depends depends on its size. Absolute well-being, however, will depend on other factors. So, while the city of New York and Mexico City classify both in the group of the world\u2019s largest cities, their respective productivitys are clearly different. And this, if we are to believe Ortman and collaborators, is independent of the degree of capitalism, industrialization or democracy of the country. In this regard, one must ask for the average standard of life in Tenochtitlan \u2013without taking into account the prisoners destined to be sacrificed in the Temple of Major. How does it compare with the average standard of life in the current City of Mexico? Did it win or lose the city with the Spanish conquest?",
    "https://upload.wikimedia.org/wikipedia/commons/e/e1/Drought.jpg": "According to the climatologists, North America experienced in the medieval period, between the 900-1400 years of our era, a series of severe droughts of long duration. Droughts so prolonged that Richard Seager, Celine Herweijer and Ed Cook of the Lamond-Doherty Earth Science Laboratory of Columbia University, consider that it is more appropriate to think that this medieval epoch was simply arid than the time that followed it. As an interesting fact, Seager and collaborators note that the number of bison bones found in the North American region with an antiquity of about a millennium is small compared to those found with older or younger antiques. An explanation to this fact is that a thousand years ago the aridity of the land was such that there were no conditions to sustain a larger population of bison.An evidence of the mega-sekians that ravaged the southeast of the United States in the medieval period are the remains of trees of that antiquity \u2013 revealed by dating with Carbon 14\u2013 that it is possible to be found in today's beds of rivers and lakes. The period of medieval drought these rivers or lakes were dry, which allowed the trees to grow. At the end of the drought, however, lakes and rivers were flooded and the trees died.A prolonged drought would have had a strong impact on food production and, according to some specialists, would have caused the collapse of civilizations in the southeast of the United States, as well as civilizations in Mesoamerica. In an article published this week in the inaugural issue of the online magazine \u201cScience Advances\u201d \u2013 produced by the American Association for the Advancement of Science \u2013 published by a group of researchers led by Benjamin Cook of NASA Goddard Institute for Space Studies, a severe drought is predicted for the second half of this century that will affect the North American region, including our country. The magnitude of this drought would be even greater than that of the medieval period and would have no parallel with any other since that time. It would thus represent unprecedented climate change in the last thousand years, with periods of severe drought that could last decades. In this respect, it is possible to know about the climate in the past from the study of the rings of the trunk of a tree, each of which is known to correspond to a year of life of the same. A year with favorable climate is revealed by a greater thickness of the corresponding ring, at the same time that a smaller thickness reveals a difficult year. The drought to come, unlike the medieval drought, would not have natural causes but would be the product of the global warming that our planet is experiencing. This warming, in turn, is the product of the emission of greenhouse gases into the atmosphere by the uncontrolled burning of fossil fuels, which we are carrying out continuously since the beginning of the Industrial Revolution. Although Cook and collaborators in his article only explicitly consider the southeast of the United States and the region of the central plains of this country to the east of the Rocky Mountains, on the NASA website it is possible to find animations in which the projections of the central plains of this country in the east of the Rocky Mountains are shown. In these animations we can see that the drought predictions for much of our country at the end of the 21st century \u2013 including the state of San Luis Potosi \u2013 are as alarming as the corresponding predictions for the central plains of the United States.We can then hope that, if Cook and collaborators' calculations are correct, in the decades to come our country will suffer the effects of a drought that would overcome in intensity all those that occurred over the last thousand years.This even if there is a reduction in the emission of greenhouse gases to the atmosphere at a global level, which, while reducing the magnitude of the drought, as well as its adverse effects, would not prevent this century from surpassing a record that has at least one millennium of existence.",
    "https://upload.wikimedia.org/wikipedia/commons/a/aa/7th_Seal_logo.jpg": "Although we cannot see them, we know that a great variety of microbes live in our bodies, in such large quantities that they are surprising. Indeed, according to specialists, the number of cells that collectively make up these microbes is about 100 million million. This number is so enormous that it escapes our understanding; it is enough to know, however, that it is about ten times larger than the total number of cells that make up the human body. Seen this way, we are clearly disadvantaged with respect to our microscopic hosts, and it is fortunate that we can live with them peacefully, and even in some cases help us maintain health. We know, however, that coexistence is not always as harmonious as we would like, and that it may happen that some of the microbes that inhabit our bodies, or that we acquire by some way, we become sick more or less seriously. Certainly, sometimes we are very sick, as happened in the course of the bubonic plague pandemic known as Black Death, which decimated the population of Europe in the first half of the 14th century. It is also known that it was first introduced to Europe from Asia Minor through a port in southern Italy. Black Death was a catastrophe in which between 30% and 60% of the European population would have died. Because of Black Death, 14th-century Europe \u2013 which was about to emerge from the Middle Ages \u2013 was not the most pleasant place to live. As there was no idea of what produced it, people attributed bubonic plague to the most disparate causes, from air quality, to the influence of the stars, or to the supposed satanic practices of Jews and witches. Film director Ingmar Bergman in his film \u201cThe Seventh Seal\u201d transports us to Europe of that dark time. While Bergman did not intend to give a faithful description of that time \u2013 and, in fact, coincides with the crusades with Black Death, events that did not coincide in time\u2013, if he presents us with a The \u201cYersinia pestis\u201d, however, has not disappeared in any way. In fact, in an article published this week in the magazine \u201cCell Systems\u201d, it is reported that it has been found in a place that at first sight is surprising to us: the New York Metro railway stations. The article was published by a large group of experts from universities and research centers in the United States and Ireland, headed by Christopher Mason of the Weill Cornell Medical College in New York City. In that article the results of an investigation carried out with 1,457 samples of genetic material collected at 466 stations of the New York metro with the purpose of studying their DNA were reported. These samples were collected by rubbing nylon swabs on handrails, turnsniquets, benches, vending windows of tickets and other surfaces in the train stations, with which they would have had contact. In a surprising result, researchers found that about half of the DNA determined could not be identified and corresponded to unknown organisms until before the investigation. On the other hand, it was found that 47% of the DNA identified is from bacterial organisms, and that while 57% of the bacteria found have not been associated with human diseases, 31% of them are opportunistic bacteria that may represent a health risk. 12% of the remaining bacteria, including some antibiotic resistant, are associated with human diseases. In the latter group, Mason and collaborators found fragments of DNA from \u201cYersinia pestis\u201d, as well as fragments of the anthrax bacillus, both, however, at low levels. Since there has been no case of bubonic plague in New York in the last two years, researchers consider that these bacteria are not associated with diseases and are simply two more inhabitants of the New York Metro bacterial population. . They point out, however, that this has to be confirmed.In one way or another, even if the bacterium of bubonic plague lived among us \u2013 as would be the case if we were to generalize the findings of the New York subway \u2013 and had the potential to cause a pandemic like the one that devastated Medieval Europe, we would have well-founded hopes that such a pandemic would not become a reality in the future.The bubonic plague of the New York Metro, however, has the virtue of transporting hundreds of years into the past and making us present a time \u2013 created masterfully by Bergman \u2013 in which death was a thing of every day.",
    "https://upload.wikimedia.org/wikipedia/commons/c/cf/ABQ_Petroglyph_2.jpg": "Discovering and rescuing the fossil remains of a great dinosaur, of which one can admire in the great museums of natural history of the world, is not a simple thing and certainly constitutes a task for experts. As we know, dinosaurs lived a long time ago \u2013 from 65 to 230 million years ago \u2013 and if the remains of a particular specimen have been able to reach us it is because, by chance, they were quickly buried after their death and saved from being destroyed by other animals or by the action of the elements. Once underground, although soft tissues commonly disappear over time, bones can be preserved through the fossilization process, in which case they travel through time embedded in a rock matrix. During fossilization, the minerals that form the bone are replaced by other minerals without altering its form. The fossil is thus a kind of pirate copy of the bone, which faithfully reflects, however, its original morphology. Not in all places on the surface of the earth is it possible to find remains of dinosaurs. . For this it is necessary that the exposed rock has the correct antiquity; that is, that it has the age that corresponds to the time in which the dinosaurs inhabited the Earth. It is known, for example, that the western region of the United States known as the Morrison Formation, which extends from the state of New Mexico to the border with Canada, is rich dinosaur fossils that lived about 150 million years ago. To discover dinosaur fossils then paleontologists must search in the right places using their experience to find signs of their possible presence under the earth. Once located, fossil bones must be carefully released from the rock matrix that imprisons them and assembled them, for their display, if any, the way in which experts think that the dinosaur functioned in life. The former, carried out by professional paleontologists working for a museum, would be a way for such a museum to be made of fossil dinosaurs, whether for display or for scientific studies. The fossil of stegosaurus that has been on display since last December at the Museum of Natural History of London. An article published last week in the British newspaper The Guardian by Professor Paul Barrett of the Museum of Natural History of London tells us the story. Specifically, the history of the course that followed said stegosaurus until arriving at the museum.According to Barrett, during the visit that in 2012 he and other colleagues made to the Fair of Rocks and Minerals of Tucson \u2013an annual event that brings together searchers and professional traffickers of fossils \u2013 they gave with the mold of the skull of a stegosaurus and, to their surprise, they learned that the original fossil, which included the complete skeleton, was on sale. Finding out more, it turned out that this fossil constituted the best skeleton of a stegosaurus ever found. Given the interesting fossil discovered in such a surprising way, Barrett and collaborators decided to propose to the Museum of Natural History of London to acquire it for their collection and public exhibition, a proposal that was accepted without any reservations. The fossil arrived at the museum in December 2013, being baptized as Sofia, in honor of the daughter of the main donor \u2013 as much as it is impossible to know the sex of the dinosaur.Its arrival was kept secret for a year, apparently to make its public appearance more spectacular, but also to give time for museum scientists to study it without major disruptions. Dinosaurs are animals that strongly captivate our attention, among other things because while they lived many millions of years ago, the traces of their presence on Earth \u2013 the same as those of its mass extinction \u2013 have come to us surprisingly. We are also attracted because some dinosaurs had enormous proportions, while others were predators of a great ferocity. Stegosaurus, in particular, were very eye-catching dinosaurs \u2013 as can be seen on the Smithsonian Museum website or Wikipedia, for example \u2013 with a double row of plaques along the back and needles. As for the history of Sofia and her arrival at the Museum of Natural History in London, in addition to the visual appeal of the stegosaurus, it is striking that fossil traffickers have marketed a dinosaur skeleton that, according to Barrett, has a high scientific value and is the best discovered so far.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d9/Rosetta.jpg": "The issue of this week\u2019s \u201cScience\u201d magazine publishes a special section with a series of articles describing the first results achieved by the different groups of scientists studying comet Churyumov-Gerasimenko. As was announced by the European Space Agency at the time, the Rosetta probe reached the comet Churyumov-Gerasimenko in its orbit around the Sun last August, entering orbit around the comet. Rosetta will accompany the Churyumov-Gerasimenko on his journey to the Sun by studying the changes that he is experiencing and \u201clighting up\u201d to the extent that the solar radiation he receives becomes more intense. The maximum approach of the comet to the Sun will occur in August of this year. The European Space Agency had been criticized for its delay in making known promptly the first results achieved with Rosetta. This delay was motivated by the intention of the different research groups involved in the project to maintain priority over the results achieved and to make them known only through research articles that would ensure this priority. The results of the study of the comet Churyumov-Gerasimenko have finally reached public light, after a few months. These results are varied and include from the study of the comet morphology to the determination of the chemical composition of its surface \u2013 which was found to be rich in organic compounds \u2013 as well as that of the gases that allow it to escape into space. It was also found that a cloud of one hundred thousand fragments with dimensions greater than five centimeters orbits the comet, which, according to experts, possibly resulted from its last approach to the Sun. The comet Churyumov-Gerasimenko has a peculiar form with two lobes of different size bound by a neck. Experts now know that the small lobe measures 2.6x2.3x1.8 kilometers and the largest lobe 4.2x3.3x1.8 kilometers, and that the mass of the comet is about ten billion tons. It also has a density similar to that of cork or wood, so, if it is the case, it would float in water. . The specialists are not sure how the comet acquired its form. One possibility is that it would have resulted from the collision of two celestial bodies. An alternative explanation is that the comet would have reached its present form by interaction with solar radiation during its approaches to the Sun. In relation to this point, Rosetta has revealed that the emission of gases into space is particularly active in the region of the comet\u2019s neck. For non-specialists, however, perhaps the most attractive are the photographs taken at a relatively short distance by the high resolution cameras that Rosetta carries on board and that show the comet with amazing detail. One of these photographs, taken at a distance of 8 kilometers, appears on the cover of this week\u2019s magazine \u201cScience\u201d and shows a cliff and a sand field with a resolution of 15 centimeters per pixel. It also shows a dark surface, notably darker than the surface of the Earth, or even that of the Moon. According to the European Space Agency\u2019s electronic page, approximately 70% of the comet\u2019s surface, which shows an irregular and varied structure, has been photographed in detail. they have identified five types of terrain: dust fields, regions of brittle material with wells and circular structures, large-scale depressions, flat areas and areas covered with rocky material. The photographs also show what could be lines of fissure in the comet's neck, which would anticipate its fracture in an undetermined future. Much remains to be studied and learned about the comet Churyumov-Gerasimenko during its transit to the Sun in the coming months and throughout its subsequent retreat following its elliptical orbit. Of particular interest is the possibility that the Philae probe, which was sent to the surface by the comet last November to study it as short as possible, may return to life. As will be remembered, the Philae probe had a rough landing in the comet that left it in a difficult position to receive the sunlight that it needed to recharge its batteries and as a result entered into a state of hibernation. To receive high-resolution news and images from a distant, strange and fascinating world like the comet Churyumov-Gerasimenko is always rewarding. Even if those responsible for spreading these images and news make us wait for a few months.",
    "https://upload.wikimedia.org/wikipedia/commons/9/95/Sebastiano_Conca_%28atribui%C3%A7%C3%A3o%29_-_Alegoria_da_Ci%C3%AAncia.JPG": "How will our descendants live within 100 years? How will they live in the year 3000 of our era? Will they live in cities at the bottom of the ocean protected by a glass dome? Will they have managed to overcome earth's gravity and will they live on other planets? Or, in a scenario proper to the times of the Cold War, as a result of a nuclear war of global proportions?Will civilization have collapsed and our descendants live in a primitive state of social development?For some undetermined reason, many of us like to let go of imagination and ask us questions of this kind. Questions that are, however, idle, as there is no way to answer them with a reasonable degree of precision, since among our capabilities is not to predict the future. Thus, the projections and visions of the future remain, at best, in the field of science fiction.Our interest in the present-future relationship is given in another sense as well. Specifically, with the so-called time capsules in which characteristic objects of a time are kept. The pretension is that, in a future more or less, in a more or less, in the future, it is given. Last December the media informed us of the discovery of a time capsule hidden in a stone from the walls of the capital of the city of Boston. The capsule \u2013 a copper alloy box about twenty centimetres long, 15 centimetres wide and 4 centimetres high \u2013 was buried in 1795 by Paul Revere and Samuel Adams, two of the heroes of American independence. It was discovered in the summer of 2014 by radar measurements during a project of maintenance of the building by a leak of water. At 220 years old, the time capsule buried in the walls of the chapitol of Boston is the oldest that has been found in the United States. It has not been hidden, however, for so long, as it was dug up in 1855 during a maintenance operation of the building. On that occasion, after cleaning the objects it contained, the capsule was again buried in the same place, adding some objects of the time.After working for a whole day, Pam Hatchsfield of the Museum of Fine Arts of Boston. In order to explore its contents, the box was subjected to X-ray analysis. The opening of the time capsule was carried out by Hatchsfield in a theatrical manner on January 6 during a press conference. Among others, it was found that it contained the following objects: gold and silver coins dated between 1652 and 1855, a silver plate that is thought to be engraved by Paul Revere, a copper medal with the image of George Washington, some newspapers and business cards. As in 1855, on this occasion, it is planned to return the capsule to its place on the wall of the capitol. It has not been decided, however, if contemporary objects will be added to its contents. The placement of time capsules is a widespread practice, there is even an International Society of Time Capsules, based at Oglethorpe University, Atlanta, United States, which, among other things, intends to carry an inventory of capsules in the world in order to keep its trace visible over the years. There are about 10,000 time capsules distributed on the planet. The time capsules are intended to send messages to the future from a certain time. The message is possibly contained, both in the objects inside the capsule, and in the manifest intention of those who sent such objects to the future. The message sent, however, depends on the collection of objects contained in the capsule and there are those who argue that these objects will not be of great use to archaeologists of the future.In particular, in the case of the Boston Capitol Time capsule, one should wait for the opinion of experts as to how their discovery can contribute to understanding the history of the United States two hundred years ago \u2013 beyond what has served the Boston Museum of Fine Arts to make some publicity. One way or another, what can't be denied is that, finding a message that is sent to us \u2013 with full intention \u2013 directly from the past, is something that doesn't cease to be fascinating.",
    "https://upload.wikimedia.org/wikipedia/commons/4/4a/%22Colored%22_drinking_fountain_from_mid-20th_century_with_african-american_drinking.jpg": "According to the latest Gallup poll last December, 13 percent of Americans consider that the biggest problem in the United States is racism and race relations. This percentage is similar to those in the United States that place the economy as the main problem they face, and that it is only exceeded by 15 percent of those who consider that their main problem falls under the category of \u201cGovernment.\u201d Americans\u2019 concern for racism grew sharply \u2013 in November last only 1% of respondents highlighted it in the first place \u2013 following the recent riots caused by the decision not to prosecute the white police officers who killed African Americans Michael Brown and Eric Garner, respectively in Missouri and New York. As we know, the United States is a country of immigrants, with a relatively recent history, which has a population of mostly European origin but which also includes minorities of significant size. Among these are those of African Americans \u2013 the result of slave trafficking \u2013 and Latinos, who comprise 13 and 17 percent of the total population of the country, respectively. racism is a real phenomenon in the United States \u2013 just as in other countries, including ours \u2013 the concept of \u201crace\u201d cannot be precisely defined from a scientific point of view, given the interracial mixtures that have taken place throughout history. An article published in the January issue of this year in the magazine \u201cThe American Journal of Human Genetics\u201d sheds light on this issue. This article is headed by Katarzina Bryc, ascribed to the \u201cHarvard Medical School\u201d and 23andMe company, Mountain View, California, specializing in genetic studies. This article reports the results of a study carried out to find out the genetic heritage, through DNA studies, of a group of more than 160,000 Americans. The study was carried out using the data bank of 23andMe company that stores genetic data from hundreds of thousands of people. Around 150,000 participants self-defined themselves as European-Americans, 5,000 as African Americans and 9,000 as Latinos. The results obtained show that 3.5% of those who self-defined In Europe-Americans they have at least 1% of African genes. Likewise, the average African-American genome is 73% African and about 24% European. As far as the average Latin genome is concerned, it is native American in a proportion of 18%, European \u2013 mainly from the Iberian Peninsula \u2013 in 65% and African in 6%. The previous genomic compositions, moreover, depend on the state of the American Union that is considered. Thus, in South Carolina 12% of European-Americans have a genome that is African in at least 1%. Likewise, in the southern states, bordering Mexico, the Latin genome has a higher native American proportion.According to the results of the study, there is also a gender dependence on the genomic composition. Thus, the probability that a European-American has a male African ancestor would be ten times greater than the probability that it has a female African ancestor. Similarly, an African-American could have four times more indigenous American ancestors than female Native American ancestors. So we have that the African-American population is, on average, a European-African mixture. Likewise, although according to the study by Bryc and collaborators, the European-American genome is, on average, European at 98.6%, 3.5% of the European-American population that has African ancestors \u2013 many millions of people \u2013 is in a border strip between two racial categories. In these conditions we might hope that racial problems in the United States would have only relative virulence. Gallup surveys up to the last one last December seemed to indicate this. Indeed, according to these surveys, after the 1960s, when half of the American population came to consider that racial aspects were the biggest problem they faced, the concern for this issue declined dramatically \u2013 with the exception of 1992 with the case of Rodney King which, like last year, provoked large public demonstrations.According to the events of the past year, however, racial discrimination does not seem to be something that can be rationalized with scientific arguments and discarded by the case of Rodney King. Although the latter is not something that should surprise us as Mexicans, given the state of affairs in our country, where racial discrimination certainly exists no matter how much the population of our country is mestizo with all the imaginable degrees of mixture.",
    "https://upload.wikimedia.org/wikipedia/commons/4/4c/Museo_de_Arqueolog%C3%ADa_de_Alta_monta%C3%B1a_en_la_provincia_de_Salta.jpg": "It has not yet been two hundred years since we first had access to electric light. Before that, to light up the nights, we resorted to bonfires or torches and, with the passing of time and evolution of technology, to oil or gas lamps. Even in the latter case, however, the levels of illumination that could be reached were relatively low, compared with those that are possible to obtain with electric light. Thus, since our species evolved for hundreds of thousands of years without artificial light, we must wonder how it affects the fact that we are now surrounded in the night hours of all kinds of electric light that, certainly, shortens the night when we are supposed to sleep.A striking thesis in this sense is that of Roger Ekrich, professor of history at the Virginia Polytechnic Institute in the United States, who claims that the last two hundred years radically changed our sleep habits. Currently, it is assumed that we should sleep eight hours a day continuously. According to Ekrich, in contrast, before the Industrial Revolution, it was usual to divide sleep in two periods. A couple of hours after nightfall and they slept for about four hours. This was followed by a period of one to two hours and a second sleep period of four hours.Ekrich came to this concussion by consulting numerous documents of all kinds in which reference is made to a first and second sleep periods.During the vigil between these two periods, although most people remained in bed, some used it to go to the bathroom or to meditate or pray, and even to visit the neighbors. It was also stated that the waking period was the most conducive for couples to conceive a child. According to Ekrich, references to the segmented sleep become scarcer towards the end of the seventeenth century, presumably because there began to be more night life, especially among those with sufficient economic resources to acquire lighting means. With the appearance of the electric light the night life spread towards all segments of the population, and with this began to change our sleep habits until reaching the present time, when sleeping daily eight hours is considered normal. in our nature sleeping segmented in two periods separated by one or two hours of waking in the early morning as an Ekrich adventure, so that to sleep eight continuous hours is an artificially acquired practice? Although the latter is not widely accepted by specialists, there is scientific evidence that supports it. In 1992, psychiatrist Thomas Wehr conducted an experiment with a group of volunteers who were subjected to 14-hour periods of darkness for a month, allowing them to sleep as much as they wanted. Wehr found that, after a transitional phase, volunteers ended up sleeping eight daily divided into two periods, separated by one or two hours of vigil. The applications of artificial light, on the other hand, are not limited to space lighting but extend, for example, to screens of electronic tablets, whose use is also increasing. In the latter case, one may wonder about the effects that these electronic devices have on our health and in this regard, an article published this week in the magazine \u201cProceedings of the National Academy of Sciences\u201d describes the results of our electronic devices. The research was led by Anne-Marie Chang of Brigham Women's Hospital in Boston, USA, and during the study the effect on sleep of reading, for four hours before bedtime, an electronic book on an iPad compared to a paper-printed one was studied. Researchers found that reading an electronic book reduces sleepiness before bedtime and increases it the next day; this compared to the printed book. They found, likewise, that reading on an iPad reduces the levels of melatonin \u2013 a hormone that plays a role in the induction of sleep \u2013 and slows down the circadian rhythm for more than an hour. Artificial light as we know it started with Edison's incandescent lamp in the last quarter of the 19th century and has evolved continuously since then to the present white-light LED lamps, whose use to illuminate both indoor and outdoor spaces is increasingly widespread. One feature of LED devices is its high efficiency, which presumably will increase If the adverse effects of artificial lighting are confirmed on our sleep habits and potentially on our health \u2013 it has been associated, although not conclusively, with an increase in the risk of developing breast cancer, as well as other diseases \u2013 we will have found that in terms of artificial light it refers, neither so much that it burns the saint nor so much that it does not light it.",
    "https://upload.wikimedia.org/wikipedia/commons/1/1f/Taj_Mahal_N-UP-A28-a.jpg": "One of the problems that afflicts the world today is that of air pollution by burning fossil fuels. We breathe tens of thousands of times a day and in every inspiration-breathing enters and leaves our lungs about half a liter of air. With thousands or tens of thousands of liters of air circulating daily throughout our body, chemical contaminants and particles suspended in the atmosphere are, or doubt it, of prime importance to our health. Air pollution is not only relevant to beings and is also a factor that determines the \u201chealth\u201d of some inanimate objects. This is the case of one of the most famous monuments in the world, the Taj Mahal, located in the city of Arga in northern India, which is suffering from air pollution around it. As we know, the Taj Mahal is a complex of buildings and gardens built in the 17th century during the Mogol Empire. Because of its architecture, the Taj Mahal is of great importance, to the extent that it is recognized by UNESCO as a World Heritage Site. The main building \u2013 and more identifiable \u2013 of the complex is a maj Mahal. In this mausoleum are found both the remains of the Mogol emperor Sha Jahan and those of his favorite wife, in honor of which the emperor ordered the construction of the monument. The first indication was that there were problems with the Taj Mahal in the seventies when it was observed that the white marble of the complex had acquired a brownish color. The original color could be restored by means of a treatment \u2013 equivalent to the application of a facial mask\u2013 in which the surface of the marble is covered with a layer of mud that is removed once dry and finally washed with water. To maintain the original color, however, it is necessary to apply this treatment periodically with intervals of some years.The change of color of the marble of the monument was attributed from a start to the air pollution in the vicinity of the monument, and in an attempt to solve the problem the circulation of vehicles within a perimeter of one kilometer around the Taj Mahal was restricted. Likewise, the industrial contaminants in the city of the monument were limited. Agra. There was no success, however. For the latter it is necessary to first find the specific cause of the problem. Although there has been no lack of hypothesis about the identity of these causes \u2013 the chemical reaction of the surface of marble with sulphur dioxide in the air, for example \u2013 only until recent times was a systematic study carried out to determine them accurately. This study was carried out by a group of researchers from universities in the United States and India, led by Michael Bergin of the Institute of Technology of Georgia. The study was published online last week in the magazine \u201cEnviromental Science and Technology\u201d and in it it is claimed that it has finally discovered the cause of the change of coloration of the Taj Mahal. Bergin and collaborators base their conclusions on a study in which, over several months, they collected air samples in the surroundings of the Taj Mahal and analyzed them to determine the pollutants contained. They found that air in Agra has carbon particles and dust in suspension. Coal could come from several sources that include burning fuels, brick manufacturing and vehicles. The dust could be caused by agricultural activities or by vehicular traffic. To complement the previous study the researchers placed white marble samples in places near the dome of the mausoleum and exposed them to the air for a period of two months. This, in order to determine what kind of particles were attached to the surface of the samples, which turned out to be, likewise, coal and dust. With these results Bergin and collaborators had strong indications that the particles of coal and dust were the culprits they were looking for. To prove this, however, it was necessary to find the physical mechanism by which the change of color occurred. For this purpose, they noted that certain particles of coal and dust reflect more efficiently the red light than the blue light. As we know, the light of the sun is composed of all the colors and if in some way we suppress the blue color the hue of the light changes. Thus, the charcoal particles attached to the surface of the marble, reflecting more the red than the blue, change the hue of the sunlight reflected by the marble of the Taj Mahal that acquires a pardule. With this information, it would be necessary to determine the origin of the particles of carbon and dust suspended in the air of Agra and to seek to suppress them at their origin \u2013 if such a thing is possible. This would protect a work of architecture that is the heritage of humanity. And by the way the inhabitants of Agra would be protected, because if the pollution of the air there is able to damage a stone building, nothing good could be expected for humans.",
    "https://upload.wikimedia.org/wikipedia/commons/a/a7/Sahara_satellite_hires.jpg": "In recent weeks Christie\u2019s has held two public auctions of objects that, one way or another, are related to science. On the one hand, Christie\u2019s uploaded a 27.9 gram fragment of the Black beauty meteorite last November. This meteorite was expelled from the planet Mars by the impact of an asteroid and arrived on Earth after traveling for five million years through interplanetary space. It was found a few years ago in the Sahara Desert by a nomadic meteorite seeker. Black beauty reached at the auction a price of $81,250, paid by a private collector. That is, nearly three thousand dollars per gram. In recent days, Christie\u2019s also raised the Nobel medal of James Watson: Watson received in 1962 the Nobel Prize for Physiology or Medicine, together with Francis Crick and Maurice Wilikins, for the discovery of the molecular structure of DNA. This discovery is one of the most important scientific advances of all time and has established the molecular bases of DNA. In 1968 Watson became director of the \u201cCold Spring Harbor Laboratory\u201d (CSHL), a private research institution located in Staten Island in the State of New York, which carries out research on cancer, neurosciences and plant biology, among other areas related to genetics. As of 1994, Watson acted as president of this institution and later as chancellor. In 2007, at the age of 79, he was relieved of his administrative responsibilities in the CSHL, although he continued to be linked to the institution as Emeritus Chancellor. Watson\u2019s replacement of his position as chancellor was motivated by his statements made during an interview he gave in October 2007 to the British daily \u201cThe Sunday Times\u201d, in which he stated that blacks are less intelligent than whites. Specifically, he commented that \u201che was pessimistic about Africa\u2019s prospects,\u201d because \u201call our social policies are based on the assumption that his intelligence is the same as ours, while all the evidence tells us that it is not so.\u201d Likewise, he said that \u201cthere is no solid reason to anticipate that the intellectual capacity of geographically separated groups of people in their evolution has evolved identically\u201d and that \u201cOur desire for equal powers of reasoning to be a universal heritage of humanity is not enough for this to be a reality.\u201d According to the interview, Watson had the hope that everyone would be the same, but \u201cthose who have to deal with black employees know this is not true.\u201d These statements, on such a politically explosive subject in the United States and coming from someone with Watson\u2019s scientific prominence, were, of course, of great impact and raised dust. Under these conditions, it was that the CSHL\u2019s leadership was alienated from Watson and removed him from his administrative functions in the institution. In view of the reaction he provoked, Watson made subsequent statements in which he tried to soften his position and stated that \u201cTo all those who have inferred from my words that Africa as a continent is genetically inferior, I can only express my apologies without This was not what I meant. More importantly, from my point of view, there is no scientific basis for this belief.\u201d Despite these statements, however, he also stated that he is not \u201ca racist in the conventional sense.\u201d Possibly in correspondence with the fame he has acquired with his controversial statements \u2013 on another occasion he defended the potential right that a pregnant woman would have to interrupt childbirth if a genetic test proved that her unborn child was homosexual\u2013, the price that Watson\u2019s Nobel medal acquired a high price at the auction and was sold to an anonymous collector in almost five million dollars. At the same auction Watson sold the draft of the speech that he gave when accepting the Nobel Prize and the manuscript of his Nobel conference. For both he obtained more than half a million dollars. The price that the Watson medal reached was considerably higher than the $2.3 million that he obtained the Nobel medal from Francis Crick when it was auctioned in 2013. Crick, who died in 2004, who had a more moderate public profile than Watson. Before 1980, the Nobel medals were made in 23 kilates gold and had a weight of 198 grams. . For the gold it contains, Watson\u2019s medal sold at Christie\u2019s auction now has a price of around $10,000. From what we see, however, its symbolic value \u2013 to which collectors respond \u2013 is considerably higher. Especially if, apparently, the medal is accompanied by public scandals,",
    "https://upload.wikimedia.org/wikipedia/commons/4/49/Meteorit_Cabin_Creek_nhm-Wien.jpg": "Five million years ago, an asteroid struck the surface of Mars, throwing rocks into space that escaped the planet\u2019s gravity. One of these rocks penetrated the Earth\u2019s atmosphere a few thousand years ago and, through the friction with it, fragmented into several pieces. The fragments fell into Western Sahara, in a politically unstable region under the de facto control of Morocco; control that is not, however, recognized by the UN. The meteorite has become famous and is known as \u201cBlack Beauty\u201d because of its color. The searchers and meteor dealers have managed to recover fragments of \u201cBlack Beauty\u201d that in total weigh about two kilograms. According to an article published this week in the magazine \u201cScience\u201d, two thirds of these two kilograms are in the hands of Jay Piatek, a doctor who owns a slimming clinic in Indianapolis, Indiana. Pietek would have acquired such fragments of Moroccan meteorite merchants. \u201cBlack Beauty\u201d is not the first Martian meteorite that has found the way to our planet. . The experts, however, consider that it is a separate case, because of the scientific importance it has to elucidate the geological history of Mars. \u201cBlack Beauty\u201d is formed by small pebbles bonded in a finer grain matrix. Munir Humayun, of the State University of Florida, argues in an article published in the Journal \u201cNature\u201d in November 2013, that the age of \u201cBlack Beauty\u201d \u2013 or at least some parts that make it \u2013 is about 4.4 billion years. This would imply that \u201cBlack Beauty\u201d comes from an early period in the geological history of Mars. It would also constitute the oldest Martian meteorite that has arrived on our planet. The fame of \u201cBlack Beauty\u201d has even exceeded the scientific borders and a fragment of it, with dimensions of 4.4x3.6x2 cm and a weight of 28 grams, was placed this November at auction by the Christie \u0301s house. According to this auction house, the meteorite is expected to be sold for an amount of between 7x3.6x2 cm and a weight of 28 grams. 5,000 and 100,000 dollars; that is, it could reach a value of up to $3,500 per gram, which is almost 100 times the price of a gram of gold. According to some sources, however, in the collector\u2019s market the price per gram of \u201cBlack Beauty\u201d could reach $10,000. Why are experts sure that \u201cBlack Beauty\u201d comes from Mars? If there is no certainty in this respect it would be possible that the one who acquires the piece of meteorite at auction would actually be made of a worthless stone \u2013 although it would have to be recognized that this is of no importance, except, of course, for the affected one. Certainly, the meteorite did not arrive on Earth with a fact label on Mars, a planet that is otherwise at an average distance of more than 200 million kilometers. To answer the above question we must first consider that scientific claims are never absolute and that in no way should be taken as definitive. Quite the contrary, scientific theories and hypotheses are modifiable in the light of new results or measurements. This was first recognized by Carl Agee of the University of New Mexico in an article published in the magazine \u201cScience\u201d in February 2013. Agee measured the concentrations of manganese and iron in the meteorite and found that these did not coincide with the respective concentrations of land rocks, but with those of the Martians. He also measured the deuterium content \u2013 a heavy version of hydrogen \u2013 in the water trapped in the meteorite and found that it is similar to that found in the water of Mars. Carl Agee had first calculated that the age of \u201cBlack beauty\u201d was about 2.2 billion years. This figure was reviewed by Munir Humayun who extended it to the 4,400 million years mentioned above. Agge had also postulated that the meteorite originated in a volcanic eruption, which was also reviewed by Humayun who attributed a sedimentary origin. This, according to that researcher, is important from the point of view of the search for life on Mars, as given its sedimentary origin. The meteorite may have formed in the presence of water. According to experts, given the coincidences with the Martian rocks investigated by the North American probes sent to the surface of Mars, \u201cBlack Beauty\u201d is an important object of study that could shed light on the geological past of Mars and eventually on the possible existence of life in a remote past. At a cost, moreover, it is a tiny fraction of the cost of sending probes to explore the surface of our neighboring planet. At the same time it ensures the investment of those who possess a piece of Mars arrived on Earth on an interplanetary journey of five million years.",
    "https://upload.wikimedia.org/wikipedia/commons/e/e8/El_Capitan_01.JPG": "As planned, on the morning of Wednesday, November 12, the 100-kilogram Philae probe of the European Space Agency (ESA) took off from the Rosetta mothership heading towards the surface of the comet Churyumov-Gerasimenko, with which it contacted seven hours later.As reported at the time by the ESA, the Rosetta ship with the Philae probe on board met with the Churyumov-Gerasimenko comet on August 6 after a 10-year journey from Earth. The meeting took place at a point 500 million kilometers from our planet, between the orbits of Mars and Jupiter. At its arrival in the vicinity of the comet, Rosetta entered orbit around it and is expected to accompany it on its orbital journey around the Sun for more than a year, until December 2015. According to the ESA website, the Rosetta mission aims to determine the origin and evolution of the solar system. Scientists consider that the composition of comets reflects the composition of the nebulan from December 2015. This study included sending the Philae probe to its surface, which unfortunately did not work out as planned, as the landing of Philae was not as smooth as expected. Far from this, to contact with the surface of the comet the probe \u201cbounced\u201d, rising for about a kilometer, to fall again \u2013 after almost two hours of flight \u2013 one kilometer beyond the first contact. The chaotic path of the probe did not stop there, and the second contact with the surface of the comet jumped again \u2013 although now at a lower height \u2013 to finally fall side by side near a rock wall. In a photograph sent by Philae from the surface of the comet, made public by the ESA, it is possible to see one of its three legs, apparently on the \u201cair\u201d, with rocks in the background. In comparison with the Earth, comet Churyumov-Gerasimenko has one of its three legs, apparently on the \u201cair\u201d, with rocks in the background. With this value, Philae's weight on the surface of the comet would be just ten grams, which explains that he jumped one kilometer upward, remaining suspended for almost two hours. To avoid what finally happened, the ESA had foreseen that contact with the surface of the comet would trigger an air propulsion mechanism that would press the probe downwards, while at the same time firing arcons to the ground to anchor it firmly. However, neither of the two mechanisms worked with the known results. One unfortunate consequence of Philae's rugged landing is that it ended up stopping at a site near a rock wall that greatly obstructs the solar radiation that must capture its solar panels to recharge its batteries. Without this radiation, the probe only had 60 hours of energy to perform its functions.In this circumstance, the probe's probe control team accelerated the experiments. This has been done unless, as soon as the comet approaches the Sun and the intensity of solar radiation increases, solar panels capture enough energy to charge the batteries: in such a case the probe could wake up. ESA, on the other hand, has been criticized for not having made the results of the mission public with sufficient speed. An article published in this week\u2019s issue of the magazine \u201cScience\u201d, for example, notes that it has not been made public, but that it has not been made public, as it has been planned with the measuring instruments on board Philae, which included drilling the comet floor to extract samples of material that scientists consider has remained unchanged since the formation of the solar system. According to the ESA website, Philae had enough energy to carry out the planned measurements and transmit the results to the Rosetta orbiter, which in turn has sent them to our planet. At the moment the probe has exhausted its energy reserves and has entered into a state of hibernation, which could be permanent. This is due to the fact that the scientists responsible for each of the instruments on board Rosetta want to maintain the priority over the data obtained, which they will make known by means of scientific articles of their own authorship in due course. It is certainly controversial that the results of a mission that has cost 1.4 billion Euros in public funds are not made public as soon as they are available and that is something that citizens of the countries that paid the mission to comet Churyumov-Gerasimenko will be able to claim. As far as we are concerned, we would have liked to have already had the opportunity to admire colorful images and in high resolution of a world for another stranger. And at the same time we regret that, as far as Philae's landing is concerned, not everything has gone as expected.",
    "https://upload.wikimedia.org/wikipedia/commons/0/06/Alfonso_de_Borja%2C_obispo_de_Valencia_y_papa_Calixto_III.jpg": "As we know, comets are celestial objects that revolve around the Sun in eccentric orbits that draw them closer and away from it and that, by the same token, appear and disappear from the sky periodically. All of this, however, we did not know for sure until relatively recent dates. Specifically, until Edmund Halley accurately predicted, decades in advance, the appearance in 1758 of the comet that bears his name. Before Halley comets were objects that appeared in the sky at random. After Halley their behavior is predictable, and in the particular case of the comet named in his honour, the apparitions occur every 76 years.Before their true nature was known, comets were associated with all kinds of events and omens, commonly calamitous \u2013 though not necessarily \u2013 and from this have emerged numerous stories in which comets have been starring protagonists.One of these stories has to do with the so-called site of Belgrade, in which Turks and Hungarians faced themselves in 1458 in the framework of the expansion of the Ottoman Empire towards Belgrade. Europe. Seeing the threat to Christendom and the fresh memory of the fall of Constantinople in the hands of the Turks in 1543, Pope Calixto III issued a bull to exorcise the Turkish danger in which he ordered all the churches to ring one or more bells three times at twelve o\u2019clock in the day, and all the faithful to pray three Our Fathers and three Hail Marys, in other precepts. The siege of Belgrade was given shortly after the appearance of Comet Halley in June 1458 and this gave rise to a legend according to which Pope Calixto III would have excommunicated the comet by considering it the object of the devil. This legend, which today is discredited, survived, however, until the nineteenth century, propagated, among others, by the French physicist and astronomer Pierre-Simon Laplace. Even after its true nature was discovered, comets have continued to be protagonists of numerous stories not so favorable to its reputation. During the visit of Comet Halley in 1910, for example, the tail of the same, which contains cyanogenus \u2013 a gas. This caused alarm that the atmosphere could be contaminated with this gas, leading to the extermination of life on Earth. Actually, the concentration of cyanogene in the comet is so small that it does not represent any danger \u2013 although it did constitute a business opportunity for some vivals who dedicated themselves to selling pills to supposedly neutralize the effects of the cyanogene. In a more recent case, the visit of comet Hale-Bopp in 1997 caused a mass suicide of members of the \u201cPuerta del Cielo\u201d sect, who by this way intended to board a supposed alien ship that was approaching the Earth hidden behind the comet. Such a ship would have been discovered in a photograph of the comet taken by an amateur astronomer. According to the sect\u2019s beliefs, the alien ship would lead suicides to a higher stage of life. Certainly many comet stories have developed throughout the history of the world. These stories come to be told these days because on November 12th the Rosetta ship of the European Space Agency, which since last month of the world\u2019s history. August is in orbit around the comet Churyumov-Gerasimenko after a ten-year journey from Earth, will release the 100 kg Philae probe that is intended to be gently positioned on its surface and anchored on it by harpoons. According to its website, the European Space Agency will broadcast live the landing of the Philae \u2013 with the delay of time required by the distance of hundreds of millions of kilometers to the Earth comet. Once on the surface of the comet, Philae will carry out measurements to determine its chemical composition and internal structure. Likewise, it will follow, as closely as possible, the evolution of the activities of the comet as it approaches the Sun.Rosetta and Philae carry on board sophisticated instruments that will allow us to obtain unprecedented scientific information about comets. Rosetta, also carries on board, of course, photographic cameras that have allowed us to observe the comet with an amazing detail. Gerasimenko is made up of two bodies united by a neck. How it was that the comet acquired that form is something that specialists will have to determine. What is clear from the photographs, taken at a distance of tens of kilometers, is that the comet travels alone, without companions, and that among the discoveries that Rosetta will give us will not find \u2013 surely \u2013 that of some alien ship hidden behind the comet traveling stealthily towards our planet. Nor will he find any evidence that justifies the black reputation that the comets had in times past. At the moment, it would be necessary to cross the fingers for the landing of next Wednesday to pass without setbacks.",
    "https://upload.wikimedia.org/wikipedia/commons/8/82/Airbus_A380_blue_sky.jpg": "On the one hand, the Orbital Sciences Corporation rocket exploded shortly after its launch last Tuesday night from a NASA base in the state of Virginia, United States. The rocket had under contract with NASA a load of more than two tons of supplies, equipment and scientific experiments destined for the International Space Station. The launchers pressed a self-destruct button fifteen seconds after take-off, when it was evident that something was not working well and to prevent the rocket from falling into a populated area. Although the causes of the accident have not yet been officially established, it has been attributed to a malfunctioning rocket engine. Bill Ketchum, a retired aerospace engineer who worked for the company General Dynamics, who was quoted by Forbes magazine, says forbes, also Dennis Wingo, Executive Director of Skycorp Incorporated, who claims that these engines \u2013 developed in the former Soviet Union \u2013 were stored in 1975 in a cellar without the appropriate climatic conditions. And that no one wanted to buy them until Orbital Sciences did it to Incorporate them into their Antares rocket. According to Wingo, the most likely cause of last Tuesday's accident was the effort, corrosion and cracks in the structure of the rocket engines, although he believes that there could also be a crack or fracture in the fuel lines.A second accident that involved the private space industry this week occurred last Friday when the SpaceShipTwo spacecraft of the Virgin Galactic company crashed on a test flight in the Desert of Mojave, California, dying one of its pilots and seriously hurting the other. SpaceShipTwo is a vehicle that Virgin Galatic intends to use to carry out tourist flights into space. The flights would be suborbital, which means that the ship would not enter orbit around the Earth. It would rise, however, to a height of about 100 kilometers from where you will be able to observe the curvature of the Earth and the dark of space. Passengers will also be able to experience the ingravity for a few minutes and float within the Earth. To reach the space, the SpaceShipTwo \u2013 which can transport six tourists \u2013 is first raised to a height of about 15 kilometers by a mother plane and then released to reach the hundred kilometers of altitude by its own means. On Friday\u2019s flight everything happened normally until the moment the mother plane released the SpaceShipTwo. Once released, however, and after a few seconds, there were \u201cserious anomalies that led to the loss of the aircraft,\u201d according to a statement from Virgin Galactic. It is not known with certainty that this happened to the SpaceShipTwo, but it would be possible that the accident would be related to the type of fuel used, which had not been tested with an aircraft in flight, although it had been tested on land. The accident caused experts to ask about the future of the space tourism industry. They do not doubt that this would happen one day, but perhaps not as soon as Richard Branson, owner of Virgin Galactic, predicted. Last September, when he stated that the first commercial flight of the SpaceShipTwo would take place in February or March 2015. This which seemed unworkable to experts before last Friday's accident, is now clearly impossible.In fact Branson has made repeated announcements of the imminence of commercial flights of the SpaceShipTwo and in wikipedia we can find a count of them. First, in July 2008 he predicted that the inaugural flight would take place in 18 months. In December 2009 he assured 300 people that they had paid to remove a place in the SpaceShipTwo, that the flights would begin to take place in 2011. In April 2011, however, Branson stated that he was hoping that in 18 months \u201cwe will be sitting on our spaceship heading to space.\u201d Despite this, in May 2013, Branson announced that he would be on the SpaceShipTwo on his inaugural flight, which would take place on 25 December of that year, \u201cperhaply dressed of Santa Claus.\u201d feel that the company has collected $89 million from 700 people who have bought a place in the SpaceShipTwo. Not bad for a company that offers trips to space but that to date has not made any \u2013 nor does it seem to be going to do it soon. Whatever it is, aside from good or bad business, what is clear is that traveling to space \u2013 more than half a century before the beginning of the space age \u2013 remains a difficult and dangerous undertaking, as the two space accidents that have occurred in the last few days attest. And this is the comfort left to those who could not pay $250,000 to set aside a trip to space, which could well never take place.",
    "https://upload.wikimedia.org/wikipedia/commons/f/f0/Hedy_Lamarr_in_a_1940_MGM_publicity_still.jpg": "Two weeks ago we commented in this space on the award of the Nobel Prize in Physics 2014 to the Japanese researchers Isamu Akasaki, Hiroshi Amano and Shuji Nakamura \u2013 the last nationalized American \u2013 for the invention of the LED lamp of blue light. The Nobel Prize in Physics was awarded this time for the development of a practical device and not for a fundamental scientific discovery, as it has been more frequent. That is, the Nobel Committee paid more attention to the social and economic impact of the discovery than to its scientific importance. Beyond the criterion used by the Nobel Committee, the decision to award this year\u2019s prize to Japanese researchers has motivated various comments. According to Wally Rhines, for example, who is the executive director of the company Mentor Graphics Corporation, the Nobel Committee made a mistake by ignoring the work of Herbert Maruska, whom he considers the true inventor of the blue LED. In support of this claim it can be mentioned that Maruska was granted in 1974 a patent \u2013 in which Rhines participates \u2013 for a blue LED manufactured with the same material as the LED developed by the Japanese researchers. In the opinion of Rhines, on this occasion the Nobel committee awarded to those who perfected the blue LED and not to those who invented it two decades earlier. Apart from the controversy, it is interesting to mention that Maruska developed the first blue LED when he was a doctoral student at Stanford University in Palo Alto, California. Maruska was at the same time an employee of the RCA company that was interested in the development of flat screens for television. RCA\u2019s support to Maruska for the realization of his doctorate was contingent on his doctoral thesis dealing with the development of a blue LED. At that time \u2013 the first half of the 1970s \u2013 there were red and green LED lamps. For a colour screen, however, a blue lamp was also needed and hence RCA\u2019s interest in Maruska\u2019s work. The development of the blue LED in the RCA company, however, was interrupted in 1974 when RCA entered a stage of economic problems that led to collapse in 1986. It is equally interesting to make a comparison between Maruska\u2019s work and Shuji\u2019s work. Nakamura, who developed his blue LED in the first half of the 1990s when he worked for a small company, Nichia, in Tokushima, Japan. Like Maruska, Nakamura began working on this project before receiving his doctorate. This did not prevent him, as he relates in his book \u201cThe Blue Laser Diode: The Full Story\u201d, from receiving considerable support from Nichia to carry out his work. This support resulted in a grant of $3.3 million, an amount that represented 1.5% of total sales of the company. At a certain point, however, Nichia considered that the project was consuming too many resources and suspended support. With this, Nakamura had to manage to continue his work. Finally, in 1993 he succeeded in his efforts and managed to develop a process for the manufacture of blue LED lamps that proved to be commercially viable. Nakamura carried out what Edison carried out at the time with the incandescent lamps. Both, Edison and Nakamura were not the original inventors of their respective lamps, But instead they developed manufacturing methods that made it possible to commercialize and widely disseminate it. Had they not suspended RCA in 1974 their projects on blue lamps could have been this company and not Nichia that would have taken credit for its development. By then, however, Maruska had left the company. In words collected by the magazine IEEE Spectrum \u2013 published by the Institute of Electrical and Electronic Engineers of the United States \u2013 Maruska says \u201cI am sure it would not have been long before I had obtained a brilliant LED lamp. But once I was fired I could not find another job where to continue the project.\u201d Nakamura, for his part, received from Nichia $180 for the patent on blue LED and, as a result, sued the company. After a trial he reluctantly accepted nine million dollars in compensation.Many circumstances surrounded the development of blue lamps and much could be written on the subject. It is worth, however, finishing this article by reproducing one of Nakamura\u2019s arguments to explain why Nichia had success. According to Nakamura, \u201cthe project was managed by only two people: he and the president of the company. It could not have been simpler: no committees, no supervisors, no heads of department, no group leaders etc., no review committees, no internationalization, no coordinators, no international consortia \u2013 just work.\u201d",
    "https://upload.wikimedia.org/wikipedia/commons/5/54/PDB_1svm_EBI.jpg": "In 1865, the Augustinian monk Gregor Mendel published an article entitled \u201cExperiences on hybridization of plants\u201d, in which he described the results of a study carried out with pea plants in order to elucidate the laws governing the inheritance of physical characteristics from parents to children. In his experiments, Mendel found \u2013 unexpectedly \u2013 that the physical characteristics of the studied plants, such as the colour of their seeds or the color of their flowers, are inherited in an integral way or simply are not inherited. This, in contrast to the prevailing idea at the time according to which these characteristics would be the result of a mixture of the corresponding characteristics of their immediate ascendants. Thus, when crossing a plant with green seeds with another one of yellow seeds, Mendel found that a plant was produced with yellow seeds and not one with seeds of a combined green-yellow color. With this finding, Mendel gave origin to the concept of gene, a particle containing all the information of a living being \u2013 that is to say, the plans necessary to build it \u2013 and that it could be one of a combined green-yellow color. Although Mendel\u2019s work did not receive much attention at the outset, it was rediscovered as the 20th century emerged and since then it became the starting point of genetic science. Later, during the first half of the 20th century, this science progressed rapidly by establishing that genetic information is encoded in DNA molecules, similar to a piece of music is encoded on the surface of a compact disk. The molecular structure of DNA, which is in the form of a double helix, was discovered in the years 1952-1953 at the University of Cambridge, England, by Francis Crick and James Watson, and by Rosalind Franklin and Maurice Wilkins at King\u2019s College, London, England. For this discovery, one of the most remarkable scientific results of the 20th century, Crick, Watson and Wilikins received the Nobel Prize for Medicine or Physiology in 1962. Rosalind Franklin, despite having been one of the main protagonists of the discovery, could not receive the Nobel Prize because he had died of cancer in 1958 and that award was not awarded by Nobel Prize of Medicine or Physiology in 1962. Rosalind Franklin, despite having been one of the first being one of the main protagonists of the discovery, could not receive the Nobel because he had died of cancer in 1958. Genetics currently has a huge range of applications and the same is used in medicine for the development of therapies to cure diseases, which in forensic practice to identify human remains. Recently, genetics has been used to determine that the AIDS/HIV epidemic that plagues the African continent originated in the decade of the fifties of the last century, in the city of Leopolville in the then Belgian Congo. Genetics has even been used to clarify issues that have occurred in a remote past. It has been used, for example, to elucidate what has been the evolutionary path that has been followed by the human species since its departure from Africa hundreds of thousands of years ago. The information contained in DNA is unique and characteristic of each individual, and knowledge of the structure of genetic material can lead to a diagnosis and/or prognosis of certain human diseases. Using the modern techniques of molecular biology it is possible to identify pathogenic microorganisms for the human, to detect mutations, to verify paternitys, among many other applications that are carried out with great certainty and sensitivity. Thus, using the technique of \u201cReaction in Chain of Molecular Biology\u201d Polymerase (PCR)\u201d is possible to obtain DNA information using only 10 nanograms \u2013 one hundred thousandth of a milligram \u2013 of genetic material. Modern techniques of molecular biology are routinely performed and are available to the public. This, not only in the first world countries but also in Mexico, including San Luis Potos\u00ed. The detection of sexually transmitted diseases, the human papillomavirus and mutations that generate haematological diseases, are some of the tests already carried out by PCR in our city. In the near future, it will also be possible to carry out the detection of mutations that produce breast cancer, thyroid cancer, tuberculosis and influenza. As in other areas of science and technology, the applications of genetics might have seemed to us just a few decades ago a good topic for a science fiction film. These applications are, however, real and constitute novel diagnostic techniques that reinforce conventional techniques. In the future, we might perhaps think of an individualized medicine based on molecular biology and according to the genetic information of each person. an increase in the life expectancy of our species, as occurred during the 20th century with the introduction of antibiotics and hygiene measures.",
    "https://upload.wikimedia.org/wikipedia/commons/e/ea/Human_Immunodeficency_Virus_-_stylized_rendering.jpg": "Last Tuesday, U.S. health authorities released the first case of Ebola virus infection diagnosed in the United States. The diagnosis was made by a man who had flown days before from Liberia to Dallas, Texas.As we know, there is currently an epidemic outbreak of Ebola in several West African countries, including Liberia, Guinea and Sierra Leone, which has resulted in more than 3,000 deaths. Ebola virus is known to have originated in Africa and is transmitted from animals to humans. The first outbreaks detected in Ebola occurred in 1976 in Zaire (now the Democratic Republic of the Congo) and Sudan, and since then have occurred with some regularity. Ebola virus infection often has a fatal outcome. According to the World Health Organization, in past Ebola outbreaks, half of patients died on average. Fortunately, Ebola virus is not particularly contagious and transmission requires a person-to-person contact. If Ebola virus could be transmitted through the air \u2013 as the flu virus \u2013 it would certainly be. However, the experts believe that it is unlikely that this virus can mutate to the extent that it can reproduce in large quantities in the airways and thus enable its spread through the air. It is not expected, then, that this Ebola outbreak will become a pandemic that kills millions of people, as if it was the Spanish influenza epidemic that in 1918 caused between 50 and 100 million deaths. And as is the current AIDS/HIV epidemic, which emerged in the public light in the 1980s of the last century and has affected 75 million people around the world, having died half of them. Like the Ebola virus, HIV originated in Africa, and it is precisely in that continent where about 70 per cent of all people infected with this virus live. In some southern African countries, the epidemic has reached dramatic proportions, such as Botswana and Zimbabwe, where the number of people infected with HIV exceeds 25 per cent of the total population. Although the first case of AIDS diagnosed as such occurred in 1980, just over three decades ago, the epidemic reached dramatic proportions, such as Botswana and Zimbabwe, where the number of people infected with HIV exceeds 25 per cent of the total population. According to an international group of researchers led by Oliver Pybus of the University of Oxford in the United Kingdom and Philippe Lemey of the University of Louvain in Belgium, the epidemic began about ninety years ago in Central Africa. The above conclusions are based on a genetic study \u2013 published this week in the magazine \u201cScience\u201d \u2013 of HIV samples from different times and places in the Democratic Republic of the Congo (DRC) and in neighbouring countries in the centre of the African continent. As part of their study, researchers followed the mutations of the virus over time and, going back, determined its origin in time and place, which turned out to be the decade of the 1920s of the last century and the present city of Kinshasa, capital of the DRC. One point of interest for epidemiologists is to determine the specific cause or causes that led to the onset of the AIDS/HIV epidemic, precisely in the city of Kinshasa. In the 1920s, the DRC was a Belgian colony. Pybus, Lemey and collaborators, a factor that contributed to the outbreak of the epidemic was the colonial railway that connected the country's main urban centers with other regions of Africa and that allowed the displacement of infected people and consequently the spread of the virus. They also consider that the health conditions prevailing in Kinshasa in the 1960s, as well as the change in the sexual behavior of its inhabitants after the country achieved its independence from Belgium, could also have influenced the spread of HIV. Determining the causes and conditions that caused the AIDS/HIV epidemic that the world suffers \u2013 and that, above all, suffers the African continent \u2013 is of fundamental interest to prevent future epidemics.Communications are obviously an essential factor for the spread of an infection at a global level. Thus, the Ebola patient who traveled from Liberia to the United States could not have done it a century ago when the ship trip between continents took a week \u2013 he would have died in the attempt, as Ebola is a rapidly evolving disease, although probably before doing so he would have infected other passengers. is that Pybus, Lemey and collaborators have managed to find out where and how long the AIDS/HIV epidemic began, practicing a kind of genetic archaeology.",
    "https://upload.wikimedia.org/wikipedia/commons/9/9d/Mars-express-volcanoes-sm.jpg": "On Tuesday, September 23, India succeeded in orbiting the planet Mars, an artificial satellite \u2013 nicknamed Mangalyaan \u2013 that only the United States, the former Soviet Union and the European Space Agency had managed to perform. Two other Asian countries, Japan and China, unsuccessfully tried to carry out missions to Mars \u2013 Japan in 2003 and China in 2011\u2013, which adds notoriety to India's achievement and puts India ahead of its Asian competitors. Getting a probe launched from Earth into orbit around a distant planet on average 225 million kilometers \u2013 in a kind of cosmic target shooting \u2013 does not seem to be a simple task, even for the most skilled space engineers. And indeed it is not, as the fact that half of the missions to Mars in one way or another have ended in failure proves. At the beginning of Mars exploration, failed missions were frequent. Thus, the United States managed in 1965 to make a ship, Mariner 4, fly Mars \u2013 at a height of 10,000 kilometers \u2013 only until its second attempt. The NASA Mariner 9 was the first probe to be put into orbit around Mars. This happened on 13 November 1971. The US Space Agency succeeded until its second attempt, after accumulating an experience of five Mars approach missions, some successful and others failed. Two weeks after the American achievement, the Soviet Union did the same and placed Mars 2 in Martian orbit. For this it had to accumulate the experience of nine Mars missions, all failed. India, on the other hand, succeeded with the Mangalyaan at the first attempt. And, if anything was missing, the mission had a cost of only 74 million dollars, which while it was an amount of money that was not negligible, is just a fraction of what other Mars approach missions have cost. The American probe MAVEN, for example, which entered Martian orbit almost simultaneously with Mangalyaan, had a cost of 671 million dollars; that is, almost, almost, In the same way, the European Mars Express probe, which has been orbiting Mars since December 2003, had a cost about five times higher than that of Mangalyaan. It has also been ironically pointed out that the Mangalyaan mission had a lower cost than that of the film \u201cGravity\u201d, which had a budget of 100 million dollars. How did the Indians do to carry out such a complex mission with such a low budget? According to Kopilllil Radhakrishnan, director of the Indian space agency in interview with Forbes magazine, several factors contributed to this. One of them is what he calls a \u201cmodular approach\u201d, through which the Indians developed the technology necessary for the mission by adapting and improving existing technologies. In the case of the rocket launch engine, for example, from French technology that they acquired in the 1970s. The same modular approach was employed for the development of scientific instruments on board the probe. Another strategy to reduce costs was to limit ground testing, extracting the maximum amount of evidence from French technology that they acquired in the 1970s. The same modular approach was employed for the development of scientific instruments on board the probe. India has also developed strategies to reduce the fuel consumption needed to carry the probe from Earth orbit to Martian orbit. It also notes that the calendaring and execution of activities was carried to one end and that since the announcement of the mission by the Indian Prime Minister and the beginning of the mission only took 15 months. And at this point it mentions that while in some parts of Europe, even space scientists work 35 hours weeks, for them the 18-hour days of activity were common, as well as that during the launch period many of its scientists worked 20 hours a day. Despite its relative low cost and spectacularity, the Indian mission to Mars has provoked criticisms in the sense that it would have been preferable for India to invest the 74 million dollars that Mangalyaan cost in alleviating the enormous poverty problems that the country suffers. An editorial of the newspaper \u201cThe New Indian Express\u201d, however, is at odds and states that \u201cthe construction and launch of satellites is a multimillion dollar business that has been monopolized so far by some Western nations. India has India is able to provide these services to a fraction of what it would cost to do on demand. Mangalyaan\u2019s success will help India get a larger share of the business of building and launching satellites into space.\u201d The success of the Mangalyaan probe shows how organization, ingenuity and dedication to work, as substitutes for massive amounts of money, can solve complex technological problems. It also shows that, if proposed, India is a sharpshooter that puts the bullet in the eye.",
    "https://upload.wikimedia.org/wikipedia/commons/c/c7/Saturn_during_Equinox.jpg": "On September 11, NASA announced that the explorer Curiosity had finally reached the base of the five-kilometre-high Martian mountain Aeolis Mons, after a journey that took him two years. As we recall, the explorer Curiosity \u2013with a size comparable to that of a compact car and a weight close to a ton \u2013 arrived at the Gale crater on Mars on August 6, 2012 by means of a spectacular maneuver that posed it gently on the surface of the planet. Curiosity had as a first goal to reach the Aeolis Mons mountain, about 6 kilometers away from its landing point. The explorer carries on board a set of sophisticated instruments for the scientific study of Mars, including photographic cameras, chemical analysis equipment, radiation detectors and a meteorological station. It is also equipped with a drill to drill rocks and extract samples in order to determine its chemical composition. Among its stated objectives is to find out if there were ever conditions on Mars to house life.With the arrival to the Aeolis Mons mountain, the explorer Curiosity completed the primary phase of his mission that he had completed. Among other results, it shows that at some point in its geological history on Mars there were conditions for the existence of life. At this moment, Curiosity is preparing to begin the second stage of its mission in which it will ascend 8 kilometers along the slopes of the mountain, in order to search the geological past of the planet and locate habitats in which organic compounds could be preserved.John P. Grotzinger, who is the principal researcher of the Curiosity project, highlights the scientific achievements that have been achieved in the first stage of the mission and is enthusiastic about the results that he expects will be obtained in the second stage. A panel of experts hired by NASA, headed by Clive Neal of the University of Notre Dame in Indiana, United States, however, does not share this enthusiasm. He does not share it either with regard to the scientific achievements achieved, nor with regard to the studies presented in the continuation phase of the mission. The panel of experts was commissioned to evaluate the extension of a group of seven NASA projects that includes, in addition to Curiosity, the Cassini probe, in orbit around the mission. The planet Saturn for ten years, and the explorer Opportunity, who has been exploring the surface of Mars since its arrival in January 2004. Although the panel described the Curiosity mission as \u201cVery Good/Good\u201d, this rating is misleading if we compare it with the ratings of \u201cExcellent\u201d and \u201cExcellent/Very Good\u201d given to Cassini and Opportunity, respectively. In fact, in Curiosity rating it only exceeded the Mars Express project of the European Space Agency, in which NASA has an associated participation. According to the review panel, the scientific activity carried out by the Curiosity since its arrival to the Martian surface has not been as intense as it might have been expected. In particular, it notes that in the two years of operation since its landing on Mars the Curiosity has carried out only five perforations of the Martian soil and that in the next two years it is only intended to carry out eight more. Thus, the explorer operators would be more concerned about displacing the Curiosity on Mars soil than in the science that it can contribute. In addition, it is not clear whether the objectives of the mission in its first stage have been fulfilled and that it is not even clear what these objectives were. Similarly, the panel states that the objectives set for the second stage are inaccurate.To do the worst things, Grotzinger, despite being the main researcher of the mission, did not attend the sessions of the panel to answer questions and clarify doubts. In these circumstances, in an official letter addressed to James Green, Director of the Planetary Science Division of NASA, Clive Neal writes that Grotzinger\u2019s failure \u201cleft the panel with the impression that the Curiosity team felt that they were too big to fail and that it was enough to send anyone to meetings.\u201d As a conclusion, the panel urges NASA to make the necessary adjustments so that \u201cthe Curiosity team focuses on maximizing the realization of high-quality science that justifies the ability and investment of capital carried out in the explorer.\u201d Assuming that the members of the panel of experts assists the reason, it does not fail to surprise that a project In which $2.5 billion was invested \u2013 and which began with the best omens \u2013 may be a source of such severe questions as those facing Curiosity. And yet, despite the harsh qualifiers that it applied, the panel of experts approved a budget of $60 million for the extension of the mission for two more years.",
    "https://upload.wikimedia.org/wikipedia/commons/1/1c/Gideon_Mantell.jpg": "In an article published last September 4 in the online magazine \u201cScientific Reports\u201d, which was widely commented by the press, the discovery in Argentinian Patagonia of the fossil remains of a gigantic herbivorous dinosaur that lived about 66-84 million years ago. The article was published by a group of researchers from the United States, Argentina and England, headed by Kenneth Lacovara of Drexel University, Philadelphia, Pennsylvania. The newly discovered dinosaur measured about 26 meters from head to tail and weighed about 60 tons. To put this last number in perspective, it can be mentioned that it is about nine times the weight of the tyrannosaurus rex, and that it is greater than the weight of a Boeing 737 jet with capacity for more than 150 passengers. Dinosaur has been baptized \u201cdreadnoughtus\u201d, which translates as \u201cno fear\u201d, in reference to its enormous size making it inatable by any predator.The most transcendent, however, is that researchers rescued about 45% of the dinosaur\u2019s bones. In 1822, together with his wife, he discovered near the town of Cuckfield in southern London, a tooth similar to that of the iguanas, but considerably larger. With this limited evidence, Mantell conjectured that the tooth belonged to him, and he discovered that the tooth was similar to that of the iguanas, but with this little evidence Mantell conjectured that the tooth belonged to him in 1822, together with his wife, he discovered a tooth similar to that of the iguanas, but with a considerably larger tooth. With the help of fossil remains found later, Mantell was convinced that he was right and baptized into the lizard with the name of iguanodon.While Mantell managed to convince the experts about the success of his conclusions, in the skeletal and artistic reconstruction of the iguanodon, he made a curious mistake because he placed the bone of the dinosaur's thumb on his nose, so that the model acquired a rhino air. This error spread over several decades, even after Mantell's death. Indeed, in 1851, as part of the world industrial exhibition held at Crystal Palace in London, an exhibition was prepared on dinosaurs in which all the scientific knowledge on the subject was used that was available at the time. For this purpose, models of dinosaurs were built in cement as they were thought to be in life and in particular the iguanodont appeared with its fictitious horn in the nose. Only years later, when more complete igunodon fossils were found, was that paleontologists realized the error committed and the dinosaur lost its nasal horn in scientific discussions. It was not the case, however, of the models of Crystal Palace dinosaurs that were preserved with all its errors, as they were originally conceived. Today, such models can be seen in a permanent exhibition at Crystal Palace Park in London.The story of the iguanodon shows us how scientific knowledge progresses. Based on the limited information it had about its dinosaur, Mantell ventured a hypothesis regarding its aspect in life, which at the time was accepted by the experts. By having better fossil remains, however, the error was revealed and the nasal horn was discarded, even though today it is only embodied in the anecdotic memory and in sculptures that have been preserved for historical reasons; reasons that have nothing to do with its scientific accuracy. Accuracy that is remarkable in the case of the recently discovered \u201cdreadnoughtus\u201d in Patagonia as much of its skeleton is available. . Which, however, is not absolute \u2013 like everything related to scientific knowledge \u2013 and therefore can lead to errors of interpretation. Although surely not so large that they lead to putting a bone in the tail of the dinosaur in your nose or vice versa.",
    "https://upload.wikimedia.org/wikipedia/commons/9/98/EdWhiteFirstAmericanSpacewalker.1965.ws.jpg": "We were able to find out this week from the press that on September 12th from the international space station will land somewhere in Kazakhstan in Central Asia a sample of Scottish whiskey put into orbit three years ago. The experiment is carried out by the Scottish distillery Ardbeg in order to study how the microgravity conditions of space affect the process of maturation of the whiskey. On the Ardbeg page no further details are found about the experiment, beyond which it is intended to study the interaction of certain organic molecules with roasted oak particles and that the results obtained with the sample in the space will be compared with those obtained with similar sample that has remained on the ground. According to Bill Lumsden of the company Ardbeg, the experiments have the pretension of \u201cdiscovering the mysteries of the maturation process of the whiskey\u201d, same that, paraphrasing Neil Armstrong, \u201cwill constitute a small step for the man but a gigantic one for the whiskey\u201d. In the absence of gravity, for example, it is possible to manufacture perfect metal spheres with uniform diameters to be used as pellets in bearings or balers. Except in particular cases, however, the manufacture in space is too expensive and has not been economically viable. This is due to the high costs of bringing an object into a Earth orbit, which is thousands of dollars \u2013 when not tens of thousands of dollars \u2013 per kilogram. This cost reflects the energy needed to raise an object from the surface of the Earth to an orbit of a few hundred kilometers against the gravitational force of our planet. For this purpose it is necessary to accelerate that object to a speed greater than 25,000 kilometers per hour. This situation could change as the costs to place loads in orbit are reduced and there are those who anticipate that in the future we will see the installation of factories in space, hundreds of kilometers above our heads and even beyond. In this sense it is worth commenting that in the space race, in addition to the space agencies of several countries, there are also U.S.A. One of these, SpaceX, anticipates that in the Another factor that could also boost the development of factories in space is the mining of asteroids. According to enthusiasts of this field, asteroids that rotate around the sun in orbits not too far away from our planet are a potential source of raw materials, including water. These raw materials would be susceptible to exploitation and would require relatively small energy to transport them from the asteroid to a hypothetical factory that rotates in orbit around our planet is relatively small. This is due to the weak gravitational force of the asteroid. In addition to the above, water extracted from asteroids could be decomposed by sunlight into the chemical elements hydrogen and oxygen, which can be used as fuel to drive the rocket that transports minerals from the mine to its final destination.Seen this way, asteroid mining turns out to be an attractive option to provide raw materials to future factories in space. It is except for one obvious point: extracting minerals from a mine located to tens of millions of kilometers of our planet in hostile conditions is considerably more difficult. In this connection, we must remember the great difficulties experienced by the Japanese Hayabusha probe in posing on the Itokawa asteroid in 2005 and bringing back dust samples from the asteroid to Earth. Still, there are private companies such as Deep Space Industries and Planetary Resources interested in asteroid mining. Will we ever see the commercial exploitation of asteroids? Not everyone agrees that this will be feasible. Martin Elvis of Harvard University, for example, in an article that will be published in the magazine \u201cPlanetary and Space Science\u201d finds that there are very few asteroids whose exploitation could be economically viable, a conclusion with which he disagreed, naturally, the co-founder of Planetary Resources.More than half a century after the start of the space age, space exploration retains a considerable public appeal that has been used to launch controversial projects, one of which is precisely that of asteroid mining. Ardbeg gives us a surprise and through his experiments produces a whiskey with a taste beyond this world.",
    "https://upload.wikimedia.org/wikipedia/commons/0/0c/Osmium_crystals.jpg": "As has been widely disseminated by the press, on August 6, a dam of the Buenavista mine in Cananea, Sonora, spilled a volume of 40,000 cubic meters of liquid in the Bacanuchi river, a tributary of the Sonora river. This liquid was a mixture of sulfuric acid and copper sulphate, in addition to other heavy metals, including cadmium, mercury and lead. With this spill, the rivers acquired a coloration as \u201cmolcajeteate salt\u201d, as described in the press in past days. More than two weeks after the spill the problem has not been overcome, and according to a statement issued last Friday by CONAGUA, there are still concentrations of arsenic, cadmium, copper, chromium and mercury in the middle and low part of the basin, with peaks that exceed the permissible maximum limits established by the norm. Cadmium \u2013 which is toxic in very low concentrations \u2013 was the cause of the disease \u201cItai-itai\u201d that appeared in the first decades of the 20th century in the Jinzu river basin. gawa in Toyama Prefecture in Japan. Cadmium was dumped in the river Takaharagawa, a tributary of Jinzugawa, by the Kamioka mine, operated by the Mitsui Mining and Smelting company. Once in the river, cadmium was ingested by the fish that served as food to the inhabitants of the region that were thus intoxicated. A second route of poisoning was rice grown in the vicinity of the polluted rivers and watered by their water. Cadmium poisoning produces kidney damage and softening of bones. According to the website of the \u201cItai-itai Disease Museum\u201d of Toyama Prefecture, this disease \u201cstarts with a pain in the lower back, shoulders and knees. When symptoms become more serious, there are repeated breaks of bones until the victim is unable to move and is finally confined to the bed with pains attacking the whole body.\u201d These pains are those that have given the disease the name Itai-itai, which Another of the metals contained in the Cananea spill, mercury, is not left behind in terms of toxic effects, particularly in the form of methylmercury, compound that affects the central nervous system. A famous case of massive mercury poisoning occurred in the first half of the last century in Minamata, a village of weighers on Kyushu Island of the Japanese archipelago. Poisoning was caused by mercury discharges by the company Chisso in the waters of Minamata Bay, where it was absorbed by fish and shellfish and eventually by fishermen who consumed them. According to Wikipedia, until 2001 2,265 victims of Minamata's disease had been officially recognized. We know that environmental pollution has accelerated as a result of the beginning of the Industrial Revolution. In the case of some pollutants such as carbon dioxide, we have detailed information about its evolution in the atmosphere and in the oceans over the years. This, however, is not the general case and in particular, it is not for mercury that it is a highly relevant pollutant for us. The article was published by a group of researchers in institutions in the United States and Europe, headed by Carl Lamborg of the Wood Hole Ocenaographic Institution. Through the study of water samples collected at various sea depths, some below 1000 metres, Lamborg and collaborators concluded that the concentration of mercury in ocean waters at depths less than 100 metres has tripled since the beginning of the Industrial Revolution. Taking the oceans as a whole, that concentration has increased by 10% on pre-industrial levels. Thus, mercury pollution, as with other pollutants, has grown as a result of our industrial development. More than half a century after the Toyama and Minamata disasters, we would not expect others of similar magnitude to occur; in particular, this would not be expected to happen with the current Sonora River spill. Nor does it imply that those companies that generate pollutants take all the necessary care to avoid our exposure to them, nor that they take spontaneously their responsibility in the event of an accident. Chisso, for example, tried to hide in many ways their involvement in the Minamata case and, by official statements, it seems the same in the Cananea case. And somehow the strategy works. Thus, Chisso managed to circumvent the crisis and even operates as a chemical manufacturer. Even, on his website you can read \u201cWe have operated the manufacture and sale of chemicals and contributed to people having a comfortable lifestyle since our establishment in 1906.\u201d",
    "https://upload.wikimedia.org/wikipedia/commons/6/6c/Egypt.Giza.Sphinx.02.jpg": "In his travel book \u201cThe Innocents Abroad\u201d published in 1869, American writer Mark Twain writes that during his trip to Egypt he was told that trains in that country used mummies as a fuel with an age of three thousand years, and that for this purpose mummies were bought for tons or for whole cemeteries. Mark Twain claims that this was given to him for a fact and that he was willing to believe it. This, although taken as a joke by the writer, reflects the abundance of Egyptian mummies, as a result of the fact that in Ancient Egypt, thousands of years ago, it was customary to mummify the dead in order to preserve their bodies for eternity. This, in order that they could be occupied by the soul during life after earthly death. Since mummification processes had a cost that could be high, the success achieved in this company depended on the economic possibilities of each person. Thus royalty and the upper classes managed to preserve their bodies in an amazing way, while those with fewer economic possibilities had to conform to procedures. Even so, the number of mummified bodies was very large. In an interview with the TV program NOVA of the United States Public Brodcasting Services, Egyptologist Salima Ikram of the American University of Cairo considers that more than 70 million people were mummified in Ancient Egypt over 3000 years. In Ancient Egypt animals were also mummified massively, including cats, dogs and birds, with the aim of accompanying their owners or serving them as food in the afterlife. On the British Museum's electronic page, for example, it is stated that some 180,000 mummies of cats were brought to Britain at the end of the 19th century. In this case, to be used in the manufacture of fertilizers. To mummify a body artificially the Egyptians first extracted internal organs, including the brain and with the exception of the heart. The body was subsequently subjected to an organ dispossession process for several weeks using a salt called natron. At the end of which it was washed and covered with aromatic oils.As a final step, the body was wrapped in bandages impregnated with resins with bactericidal properties.With the latter, the mummy acquired the appearance that is familiar to us.Experts have considered that these mummification techniques began to develop in Egypt some 2500 years before our era, and that the mummies prior to this time that have been found, were naturally generated by the dehydration of bodies in contact with the dry and warm sand of the Egyptian desert. An article appeared this week in the electronic magazine PlosOne, however, refutes this belief. It finds, on the contrary, that the origins of the mummification process \u2013 which would reach its maximum sophistication during the New Empire between the years 1500 and 1000 before our era \u2013 had their origin more than a thousand years earlier than the experts have assumed. The article was published by a group of researchers in Australia and the United Kingdom, headed by Jana Jones of Macquarie University in Sidney, Australia. Through chemical analysis using techniques of great sophistication, Jones and collaborators found resins and other chemical components in the bandages, similar in proportions to those that were used in the zenith of the pharaohs 3000 years later. The beginning of the embalming techniques in Egypt would go back about 3,500 years before our era. The Egyptian civilization and in particular the mummies that it produced result from a great appeal to us. It is interesting to remember, for example, that in 19th century England it became fashionable to organize parties whose main attraction was to develop a mummy brought from Egypt, to which they were still champana and canap\u00e9s. Likewise, it must be remembered that mummies have been central characters in horror films of great success. But perhaps the most striking thing about an Egyptian mummy \u2013beyond frivolous entertainments \u2013 lies in its antiquity, particularly in the possibility of mummys in the early 19th century. to observe the face and body of a person who lived thousands of years ago \u2013 however deliberately we have destroyed thousands of mummies, among others those presumed by Mark Twain. And here we will have to thank the Egyptians for their concern to develop techniques for the preservation of mummified bodies, if not for eternity as they intended, yes for many years. That after the work of Jones and collaborators, it seems that they are, until now, like 6500.",
    "https://upload.wikimedia.org/wikipedia/commons/d/df/Edmond_Halley_072.jpg": "We know that comets move around the Sun with eccentric orbits that periodically bring them closer and further away from our planet. As we approach the Earth a comet may become visible at first sight if its size is large enough, sometimes offering shows worthy of the best audience. This is common with Halley comet, which appears in the sky every 76 years on average, last time in 1986 \u2013 although it should be noted that, to the disappointment of our generation, this last visit turned out to be the worst in 2,000 years from the point of view of the spectacle offered. In ancient times the appearance of a comet was seen as an extraordinary event that contrasted with the periodic and predictable movement of the planets. This led us to consider that comets were precursors of equally extraordinary events, including wars and epidemics, among other calamities. It is not surprising that the appearance of a comet has seemed like an unpredictable event if we consider that there are comets with times of revolution around the Sun so long that they have been seen only once throughout history. Even in the case of Halley comet, which has a relatively short time of revolution, its periodicity, It was not established until the 18th century. Indeed, it touched Edmund Halley \u2013 not to confuse with the Haley of the rock and roll group of the 1950s \u201cBill Haley and his Comets\u201d \u2013 to discover that the comet bearing his name is an object orbiting the Sun by describing an ellipse. Making use of the theory of universal gravitation that Isaac Newton had recently developed, as well as observations of the positions of comets spotted in 1531, 1607 and 1682, Halley came to the conclusion that they corresponded to a single object and predicted a new sighting in 1758. The latter proved to be correct, and with this comets lost their magical character as precursors of disasters and calamities, and entered the category of natural objects whose successive visits could be predicted decades in advance. One of the many comets now known, thanks to Halley\u2019s pioneering work, is the Churyumov-Gerasimenko discovered in 1969, which has an orbital period of 6.5 years. This comet made news in past days because it will be the subject of a scientific study of a The Rosetta probe was launched ten years ago and after a long journey in which it took four laps to the Sun, it was found last August 6th with the comet Churyumov-Gerasimenko at a point about 400 million kilometers from Earth, halfway between the orbits of Mars and Jupiter. At this moment, the comet and the probe travel together \u2013 albeit separated by a hundred kilometers \u2013 approaching the Sun at a speed of 55,000 kilometers per hour. The photographs of the comet that the probe has sent to Earth show that it has a very irregular and rough shape, formed by two well-different parts joined by a \u201cneck\u201d that give it the appearance of a duck. According to the ESA website, Rosetta will enter the next six weeks in orbit around the comet and accompany it over a year as it approaches the Sun. During the journey, Rosetta will study the process by which the comet becomes brighter and acquires the characteristic \u201ctail\u201d of comets, to the extent that it is heated by the Sun. In November Rosetta will send the Philae probe of 100 kilograms of weight, which will lie on the surface of the comet and be fixed by anchors. Philae\u2019s mission is to study the composition and internal structure of the comet. It has been 250 years since the comets were demystified by Edmund Halley and devoid of their magical and threatening aura. The most significant thing for the development of science, however, was that Halley was able to predict the occurrence of a natural phenomenon using the gravitational theory that Isaac Newton had developed a short time earlier, and with this he gave a demonstration of the impressive prediction capabilities of the scientific method. With certainty the Rosetta probe will provide us with detailed information about the nature of the comets. He will also witness how the sun \u201cen\u201d a comet and convert it, of a cold mass without a great appeal, in one. And all this will be possible thanks to a technology \u2013 aerospace, electronics, computing, telecommunications, etc. \u2013 based on scientific knowledge accumulated from the time Isaac Newton came to a brilliant conclusion: that the physical laws that determine the movements of celestial bodies \u2013 including comets \u2013 are the same as those that govern objects on Earth. Thus, it turns out that comets helped \u2013 through Newton and Halley\u2019s work \u2013 to develop a way of seeing the world in which magic has no place, so that we will now use it to try to find out its secrets.",
    "https://upload.wikimedia.org/wikipedia/commons/5/5b/Grib_skov.jpg": "Nocturnal photographs of the Earth taken from space \u2013 easily reachable on the Internet \u2013 show clear signs of our presence on the planet. Depending on the time of exposure, these photographs show luminous spots that correspond to the great cores of the Earth\u2019s population. Large spots of light are seen on the east coast of the United States, as well as on the coast of California, in Western Europe and Japan, among many other urban areas. In our country, Mexico City, and even San Luis Potos\u00ed, are clearly visible from space. While there are sparsely populated regions of the Earth that appear with very few lights or completely in the darkness, the night photographs of our planet tell us to what extent we have spread over its surface. In number of inhabitants we have grown to some 7,000 million, at the same time as we have dispersed globally. Our expansion has been so great that the Earth has been small in many ways and all this has led to global change. The Earth\u2019s atmosphere, for example, has been unable to dispose of all the greenhouse gases we generate, resulting in global climate change that has resulted in many ways. In the same way, the Earth is rapidly losing its forested surface, either because of logging by the timber industry, or because of the clearing of forests for agricultural and livestock activities. According to an article published last November in the magazine \u201cScience\u201d, in the first 13 years of the 21st century our planet lost 2.3 million square kilometres of forests \u2013 an area that is greater than the surface of our country \u2013 and in contrast only 0.8 million square kilometres of new forested areas were created. Last week\u2019s issue of the magazine \u201cScience\u201d includes a special section that deals with another ecological problem of global magnitude: the rapid decline in the population of wild animals that is experiencing our planet. This decline has been called \u201cdefaunation\u201d by Rodolfo Dirzo of Stanford University, California, USA, who considers it analogous to the process of global deforestation but not so visible \u2013 albeit with equally profound consequences for ecological balance. Science\u201d is headed precisely by Dirzo \u2013 who was born in Mexico and received his bachelor\u2019s degree education in our country \u2013 and leads researchers from the United States, Mexico, Brazil and England as co-authors. This article, which reviews the knowledge that scientists have on the subject, is entitled \u201cDefaunation in the Anthropocene\u201d, thus emphasizing that we are responsible for the process of defaunation. According to Dirzo and collaborators, \u201cIn the last 500 years humans have triggered a wave of extinction, threat and decline in local populations that can be comparable, both in speed and magnitude, with the five previous massive extinctions in the history of the Earth.\u201d In this regard, the reference article cites some figures. It mentions, for example, that since 1500, 322 species of terrestrial vertebrates have been extinct, and that of the 6 to 9 million animal species that are estimated to exist on Earth, annually are lost between 11,000 and 58,000. Also, from the point of view of the number of individuals, in the last four decades the average population, This includes animals such as nematodes, beetles and bats, whose decline in population is considerably less evident than that of large mammals, and which, however, could have a greater ecological impact.On the human scale, the Earth is indeed enormous \u2013 its diameter is almost ten million times our average height \u2013 and we would not think that with our actions we could bring it out of balance. And yet, the accelerated population growth of the world and its equally accelerated industrial and economic development have achieved what seemed difficult. Thus, two hundred years of greenhouse gas emissions since the beginning of the industrial revolution have triggered a process of climate change which is not clear as far as it will lead us. A process of massive deforestation has also been generated that does not contribute to the reduction of the concentration of such gases in the atmosphere. According to environmental experts, the world is in a course of defaunation that, equally, affects the global ecological balance. Given these and other calamities, it seems that the planet on which we lived was too small.",
    "https://upload.wikimedia.org/wikipedia/commons/c/c4/Please_Please_Me.JPG": "If you lived your adolescence in the sixties you may immediately recognize some of the songs that made the Beatles famous. Among these we have \u201cWant to Know a Secret\u201d, \u201cThe Night of a Difficult Day\u201d, \u201cHelp!\u201d and \u201cYesterday\u201d, to mention only some of the most well-known. The sound invented by the Beatles is certainly very characteristic and easily recognizable, especially that of their early era. We know that the Beatles changed their music markedly during their short career of less than a decade. That the musical change experienced by the Beatles throughout their existence was truly radical we can easily see by comparing songs from their first album \u201cPlease Me\u201d, with some from the \u201cpsychedelic\u201d period of the second half of the sixties \u2013 \u201cMagical Mystery Tour\u201d, for example. And yet, while the musical distance reached by the Beatles between the first and last album is considerable, between two successive albums this distance is relatively small and difficult to appreciate for the common mortals. musical expert or a Beatles fan, we would have trouble deciding from just listening to them which of the two songs \u201cWant to Know a Secret\u201d or \u201cThe Night of a Difficult Day\u201d appeared first. Researching a little we find that the first song is part of the first album by the Beatles \u201cPlease, Please Me\u201d released in March 1963, while the second is included in the album of the same name released 16 months later, in July 1964. In this context, it is interesting the article published in the August issue of the magazine \u201cPattern Recognition Letters\u201d reporting a computer analysis of the music of various rock groups, including the Beatles, Queen, ABBA and U2. The authors of that article are Joe George and Lior Shamir of \u201cLawrence Technological University\u201d in Southfield, Michigan, in the United States. George and Shamir\u2019s goal was the development of a computer program that would allow analysis without human supervision of the similarities between albums produced by a popular music group. For this purpose, they decomposed The sound of the musical pieces studied in their different frequencies \u2013 from the most serious to the most acute \u2013 and produced \u201cmaps\u201d of two dimensions on the computer screen, which showed how each of these frequencies changed as the song was played. Thus, the researchers had a \u201cimage\u201d of the musical piece under study and the musical analysis of it became an exercise of analysis of images carried out by the computer. In the case of the music of the Beatles, George and Shamir analyzed the 13 albums published by the group, from \u201cPlease Me\u201d to \u201cLet It Be\u201d, released the latter in May 1970. Based on the characteristics studied, the computer was able to correctly determine to which album a certain piece belongs in 30% of the cases. This is relevant, because if the computer had chosen an album entirely at random, it would have been successful only in 7.7% of the cases \u2013 since there were 13 options to choose.The computer was also able to order correctly chronologically, except in one case, the 13 albums. \u201cPlease Me\u201d preceded \u201cBeatles for Sale\u201d, published in December 1964, and that \u201cHelp!\u201d, released eight months later, was subsequent to both. Likewise, it correctly grouped the \u201cPsycodelic\u201d albums towards the end, followed by \u201cLet It Be\u201d and \u201cAbbey Road\u201d, in that order. This last is incorrect since the Beatles\u2019 last album was not \u201cAbbey Road\u201d but \u201cLet It Be\u201d. In this regard, Geroge and Shamir note that, despite its release date, some songs from \u201cLet It Be\u201d were recorded prior to the publication of \u201cAbbey Road\u201d. The analysis also produced a phylogenetic tree \u2013 similar to those describing the evolution of living beings\u2013 that shows the evolution of Beatles\u2019 music and indicates the musical distance between two successive albums. In this regard, the computer program finds that there was a great leap between the albums \u201cBeatles for Sale\u201d and \u201c Help!\u201d, whose publication was spaced for eight months. The Beatles are a particular case of marked musical evolution in a short period of time and it is not necessary to be a musical expert to appreciate the great distance between their music from the early times and that of the final years. It is, however, surprising that an autonomous computer program is able to distinguish albums that were produced, in some cases, with only months of difference. And, of course, it is doubly surprising that a musical group may be able to evolve in such a radical way and in such a short time. On the other hand, it is a pity that the same haste that the Beatles took to evolve musically have had it when they decided to end their life as a group, which spread for barely a decade.",
    "https://upload.wikimedia.org/wikipedia/commons/e/e7/Steaua_vs._CFR_Cluj_in_2010.jpg": "The world cup of football finished a week ago \u2013 which was more busy than usual \u2013 had an average of 2.67 goals scored per game, a figure that is significantly higher than that of South Africa 2010, when they scored an average of 2.27 goals in each match. To find a similar percentage, we have to go back 16 years to France 1998. If we consider only the matches of the eighth stage from the end onwards, however, the average of goals falls drastically to only 2.19 goals per match, which is less than the overall average of South Africa 2010. Even more, if we eliminate the 8 goals of the game between Germany and Brazil, whose result was clearly anomalous, the latter average falls to 1.8. As a result of this drought of goals, 12 of the 16 games after the group phase, including the final match, were resolved by a difference of a single goal or well by penalty scores. In this phase, without counting the games in which Brazil failed in a surprising way, the teams were generally very balanced and in good measure cancelled each other. At the next round chance played an important role then, and this is also true for the final match that either of the two contenders could win. Closed matches took place even between teams that nominally have disparate football levels, and here stands out what Costa Rica did, which showed that the football gaps between countries are closing. Thus, it turns out that many times the team that wins a football match is not necessarily the one that has the best players, but the one that runs with the best luck.Is football unfair with the contenders? A blog published last week by John Tierney in the science section of the New York Times newspaper analyzes this issue. Certainly football is unfair, but not necessarily more than other sports, in particular, those that are practiced in the United States. The reason is that in that country there are mechanisms to give a greater balance in the quality of the teams that compete in a particular league, so that the parties tend to be balanced and closed. This gives chance an important role in the definition of the winner. In the case of football at world level, although quality gaps are certainly closed in a given league. football between countries, these continue to exist, as shown by the fact that the four semifinalists of this championship have been countries that traditionally play leading roles in this type of competition. As a result, chance has a relatively minor role in football \u2013 though not null \u2013 in defining a game \u2013 it would not be the case, of course, if the two teams that are faced are balanced in quality, as happened in last Sunday\u2019s Argentina-Germany final match. A balanced football match in which the two contenders cancel can be tedious. At the same time, since the spectacular matches with many goals are only given for the exception, you might think that football is not a mass show. Far from this, football has a great appeal among the population of many countries \u2013 including ours, as we know well \u2013 and we could ask ourselves what this appeal lies in. Certainly not, at least not in a preponderant way, in the virtues of football as a show. On the contrary, we may find football attractive to a large extent by the prospect of seeing our team win, either In this way, despite the soporific match of semifinals between Argentina and Holland, the Argentines came en masse to Rio de Janeiro to witness the possible coronation of Argentina as a world champion, paying in some cases, according to the media, air fares at three times its normal price. In order for a football match to be more attractive to us, then there must be a reasonable probability that our team will succeed. In the worst case, if the encounter were between a David and a Goliath, David's followers must have a hope \u2013 so be it mild \u2013 that when it will make life harder for the giant at least. We have a paradoxical situation. According to Stefan Szymanski of the University of Michigan, quoted by Tierney in the article referred to, if the goal stands were to become larger in order for there to be a greater number of goals, the differences in football quality between countries would become more pronounced and, consequently, the role of chance would be diminished in the definition of a match. decrease of the role that chance plays in the definition of a game would negatively impact the football business. In particular, in Mexico it would become more difficult for every four years to sell us the mirage that we can play a leading role in the world cup, and even win the cup. Thus, we will have to resign ourselves to the spectacular football games and with many goals only give by exception.",
    "https://upload.wikimedia.org/wikipedia/commons/9/97/Primates_-_some_families.jpg": "In ancient times, in Europe it was believed that in remote lands there were humanoid monsters with fantastic physical characteristics. An example of this is given by the Roman writer Pliny the Elder, who in the first century of our era in his Natural History writes that, according to Greek historian Ctesias, in India \u201cthere exists a race of human beings, who are known as Monocoli, who have only one leg but are able to jump with amazing agility. These same people are also called sciapods, because they have the habit of lying back during the hours of extreme heat, and protecting themselves from the sun with the shadow of the foot.\u201d Sciapods are not the only monsters of India described by Pliny the Elder. These are joined by humans with dog heads, or either with feet turned back and eight fingers on each foot. It also includes humans with a hole by nose and flexible feet like a snake. Likewise, at the end of India locates a race of men who do not have mouths and who survive only of smells that inhale. Pliny the Old Man was able to write about. Of these fantastic creatures with a certain credibility for the remoteness of Rome from the lands in which they supposedly lived. In the present times, in which it is possible to travel anywhere in the world in less than 24 hours, it is more difficult to believe that such spawns could exist somewhere on the planet. Or almost nowhere, if we are to attend to legends such as that of the snow man or yeti who would dwell in the Himalayan mountains. As we know, the snow man would be a bipedal creature that walks slightly down, with a height greater than the typical human and with the body covered with hair. Those who defend his existence, however, typically show only indirect evidence, such as footprints in the snow that apparently cannot be associated with any known animal. Other times they show footage where the man of the snow is seen far away and fleetingly, and not solid evidence such as the presentation of a snowman specimen, alive or dead. The evidence that supports the existence of the man of the yetet are then fundamentally anec In order to remedy the latter, a group of researchers from universities and research centres in Europe and the United States, led by Bryan Sykes of Oxford University in the United Kingdom, carried out a genetic study with a series of hair fragments attributed to the Yeti and other abnormal primates, including the so-called large foot that has been spotted in the United States and the soulty of Central Asia. The study was published this month in the magazine \u201cProceedings of the Royal Society B\u201d. In order to carry out the study, the researchers requested hair samples from museums and private collections in different parts of the world. They received a total of 57 samples, one of which proved to be a vegetable fibre and another a glass fibre. After a first review they selected 37 samples, which were subjected to a genetic analysis to determine their origin. Only in 30 of the cases studied could this origin be determined, which in no case corresponded to an unknown species. The hair fragments corresponded to a known animal species, including black bears, brown bears, horses, cows, raccoons, and even a porcupine, among other animals.The animal to which each fragment corresponds, moreover, inhabits the place where the fragment was found.This is true in all cases except for two samples found in the Himalayas where genetic information coincides with that of a polar bear fossil that lived 40,000 years ago \u2013 more than that of a current polar bear. To explain this finding, Sykes and collaborators suggest that the animals to which the fragments belong are a variant of the polar bear that had not been discovered until now, or a polar bear hybrid with brown bear. This could help explain, according to researchers, the origin of the legend of the yeti, which would not correspond in this way to an unknown primate, but a variant of polar bear not recognized until now. Sykes and collaborators' study proves that none of the cases studied corresponded to those of an unknown primate and gives an indication of the fragility of the evidence offered in It does not prove, however, that the yeti or the big foot do not exist.They may exist, but until now there is no solid evidence to support this possibility.As there is no evidence that the sciapods exist or have existed in the time of Pliny the Old, although we cannot categorically deny it.And yet, it must be recognized that, given the case, we would surely be double against simple that no one, so looking for sea, sky and earth, could ever discover a sciapod lying under the rays of the sun making shade with his foot.",
    "https://upload.wikimedia.org/wikipedia/commons/6/60/Catedral_de_Barcelona_-_50270508626.jpg": "Having witnessed the accelerated manner in which the number of motor vehicles in the city of San Luis Potos\u00ed has increased in recent decades, which makes the circulation more and more difficult, we must ask ourselves what awaits us in the times ahead. On the one hand, the automobile industry in Mexico is growing, currently producing about 3 million vehicles per year, and while 87% of this production is exported, in 2013 around half a million motor vehicles were left in Mexico that joined those in circulation. A second factor that has contributed to the increase in the fleet of vehicles in Mexico is the importation of new cars. Adding locally manufactured vehicles and imported vehicles, in 2013 more than one million new units were sold in Mexico. To the latter, we must add the used cars imported legally or illegally, which in 2013 were about 650,000, according to the automotive industry of our country. As a result, the fleet of motor vehicles in Mexico grew by more than one million seven hundred thousand units in 2012. All the above has been combined to produce the dizzy increase of cars that we are witnessing. Between 1980 and 2012 the number of motor vehicles in Mexico grew by a factor of six, to reach a figure of about 35 million. In the state of San Luis Potos\u00ed this increase has been even faster. In fact, according to the INEGI, here the number of motor vehicles has increased from approximately 80,000 in 1980 to almost 900,000 in 2012, that is to say, it has grown by a factor close to 11, almost twice the national average. As regards the conurbation San Luis Potos\u00ed-Soledad de Graciano S\u00e1nchez, the number of cars has increased by a factor close to ten between the years 1980 and 2012, according to the same data of the INEGI. The numbers of the INEGI show that in the city of San Luis Potos\u00ed in the last three decades the vehicle park has doubled approximately every 9 years. To follow this trend, in the course of a decade will increase substantially the number of cars in our city, with the foreseeable increase of problems of urban traffic. The prediction of the future volumes of motor vehicles in San Luis Potos\u00ed is, of course, subject matter of specialists. It should be noted, however, that in Mexico there are approximately 300 motor vehicles per thousand inhabitants and that this number is small compared to those observed in other countries.In the United States, Spain and Bulgaria, for example, there are about 800, 600 and 400 cars per thousand inhabitants, respectively.In these circumstances, we may not be able to rule out a substantial increase in the number of motor vehicles in Mexico, and in particular in San Luis Potosi, in the coming years.The accelerated growth observed in the number of cars, however, must be self-limited at some point and tend to a saturation.This is seen in developed countries where this number increases at relatively small speeds.In the Federal District, likewise, the number of motor vehicles grew only by a factor of 2.5 in the 1980-2012 period, a figure significantly lower than the national average.This even with the activation of the Hoy no circuaci\u00f3n program, which encouraged the acquisition of more cars by the inhabitants of the capital.It is left to specialists to determine whether this low rate of growth is due to the increasing difficulties of circulation in Mexico City, which would not be surprising. At the same time, the growing number of cars in our cities makes urban traffic increasingly difficult, to the extent that some of us sometimes come to see the car at the same time as an advantage and as a plague.It is an advantage given the poor urban transport systems in our cities.At the same time, however, the accelerated growth of the number of cars requires a concomitant growth of urban road infrastructure, which is never enough to balance the growth of circulating vehicles.Cars undoubtedly occupy a place in the space and experience in Mexico is that when their number increases without measure there is a point where all the available space is saturated.At this point, to introduce more cars it is necessary to create additional spaces.In Mexico City, for example, when the Today program was not insufficient, second floors were built to alleviate the congestion of the first ones.All this, of course, is absurd and highlights the inconvenience of an urban transport model based partially on the the private car, in contrast to a model that relies on efficient public transport.It has to be taken into account that, despite the popular saying, at a certain point not everything fits into a jar, no matter how much effort we make to accommodate it.",
    "https://upload.wikimedia.org/wikipedia/commons/c/c2/Portrait_of_a_Man%2C_Said_to_be_Christopher_Columbus.jpg": "Who was the discoverer of America? According to the most widespread version, it was Christopher Columbus, who, as we know, after a transatlantic journey of several weeks from the Canary Islands arrived on October 12, 1492 to the island of San Salvador in the Bahamas. Some say, however, that the discoverer of America is the Viking Leif Eriksson, who, in the 1,000th year of our era, sailing through the North Atlantic reached the island of Newfoundland establishing a colony there, although it was not permanent. Others claim that the true discoverers of America were their first inhabitants, Siberians who crossed from Asia to the contain American through Beringia more than ten thousand years ago. According to the color of the crystal with which they look, any of the previous views could be correct. If, for example, we demand that the discoverer of the American continent be a concrete person, then the anonymous Siberians are discarded. If, moreover, we take the chronological aspect, we will have to bow to Leif Eriksson. The new candidate is Abu Rayhan al Biruni, who was a Persian intellectual who lived in the 10th century in Central Asia, south of Mar de Aral in what is now in Uzbekistan. Al Biruni was a universal genius who specialized in mathematics, physics, astronomy, philosophy and history. , and is considered one of the greatest intellectuals of the Islamic golden age. One of the contributions of the Biruni was the measurement of the circumference of the Earth. For this, from the height of a mountain of known height \u2013 measured by him earlier using methods of trigonometry \u2013 measured the angle at which the horizon was located and from there he could deduce the curvature of the Earth and consequently its circumference.The value he obtained is amazingly close to the value accepted at present.To Biruni knew of the existence of three continents, Asia, Europe and Africa, but he had no news, of course, of the American continent.However, since he knew what the circumference of the Earth and the extent of the known lands were, he could estimate that they occupied only two fifths of the total land surface. From here, he deduced that there was no reason for the three unexplored parts of the Earth's surface to be different from the two fifth known parts, since both were molded by the same forces. Frederick Starr of Johns Hopkins University in Washington, D.C., to consider the Biruni as the discoverer of America. A very peculiar discoverer and discovery, but which preceded Christopher Columbus for five centuries. The discovery of the Biruni is certainly of a very different nature than Columbus and this has led some to criticize Starr\u2019s conclusions. The \u201cScience\u201d article referred to above, for example, quotes Nathan Sidoli from Waseda University, Tokyo, Japan, who states, \u201cWe do not say Copernicus discovered that the Earth is moving around the Sun simply because he assumed it hypothetically, so I don\u2019t see why we should say that the Biruni discovered the American continent.\u201d Apart from the controversy, it is surprising the intellectual sophistication that took place in Central Asia a millennium ago and in this regard Starr notes that at that time, \u201cThe Chinese were surprised that eight-year-old children were learning mathematics in Samarkanda.\u201d This contrasts with the intellectual obscurantism of the Europe of the time, which was not overcome until centuries later. It should be admitted, however, that among ordinary people possibly few would consider it natural to switch to Christopher Colon by Abu Rayhan to Biruni as discoverer of America, as well as to October 12 by another date. Date that, on the other hand, would be difficult to determine.",
    "https://upload.wikimedia.org/wikipedia/commons/a/a6/Cellarius_Harmonia_Macrocosmica_-_Hypothesis_Ptolemaica.jpg": "Just as not all that shines is gold, not all that is written is true, and this is especially true when it comes to scientific articles. In fact, we will never be able to have the absolute assurance that a certain scientific theory or hypothesis constitutes an absolute truth \u2013 no matter how much evidence exists in its favor \u2013 and it will always be subject to its being refuted by new discoveries. Thus, when it becomes public, the result of certain scientific research is exposed to scrutiny by other specialists, who will be able to refute it or confirm it according to their own research. Only after an alleged discovery has gone through this acid test is it accepted by the scientific community \u2013 albeit very commonly not unanimously. Although scientific debate is usually given in the journals or scientific congresses, in some cases, by its impact transcends the mass media. This is the case of an article published last week in the journal of the \u201cProceedings of the National Academy of Sciences\u201d by a group of researchers from American universities headed by Kinju Jung of the Department of Business Administration of the University of Illinois. , Jung and collaborators find that, surprisingly, hurricanes with female names result on average more deadly than those with male names. As we know, throughout history hurricanes in the North Atlantic have produced great devastations and mortitudes, both in the Antilles and in Central America, Mexico and the United States. Beginning in 1954, and in order to avoid confusion and facilitate preventive measures to mitigate their effects, hurricanes were identified with their own names. Initially, female names were exclusively chosen. This, according to some, as a reference to the fact that hurricanes are unpredictable natural phenomena. In these circumstances and as it was natural, over time it was considered that giving hurricanes exclusively female names had a sexist character and, from 1979 onwards, they were baptized alternately with male and female names. For example, the first four hurricanes of the 2014 North Atlantic season that has just officially begun on June 1st are: Arthur, Bertha, Cristobal and Dolly. If we are to attend to the results of the work of Jung and collaborators, however, even with In fact, according to the reference article, the degree of femininity of the name of a hurricane, as it is perceived subjectively, determines the degree of danger with which this hurricane is judged. Thus, a hurricane with the name of Victoria would be perceived as less dangerous than another baptized like Victor, even if both were of the same magnitude and dangerousness.This would be due to our cultural prejudices according to which masculinity is associated with force and aggressiveness, in contrast to the passive behavior that we attribute to femininity. Thus, there would be a tendency to relax our state of alert to a hurricane with a female name, which we tend to perceive with a lesser degree of danger than the real one. This would explain the greater number of fatalities associated with female hurricanes compared to male ones. These conclusions, however, are not shared by other researchers and a public debate has taken place in this regard in the internet space. For example, Jeff Lazo of the National Center for At Att the United States' mosphere Research considers that there is no sufficiently strong statistical evidence that female hurricanes are actually more deadly than male hurricanes. It also notes that Jung's study and collaborators were carried out with hurricanes in the 1950-2012 period, which includes the period when hurricanes had exclusively female names.This would be important because at that time hurricanes produced on average more victims.Lazo also argues that Jung and collaborators include in their count of fatal victims those who died after the meteor \u2013 due to the fall of a light post, for example \u2013 deaths in which obviously had nothing to do with the hurricane genus.Are hurricanes of the female gender more deadly? The name that came into luck to a given hurricane has, of course, nothing to do with its degree of danger.According to Jung and collaborators, however, female hurricanes are more deadly than male hurricanes due to our prejudices about the respective attributes of both genders. If this is true, we could perhaps give a prior idea about the intensity and dangerousness of the first four hurricanes of the hurricanes of the United States. Atlantic of this season: Arthur, Bertha, Cristobal and Dolly what do you think will be the most dangerous?",
    "https://upload.wikimedia.org/wikipedia/commons/3/31/World_GDP_Capita_1-2003_A.D.png": "Today it is widely accepted that science and technology \u2013 which is derived from it \u2013 play a fundamental role in the economic development of a country. An obvious difference between industrialized and developing countries is certainly that of their respective scientific developments. As part of their policy of economic growth, developing countries are then obliged to promote the creation of their own scientific infrastructure and to seek to have it impact on economic activity. To Mexico, science and technology arrived with considerable delay. Indeed, it was only until 1971, with the creation of CONACyT, when the country put science and technology in the forefront \u2013 second, on occasions \u2013 as a factor for the economic development of the country. From that year, CONACyT established a wide-ranging scholarship programme for postgraduate studies in Mexico and abroad \u2013 with few parallels in the world \u2013 that has led to the training of numerous researchers, many of whom have joined research centres and universities in Mexico. CONACyT has also established programmes to support research projects carried out in Mexico. In the present administration, CONACyT, headed by Dr. Enrique Cabrero Mendoza, who visited the UASLP this week, has made public the purpose of raising national spending on science and technology to 1% of the country\u2019s gross domestic product \u2013 from the current figure of less than 0.5%. Accordingly, CONACyT has issued new calls of all kinds addressed to research institutions in Mexico, as well as to the private sector. Since there will never be enough resources to support all scientific fields equally, the question arises as to how to prioritize support for science in a country with limited resources in order to optimize its impact. In the first instance, one might think that the correct strategy is to support those scientific fields that are closest to industrial applications, without neglecting those aimed at solving social problems. This would not be the case, however, if we are to attend to an article published in the online magazine \u201c Plos One\u201d last year by a group of researchers from the Sim\u00f3n Bol\u00edvar University in Caracas, Venezuela, headed by Kalus Jaffe. In this article, a research carried out with the purpose of determining which scientific fields have the greatest impact on the economic development of a country is described. For this purpose, Venezuelan researchers compared data from the World Bank regarding the growth of per capita gross domestic product in about 100 countries, with its scientific productivity in several basic and applied fields. This productivity was determined on the basis of the number of scientific articles published in a specific field. It should be clarified, however, that this number varies greatly between developed and undeveloped countries, so that instead of considering absolute numbers the researchers took numbers relative to each of the countries studied. From the study there is a surprising result: the scientific productivity of a country in areas of physics and chemistry at a certain time is correlated with the economic growth of the country in the next five years. Scientific productivity in physics and chemistry is then a reliable indicator of economic growth that a country will experience in the near future. In contrast, scientific productivity in other fields of applied science, such as The fact that there is a correlation between two parameters, in this case scientific productivity and economic growth, does not mean that one is the cause of the other. In fact, Jaffe and collaborators do not find any causal relationship between productivity in physics and economic growth. Instead, they suggest that the decision to support basic science \u201cis a reliable indicator of the existence of an atmosphere that favors rational decision-making that, given the right circumstances, promotes economic growth.\u201d Jaffe concludes and collaborators that \u201cNo country with a preferential investment in technology, without a concurrent investment in basic science, has achieved a relative high economic growth. Thus, technology without science is unlikely to be sustainable.\u201d Modern technology is the daughter of science and has been able to develop properly only in countries where the latter has a naturalization charter. It is not possible, then, to skip stages, and if Mexico is to develop technologically it will have to create a robust scientific base. At least according to the findings of Jaffe and collaborators.",
    "https://upload.wikimedia.org/wikipedia/commons/8/87/IAEA_02790015_%285613115146%29.jpg": "As we know, Christopher Columbus\u2019s first trip to our continent lasted a little more than two months. Today a similar journey on a commercial jet plane can be carried out in a time that is measured in hours. This contrast of times can be seen from different points of view.One of these is that of the amount of energy per passenger required for each means of transport, which is substantially larger for a jet plane than for a sailing boat. Thus, using modern means of transport we can move faster than five centuries ago, but at a considerably higher energy cost.Since the time we were hunters gatherers about ten thousand years ago the average per capita energy consumption has increased almost one hundred times. The increase has been gradual but has accelerated in the last 200 years since the Industrial Revolution. And this has been through the exploitation of fossil fuels, coal, oil and natural gas. On the other hand, in the first half of the 20th century fundamental discoveries were made about the nature of the structure of the atom, which revealed the enormous amount of energy stored inside it. Scientists and engineers devised ways of releasing this energy, whether in an uncontrolled way \u2013 as in an atomic bomb \u2013 or in a manner controlled by nuclear reactors. Given the enormous magnitude of the energy stored inside atoms, it was natural to think that nuclear energy was the future energy of the world. As the years went by, however, this energy did not have the development that could have been thought of. Thus, while there are countries that obtain their electricity mostly from nuclear energy \u2013 notably France, with 75% of its total consumption \u2013 nuclear energy plays a relatively minor role compared to fossil fuels and globally only 13% of the electricity consumed by the world is of nuclear origin. One problem with the energy of the atom is that its exploitation generates highly toxic radioactive products. Three nuclear accidents of great magnitude remind us of the dangers of nuclear energy: the accidents of \u201cThree Mile Island\u201d, which occurred in Pennsylvania, United States, in 1979, of Chernobyl, Ukraine in 1986 and of Fukushima, Japan, in 2011. The study was carried out by a group of researchers from Europe, the United States and Japan, headed by Ismael Galv\u00e1n of the Higher Council for Scientific Research of Spain, which was published online last April in the journal \u201cFunctional Ecology\u201d. One of these studies was carried out with several species of birds, both inside and outside the exclusion zone, and dropped a sample of a number of species of birds, both inside and outside the exclusion zone, and resulted in the evacuation of more than 100,000 people from the area around the nuclear power plant. The Soviet government established an exclusion zone of 30 km radius around the reactor site, which is heavily contaminated and has been maintained to the present day. It is known that high-energy radiation caused by the disintegration of radioactive materials can cause cell damage that can lead to the development of cancers, to the alteration of genetic material, and even to the death of cells themselves. Astonishing result: he found that birds living in highly contaminated areas seem to have adapted to the effects of radiation. This, according to one of the authors of the study, is a kind of \u201cnatural selection\u201d. Researchers also found an inverse effect between genetic damage and the level of pollution, so that birds living in less polluted areas are less adapted than those living in areas with more pollution. Not all specialists, however, agree with Galv\u00e1n\u2019s conclusions and collaborators. In particular, one expert states that it is difficult to demonstrate that radiation in the exclusion zone may have had a appreciable effect on the birds studied. In any case, whether or not the conclusions of the article in question are correct, nuclear energy does not lose its high-risk character, incompatible with life, and is not a viable substitute for fossil fuels. Even if some organisms were able to adapt to levels of radioactivity beyond those of the natural world. By a selection process that is not of this world.",
    "https://upload.wikimedia.org/wikipedia/commons/7/7b/DR_Congo_pygmy_family.jpg": "A lot of noise has caused the incident that happened last weekend when an assistant to the Barcelona-Villareal party of the Spanish football league threw a banana at the Brazilian player Dani Alves. In an unprecedented action, the player lifted it from the ground and ate it from a bite, and then proceeded to throw a corner shot. The event was amplified surprisingly through the internet in favor of Alves, to the extent that the author of the racist insult has problems with the police. This type of events are not rare in European football stadiums. It must be recognized, however, that racist prejudices in Europe, at least in appearances, have diminished in recent decades. Especially if we remember that it has not yet been long since there were exhibitions of people from different races to the European ones \u2013 the so-called human zoos. The Paris World Exhibition of 1889, for example \u2013for which the Eiffel Tower was built \u2013 included among its exhibitions a \u201cBlack Village\u201d with 400 indigenous people. Ota Benga was exhibited in 1906 at the Bronx Zoo in New York, enclosed in a cage together with a perico and an orangutan. But it is not our purpose to dedicate this article to racial discrimination, so widespread in the world, but to deal with a subject that is somehow related to it. This topic refers to the article that appeared this week in the online magazine PLOS ONE in which it revalues the Neanderthal species, which is commonly described as inferior to our species. The article takes Paola Villa from the University of Colorado Museum, in the United States and Wil Roebroeks from Leiden University, Holland, as authors. Experts know that Neanderthals lived in Europe and in the Near East for 350,000 years, until about 40,000 years ago when they became extinct as a species. This extinction coincided with the arrival of Homo sapiens from Africa. According to an extended opinion, extinction was As a result of the superiority of our species over Neanderthal. According to specialists, Homo sapiens originated in Africa and from there emigrated some 50,000 years ago to Europe and to other parts of the world. During our stay in Africa we would have developed a series of cognitive, language, weapons manufacturing, hunting techniques, food diversity and social organization that Neanderthals did not possess and in these conditions of great disadvantage, the latter would not have resisted the clash with modern man surviving its extinction.After doing an investigation of existing archaeological evidence, however, Villa and Roebroeks disagreed with this point of view. They conclude that the skills commonly associated with modern man also possessed Neanderthals. Thus, they find evidence, for example, that Neanderthals hunted bison animals and caused them to fall into wells. Likewise, there is evidence that they had a varied diet. Pigments have also been found in Neanderthal sites that could have used to paint their bodies. This would indicate that Neanderthals practiced rituals and had the ability to think symbolically.According to Villa and Roebroeks, the supposed inferiority of Neanderthals with respect to our species originates in the practice of researchers to compare the abilities of Neanderthals who lived in the middle paleolithic, with the abilities of modern men in the upper paleolithic. In Villa\u2019s words \u201cit is like comparing a Ford model T with a modern Ferrari and concluding that Henry Ford had congnitive abilities inferior to those of Enzo Ferrari.\u201d Apart from the above, it is interesting to wonder how much our racial prejudices influenced to reach a conclusion (precipitated?) on the cognitive inferiority of Neanderthals. Certainly Neanderthals constitute a species different from ours. At the same time, however, they do not seem too far away and this can stimulate our racial prejudices. While Neanderthals exting them long ago and it is not easy to determine what their cognitive abilities were, future investigations will surely give us more data in this regard. interesting that we do know is that Neanderthals and modern humans crossed and from this point of view we can say that the first ones have not really died out.Or seeing it another way, that we are all a little bit Neanderthal.One last comment.If the one who threw a banana at the football game had known that his ancestors left Africa 50,000 years ago, he would have realized that if Dani Alves liked the fruit \u2013 and it seems to be the case \u2013 it is probably not because of his kinship with the monkeys. That in reality if he does, as we all do and in equal degree \u2013 including the barbaj\u00e1n \u2013 but quite far away.",
    "https://upload.wikimedia.org/wikipedia/commons/9/9f/Cam_degree_ceremony.jpg": "As we commented in this space a week ago, with the departure of Gustavo Del Castillo and Candelario P\u00e9rez de San Luis Potos\u00ed mediating the last century, a second and brilliant period of construction of scientific instruments was closed at the UASLP, which lasted from 1955 to 1966. Previously, during the last quarter of the nineteenth century, Francisco Javier Estrada, in his capacity as head of the Chair of the Scientific and Literary Institute \u2013an immediate predecessor of the UASLP \u2013 developed a remarkable career as a builder of the most diverse devices and devices and with this gave life to a first period of instrument construction at the University. Clearly, Gustavo Del Castillo and Candelario P\u00e9rez \u2013 not to say Francisco Javier Estrada \u2013 were ahead of their time and, like all the pioneers, did not have it easy to carry out the company that was proposed. In the middle of the twentieth century the country in general and the University in particular were not mature enough to accept an initiative with these characteristics \u2013 it is necessary to remember that the School of Physics of the UASLP was the third in Mexico, while the Institute of Physics of Physics in particular However, the pioneering work of Gustavo del Castillo and Candelario P\u00e9rez planted a seed in the UASLP that eventually produced and turned San Luis Potos\u00ed into one of the main centers of physics research in Mexico. Had there been better conditions for the Del Castillo and Candelario P\u00e9rez project, the UASLP would have been made of a pioneering research project in the country and the research in physics would certainly have taken on earlier roots in the UASLP. And with an additional bonus: the capacity to build scientific instruments, which is not something that can be cultivated in pot A scoundrel that faced Gustavo del Castillo and Candelario P\u00e9rez were the low salaries that the University could offer. In fact, it was only up to 1978 \u201312 years after Candelario P\u00e9rez\u2019s departure \u2013 that the UASLP awarded the first full-time professor-investigator appointments. In principle, these appointments made it possible for a professor to devote part of his time to the development of a research project. In practice, the salaries offered by the universities in the country\u2019s Mexico \u2013 with very few exceptions \u2013 were not competitive and this gave rise to a \u201cbrain drain\u201d, both external and internal \u2013 not to mention \u201cmultichambism.\u201d Two federal programs largely solved this situation: the National System of Researchers, created in 1984, and the program of stimuli to academic work. At the same time, CONACyT \u2013 founded in 1970\u2013 established a program of scholarships for postgraduate studies and programs of support to research projects. Thus, a few decades after the second incursion of physics in San Luis Potos\u00ed, the conditions were adequate for the advent of a third period of instrument construction in the UASLP, in force today, which we hope will be extended indefinitely. With the help of Dr. Jos\u00e9 Refugio Mart\u00ednez Mendoza and the Directorate of Image and Institutional Promotion of the UASLP, during the academic week of the UASLP Institute of Optic Communication Research carried out at the beginning of this month of April, an exhibition of instruments built in the UASLP was set up. To recreate the three well-defined epochs of the construction of scientific instruments in the UASLP that have been the subject of the last three articles, including the current one, published in this space: the last quarter of the 19th century, the years 1955-1966 and the present time. In reference to this last epoch, and as two examples of the many current instruments built in the UASLP, a microscope was exposed that employs a thin glass tip to obtain an image of the surface of a material \u2013 and even, in some cases, of details that they find below that surface\u2013, and an optical instrument for use in processes of synthesis of materials for electronics. Both instruments are currently in operation at the Institute of Optic Communication Research of the UASLP and in some way, if imperfect, reflect the degree of current development of the field of instrument construction at the University.And, above all, they do justice to the pioneers of this field at the UASLP, who worked in disadvantaged conditions in a national environment that did not promote the development of their own science and technology, in particular the development of instruments. of everything, half a century later, his legacy is now more than ever present at the UASLP.The reference exhibition will be re-assembled at the University Center of the Arts of the UASLP and will be seen soon.",
    "https://upload.wikimedia.org/wikipedia/commons/4/41/Primer_daguerrotipo_en_Espa%C3%B1a%2C_Casa_Xifr%C3%A9%2C_1848.jpg": "As we wrote a week ago in this same space, shortly after the death in 1905 of Francisco Javier Estrada \u2013 a pharmacist by profession but who developed in San Luis Potos\u00ed in the last quarter of the 19th century numerous devices and devices of the most diverse nature\u2013 the country entered a period of civil wars and military uprisings not conducive to the development of creative activities, and in particular for the construction of scientific instruments. In 1935, having reached a relative calm, President L\u00e1zaro C\u00e1rdenas created the National Council of Higher Education and Scientific Research (CONESIC). This meant the beginning of a change in the country \u2013 albeit too slow and slow \u2013 in terms of the governmental impulse to science, very discredited during the revolutionary conflict by that of the \u201cscientific\u201d Porfirists. Although CONESIC faced many political problems and had an ephemeral life, in 1942 it was created by President \u00c1vila Camacho the Impulsora Commission and Coordinator of Scientific Research. This, in turn, was replaced in 1950 by the National Institute. This rebirth was due to the efforts of both Gustavo Del Castillo and Gama and Candelario P\u00e9rez Rosales. Gustavo Del Castillo, Potosino and chemical of formation, became interested in physics and decided in 1951 to travel to the United States in search of a doctorate in this specialty. For this purpose he entered Purdue University in the state of Indiana. There he met Candelario P\u00e9rez Rosales, also Potosino, who was also a student of physics but at the level of bachelor. As Candelario P\u00e9rez relates in his book Physical at Dawn, it was in the summer of 1954, when Del Castillo was preparing his return to Mexico, who made plans for the creation of a physics school at UASLP. This materialized in late 1955 when the University Board approved the creation of the School of Physics, which began operations on March 5, 1956, with Gustavo Del Castillo and Can. In parallel to the creation of the School of Physics, Gustavo Del Castillo, who was a formidable instrument builder, began the construction of a \u201cmist chamber\u201d for the detection of the resulting particles by interacting the cosmic rays from outer space with a lead plate. The construction of this camera in a record time of one year and four months is one of the most notable examples of instrument construction in the country. In his book \u201cPhysics at Dawn\u201d, Candelario P\u00e9rez describes the operation of the camera: \u201cIt was impressive to behold in action that tireless automaton that photographed, day and night, trajectories of particles that were the product of cosmic radiation. In the middle of a dense and suffocating darkness, dotted by the blinking of the focus points of automatic control, the thunderous explosion that produced the air suddenly leaving the chamber of expansion was heard; then, a blinding flash illuminated the inside of the fog chamber, while the camera recorded the nuclear events; Candelario P\u00e9rez Rosales followed the tradition and began the construction of a scintillating spectrometer, which was in operation in 1960. For this development, the Government of the State of San Luis Potos\u00ed awarded him the \u201cFrancisco Javier Estrada\u201d Prize in Sciences. Today, 60 years after Gustavo Del Castillo built his fog chamber, one cannot but be surprised by the unusualness of his achievement. Not only because of the unusual technical skill he displayed, but also because he had to look for support, both to acquire the necessary materials to build the camera, and to supplement his salary as a professor at the University \u2013 it must be remembered that UASLP established the position of professor-investigator only until 1978\u2013. In his company, Del Castillo was supported both by the INIC and by PEMEX. The remains of the fog chamber could be admired the first days of this month of April at the exhibition of instruments organized as part of the academic week of the Institute. The conditions that both Gustavo Del Castillo and Candelario P\u00e9rez found in San Luis Potos\u00ed for the development of their projects, however, were not the right ones and over time they were forced to emigrate. First, Del Castillo did so in 1959 and 7 years later Candelario P\u00e9rez. With the departure of both, a second and brilliant period of instrument construction in the UASLP was ended. It had to take several decades for the conditions of the country to allow a third epoch, in force today, which we hope will last indefinitely. At this last time we will take up next Sunday.",
    "https://upload.wikimedia.org/wikipedia/commons/5/5a/Jupiter_by_Cassini-Huygens.jpg": "While it is true that the sense of sight gives us an amazing amount of information about the world around us, it is also true that it has its limitations. We can, for example, perceive light in a range of colors that extends from red to violet, through orange, yellow, green and blue. We cannot, however, see neither infrared nor ultraviolet, which are beyond the colors red and violet, respectively. Likewise, we are able to see at a glance an ant and even a flea, but definitely not to a microbe, not to mention molecules or atoms.What is valid for the view is also for the other senses: all have a great sensitivity which, however, is at the same time severely limited. In this sense, if we were to depend only on our senses the knowledge that we could reach from the physical and biological world would be only partial. Fortunately, we have developed instruments that have allowed us to observe the world beyond our limitations. Galileo Galilei, for example, using the telescope, could observe that around the Jupiter planet \u2013 that at a glance only one can perceives only partial. The Dutchman Antonie van Leeuwenhoek discovered, using microscopes from his manufacture, the existence of unicellular organisms invisible to the naked eye. By using scientific instruments we have discovered a huge amount of things about the physical and biological world, from the chemical composition of stars to the atomic structure of DNA, and the scientific knowledge achieved has derived modern technology, which has given us the same means to cure diseases that developed a vast global network of communications that has changed our way of life. We can perhaps say that a measure of the scientific and technological capacity of a country gives us its capacity to construct instruments. In Mexico, given the little importance that has historically been given to science, the development of scientific instruments has been equally limited. We have, however, some notable examples. In relation to this, and as part of the activities of the academic week of the Institute of Optic Communication Research of the UASLP, it was organized in the week that today ends an exhibition entitled \u201cThe scientific instrumentation in the history of the UASLP\u201d, which he sought To recreate three epochs of the development of instruments in the Potosine university: the last quarter of the 19th century, the period that spans from 1955 to 1966 and the present epoch. The first re-created period focuses on Francisco Javier Estrada, born in 1838, who although he did not have a formal education in physics or electrical engineering, did have a strong interest in these fields and he focused on the development of various instruments as head of the chair of Physics of the Scientific and Literary Institute of San Luis Potos\u00ed \u2013an immediate predecessor of the UASLP. The appointment as a professor was granted to Estrada shortly after the reopening of the Institute in 1867, once restored the Republic. In a country that had just overcome a foreign invasion and that carried more than half a century of political instability, Estrada must have had considerable difficulties to succeed in its efforts as a builder of apparatuses and instruments. And despite this, it had an unusual performance, developing various notable devices for its time. These include, to mention only a few, a telephone for long distances, a phonograph and a system for communication of instruments. In 1886, President Porfirio D\u00edaz granted Estrada an exclusive privilege for ten years. To put this achievement in context, it should be remembered that the first public transmission of wireless telegraphy was made by Guglielmo Marconi in London, England, until 27 July 1896. Estrada was stopped in his creative activity not only because of the general situation in the country but also because of health issues, and apparently also because of political problems within the Scientific and Literary Institute. Thus, in 1886, he lost his position as a professor of physics; the reason: his physical inability to attend teaching, leaving the students to go to the house of Estrada to receive instruction. The dismissal of the professor provoked the anger of the students, who protested vigorously in an open letter addressed to the then governor of the state Carlos Diez Guti\u00e9rrez. The letter was published in the newspaper \u201cEl Estandarte\u201d on 8 February 1886. Francisco Javier Estrada died in the City of Carlos Diez Gutierrez. Mexico in 1905, blind and without taking more advantage of its inventions. As we know, shortly after Estrada's death the country entered a period of wars and conflicts again, not conducive to the development of creative activities. Thus, the construction of instruments in the UASLP had to wait half a century to have a rebirth. This we will talk about next Sunday.",
    "https://upload.wikimedia.org/wikipedia/commons/e/e8/C%C3%A9dula_de_identificaci%C3%B3n_personal_o_%22carn%C3%A9_de_identidad%22_de_un_esclavo.jpg": "According to Wikipedia, the first photograph of a person was made by Louis Daguerre in 1838. This photograph, which required a time of exposure of about ten minutes, shows the \u201cBoulevard du Temple\u201d of Paris on a sunny day. On a close-up, in the lower right side of the image we can see a three-story building, behind which rises diagonally the boulevard bordered by buildings. The visual effect produced by the photograph is peculiar, because although it clearly shows the effect of the passage of the years \u2013 which gives it an aspect that we might even qualify as phantasmagoric\u2013, at the same time the images of the buildings and the trees along the avenue are clearly delineated. The exposure time that was used by Daguerre did not allow to register people in motion \u2013 if there had been any. On the lower left side, however, we can see the silhouette of a person polishing the shoes, which must have remained relatively immobile during the taking. Given the distance to which he was, however, outside of his silhouette the photograph does not shed any other information about him. As we know, Daguerre and the daguerreotypes were only the beginning of a revolution that in the course of half a century led to the development of cameras that could be handled by ordinary people, and not only by specialists. Revolution that has finally led us to the present era in which taking a photograph can be as simple as pressing a button \u2013virtual or real \u2013 of a device \u2013 a cell phone \u2013 that was ironically designed for another purpose. The appearance of photography allowed us for the first time to record images for posterity. Before photography, the image of a person could be preserved, for example, in a study painting. In that case, however, there is no assurance of the degree of fidelity of the painting with respect to the person represented. In contrast, if we discard those photographs manipulated on purpose, a photograph is an image of a real person, resulting from the light that reflects the person photographed, and in that sense ancient photographs are a window into the past. An example of this is given to us by the internet site called \u201cMirroror of Race\u201d in which the light that reflects the person photographed, and in that ancient photographs are a window into the past. photographs of the second half of the 19th century around the issue of racism and slavery in the United States were exhibited. This site was the subject of two articles published a few days ago by \u201cThe New York Times\u201d and the British newspaper \u201cThe Guardian\u201d. According to its creators, \u201cMirror of Race\u201d is a \u201cplace for reflection on the meaning of race in the United States, both in the past, as well as in the present and future.\u201d The site contains photographs of a period ranging from the 1840s to the end of the 19th century. It therefore includes images obtained before and after the abolition of slavery in the United States in 1865. Although some of the persons photographed are identified, most are anonymous or are identified only by their own name. Each photograph is initially presented with a concise information with the aim of having those who see it form their own opinion without external interference. The factual information that is available about photography is presented immediately and, finally, an expert interpretation is provided in the conceptual framework of the site. Some of the photographs of \u201cMirror of Race\u201d are representative. They include, for example, the photograph of a white person identified as \u201cAbraham, master of slaves\u201d, of sinister appearance \u2013 appropriated for a horror film of the 1930s\u2013, with a leather whip on his hands. This photograph, from the late 1850s, transports us \u2013 perhaps more than any other \u2013 to the slave violence world of the 19th century. The site also includes several photographs of freed slaves who were employed in a campaign to abolish slavery. Among the people photographed is Wilson Chinn, who shows the VMB letters on his forehead that were struck by his owner Volsey B. Marmillon. Likewise, the site includes photographs of children in appearance of a white race, children of slave parents and therefore slaves. It does not reach the space of this column to describe with words a sample of extremely interesting photographs that brings us closer to a somewhat forgotten but not so distant past; neither in time nor, unfortunately, in that it has overcome the prejudices of racism. \u201cMirror of Race\u201d is \u201cMirror of Race.\u201d It must be remembered that an image says more than a thousand words and that a photograph of the past tells us more than a thousand words of the past.",
    "https://upload.wikimedia.org/wikipedia/commons/a/a1/Debris-GEO1280.jpg": "Space debris in orbit around the Earth \u2013 the product of more than half a century of space activities \u2013 represents, in the opinion of experts, a growing danger for satellites and spacecraft. According to NASA, about 500,000 objects of all kinds circulate in orbit around the Earth \u2013 parts of rockets, screws, gloves, etc. \u2013 that travel at speeds that can reach 28,000 kilometers per hour. Although most of these objects are small in size \u2013 the order of a marble \u2013 about 20,000 are larger than a softball. It is not difficult to imagine the consequences that would have to hit one of these objects traveling at such speeds. It should be noted, however, that even small objects can be lethal to a satellite or spacecraft in case of a collision, given the enormous speed they carry in orbit. Space debris reached notoriety in recent months because it was the subject of the film \u201cGravity\u201d that received huge publicity. While some things seen in this film are unlikely and with little scientific sustenance, catastrophic shocks In February 2009, for example, an American commercial satellite collided with a Russian satellite already out of operation, resulting in more than 2,000 fragments that were added to space debris. Similarly, in 1996 a French satellite was damaged by colliding with debris from a French rocket that had exploded ten years earlier. In 2007, an event that possibly inspired the director of Gravity, China destroyed in space \u2013 as part of an experiment \u2013 a disused meteorological satellite that disintegrated into 3,000 fragments that were added to the cluster of space debris. In view of its dangerousness, NASA maintains an inventory of the largest fragments of space debris, including the trajectories that follow. This, in order to anticipate possible collisions with ships or satellites in orbit and apply the relevant measurements if applicable. In past days, for example, we learn from the media that NASA moved half a mile into the position of the international space station to prevent a possible impact with a fragment of a satellite. As the number of fragments in orbit increases, however, it will become increasingly difficult to avoid them and the only feasible solution will be that of their destruction. Otherwise, specialists consider, the planet\u2019s satellite system would collapse and space travel would become impossible. A space fragment can be destroyed by causing its re-entry into the atmosphere where it would be consumed by friction with the air. To carry out this re-entry, it is necessary to destabilize the orbit of the fragment by modifying its velocity by some means. In the past few days a group of researchers from the Australian National University announced a project in collaboration with NASA to achieve this by using a high-powered laser. The laser will be placed in the Observatory of \u201cMount Stromlo\u201d in Australia and will have an impact on the debris fragment to be destroyed, to which it will \u201cclap\u201d by modifying its speed and inducing its re-entry into the atmosphere. Making white with a laser in an object that is hundreds of kilometers away does not seem, of course, something simple to do. In order to achieve this, Australian researchers will use techniques developed by astronomers to observe distant objects through the atmosphere, from telescopes placed on the surface of the Earth. We will have to wait to find out if Australian researchers succeed in their project and manage to destroy, even partially, space debris accumulated over half a century. By the late 1950s, when the space age began with the launch of the first artificial satellite, \u201cSputnik 1\u201d, it might have been difficult to anticipate that space in the vicinity of the Earth would one day come to be saturated with space debris, because on the human scale this space in immense size. Time has shown us, however, that half a century of neglected space activities made possible what seemed unlikely.",
    "https://upload.wikimedia.org/wikipedia/commons/1/13/Sony_KDL-S19A10.jpg": "It is no secret that with regard to the manipulation of novel electronic objects of high technology it refers \u2013 a television, a computer, a digital clock, etc. \u2013 children and young people show a skill worthy of envy: to manipulate with skill gadgets that are not familiar to them. As adults such it seems that we have lost to a great extent this ability, which is regrettable in certain situations. As when we are entangled trying to change TV mode as a video, in which case it is better for us to ask the help of some young person \u2013 or child \u2013 around us. With the miniaturization of electronic circuits that took place over the last half century electronic devices acquired an unimaginable complexity until a few decades ago. With cell phones, for example \u2013 and according to the fashion joke \u2013 besides being able to take photographs and videos, consult the Internet, and send and receive messages, we can also make phone calls. One characteristic of new electronic objects is that they have multiple modes of operation. This feature is disconcerting and difficult to handle for those who were not exposed when young or children to digital technology \u2013 it is not. Before the advent of the microelectronics, the objects were immutable in the sense that they had only one mode of operation. The buttons of a television in the past had a unique function: to turn on or off the apparatus, to change the channel, to change the brightness of the screen, etc. Today a button has a multiple function that depends on the mode of operation in which the television is found and this is something difficult to handle for those who are not so young. The ease with which children, compared to adults, understand the operation of a device that is unknown to them indicates that they have a different way of reasoning? In an article published in the last issue of the magazine \u201cCognition\u201d, researchers from the University of Edinburgh in the United Kingdom and the University of California, Berkeley, in the United States, respond positively to this question. In particular, they find that in certain cases preschool children have a greater ability than adults to understand the functioning of unusual devices. The above conclusion was reached through a study with 106 children aged 4 and 5 years old. , and with a group of 170 university students. During the study, participants were presented with a music box \u2013 with a red cap \u2013 which lights up and starts to function as a response to placing a correct object or a certain combination of objects of defined shapes \u2013 cylinders, pyramids, cubes, etc. \u2013 on its lid. The object or combination of objects that activates the music box changes during the experiment and participants have to determine which object or combination is the right one. Researchers found that with certain unusual combinations of objects children outperform adults at the time of determining the correct combination. This is because children have greater flexibility to establish a cause-effect relationship in a novel situation compared to the flexibility of an adult who, due to their previous experience, may have preconceived ideas about such a relationship. According to the authors of the article referred, the results obtained suggest that \u201ctechnology and innovation can benefit from the exploratory and reasoning skills that are natural to young children, many of whom are learning to use an intelligent phone even before learning to open. Our lack of ability to manipulate electronic gadgets that are unfamiliar to us could then have an objective explanation. Thus, as we grow up we acquire experience, which is certainly valuable and we use for our benefit. At the same time, however, that same experience rigidizes us and makes it difficult for us to adapt to situations that require novel solutions.In particular, it would make it difficult for us to understand how the remote control of a television works to those we are not part of the digital generation.An objective explanation of our limitations, however, is of little comfort when we try to watch a film on television and we do not begin to press the proper button of control of the apparatus.In those moments we find that children and young people have in truth an enviable ability, that we adults unfortunately have lost to no small extent.",
    "https://upload.wikimedia.org/wikipedia/commons/e/e2/John_Gower_world_Vox_Clamantis_detail.jpg": "We would hardly find today someone who claims that the Earth is flat. For more than very few \u2013 those who have traveled into space \u2013 have been able to verify with their own eyes that this is spherical. The generality of mortals believe it because they taught us this in school and because there is a lot of indirect evidence in their favor, including the photographs of our planet from the space that others have taken for us.In fact, long before we could travel to space we already knew that the spherical Earth. We knew it even before the circumnavigation journey of Magellan and Elcano when this was verified in a practical way. It was the Greeks, more than two thousand years ago, who came to the conclusion that the Earth is spherical. Conclusion they reached observing, for example, how the height of the stars on the horizon changed when traveling north or south; it was good to observe the circular shadow that the Earth casts over the moon during an eclipse. These conclusions reached thinkers such as Plato and Artistotheles, who dealt with elu. To cover the world, and not so much ordinary people who had other concerns.In fact, for the profane it was \u2013 and even to some extent it is \u2013 more natural to think that the Earth is flat, because this is what we think at first sight.The experts, however, found so many arguments in favor of a spherical Earth, that the roundness of our habitat ended up being accepted in a general way.Do you believe in global warming, as it does in the sphericity of the Earth?According to the Pew Research Center, in 2013 only 67% of Americans believed that the Earth was warming up.This percentage, moreover, has not remained constant in the last few years and while in 2006 it was 77%, in 2009 it was reduced to 57%.Our belief in global warming is not in this way as solid as our faith in the roundness of the Earth, to the extent that it even varies significantly \u2013 up and down \u2013 over the course of a few years.Is the planet really warming? For the profanate this is not always obvious \u2013 the past \u2013 In January, for example, it seemed like it was getting colder. \u2013 So, after a crude winter it is more difficult to believe in global warming and the opposite happens in the middle of a torrid summer. An objective answer to the question can only be given to us by the experts who study the climate and in this sense the consensus is that there is global warming, and that the average temperature of the surface of the Earth today is about 0.8 degrees Celsius higher than in 1900. This is what is explicitly stated in a paper that appeared the week that ends today, published jointly by the NationalAcademy of Sciences of the United States and the Royal Society of the United Kingdom. A significant point in the document is the fact that it has been signed by two organizations of solid scientific authority, which makes it worthy of the greatest credibility. The document also states that with a very high probability the rise in temperature has been caused by human activities. In addition, more than half of this increase has occurred since 1970.If the emission of greenhouse gases is not changed, the temperature of the Earth in 2100 will be 2.6 to 4.8 degrees Celsius higher than today. This will cause climate changes that will make some wet and dry areas more humid, and possibly lead to an increase in the frequency of climate-related events. There will also be an increase in the level of the oceans, which is already about 20 centimeters higher than a hundred years ago. While global warming produces slow changes that are difficult to appreciate for the non-specialist, the scientific consensus is that this is real. Thus, even in the midst of the crudest of winters we would have the profane ones to believe that the Earth is slowly warming, just as we believe in the sphericity of the Earth even against our intuition. Not objective to deny global warming.In particular, because believing in it means fighting it by reducing the emission of greenhouse gases and this makes it an economic and political issue. Thus, the Pew Center reports that those in the United States affiliated to the Democratic Party remain, 88% consider that there is solid evidence of global warming.In contrast, in the case of Republicans this percentage is only 50%.It seems that giving credibility to global warming is a more complicated issue than deciding between a flat earth and a spherical one.",
    "https://upload.wikimedia.org/wikipedia/commons/8/81/S%C3%ADmbolo_radiaci%C3%B3n.png": "The \u201cMars One\u201d project, which made news this week, is certainly a very peculiar project \u2013 to say the least. It is peculiar not only because it intends to carry out a manned mission to Mars \u2013which has no precedent \u2013 with private funds, but because the planned journey will be only one way, because it seeks for astronauts to remain to colonize the planet. The project, however, does not seem to have technical viability, since Mars is at a very large distance that varies, according to its alignment with the Earth, between 59 and 102 million kilometers. The distance in fact does not prove to be an insurmountable obstacle to travel to Mars. In fact, it takes only five to ten months to get there, since interplanetary ships travel at a considerably high speed. A larger problem is the high energy radiation that permeates space and to which astronauts would be exposed throughout the journey. In fact, part of this radiation comes from sources of energy beyond the solar system; another, the most unpredictable and dangerous part, originates in the sun. On the surface of the Earth we are protected from these radiations by the atmosphere. On the voyage to Mars, travelers would be without this protection and would absorb radiations capable of making them sick or killing them. How high are the radiation levels in space? An article published last December in the magazine \u201cScience\u201d gives us the answer: on a 180-day journey astronauts would receive a radiation dose that is approximately one third of the safety limit set by NASA. These data, which were obtained by the \u201cCuriosity\u201d probe on their trip to planet Mars, do not, however, take into account that the Sun\u2019s activity can increase unexpectedly by significantly raising its level of radiation emitted. In relation to this, it can be read on the NASA electronic page that in the period between the Apollo 16 and Apollo 17 missions, which brought astronauts to the surface of the Moon, the Sun\u2019s radiation increased dramatically, and that if this event had occurred during the transit of one of the ships to our satellite, the astronauts would have received lethal doses in about ten hours. . According to NASA, for future interplanetary manned missions, one of the key problems to be solved is precisely that relating to the protection of crews against space radiation. Apart from the above, the astronauts of the Mars One project would eventually receive lethal doses of radiation on the surface of Mars, as this planet has an atmosphere that is too dim and does not have a protective magnetic field like that of Earth. It does not seem, then, that the Mars One project has technical feasibility. It does not seem to have financial viability either if we take into account that sending a man to the Moon \u2013 which is considerably closer to Earth \u2013 cost about $170 billion. And yet, the project is taken seriously \u2013 at least in appearance \u2013 by many people. At least by the 200,000 who, according to its promoters, were enrolled \u2013 paying a fee \u2013 to search for one of the 24 sites on one of the ships that would travel to Mars from 2024. One may wonder who might be interested in making such a dangerous trip and, moreover, without return, . An online review among the semifinalists throws some names at us. We find, for example, that Ken Sullivan, who lives in Utah and is the father of four children, is interested in traveling to Mars \u2013 even though he has been threatened by his wife with divorce if he continues with his plans. Sullivan worked as a contractor in Iraq fixing helicopters. Nuria Tapias, 30, from the town of Calafell in Catalonia, is also interested in traveling to Mars. Nuria studied philosophy and works in a real estate company. She is passionate about astronomy and hopes to live 40 years on Earth and the rest on Mars. She does not know that they were based on her choice, since they only asked her to be over 18 years old and measured between 1.60 and 1.90 meters high. Among the 1058 semifinalists highlights Andr\u00e9s Eloy Mart\u00ednez Rojas, Secretary of the Committee on Science and Technology of the Chamber of Deputies. Mart\u00ednez Rojas is an amateur astronomer and considers that one point that she has in her favor to achieve being among the finally elected is that she baptized a crater that is on Mars with the name of Jojutla \u2013Mar. tinez is a deputy for the State of Morelos\u2013. One of his motivations for the trip is precisely to visit this crater. It is not clear how firm are the intentions to travel to Mars by the more than a thousand preselected and if given the moment and they are among the real finalists dare to leave this planet. Certainly, although it is true that everything is in the Lord\u2019s vineyard, it is also true that there is no madman who eats light. In any case, it is possible that they never have to make the decision and that it is only a Chinese tale about Mars that will certainly leave profits to its promoters.",
    "https://upload.wikimedia.org/wikipedia/commons/b/bd/Caldera_Mt_Tambora_Sumbawa_Indonesia.jpg": "The Sun is ComingThe sun is coming, and I say It's all rightThe Beatles, 1969There's no harm that it lasts a hundred years \u2013 fortunately \u2013 and although we still have a good number of cold fronts to come before the end of the winter season, it seems that time starts to improve and restores us confidence in the sun as a support for life on the planet. This winter has been characterized not only by the low temperatures that we have suffered but also by the many sudden climatic changes. And yet, it may not happen to history as a particularly crude winter. At least not as happened with the year 1816, which is known as the Year that did not have summer. 1816 was, in effect, a year with an exceptionally cold climate \u2013 in England the average temperature dropped 2 degrees centigrade. It is thought it was the result of the eruption of the Tambora volcano in Indonesia in April 1815. According to Alan Robock of the University of Maryland, quoted by the magazine \u201cNew Scientist\u201d, such eruption would have thrown into the atmosphere between 100 and 200 cubic kilometers of stone and ash \u2013the The eruption of Tambora, which could have been heard 2,000 kilometers away, would have been the largest in written history. The ashes of the explosion were scattered in the atmosphere, blocking the sunlight, ruining crops and causing famines. Inspired by a dark day in which \u201cthe candles lit up as if it were midnight\u201d, the English poet Lord Byron wrote in the Year that he did not have summer: \u201cI had a dream that was not quite a dream/The bright sun went out, and the stars/vague diluting in the eternal space,/without rays, without paths, and the icy earth/oscile was blind and darkening in the air without moon;/ the morning came, and came, and did not bring/get the day\u201d (Oscuridad, 1816).The Year that did not have summer is, however, a unique case in history. A much more serious event occurred in 536 d.C. He wrote about Procopius of Caesarea, a chronicler of Justinian, emperor of the Byzantine Empire: \u201cAnd it happened during this year that a terrifying omen occurred. The sun lit up without brightness, like the moon, throughout the year, in the same way as the sun in an eclipse, and the rays it sent were not clear nor as usual to send.\u201d The cooling resulting from the decrease of solar radiation brought with it bad harvests, famines and social chaos. It is also considered that it was responsible for the epidemic known as Plague of Justinian, which was triggered in the Byzantine Empire from 542 onwards and which, according to Procopio, caused 10,000 deaths daily. Experts believe that the Plague of Justinian was an epidemic of bubonic plague that preceded the epidemic of the 14th century in Europe known as Black Death, in which the climate is also thought played an important role.In addition to the chronicles of the time, scientists have proof that, in fact, around 536, there was a global cooling. Michael Baillie, of The Queen's University Belfast in the United Kingdom, carried out studies with tree trunk rings and found that the growth of thinner rings occurred around 536, which is indicative of the prevalence of low temperatures. As we know, tree rings grow annually with thicknesses that depend on prevailing climatic conditions. If these are good the thickness of rings is greater and the opposite happens if they are unfavourable. It is not clear, however, that it was what caused the blocking of solar radiation. According to specialists, there are two possibilities. One of them is that of a massive volcanic eruption, similar to that that which gave rise to the Year that did not have summer. Another possibility would have to do with the impact of comet debris on Earth. It has ventured that fragments detached from Comet Halley, which approached the sun in the year 430, could have been intercepted by our planet some years later and throwing clouds of dust into the atmosphere.Returning to the present time, the problems we have suffered in the last weeks by the crude winter are nothing compared to those suffered by our ancestors \u2013 However, and the worrying threat of influenza that grows day by day according to official data \u2013 which contradicts that of which all past time was best. This, of course, of little comfort serves us and moves us to ask the sun, in the future, not to stray too far.",
    "https://upload.wikimedia.org/wikipedia/commons/0/09/C60-rods.png": "During the intense colds that we suffered in past days, in which the sky was kept covered by a thick layer of clouds, it was more than obvious to us \u2013 in case we had forgotten it \u2013 how important the Sun is to us. In fact, we know that our star is the source of all life that exists on Earth, because without the light of the Sun the process of photosynthesis could not take place through which plants create organic matter. Thus, without the competition of solar radiation our planet would be a mass of inert rock, without the slightest trace of life. The Sun also has the function of maintaining the surface of the Earth at a temperature suitable for the development and survival of living beings \u2013 even though in days past doubts have arisen about it. And, of course, it is the Sun that is the ultimate source of energy to produce the food that we need to not die of hunger. At present the Sun is also important to us in another sense, which it goes beyond our mere survival. Indeed, for a couple of centuries we have required increasing amounts of energy to maintain and increase our industrial capacity. To date, energy has been mostly obtained from fossil fuels \u2013 coal, oil and natural gas. These, however, in addition to pollutants in the atmosphere are non-renewable and at some point will be exhausted. Fortunately, we have the resource of solar energy, which could provide us with the energy we need, when in the future we run out of fossil fuels. Unfortunately, although we have solar energy in abundance, it has a basic problem: it is intermittent. Thus, if we are to a large extent to rely on this energy in the future, we will have to develop means to store it during the day to use it at night \u2013 or in the hours when solar radiation decreases for some reason.What means are currently used, or are planned to use in the future, to store solar energy? There are several. It can, for example, generate electricity by means of solar modules and use it to power pumps to compress air. Air under pressure is stored in underground caves for later use. Water can be pumped and stored in a high place as gravitational energy. . In another scheme, solar electricity can be used to generate hydrogen by decomposing water. The hydrogen thus generated is stored for later use as fuel. There is certainly a good number of means used to store solar energy \u2013 the same as wind energy, which is equally intermittent \u2013 but perhaps the first one that comes to our head is the lead-acid battery, like the one we use in cars to start them up, or the lithium battery of cell phones.This type of batteries, however, is not the most suitable to store solar or wind energy.A better option is the flow battery, which generates electricity from fluids that are circulated by it. Thus, the amount of energy stored depends, not on the size or power of the battery, but on the amount of fluids stored.The energy storage capacity can then be increased by increasing the volume of fluids without the need to increase their power. This contrasts with conventional batteries where power and energy storage capacity are directly related. In an article published this week in the British magazine \u201cNature\u201d a group of researchers from \u201cHarvard University\u201d in the United States and \u201cEindhoven University of Technology\u201d in the Netherlands reported the development of a flow battery that uses low-cost organic molecules. According to Michael Aziz, one of the authors of the article, the new battery can solve the energy storage problem. In the case of a house-room, for example, it argues that a 2,000-liter tank could be sufficient to store enough solar energy during the day to meet the night needs. Not everything looks so pink, however, as the new battery uses bromine and brom hydro acid that can cause severe pollution problems in case a leak occurs. In fact, according to Aziz, bromine is the Achilles heel of that battery.If the new battery will actually solve the energy storage problem, it is something that will tell us the future. another, however, will have to find a solution if we are to secure the energy future of the world on the basis of solar energy. Otherwise, it will not be a source of pride that, given the enormous amount of energy that the Sun puts at our disposal, we cannot take full advantage of it.",
    "https://upload.wikimedia.org/wikipedia/commons/9/92/Retrato_de_Hernando_de_Magallanes.jpg": "Perhaps we could not expect that anyone who prepares to make a trip to the planet Jupiter will have too great a concern for the food he will carry for the journey. Certainly, not because he considers that food is superfluous \u2013 unless he intends to commit suicide or to travel in a state of hibernation, as in Stanley Kubrick\u2019s famous film of the sixties \u2013 but because he will surely have his mind occupied in a number of other matters, typical of a journey to such a distant and inhospitable place. Traveling to Jupiter is not a simple undertaking. In fact, it is not expected that we will do so in the coming decades, because it is far above our current technological and economic capabilities \u2013 and we do not have a real motivation to do so. However, there are those who are concerned about the food that the astronauts of the future will consume in long-term trips, foods that are not intended to be too different from those we use on our planet. This, in order to reduce psychological pressure on space travelers, already very large. the week that ends today in the magazine \u201cFood Research International\u201d by chemical researchers of the Aristotle University of Thessaloniki in Greece. This article reports the results of a study, funded by the European space agency, carried out to determine the effect that a force of gravity greater than the Earth\u2019s \u2013 like Jupiter\u2019s \u2013 would have on the preparation of fries. It is known that the golden grade of a potato depends on the heat that is transported by convection from the bottom of the fryer to the surface of the potato. Convection is the phenomenon by means of which a volume of hot liquid in the bottom of a container experiences a flotation force and rises to the surface by shifting to another similar volume of liquid at a lower temperature\u2013 as when we heat water in the stove\u2013. The force of flotation that produces convection, on the other hand, depends on the force of gravity, so that the convection will be greater as the latter increases. In a few words, we could expect that on the surface of Jupiter you can prepare crisper fries, as indicated in the magazine \u201cScience\u201d in its last issue when commenting on the article by Greek researchers. Although space exploration trips are qualitatively different from exploration trips of the 15th and 16th centuries that led to European colonization of the world, it is interesting to make a comparison between the food of travelers in both cases. As we know, Spain\u2019s interest in finding a route to the west to the eastern Indian first led Christopher Columbus to \u201cdiscover\u201d the New World and years later to the circumnavigation of the terrestrial globe by an expedition that began in 1519 Fernando de Magallanes and ended Sebasti\u00e1n Elcano three years later. With the passing of the centuries, exploration trips initiated by Spaniards and Portuguese led to virtually all corners of the earth\u2019s surface. In comparison, the results of space travel have been modest and the only extraterrestrial destination that has reached a manned journey is the Moon. This last of course, is the result of the technical difficulties presented by space travel, which have demanded great technological developments in many fields. In this context, it is not surprising that the astronauts\u2019 food is also the focus of attention. One of the rapporteurs of Magellan and Elcano's circumnavigation journey was Antonio Pigafetta. After leaving the Strait of Magellan and entering the Pacific Ocean, Pigafetta recounts in her diary: \u201cOn Wednesday, November 28, 1520, we left the strait and entered the peaceful sea where we stayed for three months and 20 days without bringing fresh food, and we only ate cookies reduced to a powder full of larvae and stinking from the dirt that rats had made when they ate the good cookies, and drank water that was yellowish and stinky. We also ate ox leather... which was very hard and we had to put four or five days in the sea and then in the coals....In addition to all the previous calamities, the misfortune I will mention was the worst, this was that the upper and lower gums of the largest part of our men swelled so much. They couldn\u2019t eat, and they suffered so much that 19 died.\u201d As we now know, sailors\u2019 gums swelled because of scurvy, which in turn is caused by a lack of vitamin C in their diet. The care that marine explorers put in their diet five centuries ago was evidently very different from that enjoyed by future solar system explorers, who may even enjoy better fries in compensation for all the inconveniences of the trip. In the case, of course, interplanetary travel is one day feasible.",
    "https://upload.wikimedia.org/wikipedia/commons/1/1e/Khotan-fabrica-seda-d17.jpg": "Although today an object made of plastic is often considered a cheap and unsophisticated imitation of its equivalent made of natural materials, this has not always been the case. Indeed, and by way of example, we can mention that at the end of World War II there was in the United States what is known as the \u201cNailon riots\u201d, in which groups of women fought in clothing stores for a pair of half-mades using this material. Many of them were unsuccessful.Nailon is a fiber developed in 1935 by chemist Wallace Carothers, who worked for the DuPont company in the United States. This company saw in the nylon an attractive substitute for silk to make stockings; and it was not wrong, as the nylon stockings enjoyed instant success when they were put on sale. According to Emily Spivak in an article published in the Smithsonian Magazine, on 16 May 1940 they were put on sale in the United States 4 million pairs of nylon stockings with a price of $1.15 per unit, with such a price of $115. When the United States entered as a fighter in World War II, the nylon stockings disappeared from the shelves when fibre production was dedicated to the manufacture of parachutes and other military implements. Only at the end of the war were they again available, causing the aforementioned tumults until DuPont managed to increase its production volume to meet demand.Nailon is an artificial material \u2013 that is, it is not found in a natural way \u2013 formed by long chains of atoms called polymers.Chemics had discovered in the first decades of the 20th century the way atoms join together to form a chemical compound and this knowledge was key to the manufacture of nylon.Nailon is thus a technological development in which science played a central role.It is not the only example, of course. Far from this, modern technologies, which are characterized by a great sophistication, are the result of the application of scientific knowledge.Another example in this regard is silicon \u2013 even a material that does not exist as such in nature \u2013 that It is used for the manufacture of brains and computer memories. Without the scientific discoveries made during the first half of the 20th century, concerning the internal \u2013atomic \u2013 structure of materials, silicon would not exist and consequently there would be no computers as we know them \u2013 and, of course, neither the Internet nor social networks.One of the most active fields of research at the Autonomous University of San Luis Potosi is that of materials, and in this regard it is necessary to highlight the National Prize of Sciences that was recently given by the President of the Republic to Magdaleno Medina Noyola, researcher of the Institute of Physics of the University. Medina Noyola is specialized in so-called vitreous materials \u2013 or just glass \u2013 that are distinguished from other materials such as silicon by the way atoms are ordered inside. In the silicon of sufficient quality to manufacture \u201cchips\u201d of computer atoms are spaced regularly, except for some defects that in some cases are intentionally introduced and in others are inevitable. We have, however, that although silicon atoms have a tendency This in order to give atoms the possibility to move in search of their preferred position, before the silicon mass is solidified and remain motionless.In contrast, in vitreous materials even with all care it is not possible to make atoms fit in a regular way. One example of these is precisely the common glass, inside which atoms are placed in a messy way. As Medina Noyola explains, the behavior of vitreous materials constitutes a mystery whose revelation has resisted the efforts of specialists over almost a hundred years. Certainly, experts have developed theories to explain the peculiar behavior of glass. These, however, have been controversial and have not reached a general consensus. Medina Noyola thinks that he has the answer and that a theory that he has developed in the UASLP can explain how to cool a glass. vitreous material their moving atoms fail to reach the ordered final state \u2013 which if they reach other materials such as silicon \u2013 and are immobilized along the way in a disordered intermediate state. Solving the problem of vitreous materials is possible that it had only an academic interest not to be, as Medina Noyola comments, because the vast majority of the substances with which we have contact in our daily life \u2013 including food and medicine \u2013 belong to this category of materials. Thus, understanding the behavior of vitreous materials could have even a greater impact than nylon, which at the time caused even tumults.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d2/Howard_Walter_Florey_1945.jpg": "Do you remember when for the first time you used a word processor or did you know about its existence? For those who write the memory of the first contact with one of these tools, which has facilitated the writing of all kinds of texts, it is lost in the night of time. This is certainly an exaggerated expression, whereas the time horizon of the night of the times for word processors does not go beyond just about three decades. Three decades have been enough to make us forget that there was a time when these processors did not exist and that writing a text, and above all making corrections to it, was complicated, at least in comparison to the present times. This, on the other hand, is not surprising, because it is easy to get used to it. As we have become accustomed \u2013 even in a short time \u2013 to modern medicine, which has freed us from the threat of numerous diseases that in the past plagued the world\u2019s population. A milestone in this sense was, as we know, the discovery of penicillin by Alexander Fleming in 1928, and its application to combat bacterial infections carried out by Howard. Florey, Ernst Chain and Norman Heatley at Oxford University. Penicillin was used for the first time by Florey and therapeutic collaborators in the person of Albert Alexander \u2013 43 years of age and of police profession \u2013 who had scratched his mouth with the thorn of a rose when he worked in his garden. As a result of the scratch, Alexander came with a severe infection that led him to lose an eye and put him on the verge of death when he spread to his lungs. Since the case was desperate, Alexander became a candidate to experiment with penicillin, which was risky because the side effects that he could have on humans were not known. After a first dose was given, the patient experienced an improvement and gave him the fever. Unfortunately, one dose was not enough and since he did not have more penicillin, the infection returned and Alexander died within a few days. Today, thanks to antibiotics, we would not expect to die from the scratch of a rose spine; seven decades ago this was not guaranteed, as it was not guaranteed, as it was so. Albert Alexander. Antibiotics have given us a margin of safety against bacterial infections that have caused numerous epidemics and claimed numerous victims throughout the history of the world. One of the most famous, during which one third of the population of Europe would have died, is the epidemic of bubonic plague called Black Death that occurred in the 14th century. According to experts, the epidemic penetrated the European continent through southern Italy, transported from Asia by merchant ships. In this week\u2019s issue of the magazine \u201cScience\u201d is included an article describing a study that is being carried out by a group of researchers led by anthropologist Clark Spencer Larsen of Ohio State University in the United States, at St. Peter\u2019s Abbey near Pisa, Italy. The research focuses on the numerous tombs that are located around this abbey, whose antiquity spans a thousand years, between the 11th and 19th centuries. The study aims to find out as much as possible about the victims, including their place of origin, the food they consumed, the Among the graves, researchers expect to find some belonging to victims of Black Death. A study of the skeletons by means of different techniques, such as three-dimensional computed tomography and the analysis of isotopes of the teeth, will allow them to determine the strain of the pathogen with which they were infected. They will also find out their state of nutrition and if they suffer simultaneously from another disease such as tuberculosis, which would have weakened them and made them more susceptible to the attack of the bacillus of bubonic plague. Furthermore, according to the researchers, since the dead buried in St. Peter\u2019s Abbey would have been among the first victims of the epidemic, because they were near the point of entry of the bacillus to the continent, a comparison of the pathogen that caused their death, with strains found in other parts of northern Europe, will give them indications of the ways of spreading the epidemic. Experts are not sure that it was what made so deadly to the bacillus of Black Death. It hides \u2013 that yes \u2013 in the night of the times. Let us trust, however, that the analytical techniques of modern research will at some point be able to penetrate the night darkness and reveal a mystery of seven centuries.While this happens, let us also trust that no longer can anyone irremediably die from a scratch of a rose thorn and that this memory will be lost definitively in the night of the times. As, by the way, the typewriters have been lost.",
    "https://upload.wikimedia.org/wikipedia/commons/a/a4/Kyrgyz_Manaschi%2C_Karakol.jpg": "The scientific knowledge that we have about the world has been accumulated by leaps and bounds for some four centuries with the birth of modern science.This knowledge has given us an increasing dominion over the forces of nature and from it has been born modern technology, which has had a profound impact on our civilization, particularly over the last two centuries.Although in the beginning the scientific method was used to investigate the natural world, object of study of sciences such as Physics, Chemistry and Biology, over the last two centuries that method extended to the research of social phenomena. This is, for example, the case of the study carried out by anthropologist Jamshid Tehrani of the University of Durham in Great Britain, which aimed to find out the origin of the story Caperucita Roja. The results of that study appeared in this week\u2019s issue of the online magazine \u201cPLOS ONE\u201d. The most well-known version of this story is the one that the Grimm brothers published in 1812, based on a tale of the 17th century by Charles Perrault. The latter, however, is not the most well-known version of this story published in 1812, based on a tale of the 17th century by Charles Perrault. In fact, Tehrani points out that it is accepted that Perrault took it from an ancient legend, The Tale of Grandma, which has survived as an oral tradition in rural areas of France, Austria and northern Italy. In many of the versions of this tale, the girl \u2013 who does not wear a red cape \u2013 is caught by a wolf. She nevertheless escapes when she convinces her captor to let her go to the bathroom. As a precaution, the wolf tied a rope at her foot to prevent her from escaping. Which the girl achieves by cutting the rope and tying it to a tree. Tehrani mentions the rediscovery of a 11th-century Belgian poem that describes a story similar to that of Little Red Riding. The poem, which circulated through Western Europe in the Middle Ages, speaks of a girl who wandered through the forest with a layer of red baptism that had been given to her by her godfather. In her wandering, she finds a wolf that kidnaps her and takes her to her burrow. The girl, however, manages to escape from her captivity. Other stories similar to Little Red Riding Hood exist as oral traditions in other non-European countries, according to Tehrani. Among them is Grandmother Tiger, a story that is popular in China, Korea and Japan. In this tale a group of brothers sleep with a tiger who pretends to be their grandmother. When the tiger devours younger brothers the older ones convince him to let them go out to the bathroom, which they take advantage of to escape. In Africa, likewise, there is a story about a girl who is devoured by an ogre who tricked her by imitating her brother's voice. The girl manages to escape alive once they open her belly to her victim. In Europe and the Middle East there is a story known as The Wolf and the Cabritos in which a goat instructs her children not to open the door while she is not in the house. When she is absent, the wolf calls to the door pretending to be the mother and when they open her to the kids. Tehrani's research had as its objectives to find the relationship that exists. Among these stories, which contain elements of similarity, and perhaps all had the same origin. For this purpose he used a methodology similar to that used by biologists to determine the evolutionary path that biological species have followed. That is, he considered that popular stories are transmitted from generation to generation with small changes, analogous to the mutations suffered by living beings. Thus, he first identified the characteristic elements of the different stories. He considered, for example, whether the protagonists were human or not, whether there were one or several victims of the villain, the kind of villain \u2013 ogre, wolf or tiger \u2013, the methods used by him to deceive his victim, and whether it was devoured, escaped or rescued. With these elements \u201372 in total \u2013 Tehrani mathematical procedure he compared the different stories and determined that Little Red Riding had as an ancestor El Lobo and the Cabritos. This last story already existed in Europe at the beginning of our era and would have given origin to Little Red Riding in the 11th century. The African and Far East versions of the story would have also had their origin. In The Wolf and the Cabritos. It might seem superfluous the knowledge that we now have about the origin of Red Riding Hood and a waste of money the resources that have been used to investigate it. According to Tehrani, however, \u201cthe folk tales involve fantasies, experiences and fears, and are really a good way to find out, through the products of our imagination, what really matters to us.\u201d Apart from this, any new knowledge we acquire about the world is important, because we cannot rule out that one day it will be useful. As so many scientific research results have been.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d7/8-cell.gif": "Some think that 3D printers (three-dimensional printers) will revolutionize the industry as we know it. This is likely to happen in the future, although, certainly, in order to compete with the traditional industry, 3D printers \u2013 with sufficient precision \u2013 will first have to lower their price, increase their printing speed, expand the range of materials they handle and, in certain cases, increase their size. Soon, however, 3D printers have given us new ways of making objects. Handcrafted work is unprecise in nature and produces imperfect objects, in a measure that depends on the skill of the craftsman or the haste with which he works. Likewise, two nominally equal craft objects will not necessarily be, even if they were manufactured by the same person. In contrast, the industrial revolution initiated in England more than two centuries ago brought, among other things, techniques of automated manufacturing that produce in mass and at great speed objects with fewer imperfections and variations than those typical of artisanal work. The imperfections of the old coins are not only in their form, but also in the die-cut motifs on their faces. Even in some cases it is possible to see that the die-cut is out of the center, possibly due to the haste with which the craftsman worked. In turn, 3D printers have brought a new sophistication in manufacturing techniques and, among other things, have made it possible to duplicate objects with a coded form in a computer program. Thus, anyone would be able to make an object with a complicated form using a computer code that he could possibly get on an internet site. He could also reproduce the object whenever he wanted, getting an exact duplicate and largely imperfection-free. And all this could be done by someone without the least skill as a craftsman \u2013 albeit with the corresponding ability to handle a computer. All this is surprising to us another surprise that sounds like science fiction, as recently there was the possibility of building 4D printers from 4D technology. 3D. It should be clarified, however, that these are not machines that print objects in a four-dimensional hyperspace or anything that it looks like and that the fourth dimension actually refers to time. Thus, it is intended that 4D printers produce, not rigid objects, but objects with the ability to transform themselves in response to changing environmental conditions. It is proposed, for example, the manufacture of pipe conductors of water with intelligent materials, whose diameter increases or decreases depending on the flow of water to drive, or that they close completely to make the function of a valve. They could also contract and expand periodically to boost water, as in the digestive tract to advance food. Intelligent materials could also be used to manufacture car wheels that change their characteristics to adapt to the conditions of the road. However, while all this sounds exceptionally attractive, it should be noted that at present 4D printers and their applications with intelligent materials are only at an early stage and in some cases are nothing more than ideas. \u201cNew Scientist\u201d is published an interview with Skylar Tibbits of the Massachusetts Institute of Technology (MIT). Tibitt is an architect and computer specialist who is conducting research on the use of 4D printers and smart materials in the design area and in infrastructure applications. Tibbits does not see 4D printers and smart materials competing with the current industry and finds their application rather in peripheral areas where manufacturing is currently impossible, by face, dangerous or inaccessible, as is the case with the manufacture of objects in space. Tibbits exemplifies their ideas with objects made using material that expands in contact with water. It shows, for example, a stick that when immersed in the liquid becomes an object that simulates a cube, or another case where the rod bends to form the MIT letters. It is easily possible to find online videos showing these effects. When 4D printers come true \u2013 hopefully in the future, a lot of water will flow under the bridge. Since those times, hundreds of thousands of years ago, when our ancestors developed craft techniques to manufacture axes and stone tips. A long time will certainly have passed, but it is remarkable that it is in the last two hundred years when so many and so profound changes have occurred in our manufacturing techniques.",
    "https://upload.wikimedia.org/wikipedia/commons/9/99/Arbeitsbuch_f%C3%BCr_Ausl%C3%A4nder.jpg": "In the 1960s and 1970s, U.S. physicist William Shockley embarked on a campaign to convince American public opinion, as well as politicians and the scientific community, that the \u201cquality\u201d of the U.S. population might be declining because of the phenomenon he called dysgenesis. According to Shockley, there was an inverse relationship between the quality \u2013 which he understood as intelligence \u2013 of a person and the number of children he produced. Thus, the population of the \u201cless fit\u201d would grow at a higher rate than that of the \u201cmost fit\u201d leading to the decline in the average intelligence of the U.S. population. In reality, Shockley\u2019s ideas were not new. Francis Galton \u2013 Charles Darwin\u2019s second-degree prime minister \u2013 expressed them for the first time in the second half of the 19th century, giving rise to the discipline that was later known as eugenic. At the time that Shockley launched his campaign, eugenics had already been the cause of multiple calamities in the world. The Nazi regime\u2019s campaign against the \u201clower races\u201d in particular. Thus, at the time that Shockley launched his awareness campaign, eugenics was highly discredited. However, given Shockley\u2019s scientific notoriety, this campaign attracted the attention of the public, although to a large extent with adverse comments, as we can read in the book \u201cShockley on Eugenics and Race: The Application of Science to the Solution of Human Problems\u201d, edited by Roger Pearson. As it may have been, the situation that Shockley posed may not have been so worrying at the end of the day, since in the 1960s contraceptive methods broke into the scene, thereby reducing the population\u2019s growth rate, including that of supposed low quality. Moreover, far from deteriorating, American society was enriched by the immigration of scientists and engineers from all over the world, notably from India and China. Indeed, according to data from the National Science Foundation of the United States, in In 2009 there were almost 600,000 foreign students enrolled in universities in that country in all areas of knowledge. In areas of science and engineering this number was about a quarter of a million students. China, India and South Korea are the three countries that contribute the most, with more than 50% of the total. Mexico for its part is among the top ten countries in this area, with almost 3,300 students enrolled in science and engineering. In percentage terms, according to figures quoted by Wikipedia, in 2011 28% of all graduates in US universities in science, engineering and health were foreigners. Likewise, in 2004 55% of doctoral students in engineering in the United States were born abroad.Wikipedia also cites figures that show the impact that foreign-born scientists and engineers have on the labor market in the United States. In 2000 37% of all scientists and engineers with doctoral degrees were born abroad, while 45% of physicists with doctoral degrees were born abroad, in 2004. The development that Asian countries have experienced in recent times, in particular China and India \u2013 which together represent one third of the world\u2019s population \u2013 is changing the picture. In this week\u2019s issue of the magazine \u201cScience\u201d the first of a series of articles on India\u2019s conditions for a scientific career is published. According to this article, about 15 years ago the Indian government launched a plan to expand research institutions in the country and create new ones. This has changed the perspective for Indians who graduated from universities outside their country, who previously sought to stay abroad and now see India as an attractive place to develop their scientific career. After the Second World War the United States became one of the two largest research centres in the world \u2013 the other was the Soviet Union that partially disintegrated with the fall of the Soviet regime\u2013. China and India are now emerging, and with this it is possible that the centre of gravity of research will move partially into Asia in the not-too-distant future. The United States would thus lose some of its intelligence to the extent that Asian scientists and engineers decide to settle in their home countries. They will lose it, though for reasons very different from those anticipated by William Shockley.",
    "https://upload.wikimedia.org/wikipedia/commons/2/27/Telstra_Mobile_Phone_Tower.jpg": "As we know, often at the end of an article or news published on the Internet, we include a section in which readers can express opinions on its content or on the opinions of other readers, which are sometimes surprisingly aggressive. So aggressive that we would hardly think they could express themselves face to face. They would thus be the product of anonymity from which they are broadcast. An article and an editorial published in this week's issue of the British scientific journal \u201cNew Scientist\u201d comment on this phenomenon. An Internet user who is anonymously connected causes, according to some opinions, that he behaves in an uncivilized way because he does not have to face the consequences of his words. This has been called the \u201ctoxic effect deinhibitor online.\u201d In the article of \u201cNew Scientist\u201d there is the possibility that anonymity in the Internet disappears. For this, the necessary technologies already exist. An Internet user, for example, could be identified by means of the digital fingerprints of his fingers, with the help of the characteristic movements of his hand by marking a number on the cell phone, or by means of walking such. The possibility of eliminating anonymity on the Internet raises several questions with \u201cNew Scientist\u201d. The first question is whether the loss of anonymity would be, after all, an effective measure to reduce the uncivilized comments online, which might in fact be due to the absence of visual contact between those who interact. The second question relates to the role that the Internet has played in the fall in recent years of governments that qualifies \u201cNew Scientist\u201d as repressors, a fall that may not have occurred without anonymity on the network. One more aspect concerns identity theft. At present, if someone steals a digital identity there is always the possibility of nullifying it and generating a new one. If this identification was made through our digital fingerprints or our way of walking would not exist this possibility. In the context of the great diffusion that has been given in recent weeks to the espionage of which several foreign governments were subjected by the United States, however, the main concern for the eventual loss of anonymity online would have to do with the greater ease that it would be so that the Internet users could be monitored. The Internet has a structure distributed throughout the world, which is made up of a set of interconnected networks. The Internet is maintained in growth sustained by the addition of new networks on a continuous basis. Although the Internet was created in the United States on an official initiative, today private telecommunications companies are the ones that keep it in operation. The Internet is a distributed communications network that does not have centralized control. Much of the international communications traffic, however, passes through the territory of the United States, as a result of having been this country the initiator of the network. This happens even if it implies that a message has to travel a distance considerably greater than that which exists between the point where the message originates to the destination point. Thus, for example, a message sent from Brazil to Uruguay travels first to Miami and from there to the south to this last country. This does not prove impractical due to the great speed with which the messages travel on the Internet that eliminates the geographical barriers. It is Brazil \u2013 one of the critical countries of espionage revealed in recent months \u2013 that is considering carrying out It is, for example, demanding that communications companies that store personal data from users in Brazil, such as Google and Facebook, keep them on computers that are physically in this country and not in the United States, demand that these companies refuse to satisfy. Brazil is also proposing the creation of a communications network with South American countries that would not have depended on the infrastructure of telecommunications companies based in the United States. The time that we had to live has witnessed great technological developments that have had a profound impact on our lifestyle. One of these developments is undoubtedly the Internet, which has revolutionized telecommunications so that it would have been difficult to imagine just a few decades ago, and with this it has changed the world for the better; although it is possible that it has also done so for the worse, if the Internet and the enormous power of computers that store the allud of data they receive day-to-day \u2013 from network users \u2013 help to make the world conceived by George Orwell come into being more than half a century ago. the removal of anonymity on the Internet inhibits or does not inhibit aggressive online comments has, of course, no greater relevance.",
    "https://upload.wikimedia.org/wikipedia/commons/6/68/ScientificReview.jpg": "The cover of the last issue of the British weekly newspaper \u201cThe Economist\u201d is dedicated to science. We might think that science deserves the honor of appearing on the covers of all kinds of magazines, given how much we owe it because of the huge impact it has had on our lives in the last two centuries. On this occasion, however, the comments of \u201cThe Economist\u201d were not entirely flattering, by filling its cover with the phrase \u201cHow science twists\u201d in which it alludes to some problems that concern scientific practice, typical of the time when we lived. \u201cThe Economist\u201d is not a scientific journal. It is also not a publication dedicated to the dissemination of science. According to Wikipedia, \u201cThe Economist\u201d \u201cis a publication of liberal philosophy in the economic and political fields, which deals with issues of politics, international relations, finance, technology and science.\u201d For a magazine with these interests, it is not difficult to understand that science is important as the ultimate source of modern technology, which in turn is an essential element. As we know, the scientific method is a relatively recent invention. Its origin does not go beyond about four centuries, being Galileo Galilei \u2013 in the early days \u2013 one of its main figures. The central ideas of the scientific method are very simple, at the same time powerful; in fact, they are to such an extent that it is somewhat surprising that they have not been discovered until such late dates in the history of humanity. According to the scientific method, the way to discover the laws that govern the world is experimentation. This, which today seems obvious to us was not so in past times. Thus, Aristotle claimed that the females \u2013 including those of the human species \u2013 for their supposed inferiority had less teeth than the males. Certainly, Aristotle could have easily come out of his error by the simple experiment of telling his wife\u2019s teeth. It should be noted, however, that experiments are subject to errors of various kinds, as well as to the prejudices of the experimenter. Thus, for the result of a particular experiment to acquire scientific validity, it must be reproduced by others. This is an essential feature of the scientific method. Hence, a second characteristic of science emerges: its results and truths are never definitive, but are subject to being refuted by new experiments. Thus, any false result, the product of errors committed during experimentation \u2013 or either the result of the prejudices of the experimenter \u2013 would be discarded sooner or later inevitably. Thus, science would advance linearly towards the perfection and understanding of the world around us. However, this process of self-purification \u2013 by means of which science systematically corrects its own errors \u2013 is not free of obstacles. Indeed, although this process certainly looks simple and solid, as in many other situations of life we find that the devil is in its details. This motivated the cover of \u201cThe Economist\u201d and the related articles that appeared within it. One characteristic of Science today is the enormous expansion that it has had, both in the number of practicing researchers and in the number of published research articles. At the same time, the career of scientific researcher has been consolidated and intense competence has been generated. The cost of scientific research, on the other hand, is very high and the researcher has to look for support to carry out his projects.This has also generated intense competition for the research funds available.As a result of all this, the researcher is under great pressure to publish as many technical articles as possible, which has led, in some cases, to the hasty publication of results. So hastily that a high percentage of them have not been confirmed. \u201cThe Economist\u201d, for example, cites the case of 63 studies of great relevance in the field of cancer research of which only 6 could be reproduced. Likewise, the number of articles published and the number of scientific journals have grown so much that peer reviews of the articles submitted for publication \u2013 which is one of the pillars of scientific research \u2013 have been made difficult, and as a result the probability that some of the published articles contain errors has been increased. These latter, of course, will be virtually eliminated from scientific literature by not passing the test of reproducibility. n an obstacle to scientific progress; progress which, however, will take place in one form or another, slowly or acceleratedly, as has happened over the last two centuries. No matter how much the devil wants to put the tail with his details.",
    "https://upload.wikimedia.org/wikipedia/commons/5/5d/1665_journal_des_scavans_title.jpg": "As discussed in this space last Sunday, the journal \u201cScience\u201d published in its October 3 issue an article describing the results of an experiment carried out in order to evaluate the editorial practices of so-called open access scientific journals. The experiment was carried out by John Bohannon, who wrote a series of false articles in which they reported alleged anti-cancer properties of a certain lichen and sent it to more than three hundred free access journals, being accepted for publication in more than half. Free access magazines, which can be consulted free of charge via the Internet, are supported by the quotas charged to each author by the publication of his article. This last contrasts with classical journals that require a subscription, which is typically paid by the libraries that acquire them. As the investigation of \u201cScience\u201d reveals, the funding model of free access journals has led to the emergence of unscrupulous publishing companies that have done business by publishing scientific articles of dubious quality through the payment of a quantity of money, which can reach The above, while not surprising, is not without concern, since free access magazines are advantageous for many libraries and researchers in view of the high costs that some scientific journals have achieved, particularly those published by large private publishing companies. In some cases these costs are so high that journals have been out of reach of many libraries. Thus, the free circulation of scientific research results is impeded, an indispensable condition for the progress of science. Research published by \u201cScience\u201d has also provoked criticism. Some claim that it constitutes an attack against free access journals, which in some cases have publication standards similar to those of classical journals. It is pointed out, for example, that the study should have been extended to classical journals, some of which would surely have also fallen into the trap and accepted the article. It is also noted that the article of \u201cScience\u201d is tendentious and goes against the science that is done in developing countries. Thus, the names of the authors of false articles were generated permuting African own names and including randomly This resulted in fictitious names such as \u201cOcorrafoo M.L. Cobange\u201d, who would work as a biologist at the \u201cWasse Institute of Medicine\u201d (non-existent) in the city of Asmara \u2013 this if real \u2013 in Eritrea. We could ask ourselves why Bohannon chose Africa as the place of residence of his fictional authors and did not place some, for example, in the United States, in which case a possible author might have been John Smith, an employee of a dark university in that country. According to Bohannon, he did so \u201cwith the purpose of not creating suspicions in case a curious publisher unsuccessfully sought the name of the alleged author on the Internet.\u201d This, which is only moderately convincing, perhaps reveals prejudices \u2013 unfounded in many cases and possibly valid in others \u2013 towards the science of developing countries. With the same logic, in order not to rat out a native English speaker as the author of the fake article, Bohannon translated the text into French using \u201cGoogle Translate\u201d and from there. Bohannon mentions in his article that the country with more publishing houses that accepted the fraudulent article is India, followed by the United States. On the other hand, although the flow of money for payment of quotas originates largely in developing countries, according to Bohannon the money finally ends up in a bank in the United States or in Europe. Moreover, in some cases they are highly prestigious publishing companies that are at the end of the process. As the Internet developed new possibilities of communication for science were opened up. At the same time, as \u201cScience\u201d expresses, a kind of \u201cwestern savage\u201d scientific communication was generated, with unhonest publishing houses taking advantage of the occasion and doing unclear business. Situation that, however, will surely be normalized in the future as the polvareda and free access magazines reach the place they deserve. And Bohannon\u2019s article, with all the criticisms that can be made, will undoubtedly contribute to this. The experiment also points to another worrying aspect: Bohannon could This is alarming not only because of the fact itself, but because of what this number expresses as regards the explosion in the number of research journals. Let us only hope that once the wild west becomes civilized, the number of scientific journals will be reduced considerably. Otherwise, which researcher will be able to read everything that is published today in your field? Plus what accumulates in the week.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d3/Albert_Einstein_Head.jpg": "One of the pillars of current science is the so-called \u201cpeer review\u201d, by which an article submitted for publication to a specialized journal is sent by the editor of the journal to one or more referees to assess its scientific quality. Based on the report or reports received, the editor decides to accept or reject the article in question. It has not always been so, however. An example in this regard are the three articles \u2013of enormous scientific relevance \u2013 published by Albert Einstein in 1905 in the magazine \u201cAnnalen der Physik\u201d \u2013the so-called articles of the \u201cAnnus mirabilis\u201d\u2013. These articles \u2013including the one in which Einstein makes known his famous theory of relativity\u2013 were accepted for publication by Max Planck \u2013the editor of the journal \u2013 without resorting to external reviewers. However, with the explosion and specialization of scientific knowledge \u2013and as a result of the number of articles published\u2013 that took place throughout the twentieth century, the editors of scientific journals had to turn to experts on the subject of the article in question, in order to decide their acceptance or rejection. This problem, however, seems to be less than the one that has been raised by the emergence of the Internet with all the new communication possibilities that it offers. In fact, in the number of this week, it should in principle ensure that this article represents a scientific advance, in the worst of cases it contributes to preventing the proliferation of articles of little or questionable value. Despite its virtues, however, the peer review system also has its flaws. Thus, since it inevitably involves elements of subjectivity by editors and reviewers, it has led to the rejection of articles describing the results of research that have subsequently proved to be of great relevance. In an article published in 2009 in the journal \u201cScientometrics\u201d by Juan Miguel Campanario of the University of Alcal\u00e1, in Spain, it has led to an account of the problems that future Nobel Prize winners have had in publishing the results of the work for which they were subsequently awarded. These journals, which have an electronic format, can be consulted free of charge via the Internet. Traditional research journals are edited in some cases by scientific societies and in others by private companies. The cost of operating these journals is commonly covered by the sale of subscriptions to universities and research centers. Free access journals, in contrast, operate by charging a fee to the author or authors of the article to be published \u2013typically, between $1,000 and $2,000 per article\u2013, a situation that, according to John Bohannon of Harvard University, has led to the appearance of more concerned scientific journals in the business of charging fees to their authors that in ensuring that what they agree to publish complies with a minimum of quality. \u201cScience\u201d comes to this conclusion through an experiment carried out by John Bohannon of Harvard University with a large group of free access magazines, some published by private publishing houses of recognized prestige. The purpose of the experiment was to find out how much For this purpose, he wrote an article describing the alleged anticancer properties of a certain plant and sent it to 306 journals.According to Bohannon, the article had so many flaws that any competent specialist could easily detect them and recommend that it should not be published.The article in question was, however, accepted for publication in 157 journals, being rejected only in 98.Of the remaining 49, no response was obtained.According to Bohannon, of the 255 articles that were accepted or rejected, 60% did not show signs that they had experienced a peer review process. Also, of the 106 that appear to have gone through this review, 70% were accepted. Faced with the opportunity offered by the new electronic media, it is not surprising that a multitude of publishing companies with little professional ethics emerged and published, for a fee, scientific articles that falsely claim to go through a rigorous peer review process. This is certainly alarming. In the field of scientific publications they have also agreed to publish the article with fictitious results. Some subscriptions of successful journals published by private companies have reached stratospheric prices \u2013 in some cases up to $20,000 per year. This limits the dissemination of research results and therefore hinders scientific progress. In this context, the option offered by free access journals is attractive. As long as, of course, the research published there is not fictitious.",
    "https://upload.wikimedia.org/wikipedia/commons/0/0f/East-Hem_050ad.jpg": "Two hundred years ago Robert Malthus argued that since the world\u2019s population grew faster than food production, the number of inhabitants of the planet would reach a limit beyond which the available food would not be sufficient for the entire population. At this point, various mechanisms would emerge that would act to limit the growth of the population beyond the limit of sustainability. These mechanisms would include wars, famines and epidemics, caused by unhealthy living conditions. Since the times of Malthus, however, the world\u2019s population grew by a factor of seven \u2013 from about one billion people in 1800 to more than seven billion today \u2013 a growth that Malthus could not have foreseen and that has been possible thanks to the great increase in the efficiency of food production brought to us by agricultural technology. In the last two centuries, moreover, the standard of living of a significant percentage of the world\u2019s population \u2013 which, however, lives to a large extent in developed countries. At a high cost, it has led to an overexploitation of the planet's resources, which is certainly the cause of the coup.In this regard, last Friday the United Nations Intergovernmental Panel on Climate Change (IPCC) released in Stockholm, Sweden, a summary of its fifth report on global warming and climate change, with conclusions that are not expected to be less shocking.With sound scientific arguments, the panel of experts that make up the IPCC confirms that the burning of fossil fuels generates greenhouse gases that are producing a global climate change that, if not stopped, will lead to unprecedented situations. These include: an increase in the level of the oceans between 40 and 80 centimeters in 2100, an increase in the number of cyclones and periods of drought, and a change in rainfall patterns, which will increase the contrast between the dry regions and the humid regions of the planet. As the IPCC notes in its fifth report, the current level of carbon dioxide in the atmosphere is 40% higher than in the pre-industrial period. The conclusions of the IPCC, however, are disputed by some. In the last 800,000 years \u2013 i.e., from an age well before the emergence of modern man \u2013 this last data does not come, for obvious reasons, from a direct measurement, measurements carried out continuously since the late fifties clearly show that the level of carbon dioxide in the atmosphere is gradually increasing. The sustained growth of the level of this gas in the atmosphere is thus, and at least during the last fifty years, an incontrovertible fact. Concomitantly, during the last hundred years, and with the exception of the last decade and a period of time between the decades of the 50s and 70s, the temperature of the surface of the planet shows an upward trend. This also turns out to be an incontrovertible fact, which has manifested, for example, in the gradual decrease of the volume of glaciers and polar ices. On the other hand, since carbon dioxide is a greenhouse gas, the increase of the Earth's temperature is associated with the growth of its level in the atmosphere. In particular, the Heartland Institute, based in Chicago, Illinois, which released last week a paper in which it refutes the IPCC conclusions and the alarmists\u2019 list. Specifically, it argues that the decrease in the rate of growth of the Earth\u2019s temperature observed in the last decade proves that the temperature of the planet has stabilized and that there is no connection between carbon dioxide in the atmosphere and the increase in the Earth\u2019s temperature. The IPCC, for its part, notes that the Earth\u2019s temperature is commonly recorded in natural variations and that the slowdown in the recent temperature increase is one of these variations. Indeed, the IPCC shows that the average temperature per decade has increased gradually in the last three decades. It also estimates that the period 1983-2012 is likely to be the 30-year period warmest in the last 1400 years. The IPCC\u2019s conclusions are based on a review of specialized publications and have a solid scientific basis. Robert Malthus two centuries ago did not foresee that future technological advances in food production, which he would no longer see, would make it possible to multiply by a factor of seven the world\u2019s population \u2013 albeit with a good number of undernourished. In line with his concepts, however, the industrial revolution, with all its virtues, has generated a limiting factor in population growth, not so much because of famines, wars or epidemics, but because of the abuse we have made of our planet.",
    "https://upload.wikimedia.org/wikipedia/commons/6/6a/55cnc2a.jpg": "According to an article published this month in the magazine \u201cAstrobiology\u201d by scientists of the University of East Anglia in the United Kingdom, our planet is approaching the inner limit of the habitable zone around the Sun. Once outside this area, the heat of the Sun will be so great that it will make life on Earth impossible as we know it. Scientists estimate, however, that this will happen within several billions of years, when our Sun ages and increases its size, and as a result the habitable zone extends beyond the Earth\u2019s orbit. Thus, while life on Earth is irremediably doomed to disappear one day burned by the Sun \u2013 if not earlier by the effect of some natural catastrophe or caused by us \u2013 that day is so far away that it is not cause for major concern. As is the global warming that is experiencing our planet, it may not have such dramatic consequences as the Earth will suffer when it leaves the habitable zone, but it is just around the corner and not thousands of years away. Moreover, while global warming will involve In the next hundred years a maximum increase in the temperature of the Earth of only a few degrees Celsius, the consequences to the climate of our planet could be disastrous, as the experts argue. Global warming has had a greater presence than usual in the press in the last few days. This is due to the announced appearance next week of the fifth report of the Intergovernmental Panel on Climate Change (IPCC) of the United Nations. For this reason, the scientific journal \u201cNature\u201d published in this week\u2019s issue a special section on different aspects of global warming and consequent climate change. A version of the next IPCC report filtered to the press in June makes it clear to specialists that the panel will highlight in the official document that in the last fifteen years the average temperature of the surface of the earth has remained stable to a large extent, in contrast to the previous two decades during which that temperature increased to more than half a degree centigrade. This fact, which is against the predictions of the experts, has been used by the activists who deny the climate change, who argue that it constitutes a proof of more than half a centigrade degree. that global warming has stabilized and that it is not associated with the increase in the concentration of greenhouse gases in the atmosphere, which has gradually grown over the past two centuries. Thus, climate change skeptics consider that changes in the temperature of the Earth are fundamentally due to natural phenomena and that greenhouse gases produce only small effects. This view is not shared by climatologists who argue that the stabilization of the Earth's temperature over the last fifteen years could well respond to natural phenomena, but that the warming induced by greenhouse gases is underlying and that the rate of increase of the temperature of the earth's surface will resume once such natural phenomena disappear. It could also be that the extra heat produced by the greenhouse effect \u2013 whose existence is beyond doubt \u2013 would have been channelled to the bottom of the oceans and not to the surface of the Earth. Or, as a third possibility, that extra heat would never actually have reached the Earth, due to the reflection of solar radiation from suspended pollutants in the atmosphere \u2013 supposedly the result of the increase in industrial activity in Asian countries. In any case, the skeptics of global warming do not mention that although the Earth's temperature stabilized to some extent in the last 15 years, the first 12 years of this century are among the 14 hottest years since 1880. Earth's climate is so extremely complicated that many of the mechanisms that govern it are still out of the scientists' understanding. This has favoured groups of activists and organizations that deny global warming. One of these, the Heartland Institute, based in Chicago, Illinois, refers to the existence of two teams, the IPCC's Greens, who defend the existence of global warming and the Institute Heartland's Reds, who assume the opposite position. Thus, global warming would be a matter of faith to no small extent. It is not, however, and although many of the climate secrets are not yet understood, the majority consensus among climatologists is that global warming is real and that it is due to the increasing emission of greenhouse gases into the atmosphere. If not, humans may not be able to take advantage of all the years of life that the design of the solar system apparently has reserved for us.",
    "https://upload.wikimedia.org/wikipedia/commons/1/10/The_Rolling_Stones_Summerfest_in_Milwaukee_-_2015.jpg": "The term \u201cfracking\u201d is now in fashion. It has been for some time in the United States and in Europe, and it is increasingly so in Mexico in connection with the energy reform currently under discussion. In the current context, the word \u201cfracking\u201d, or hydraulic fracturing, refers to the technology used to facilitate the extraction of gas and oil from non-conventional deposits, which until recently were economically unworkable to exploit. With the help of the \u201cfracking\u201d technology, the United States has reversed the downward trend that its oil production maintained since 1986, which has increased year after year 2008. According to the \u201cAnnual Energy Outlook 2013\u201d of the Energy Information Administration of the United States, oil production in that country, which was 5 million barrels a day in 2008, increased to 6.5 million barrels a day in 2012. With respect to the production of natural gas, by means of \u201cfracking\u201d techniques, the United States increased its production of this fuel by 25% between 2005 and 2011. The \u201cfracking\u201d is so fashionable that it even has a presence in popular music. Thus, the term \u201cfracking\u201d is so fashionable. in the song \u201cDoom and Gloom\u201d by \u201cThe Rolling Stones\u201d \u2013 appeared on the album released in 2012 on the occasion of the band\u2019s 50th anniversary\u2013 Mick Jagger alludes to the search for oil using the \u201cfracking\u201d, singing: \u201cFracking deep for oil but there is nothing in the sump.\u201d The \u201cfracking\u201d is, however, a highly controversial technology, which suffers a strong rejection by environmental groups concerned about the damage that, according to them, causes to the environment. In particular, they point out its potential to contaminate aquifers with methane \u2013 the main component of natural gas \u2013 and with the chemicals used in drilling wells. Thus, while it has defenders \u2013 some of good faith and others who care for the big economic interests involved \u2013 the public image of the \u201cfracking\u201d does not necessarily enjoy good health. In the oil or slate gas deposits the fuel is trapped in a rocky substrate that is not permeable. It prevents its free flow into the well, which makes it economically invia ble. In addition, with the aim of optimizing the process of collecting fuel, once the well is drilled to the level of the deposit, drilling is carried out horizontally along the deposit. As mentioned above, a point of concern with the \u201cfracking\u201d technology is that chemical substances injected into the subsoil can contaminate aquifers; with the aggravating fact that these substances are not commonly made known by drilling companies, which makes it difficult to determine the possible degree of contamination of a given aquifer. This is not the only problem that environmentalists associate with \u201cfracking\u201d. They consider, for example, that during the extraction of methane gas a significant part of it escapes into the atmosphere and contributes to raising global warming. In this regard, it should be noted that methane is a greenhouse gas more powerful than carbon dioxide, which is primarily responsible for the climate change that afflicts the world. environmentalists are also concerned about the residual water from the drilling process of the wells, which returns to the surface contaminated with salts and radioactive waste. And if that were not enough, the practice of \u201cfracking\u201d has been responsible for generating medium-intensity earth tremors. According to the U.S. Department of Energy, our country has one of the largest reserves of slate gas. These are located in the states of Coahuila, Nuevo Le\u00f3n, Tamaulipas and Veracruz. Given this circumstance there are those who consider that in the slate gas is much of the future energy of the country \u2013 now that oil production is waning \u2013 and that this fuel will play a central role in energy reform.Not everyone agrees, however. And not only because of the impact to the environment that is attributed to the \u201cfracking\u201d, but because of the enormous amounts of water that are needed for the implementation of a well \u2013 at least 8 million litres of water, enough to provide 50,000 houses for one day\u2013. \u201cFracking\u201d is not an appropriate technology for our country, which is not characterized precisely by its abundance of water resources. Moreover, we should wait for hard data on the ecological impact of the practice of \u201cfracking\u201d, in order to determine its environmental dangerousness. At the moment this technology is under intense fire in Europe, and has even been banned in Bulgaria and France.",
    "https://upload.wikimedia.org/wikipedia/commons/9/94/TevereCastello-PonteSantAngelo.JPG": "The wolves are indeed animals with a bad reputation, which have often been considered the incarnation of evil. It is a wolf, for example, that in the first song of the Divine Comedy prevents Dante from approaching the luminous summit where he would find the path of lost virtue in the middle of his life. Centuries later, the children's tale of Little Red Riding Hood of the Brothers Grimm tells us of a little girl whom an evil wolf deceives and devours, as he had done before with his grandmother. The wolves as incarnation of evil also appear in Bram Stoker's novel \u201cDracula\u201d. When the protagonist Jonathan Harker, ignorant of the dangers that haunted him, approaches the castle of Dracula in Transilvania in the middle of a night lit by the full moon, he does it surrounded by howlings of wolves. Harker later finds that wolves obey Dracula, when he orders them to kill a woman who claimed to be kidnapped by the vampire. However, wolves are or have not always been considered evil entities. It is enough to remember the legend of Romulus and Remo, who at birth would have been abandoned to their fate in a basket in the Tiber River, succeeding in surviving breastfed by a wolf, an episode that would ultimately have led to the foundation of Rome. In another context, the nickname \u201cwolves\u201d is considered suitable for sports teams that require speed, aggressiveness or violence \u2013 as is the case with American football. In one way or another, wolves \u2013 not as symbols but as flesh and bone beings \u2013 do not enjoy our sympathy, as predatory and ferocious animals they are. And Hollywood films, in which humans become killer wolves on full moon nights, do not contribute to conquering it. Indeed, it is precisely Hollywood who is responsible that the silhouette of a wolf howling, having as a background the full moon, has become an iconic image of horror stories. But, what is really the reason why the wolves howllan? University of Parma, Italy, and a group of collaborators from several research centers in Europe, wolves howl to communicate with other wolves; and they do so in a conscious way and not only as an automatic response to a certain stress situation. They reached this conclusion by means of a study carried out in Austria with nine wolves kept in captivity, which was published on 22 August last in the magazine \u201cCurrent Biology\u201d. As part of the investigation, Mazzini and collaborators separated and took away from the group one of the wolves and recorded howls that the remaining animals issued in response. They did this 27 times, choosing each time a random wolf. At the same time, by means of a saliva analysis, they measured the level of stress that the wolves suffered by the fact that one of them was removed from the group. They found that the number of howls was in direct relation to the hierarchy that the segregated wolf had in the group, being more frequent when it came to the dominant wolf. Likewise, the frequency of howls of a certain wolf was related to the particular relationship that The researchers did not find a clear relationship between the level of stress and the frequency of the howls. In another series of experiments, a wolf was separated from the group and placed in a nearby place. The other members of the group could not see it but knew where it was. It was found that in only 2 of 27 experiments there were howlings 20 minutes after the separation. This contrasts with the experiments in which the segregated wolf was taken away from the group, where howlings were produced in 26 of 27 tests.Mazzini and collaborators concluded that howlings are the product of the conscious knowledge that wolves have of their situation and their surroundings and do not merely result from the level of stress they are subjected to. That is, howlings have a social basis, because for the group of wolves the role of the leader is important. A wolf also responds to the situation he experiences when separated from another wolf with whom he has a close relationship. However, John Teberge of Waterloo University, Canada, believes it is dangerous to extend results obtained with wolves. In captivity to those who are at liberty. For these, who can follow other wolves freely by smell, the function of howling may be different. He also points out that free wolves howl after waking up from a long period of sleep, for causes clearly different from those of experiments.If you can extend the results obtained with wolves in captivity to wolves in freedom is something that will have to be established with new research. It is, however, interesting to contrast the image of wolves given to us by the article of Mazzini and collaborators, with that common idea of these animals as killer beasts and incarnations of evil. And to note, moreover, that they do not need the full moon to howl.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d5/Desembarco_de_Col%C3%B3n_de_Di%C3%B3scoro_Puebla.jpg": "As the history books teach us, when in the year 1453 Constantinople fell into the hands of the Ottoman Turks, land trade routes between Europe and the Far East that had flourished for several centuries were obstructed. This led to the search for alternative marine routes by Portugal and Spain. In this context, between 1497 and 1499 Vasco da Gama made, financed by Portugal, a round trip by sea between Lisbon and the western coast of India, bordering the African continent by Cape of Good Hope. Vasco da Gama thus discovered, for the benefit of the Portuguese, a marine route practicable between Europe and Asia. Spain, for its part and as we know, sent Christopher Columbus to find a route to the East Indies traveling to the west. Which did not succeed, discovering instead the American Continent, which, of course, resulted in more impact, not only for Spain but for the rest of the world. Spices were one of the most valuable Asian goods for Europeans. Indeed, some consider that they were the main motivation for travel. And that led to the discovery of the New World, an event that changed the face of the planet and the course that would follow in the following centuries \u2013 and as an extra bonus, in case something was missing, to the discovery of chili and vanilla, spices that were unknown in Europe and that were later spread throughout the world.Why have we been so addicted to the consumption of condiments that have no nutritional value alone and only modify the taste of food? It has been argued that species have an antimicrobial action and that in times past were used to preserve food. Also that they contributed to masking the bad taste of them because of their putrefaction or fermentation. Or, that we have used them simply because we like their taste, explanation that, in the absence of objective evidence, it would be the best to be the simplest. Although it is not clear why we use spices, what we do know is that we have used them for a long time. At least six thousand years, as concludes one conclusion: This article appeared last Wednesday in the magazine \u201cPLOS ONE\u201d, published by a group of researchers led by Hayley Saul of the University of York in the United Kingdom. This article refers to a study of mineral remains of food preserved in prehistoric peroles found in the western Baltic region. According to Saul and collaborators, these remains, aged between 5750 and 6100 years, correspond to seeds of garlic herb (\u201cAlliaria Petiolata\u201d). These seeds have a strong flavor and little nutritional value, which, together with the fact that they were found in a greater quantity within the peroles than outside them and alongside the remains of terrestrial and marine animals, allows to conclude those researchers who were deliberately added to season the food.The authors of the reference article note that, at least in one of the cases studied, the habit of condimenting food preceded the introduction of agriculture in that region of Europe.This testes the notion that hunter-gatherers ingested plants only as a source of energy. the Baltic region 6000 years ago for the nomadic population must have been hard. And yet, according to Saul and collaborators, the hunter-gatherers who inhabited this part of Europe thousands of years ago had enough time and willingness to take the job of seasoning their food, no matter how much this was not indispensable for them to survive. The taste for the species that contributed to changing the world so radically 500 years ago would then have deep roots and would come from a long time ago.",
    "https://upload.wikimedia.org/wikipedia/commons/1/19/Oceano_Atlantico.png": "On the Day of All Saints of 1755, the city of Lisbon, the capital of Portugal, was shaken by a great earthquake with an epicenter in the Atlantic Ocean, about 200 kilometers from the coast. As a result, Lisbon was largely destroyed, both by the earthquake itself, as well as by the tsunami and fire that followed it. One of the buildings partially destroyed was the Church of Carmen, which at that time was full of people attending the religious celebration and on which the roof of the building collapsed. After the earthquake the church of Carmen \u2013 built at the end of the 14th century \u2013 was not rebuilt, but has been kept in a ruinous state in memory of the tragedy. The Church of Carmen in Lisbon was not, of course, but one of the many temples that have been destroyed by a tremor. More recently, in February 2011, the Anglican cathedral of the city of Christchurch in New Zealand was partially destroyed by a earthquake. Although fortunately on this occasion there were no mortal victims within the cathedral, it was rendered useless. In fact, it is currently in the process of being demolished, although the opponents to this happening have stopped the process that has become a political issue.In one way or another, Christichurch has for the moment been left without Anglican cathedral. To solve this problem immediately, Victoria Matthews, Bishop of Christchurch, resorted to a singular solution: the construction of a cardboard cathedral, same that began to operate last Sunday. The new cathedral is the work of the Japanese architect Shigueru Ban that has been characterized by the use of non-conventional construction materials; in particular, by the use of large cardboard tubes as structural elements. Christchurch\u2019s new cathedral, has a capacity for 700 people and resembles a large triangular tent. The body of the building is formed by 98 cardboard tubes of 60 centimeters in diameter and 20 meters in length. According to its designer, the construction will have a life time of 50 years. In relation to this, the question that arises immediately is whether cardboard tubes will not get wet and soften with the first rains. In addition, the roof of the building is made of waterproof polycarbonate for the protection of cardboard tubes. Shigueru Ban has used cardboard tubes to design structures and solve problems in various emergency situations. Among other things, he has designed and built tents for refugees in Rwanda at a cost of $50 per unit, as well as divisions in the shelters that were implemented for earthquake victims that devastated northern Japan in 2011; the latter in order to provide them with a certain degree of privacy. He also designed a church with cardboard tubes as structural elements after the earthquake that affected the Japanese city of Kobe in 1995. After some time of use, this church was disassembled and moved to Taiwan where it was re-established, it is now permanently. A cardboard construction does not in any way have the potential durability that a stone or concrete construction has. Thus, while the new cathedral in Chistrichurch is estimated to have a 50-year lifetime, the church of the church in the church of the church of the church of the church of the church of the church of the church of Chistrichurch. Carmen de Lisboa survived for 350 years and the old cathedral of Christchurch did so for more than a century. On the other hand, according to the Japanese architect, the new New Zealand cathedral, built with light materials and therefore with little inertia, is resistant to earthquakes. This, of course, is important in a country like New Zealand, which is placed on the so-called ring of fire of the Pacific. From this last point of view, then, a cardboard building is superior to one of stone or concrete. As it is also from the point of view of the impact that its construction has on the environment and the use of natural resources, since the cardboard can be recycled. In addition, it is superior for its lower construction costs. A cardboard building, on the other hand, does not fulfill the function that, as Shigueru Ban expresses in an interview granted to the Japanese newspaper \u201cThe Japan Times\u201d, architecture has had to make visible the wealth or political power of those who do or have it. In this sense it will have to be recognized that a cardboard building is not as spectacular as a marble building or a Gothic stone cathedral. However, the spectacular nature of a building should not prevail over aspects of safety, environment and benefit to a majority of the population.",
    "https://upload.wikimedia.org/wikipedia/commons/4/49/Lelightbulbs.jpg": "On July 22, NASA released a photograph of the Earth taken three days earlier from Saturn by the Cassini probe, which the U.S. space agency has kept orbiting this planet since 2004. This photograph, in which Saturn\u2019s rings are spectacularly seen in the foreground, shows the Earth just as a pale blue light spot \u2013 although in an amplification of it they can see our planet and the Moon as two separate objects. This was to be expected, as the photograph was taken at a distance of almost 1.5 billion kilometers, which is approximately ten times the distance that separates Earth from the Sun. In order to promote interest in space and achieve greater support for its projects, NASA invited the general public through its website to say \u201chello\u201d to the camera at the time of taking the photograph to which 20,000 people responded. As expected, despite the large participation, no one appeared in the take-up with a loud hand. In fact, based solely on that photograph, an alien would not have been able to take the photograph. This, in contrast, would be evident from a photograph taken at a lower distance: let's say from a height of hundreds of kilometers above the earth's surface, which is the height at which most artificial satellites orbit. Indeed, a night-time photograph taken from this distance will reveal that the earth's surface is dotted with lights, which have appeared in a period of just a hundred years, and that in some areas these lights are brighter than in others that are in near-darkness. On the NASA website we find photographs of the Earth with which we can see the above. In them we can see that the intensity of the lights is associated with population density. Thus, the brightness is remarkably high in the large urban centers of the United States and is almost absent in places such as the Amazon rainforest, the center of Australia or the Sahara desert. We also learn that the inhabitants of the earth like to settle down on the coasts, judging by the higher density of light along them. Not necessarily, however, at a higher density of population corresponds to a greater intensity of light, as this also depends on the fact that the earth's inhabitants of being established on the greater density of light. Thus, we have that the regions with the greatest profusion of light correspond to the territories of the United States, Western Europe and Japan. China and India, which together comprise one third of the world's population, appear relatively less enlightened.As we know, electric light is a relatively recent invention, which gradually developed in the United States and Europe throughout the nineteenth century. In the last decades of that century, Thomas Alva Edison manufactured the first commercially successful electric lamp and with this began the age of light, until reaching the present time when there are areas of the world profusely illuminated and visible from space. The first commercial lamp developed by Edison was of the incandescent type and depended on a carbon filament to which an electric current was passed that considerably raised its temperature. As a result of the warming, the filament emitted light, whose hue depended on the temperature reached. Over time, the carbon filament was replaced by a tungsten filament, and it is in this form that the incandescent lamp has arrived. To this day, as one of the most used sources \u2013 although not the only one \u2013 to produce electric light.The incandescent lamp, however, is markedly inefficient, because only about 10% of the energy it consumes is transformed into light.This lamp is therefore not environmentally friendly and is being replaced by other significantly more efficient lamps.An option that turns out to be about four times more efficient is that of lamps based on light-emitting diodes, or LEDs, as they are commonly known.These lamps are still relatively expensive but, as they are efficient, resistant and durable, they are presented as the option that will prevail in the near future.However, even with the new more efficient lamps, some consider that energy spending on lighting is excessive in some regions of the world, given the climatic emergency that crosses the planet as a result of burning fossil fuels.In this regard, it should be noted that the world's lighting system consumes 19% of the electricity generated globally.With these numbers, it is not surprising that the lights that we artificially generate are visible from space. But fortunately not from Saturn.",
    "https://upload.wikimedia.org/wikipedia/commons/5/56/%C2%ABDiccionario_de_la_lengua_espa%C3%B1ola%C2%BB_%282014%29.jpg": "Even a man who is pure of heart / and prays at night / can become a wolf when the belladonna blooms / and the autumn moon shines.Attributed by Wikipedia to the screenwriter of the film \u201cThe Wolfman\u201d (1941).Despite what Hollywood says, it is highly unlikely that the full moon will have the power to transform a person into a werewolf, who attacks and kills all those whom he finds in his path with extreme ferocity. More likely this will not pass from being another invention of the film industry, based on European folklore. Some argue, however, that the Moon does influence humans, although not in such a dramatic way as to turn us into monsters. A quick review on Wikipedia gives us some examples: it is assumed that the full moon produces, among other things, an increase in human fertility, in levels of violence among humans, and in the possibility of dying in a surgical operation. It is also argued that the full moon influences our mental state. Proof of this latter is that there is even the term \u201c lunatic\u201d, which, according to the dictionary of the Royal Spanish Academy, refers to someone who \u201cdoes not suffer madness, does not continue, but by intervals.\u201d Despite its popularity, however, the beliefs about the influence that the full moon has on our behavior are nothing more than legends without more sustenance, no matter how much they have been around us for a good number of years. Although, after all, the influence of the full moon may be real in some cases. This, at least according to an article published this week in the magazine \u201cCurrent Biology\u201d, published by a group of medical researchers headed by Christian Cajochen of the Psychiatric Hospital of the University of Basel in Switzerland. In that article the results of the research carried out with the aim of finding out if the lunar cycle has an influence on sleep habits.The reference study was carried out with 17 young adults, men and women, with ages ranging from 20 to 31 years, and with 16 older adults, also men and women, with a mean age of 65 years. The researchers found that on the nights around the day in The moon reaches its maximum brightness, sleep undergoes clear alterations. Specifically, on average it takes five minutes more to reconcile it, we sleep about 20 minutes less, and we do it with less depth. An important point to point out is that the experiments were carried out during the years 2000-2003, and with a different purpose than that of the study we are dealing with \u2013 the original objective was to determine how age affects the patterns of sleep. Thus, the participants did not have preconceived ideas about the research in which they participated, and could not react subjectively, falsifying it unconsciously. In contrast to the process of transforming a human into a wereobobonic man \u2013which apparently, according to Hollywood, requires the light of the Moon\u2013, the effect measured by Cajochen and collaborators did not depend on the presence of a greater or lesser night shine, since the participants could not see the Moon. Thus, the researchers conclude that the association they found between a more intrachyl dream and the occurrence of the full Moon must be a reflection, not the fact that there is a greater amount of night light, but rather than the fact that the moon. The existence of a biological clock synchronized with the lunar cycle, which persists even in the absence of light or darkness. This, similar to how the biological cycle of sleep-vigility is synchronized with the day-night cycle. If what is reported by Cajochen and collaborators is confirmed, the full moon \u2013 or more precisely, the lunar cycle \u2013 would have an effect on our behavior. Not to the degree of becoming a werewolf, but in a more subtle way, altering our sleep. For now little more can be said scientifically about lunatics and the effect that the full moon exerts on humans. If we considered it as an argument for a film it would be too poor, since the full moon makes us sleep 20 minutes less a day does not seem to be a subject with which substantial profits can be generated for the film industry. Although for this industry scientific arguments are the least. To convince us, it is enough to observe the economic success that a large number of films have had in which humans appear to be transformed into fierce werewolves on full moon nights.",
    "https://upload.wikimedia.org/wikipedia/commons/c/ce/Buque_de_perforaci%C3%B3n_%28Drill_Ship%29_PACIFIC_KHAMSIN%2C_a%C3%B1o_2013%2C_fondeado_en_Tenerife.JPG": "Were the oil veneros written by the devil to us? If the question is taken literally we will hardly know it with certainty, for to begin with we would have had to prove the existence of the devil. If, on the contrary, we took it metaphorically \u2013 as far as the devil is concerned \u2013 we can say that L\u00f3pez Velarde was right, although the deed, like any demonic pact, would have had both negative and positive aspects.In fact, at the time L\u00f3pez Velarde wrote Suave Patria (1921) the oil industry in Mexico \u2013 which was born with the century \u2013 was on the rise, which continued in the decades that followed to become a fundamental support of the economy of the Country. We would have done this way a kind of pact with a metaphorical devil, which had to write us a wealth that allowed us to live with a certain drain. All this, of course, at a cost and oil also had to become a source of calamities of all kinds as we all know. On the other hand, Mexico has not been the only country to which the devil would have written oil springs. With coal and natural gas, they are the main sources of energy in today\u2019s world, and while it is true that the benefits of industrialization have not reached all the inhabitants or all regions of the world in the same way, we cannot deny that something has progressed in the last two centuries in terms of levels of well-being. Industrialization, however, also has its negative aspects. The prototypic example in this sense is global warming, a product of burning fossil fuels for two centuries that threatens to change the climate of the planet. A series of articles published in this week\u2019s issue of the magazine \u201cScience\u201d deals with another of the negative aspects of industrialization: the generation of earthquakes produced by the injection of fluids into the subsoil at high pressure. This injection is carried out in various circumstances. In the energy industry, for example, techniques of rock fracture in the subsoil are used to enable or increase the extraction of oil or gas. For this purpose, it is injected under pressure in the subsoil, water mixed with sand and certain chemical additives, a procedure known to be used with coal or gas. According to an article published this week by William Ellworth of the \u201cUS Geological Survey\u201d in \u201cScience\u201d, these micro-tremblers are too small to cause damage. Thus, of 100,000 wells that have been subjected to the rock fracture process, the largest tremor that has been generated had a magnitude of only 3.6. However, during the process a large amount of residual water is generated that is re-injected in the subsoil to a greater depth, a procedure that has been associated with the generation of mean magnitude tremors in the center of the territory of the United States. Among these are a tremor in the state of Oklahoma of 5.6 magnitude which in 2011 destroyed 14 houses. According to another article also appeared in the last issue of \u201cScience\u201d, published by a group of researchers from Columbia University in New York and the University of Oklahoma, medium magnitude tremors may occur in areas where rock fracture is practiced, as a result of large natural tremors occurring in remote places. This is the case of Chile in February 2010, Japan. In March 2011 and Sumatra in April 2012, which caused tremors in several states in the center of the United States. The use of rock fracture technology has spread in recent years in the extraction of the so-called shale gas from the subsoil, which has led to a considerable increase in gas reserves that are likely to be recovered. According to the Association of Natural Gas Suppliers of the United States, this technology has made it possible to increase the gas reserves of that country by 39% between 2006 and 2009. Rock fracture technology counts, however, also with critics, who claim that it has adverse effects on the environment. In particular, because of its potential to contaminate aquifers with fluids injected into the subsoil, and to the atmosphere by gas leaks from the wells; and, of course, because of its potential to produce earth tremors. Perhaps all this is part of the price that the devil charges us for providing us with new energy wealth \u2013 Mexico, in particular, it would count on one of the world\u2019s largest reserves of shale gas. When L\u00f3pez Velade wrote \u201cEl Ni\u00f1o Dios wrote a stable/and the oil veneers the devil,\u201d Mexico was in the process of changing from a rural society to an urban one, in which oil-based activities would inevitably grow in importance at the expense of those based on stables. Putting the latter ahead of the former then sounds like a misdemeanor. Although, on second thought, the price that the devil wants to charge us now for the new energies may be too great and possibly the Zacatecan poet after all was right.",
    "https://upload.wikimedia.org/wikipedia/commons/f/f4/Soyuz_TMA-5_launch.jpg": "With the last flight of the space shuttle programme carried out in 2011, the United States lost the ability to carry out manned space missions, in particular to the International Space Station. They were thus forced to resort to the Russian space agency that offers transport services, back and forth, to that station. Russian flights depart from the Baikonur cosmodrome, located in the Republic of Kazakhstan. This space port, founded in 1955, has played a prominent role in the space age. Hence, the rockets that orbited the first artificial satellite \u2013 the Sputnik I \u2013 and the bitch Laika, the first animal to travel into space. Baikonur were also placed in orbit by Yuri Gagarin, the first human in space, and Valentina Tereshkova, the first cosmonaut woman. Baikonur port has certainly been key in the history of space flights. Since the Baikonur Cosmodrome was launched as a military facility, it was chosen to establish a remote place in the then Kaz Soviet Republic of Somalia. Ajistan, about 200 kilometers east of the Aral Sea \u2013 in a region with sand storms and extreme temperature variations that reach 90 degrees Celsius throughout the year. The name Baikonur corresponded in fact to that of a small mining town located about 300 kilometers from the cosmodrome. The Soviets, caught up in the Cold War with the United States, gave the cosmodrome the name of the mining village \u2013 the same as its geographical coordinates \u2013 in order to hide its true location. Next to the cosmodrome a town was born to house its workers. This town was originally called Leninski. In 1995, however, it adopted the name of the cosmodrome \u2013 and, in the final analysis, the name of the small mining town used as bait to deceive spies. The current Baikonur is then a young town, with little more than half a century of antiquity. It is also a very peculiar town, with great contrasts, as described by an article that appears week in the newspaper \u201cThe New York Times\u201d authored by Andrew Kramer. Baikoiur is today the main door to space for manned flights \u2013 the only other door is the Chinese space center of Jiu Quan, in Inner Mongolia, which has a much smaller activity. \u201cDe Baikonur depends for its flights not only NASA, but also the European space agency, that of Japan and that of Canada, which have participation in the International Space Station. Baikonur and its cosmodrome are thus at the technological forefront in terms of space flights. At the same time, the town of Baikonur itself shows delays in other aspects. Thus, according to Kramer in his article, the first cell phones arrived in Baikonur just in 2005, and it was only until 2011 that the town had a medical diagnostic apparatus by magnetic resonance. At the same time, Baikonur suffers a process of urban degradation in which many abandoned buildings \u2013 being impractical in the extreme climate of the region \u2013 are occupied by waves of Kasajo nomads. And what is worse, the future does not look better. Baikonur was built by the Russians when Kazakhstan formed par with the Soviet Union. When it dissolved in 1991 and Kazakhstan became an independent country, the cosmodrome remained in Kasajo territory. In order to make use of the facilities of the Russian port, it pays Kazakhstan an income of 115 million dollars per year by means of a contract that will expire in 2050. Russia, however, has decided to build a space port in its territory, in order to \u201censure access to space\u201d, as stated by President Putin. The new space centre \u2013 the Vostochny Cosmodrome \u2013 is already under construction and will be located in the far east of Siberia. It is planned to be completed in 2018 and to transfer all Baikonur operations to the new space port in 2020. With this, the Baikonur Cosmodrome would disappear with its impressive spatial achievements, and Baikonur would surely become a ghost town by fading the agent that gave it life. A purpose not worthy of such a distinguished past.Baikonur, however, has a geographical advantage. With regard to the site of the new Russian space port: it is located at a lower latitude, closer to the Earth\u2019s equator. This is certainly an advantage, as it allows it to better take advantage of Earth\u2019s rotation to reduce the amount of fuel needed to place a weight in Earth\u2019s orbit. In this sense, the lower the latitude the higher the fuel saving will be. Russia, however, is a northern country without access to low latitudes and, in fact, this was the reason why it decided to build the cosmodrome in Kazakhstan. Considering only economic aspects, it could be advantageous for Russia not to fully transfer its space flights to the new cosmodrome. If its geographical advantage is worth to Baikonur to survive, it is something we will see in the coming years.",
    "https://upload.wikimedia.org/wikipedia/commons/4/48/Basketball.jpeg": "When, in 1863, London\u2019s football clubs and schools gathered in a tavern in the centre of the British capital \u2013 called \u201cFreemason\u2019s Tavern\u201d \u2013 to unify the rules of the game \u2013 which until then everyone practiced in their own way \u2013 they certainly never imagined the impact that their initiative would have on the course of the years. Indeed, given the leading role that the British played in the world at that time, organized football \u2013 the so-called association football \u2013 not only gained strength in the United Kingdom, but spread throughout the world. And it did so with such force and in such an exhaustive manner that, according to FIFA, football today has 250 million practitioners. Moreover, in the last half century this sport has become a multifaceted business of enormous dimensions, whose scope is not necessary to comment. Compared to its close relatives, rugby and American football, football association looks like a less dangerous sport. Certainly, as experts have documented, there is a lower chance of going out in football with a broken bone or a dislocated shoulder that In rugby. A feature of football, however, is the use of the head to hit the ball, and given that it has a weight of almost half a kilogram and that it can make contact with the head of the player at a speed of 80 kilometers per hour, one wonders if this is dangerous for health. This could be the case, according to Michael Lipton of Albert Einsten College of Medicine of Yeshiva University in New York. Lipton and collaborators carried out an investigation with 37 football amateur players, 28 men and nine women, with an average age of 31 years. Players had practiced football 22 years on average and all had had activity in the last year. The objective of the research \u2013 published this week in the magazine \u201cRadiology\u201d \u2013 was to find out if the continuous beating of ball against the head of a football player causes changes in the white matter of the brain. Experts know that white matter fulfills the function of connecting different parts of the brain where the information is processed, so that a damage to it will affect the cognitive functions. Lipton and collaborators found that white matter fulfills the function of connecting different parts of the brain where the brain is processed. that the brain of the players who headed the ball a number of times beyond a threshold value \u2013 between 885 and 1,550 times per year, according to the region of brain considered \u2013 showed alterations in white matter that are associated with cognitive deficiencies in patients who suffered a medium-intensity concussion. They found, moreover, that players with more than 1,800 heads per year \u2013 about five per day \u2013 tended to obtain lower marks in memory tests than those who nodded less frequently. Thus, while gliding a football for one time probably does not generate greater problems, according to Lipton doing so repeatedly has a cumulative effect and leads to alterations in the integrity of the white matter. He warns, however, that the results of his study are preliminary and that they were taken with a small sample of players. It would then be necessary that they were confirmed by other independent investigations.If the results were confirmed, the solution for children and amateur players \u2013 who do sport for taste and for the benefit of exercising \u2013 would simply avoid faltering the ball. In fact, Lipton advises that , as a precaution, this is done in trainings, during which it is more frequent to head balls. As for professional players, the danger of brain damage could simply be taken as a professional risk. After all there are professional sports more dangerous to the brain, as is the case with boxing, in which \u2013 for the benefit of the business \u2013 details regarding the safety of competitors are overlooked.Another solution could be a change in the rules of association football. Thus, in the same way as it was forbidden to use the hands to carry the ball in the rules written in the \u201cFreemason \u0301s Tavern\u201d 150 years ago \u2013 and that is allowed in rugby and in American football \u2013 the new rules could forbid to play the ball with the head intentionally. It must be admitted, however, that the latter would change the football substantially and therefore it would be unlikely to be carried out.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d7/Unidentified_disease_on_potato_leaf.jpg": "When an impoverished Irishman in the nineteenth century made the decision to leave his country to prove his fortune in the United States, Australia or another distant country, he was certainly aware that he would never return to his land or see his family again. Likewise, his relatives knew that the farewell was forever and in that spirit they were. By searching the Internet one learns that in the vicinity of the town of Falcarragh in northern Ireland, there is a small stone bridge called the \u201cPuente de Tears\u201d. Until there the relatives of the emigrant used to accompany him on his way to the port of Londonderry, where he would embark to begin his adventure in search of a better life. The family went no further than the bridge, so that there was the farewell there. Thus, under the circumstances, \u201cPuente de Tr\u00f3rres\u201d is undoubtedly a successful name.Irish emigration, which existed since the beginning of the nineteenth century, accelerated in the decade of the forties of that century by the plague that destroyed the seed of pope, a tubercle from which he depended entirely a third of the population for his food. The famine that followed the plague caused the death of one million Irishmen and the emigration of another. As a result, the population of the island, which numbered about 8.5 million in 1845, decreased to 6.5 million in 1852. It is known that the pope is native to the region of Lake Titicaca on the border between Peru and Bolivia. There it was discovered by the Spanish conquerors who took it to Europe in the second half of the sixteenth century, becoming over time an important source of food, particularly in Ireland. The cause of the famine of the pope was the fungus \u201cPhytophthora infestans\u201d that specialists believe is native to the Valley of Toluca. Europe remained isolated from this pathogen for about three centuries; until it made its appearance on that continent in 1845. It was thought that the famine of the potato was caused by the strain US-1 of \u201cP. infestans\u201d. An article appeared online this week in the magazine \u201ceLIFE\u201d, however, refutes this belief, and finds that the famine of Ireland was actually caused by a strain \u2013 named HERB-1. \u2013 originated in Mexico at the beginning of the 19th century. This strain spread to the United States and from there to Europe, to finally disappear at the beginning of the 20th century. The reference article is the result of a genetic study carried out by an international group of molecular biologists headed by Kentaro Yoshida of \u201cThe Sainsbury Laboratory\u201d in the United Kingdom, which deciphered the genome of the microorganism causing the famine of the potato. The study was carried out with dried leaves of potato plants attacked by the fungus, which were obtained from European herbariums. It is not clear why the strain of \u201cP. infestans\u201d disappeared, but, according to Yoshida, it is possible that this occurred when the first varieties of potato resistant to the microorganism were created at the beginning of the 20th century. Although in the case of the Irish famine the events occurred relatively little time ago, genetics have also been useful to investigate events that occurred in later times. a group of researchers from institutions in Europe and the United States \u2013 recently published in the magazine \u201cPlos Pathogens\u201d \u2013 who identified the bacteria \u201cYersinia Pestis\u201d as the cause of the so-called Justinian plague, which struck the Roman Empire of the East in the 6th-VIIIth centuries of our Era. This conclusion was reached after studying skeletons of victims of the epidemic from a cemetery of the time, which showed the presence of DNA from \u201cYersinia Pestis\u201d. Justinian\u2019s plague, according to some, could have caused up to 25 million deaths and caused the weakening of the Roman Empire. Centuries later, the same bacteria caused in Medieval Europe the epidemic known as the \u201cBlack Death\u201d, which also resulted in tens of millions of deaths. Research that unraveled the origin of the famine in Ireland and the plague of Justinian are examples of how modern genetics \u2013 employing methods that would have long ago been magical \u2013 can help us to unravel traumatic events of the past. These events are, of course, essential to prevent them in the future. Something that the 19th-century Irish or the Byzantines of the 6th-VIIIth centuries would certainly have been appreciated.",
    "https://upload.wikimedia.org/wikipedia/commons/3/39/Luigi_galvani.jpg": "For those students who have problems with their mathematics course and are concerned about their next exam, a group of researchers from Oxford University in England offers them a solution: stimulation of a particular region of their brain by means of light electrical shocks. With this treatment they will manage to increase their ability to perform mathematical calculations and they will obtain a better qualification in the exam. This at least according to the results of a study carried out by that research group, headed by Albert Snowball, and published this week in the magazine \u201cCurrent Biology\u201d. The relationship between electricity and living matter was discovered at the end of the 18th century by the physicist and physician Luigi Galvani by accidentally touching with a knife a frog leg hanging from a hook and observing that it contracted. Galvani postulated from this experiment that the leg muscles were triggered by the effect of the \u201canimal electricity\u201d that was intrinsic to living matter, and that it was driven by the nerves towards the muscles. This seems to be what Mary Shelley had in mind when she published in 1818 the novel Frankenstein, which deals with Victor Frankenstein and his misfortunes. This character, as a teenager, lived obsessed with alchemist texts and with the search for the \u201celixir of life.\u201d Despite his initial enthusiasm, these texts soon began to disappoint him and abandoned them definitively when he entered the University of Ingolstadt. It was not the same, however, with his obsession with the search for the source of life. Thus, with the knowledge acquired and his own research, he created in Ingolstadt a monster of two and a half meters high uniting pieces of corpses. Shelley does not detail the procedure that Frankenstein followed to bring his creation to life, but it is thought that he involved the use of electricity, because in a scene of the novel the protagonist is very impressed when he witnessed a lightning that fell on an oak completely destroying it. Although the concept of electricity as the generating force of life over time fell into disrepute, studies on the effects of electricity on living beings took hold. Giovanni Aldini, the grandson of Luigi Galvani and a fiery advocate of his ideas, contributed a great deal to this. Aldani carried out studies on muscle stimulation through electric currents. He also carried out public demonstrations that included the use of electricity to provoke the movement of corpses of executed criminals who received a lot of publicity. In these conditions, it is not difficult to understand that Mary Shelley had conceived electricity as a means of encouraging her monster. In addition to her experiments with criminals, Aldini was interested in the therapeutic applications of electricity and used it to cure mental disorders. These studies originated the electric shock therapies used today for the same purpose\u2013and that they are still controversial, among other things, because of their side effects.The technique used in studies reported by Snowball and collaborators in \u201cCurrent\u201d Biology is called \u201cIntercranial stimulation by random noise\u201d and also has its origin \u2013 ultimately \u2013 in Aldini\u2019s studies. The electrical currents employed are, however, very small, so that the technique is not traumatic at all. The studies, which lasted five days, were carried out with 25 students from Oxford University, which were divided into two groups. To one group applied the technique of inter-cranial stimulation, while to the other only its application was simulated. At the end, arithmetic tests of two classes were presented: tests of memorization of arithmetical operations such as 4x8=32 and tests that demanded solving a series of steps such as 32-17+5=20. The number of correct responses and speed with which they were achieved was evaluated. The study found that students who had received brain stimulation obtained better marks in both types of tests. In addition, in tests carried out six months later, without further stimulation, they found that those students who had received the stimulus exceeded the other group in the test involving operations of brain stimulation. In the memorization test, in contrast, no difference was observed. According to Roi Cohen Kadosh, one of the authors of the reference article, quoted by the journal \u201cScientific American\u201d, \u201cif it is shown that inter-cranial stimulation is safe and effective for larger groups of students, the technique could modify traditional forms of study. Some will say that those who are bad in mathematics will remain the same. This may not be the case.\u201d Time will give us the answer. What is certain is that even using sophisticated learning techniques, students will depend largely on their personal effort to obtain better grades in mathematics.",
    "https://upload.wikimedia.org/wikipedia/commons/5/52/MomiaChinchorro.jpg": "As the Chilean newspaper \u201cLa Estrella de Arica\u201d recounted in its October 19, 2003, edition, when \u00d3scar Mu\u00f1oz \u2013who had as his hobby the search for objects of historical value in the desert salty region of Atacama \u2013 was digging in a church in the village of La Noria, he found a mummified body apparently human, wrapped in a white cloth and tied with a purple ribbon. The finding would not have been particularly noticeable if it were not for the average body only about 15 centimeters, had a disproportionately large head, and had only 20 ribs instead of 24 as it is normal. With these characteristics, he should not be surprised that the UFO enthusiasts considered it to be the remains of an extraterrestrial visitor. A DNA study of the body carried out by Stanford University in the United States and made known in the past days, however, showed conclusively \u2013 to the disappointment of the believers in the extraterrestrials\u2013 that it was human remains. It was also determined that the subject had possibly died a few decades ago, at an age between six and those eight years, and that her mother was an indigenous woman from northern Chile. On the other hand, the reason why she died was only 15 centimetres for the time being without a firm explanation, as well as other anatomical traits. Although La Noria\u2019s finding happened almost a decade ago, in recent weeks it was broadcast in the United States media on the occasion of the promotion of the documentary \u201cSirius\u201d, which deals with the presence of extraterrestrials on our planet. \u201cSirius\u201d is part of the so-called \u201cDisclosure Project\u201d promoted by Steven Greer, which aims to expose the US government\u2019s alleged efforts to hide the presence of extraterrestrials on Earth. Greer is a doctor of profession who after working for a time as such became an expert on extraterrestrial issues. According to Greer, the US government has an interest in hiding the visit of extraterrestrials to our planet because of the impact that the world would have if the secrets of the energy used by extraterrestrials were revealed to propel their ships along interstellar distances. Clean and infinitely superior to everything we know, we would dispense with fossil fuels and change the global economic order. We would ensure the supply of energy for industry and transport, while at the same time solving the problem of environmental pollution that threatens the collapse of the planet. We would solve, in short, the problems of poverty, scarcity of natural resources and inequality in the world. In the promotion of the documentary \u201cSirius\u201d, released last April 22, the mummie found in La Noria was manipulated, presenting it as a test of the presence of extraterrestrials on Earth. The documentary itself, however, included the results of research carried out at Stanford University that demonstrate their terrestrial origin. In another related action, the organization \u201cParadigm Research Group\u201d, held this week a meeting in Washington, D.C., called \u201cCitizen Hearing on Revelation\u201d, in order to discuss the presence of extraterrestrials on our planet and to convince the Congress of the United States to take the issue seriously. In order to give credibility to the meeting, its organizers invited to six former congressmen, who were paid $20,000 each for their participation. According to \u201cThe New York Times,\u201d the motivation of former congressmen to participate in the meeting \u2013 apart from the $20,000 fee \u2013 could have been curiosity. According to Carolyn Kilpatrick, former representative for Michigan, \u201cOur country has trivialized the issue, has made it a joke. Now I find that it\u2019s much more than that. And it\u2019s not a joke. And there\u2019s scientific data that shows that there may be something out there.\u201d The fact is that, given the huge number of stars in our galaxy, it is accepted that there are very likely to be inhabited worlds, especially now that we know of the existence of numerous planets orbiting stars. In this regard, this week\u2019s issue of the magazine \u201cScience\u201d includes a special section on exoplanets \u2013 planets outside the solar system \u2013 where 900 of these have been detected to date and that several thousand more are under investigation. Any inhabited planet, however, will be at a phenomenal distance, so that it is extremely small. The probability that its inhabitants have chosen us, in the first place, to make a visit and, in the second place, that they have had the means and the desire to make such a long trip for unclear purposes.In spite of this, it might be incomprehensible that there are groups in the United States pushing forward ideas that are wildly desirable. It is not, however, when we take into account that, according to a recent survey, a third of Americans believe in the presence of aliens on our planet, another 50 percent are not sure, and only 17 percent think it is a hoax. Moreover, 79 percent believe that the government keeps secrets on this issue. With these numbers, the issue has an obvious political interest.",
    "https://upload.wikimedia.org/wikipedia/commons/8/8c/Koekjestrommel_open.jpg": "In his autobiography, British philosopher and mathematician Bertrand Russell relates that when a child, in the second half of the 19th century, was strictly forbidden to eat fruit, because it was considered bad for children\u2019s health. Contrary to this, we now know that fruit is indispensable for a good diet. Despite the prohibition, Russell was a very healthy child, except for a benign measles attack that he suffered at the age of eleven. He was healthy, perhaps because of the apples he stole and ate in hiding, according to him himself.Today, although we have overcome the perception that fruit is harmful to the health of children, we are faced with a very serious public health problem associated with excess consumption of other foods: the global epidemic of obesity. Indeed, according to the World Health Organization (WHO), in 2008 more than 14 billion adults over 20 years old were overweight and of these, 200 million men and 300 million women \u2013 more than 10% of the adult population \u2013 were obese. WHO defines the degree of overweight according to the parameter. For WHO, a person is overweight when this index exceeds 25, while for values over 30 the person is classified as obese. The United States is one of the countries in the world where the obesity epidemic is the most severe. According to WHO statistics, 35% of Americans over the age of 15 were obese, while a total of 70% were overweight. These numbers rose to 45% and 80% in 2010. The figures, in addition to being alarming, are growing rapidly.In this regard, Mexico is not left behind and while in 2002 25% of all Mexicans over the age of 15 were obese, this number rose to 35% in 2010. In the last year, 73% of our compatriots over the age of 15 were considered overweight by WHO. The global obesity epidemic is due to excessive consumption of foods rich in fats and carbohydrates, as well as lack of physical exercise. It affects many countries. , not only industrialised, but also developing countries. It also affects both children and adults. In an article recently published in the journal Food Quality and Preference by a group of researchers from several European countries, results are reported from a work carried out in order to find out what determines the preference of children for certain flavors and foods, and thus obtain information that facilitates the fight against obesity. The research was carried out with 1,700 children, between six and nine years of age, from eight European countries \u2013 Italy, Estonia, Cyprus, Belgium, Sweden, Germany, Hungary and Spain. During the experiment, children were asked to eat two kinds of cookies: simple in one case, and with added fat, salt or flavoring \u2013 monosodium glutamate \u2013 in the other. They were also provided sugar-free juice with added sugar. After testing the foods, children were asked what they preferred, those simple ones without an additional flavor, or those to which they were added substances to modify their taste. In contrast, only 34% of the children preferred the cookie with flavoring.There were, however, differences between countries. Thus, while 85% of the children in Estonia liked the cookies with salt more, only 50% of the Cypriot children showed the same preference. Likewise, more than 70% of the German children preferred the cookies with fat, in contrast to 35% of the children in Cyprus. Similar results were obtained in relation to sugar. It was also observed that the taste for sugar and salt increases over the years, until reaching a maximum and decreasing when reaching adolescence. According to the authors of the study, their results show that the culture of each country defines to a certain extent the tastes of the children for the flavors. It also shows that these tastes are not unalterable but change throughout childhood. These results have value for the development of strategies, particular for each country, in order to attack the obesity epidemic that threatens to be affected by the epidemic of obesity. In the second half of the 19th century, when Bertrand Russell was touched by his childhood, children \u2013 at least those of the well-to-do class he belonged to \u2013 were not allowed to consume fruits with the consequent lack of nutrients necessary for the functioning of the body. More than a century later, there is, in contrast, a great permissiveness for children to eat all the food they want, with the disastrous result of which we are witnesses. It is worth here the popular wisdom: neither so much that I burn the saint, nor so much that I do not light him up.",
    "https://upload.wikimedia.org/wikipedia/commons/4/45/A_small_cup_of_coffee.JPG": "Self-medication, understood in a broad sense, is certainly a widespread practice. Thus, in view of the presence of a minor physical discomfort \u2013 of a stomach nature, of the airways, or product of a fall, to mention only a few \u2013 many of us will go without hesitation to the nearest pharmacy to acquire the medicines that we consider will provide us with relief. There will be those who, of course, lean for products of traditional medicine and prefer natural products, also self-medicated. Or, maybe they will decide to make use of recipes prepared with ingredients that are not necessarily medicinal, but whose combination, in their opinion, will provide the relief sought. In some extreme cases, self-medication is practiced even more serious situations, which fortunately are the least. This includes the use of antibiotics without medical prescription, a practice that until a few years ago was possible in our country. The existence of a practice of self-medication is not in any way surprising. In fact, we share it with other species. It is known, for example, that chimpanzees in equatorial Africa, when they suffer stomach discomfort due to parasites. These animals also ingest whole leaves which pass through the entire gastrointestinal tract without digesting themselves.The function of these leaves is to drag and expel the parasites lodged in the intestine.We may even have learned from animals to use certain natural products to stimulate us and cure diseases.In this sense, according to Michael Huffman of Kyoto University, the roots of a plant that is used in India as a cure for intestinal parasites are also consumed by wild boars in that country.It is also speculated that the use of Gabonese natives to a plant stimulating the nervous system was learned after observing the effects that the plant produces on gorillas and swine spins.According to legend, coffee was discovered after Kaldi, a goat herder in Ethiopia in the 9th century, observed that his animals were excited and acquired a great energy after eating the red fruits of a bush.Intrigated, Kaldi tasted those fruits and it was discovered. To share his finding, he filled the bags of red fruits and took them to a nearby monastery. There, the monks cooked them, resulting in a bitter and unpleasant liquid that they discarded by throwing it into the fire. With such good luck, however, that when the seeds were roasted they fired the characteristic aroma of coffee, which was thus discovered. Although Kaldi\u2019s story and coffee is probably only a legend, it is representative of the many stories \u2013 those yes real \u2013 about what the animals have taught us regarding the healing and stimulating properties of plants, a subject about which they seem to have a wide knowledge. Indeed, as discussed in an article published this week in the magazine \u201cScience\u201d, published by a group of researchers headed by Jacobus C. de Roode of Emory University in the United States, the practice of self-medication is common among animals. And not only for therapeutic purposes, to cure diseases, but prophylactic, to avoid them in case of a danger of infection. Self-medication is observed, In addition, not only among higher animals with a brain complex enough to learn by imitation, but also among insects, which, of course, constitutes an innate characteristic. Among insects, self-medication can be done in several ways. It can be individual and constitute a measure of self-protection. In other cases it can have a transgenerational purpose and be aimed at protecting offspring. This is the case of fruit flies that deposit their eggs on food with a great content of alcohol in order to prevent their infection by parasitic wasps. According to Roode and collaborators, the study of the forms of self-medication of animals, the result of millions of years of evolution, can help to discover substances to cure our infections, substances that will have a natural origin. Jacobus de Roode and collaborators also put into perspective the importance of self-medication among animals for the production of food. In relation to this, they point out that it is important that it does not interfere with the mechanisms of self-medication in order to avoid imbalances in the populations of parasites that could have negative effects. In agriculture, self-medication seems then to be a more common practice than one could have thought, and it is practiced not only by the human species but by a large number of animals.Even some with a low position on the evolutionary scale and with primitive brains, unable to make conscious decisions.This does not, however, free us from the responsibility of caring for our own self-medication practices \u2013 these are carried out in a well-conscious way \u2013 in order to avoid the proliferation of germs resistant to medical treatments within our reach.In particular, antibiotic-resistant microbes, whose development has been encouraged by the abuse of these substances, according to experts..",
    "https://upload.wikimedia.org/wikipedia/commons/9/97/Edgar_Allan_Poe%2C_circa_1849%2C_restored%2C_squared_off.jpg": "If the American novelist Edgar Allan Poe (1809-1849) had taken a century to be born, he would probably have written his short story \u201cThe Murders of Morgue Street\u201d differently \u2013 assuming, of course, that it would have been given to the task of writing it. As we know, this story revolves around the mysterious murder of two women \u2013 mother and daughter \u2013 in a room on the fourth floor of a Morgue Street house in Paris. The murders were carried out with such violence that the daughter\u2019s body was found lying face down in the firefire. The whole matter was a mystery, because despite the numerous witnesses who gathered at the entrance of the house when they heard the screams of the victims and quickly climbed the stairs to the fourth floor, once the door was forced, the murderer disappeared without being seen. This despite the fact that, in appearance, the attacker would have had to go down the stairs with what would have necessarily crossed with those who climbed.The mystery was solved by C. Auguste Dupin using investigation methods similar to those that characterized Sher Sher Lock Holmes years later. It turned out that the murders were committed by an orangutan taken to Paris from Borneo by a sailor and from whom he had escaped. Since these animals are adapted to live most of the time in the trees, the orangutan had no problem climbing through the chain of a lightning rod to the height of the window of the room on the fourth floor and from there jumping inside it. The escape after committing the murders did so by the same route, without the neighbors being aware. \u201cThe murders of Morgue Street\u201d was published by Poe in 1841, half a century before Juan Vucetich in Argentina first used the fingerprints \u2013 which are unique to each person \u2013 to solve a criminal case. Since the orangutan of Poe strangled one of the victims, his fingerprints must have been printed on the woman\u2019s neck. It would have been clear from an examination of those fingerprints that the killer was not human. Thus, Dupin\u2019s analysis capabilities would have been less critical to solve the case. After a century Poe would have taken 150 years to be born, he would have known that each individual could also be identified by his genetic code, which is equally unique. Thus, even if the information provided by the fingerprints of the orangutan had not been sufficiently accurate, from an analysis of the DNA of the hair locks that one of the victims ripped off the aggressor in the struggle, it would have been beyond doubt the non-human nature of the same. Now suppose an even greater delay in the birth of Poe, which would have happened just a few years ago. We assume, moreover, that \u201cThe murders of Morgue Street\u201d will be published in, say, 2030 and that Poe will make use of the forensic techniques available within two decades. What will these techniques be? Of course, we cannot know this with certainty, but an article published this week in the magazine Plos One by a group of researchers headed by Renato Zenobi of the Federal Technical School of Zurich, gives us a clue \u2013without very firm. According to Zenobi and collaborators, besides the genome and This conclusion was reached by an experiment in which the air exhaled by a group of volunteers was chemically analyzed over nine days. The researchers found that the chemical composition of the breath was particular to each individual. To be precise, the composition of the exhaled air changes during the day; for each person, however, there is a set of chemical compounds that is always the same and that constitutes his breath footprint.The fact that the breath constitutes a mark that allows to identify a person \u2013 like the genome and the fingerprints \u2013 is something that will have to be tested and in this direction the article by Zenobi and collaborators gives us only a first indication.In fact, these researchers do not mention the identification of people as a possible application of their discovery. In this regard, their interest is focused on the development of a medical diagnostic technique, complementary to the blood and urine tests that are practiced at the moment. That is, if the breathprint of a healthy person varies at a certain moment, this fact may be indicative that something More research will have to come to show if a person\u2019s breath is truly unique. This, however, does not prevent us from speculating about how a hypothetical Edgar Allan Poe would have written \u201cThe Murders of Morgue Street\u201d in 2030. Would the killer orangutan have been discovered by the foul breath with which he aired the room witness of his crimes?",
    "https://upload.wikimedia.org/wikipedia/commons/b/bc/Namib_desert_MODIS.jpg": "If you had an excess of $50 and you did not know what to do with it, one possibility is to invest them in the purchase of a \u201cfairy circle\u201d from Namibia. This amount is not excessive and there will be anyone willing to consider the purchase; subject, of course, to find out more about it. First of all, the $50 does not give you the right to take the circle home, but only to adopt it. In fact, it would not be practical to transport it from Namibia, a country located on the west coast of Africa, since these circles have a diameter of between 2 and 15 meters \u2013 and more than a considerable weight. While this may be disappointing, it is necessary to consider that your $50 will be channelled to the conservation fund of the Namibrand Nature Reserve in Namibia. The investment would not then have a materialistic motivation, but would largely constitute an altruistic action for the preservation of the environment. The central area of these circles, approximately circularly, is devoid of vegetation and is very commonly delimited by a strip of high grass. Namibian circles, with a density of between 11 and 47 circles per hectare, stand out clearly on the surface of the desert that covers grass lower than that of the periphery of the circle. From the air the impression that is obtained is that of a surface dotted with craters. The origin of the haunted circles has been a mystery. For the inhabitants of the place they are the work of the gods. For some lovers of esoteric explanations it is irresistible to associate them with extraterrestrial visitors. According to scientific specialists, however, enchanted circles must have a further explanation of this world. Scientific research on the origin of the Namibian fairy circles has been initiated four decades ago and in this regard many hypotheses have been ventured. In one case they have been attributed to emanations of poisonous gases of natural origin that prevent the growth of grass in the centre of circles. In another case, it has been associated with colonies of termites or ants that feed on the roots of plants. None of this hypothesis, however, has been convincingly proven and the origin of enchanted circles has been a mystery. One of the researchers who has endeavoured to reveal it is biologist Walter Tschinkel of Florida State University in Tallahassee. Comparing satellite photographs taken over four years, Tschinkel discovered that Namibian circles do not remain static but are \u201cliving\u201d, in the sense that they are born, develop and eventually disappear. Tschinkel determined that the average time between the appearance and disappearance of a circle is about 50 years. However, he could not find a satisfactory explanation for the origin of the enchanted circles, which remained wrapped up in the mystery. Norbert Juergens of Hamburg University, in an article published this week in the magazine \u201cScience\u201d, claims to have finally revealed the mystery. are the termites that devour the roots of the plants in the center of the circle and prevent them from growing. As is known, termites need moisture to survive. Fairy circles are located in a region with very low rainfall in which plants absorb scarce rain and prevent them from reaching the termites. This does not happen, however, in the vegetation-free regions of enchanted circles. There rain pervades the earth and is retained under the surface providing moisture to the termites. On the other hand, by the relatively high humidity in the center of the circle, the grass in the periphery finds favorable conditions to grow and reaches a higher height than that outside the circle. Furthermore, in times of drought, the termites feed on the roots of the peripheral grass, which causes the growth of the circles observed by Tschinkel. While for the non-experts the explanation offered by Juergens looks coherent, as is the usual not all specialists agree that the mystery of the enchanted circles would have been finally revealed. Tschinkel, In particular, in statements collected by \u201cScience\u201d, he points out that Juergens has not shown that termites are indeed guilty of the absence of grass in the center of enchanted circles. Thus, it seems that the mystery of Namibian circles will survive for some time longer. On the other hand, when the mystery becomes clear, it is possible that the fairy circles of Namibia will lose the charm that gives them precisely the halo of mystery that surrounds them. They would thus enter the category of natural phenomena, with a natural explanation also and therefore of this world.",
    "https://upload.wikimedia.org/wikipedia/commons/b/b2/N%2C7.jpg": "On Wednesday, March 19, NASA announced that the problem with the computer program that controls the Martian explorer \u201cCuriosity\u201d had been solved, and that within a few days it would resume its normal operation. That problem occurred on March 16 and affected one of the two browser control computers. Curiosity has two identical and redundant computers. Explorer control carries out one of these two computers, while the other acts as backup in case of need. On February 27, the computer that was in charge of the Curiosity control \u2013 computer A \u2013 suffered a failure in its \u201cflash\u201d memory. This forced NASA to suspend the normal operation of the browser and to initiate a transfer of control to computer B. The problem of March 16 occurred with this second computer, before that operation had been normalized. Curiosity, in this way, has faced two problems in the course of three weeks that have affected its two control computers and that have put it out of operation. As we know, the explorer \u201cCuriosity\u201d left Earth in November 2011 and arrived at the Martian surface in August 2012. With a weight close to a ton and the size of a compact car, the Curiosity has, among other objectives, to determine whether there are currently \u2013 or if there were in the past \u2013 the right conditions for the development of microbial life on Mars. For this purpose it carries on board sophisticated instruments to chemically analyze samples of the Martian soil and determine its mineralogical composition. Amid the problems that paralyzed the explorer over the past four weeks, NASA announced on 12 March that when analyzing the dust obtained by drilling a Martian rock, the Curiosity had found the essential elements for life: carbon, hydrogen, oxygen, nitrogen, phosphorus and sulfur. Significantly, it found them in the form of chemical compounds that could be exploited as food for bacterial life. All this, moreover, was found in a site that appeared to be the bed of an old lake fed by a river that would have descended from the hillside of a crater in the vicinity. An mineralogical analysis found that the rock was composed of clay to a large extent, which it appeared to be the bed of an old lake fed by a river. The \u201cCuriosity\u201d found then, for the first time, that there was in the past \u2013 at least in the place it is exploring \u2013 the right conditions for the development of bacterial life. This, of course, does not mean that it had actually developed, of which there is no evidence so far. The explorer also has as his objectives to study the climate and geology of Mars, as well as its conditions of habitability. In particular, he is measuring the level of high energy radiations that affect the Martian surface \u2013 cosmic rays and energy particles emitted by the Sun \u2013 that are adverse to life. On Earth we are protected from these radiations both by the magnetic field of our planet and by its atmosphere. Mars does not have a magnetic field and its atmosphere is much less dense than that of the Earth, so it does not enjoy the same level of protection. Knowing the radiation levels that reach the surface of Mars is thus a subject of great interest for future tripulate trips to this planet \u2013 however far they may be seen. Find out if on Mars there are or existed in the past the right conditions for the development of life is certainly not the only objective of the Curiosity, although it is the most publicized by NASA. This is understandable, as extraterrestrial life is a subject that greatly captures the public interest and can provide popular support for the activities of the space agency. Unfortunately, the explorer Curiosity experienced problems with his two computer systems before reaching one year on the surface of Mars. This contrasts with the explorer \u201cOpportunity\u201d that descended to the Martian surface in January 2004 and that even today, almost ten years later, is active. His twin, the explorer \u201cSpirit\u201d, who arrived three weeks earlier, also had a long life and was active until March 2010 \u2013 although he also had a problem with \u201cflash\u201d memory at the beginning. It also contrasts the cost of both missions: $2,500 million for the Curiosity and a combined cost of $820 million for the \u201cS\u201d. This difference in cost reflects the fact that the Curiosity is a more sophisticated explorer than its predecessors. Consequently, specialists expect that the information you send us about our neighboring planet will be proportionately richer and that, in particular, it will clarify if Mars was ever habitable \u2013 not by Martians but by simple microbes \u2013 and that it will let us know what the conditions of habitability of this planet \u2013 which would be our first option to migrate in case of need \u2013 are. Seen this, let us hope that the problems experienced by the Curiosity have been only occasional.",
    "https://upload.wikimedia.org/wikipedia/commons/b/bc/Krunkwerke_-_IMG_4515_%28by-sa%29.jpg": "Something unusual happened on our planet about 1,200 years ago; to be more precise, at some point during the years 774-775 A.D. To this conclusion came a group of Japanese scientists from the University of Nagoya, headed by Fusa Miyake, after studying the rings of the trunk of two cedars existing on Yaku Island in southern Japan. It is known that cedars living on this island are extremely longevous. An extreme case in this sense is the so-called Cedro Jomon \u2013 with a height of 25 meters and a circumference of 16 meters\u2013, which is estimated to have an age of up to 7,200 years. Tree rings are formed because throughout the year their growth rate changes, especially in temperate climates where there is greater climatic variation between seasons. Thus, in the spring the growth is faster and the resulting wood less dense, in contrast to the subsequent months in which growth is slower and the wood denser. Thus, in normal conditions each ring corresponds to one year and its number indicates us the age of less dense wood, in contrast to the subsequent months in which growth is slower and the densest. The succession of rings of a tree, whose thickness varies year by year, gives us additional information about the environmental conditions in which it grew. Thus, a greater thickness indicates a favorable year with a high rate of growth, while a smaller thickness tells us about the adverse conditions through which the tree passed that year. Tree rings can also provide us with another type of information. Indeed, studying the cedars of Yaku Island, Miyake and collaborators found that the rings corresponding to the years 774-775 A.D. show an increase of 1.2% in their carbon concentration 14. Carbon 14 is taken by the plants of the atmosphere and incorporated into its organic tissue \u2013 together with carbon 12, most common \u2013 through the process of photosynthesis. The increase of this element in rings corresponding to specific years, is then an indication of an elevation of the concentration of carbon 14 in the atmosphere in those same years.What caused this increase? Specialists know that carbon 14 in the atmosphere has its origin in the interaction of that atmosphere with cosmic rays and other radiations of high energy that arrive in the same years. The rise in the concentration of carbon 14 in the atmosphere that occurred in 774-775 AD was then due to an increase in the intensity of radiation from outer space. In turn, these radiations originate during the explosion of a star or a solar flare. Miyake and collaborators ruled out the first possibility, since there are no historical records that an event of this type has been observed that should have been clearly visible. Japanese researchers also did not consider that what happened in 771-775 AD would have originated in a solar flare, as this should have been too large and should have caused major problems to the Earth \u2013 including a substantial reduction in the level of ozone in the atmosphere and the consequent exposure of living species to high levels of ultraviolet radiation \u2013 which did not occur. Thus, Miyake and collaborators did not find an explanation that satisfied them and left the matter as a mystery in search of an explanation. In an article published online this week in the journal \u201cGeophysical Research Letters\u201d by researchers from Washburn University and University. In the United States, it is argued that Miyake's calculations and collaborators are wrong and that there is no need for levels of space radiation as large as those that these researchers had supposed to provoke the event of twelve centuries ago. They conclude that the Sun is the main suspect of having provoked it. At such a remote time, the date of the development of technologies such as telecommunications and electrical power generation was far away. In this regard, Charlemagne avoided concerns, as if he had known them with certainty he would have used them in his wars of conquest. Thus, he would have suffered great setbacks at the time of the coup of extraterrestrial radiation, because both telecommunications and electricity distribution networks are greatly affected by solar storms. In this connection, it would have to be remembered that a solar storm in March 1989 left Quebec without electric power for nine hours. The solar blow of 774-775 AD certainly did not affect electrical installations, as these did not yet exist. In contrast, a coup of equivalent intensity at present time would have much greater security consequences. solar storm of 774-775 A.D. was neither catastrophic for Charlemagne nor possibly for his contemporaries, the episode reminds us of the threats coming from outer space to which we are permanently exposed.",
    "https://upload.wikimedia.org/wikipedia/commons/e/e8/Lake_Vostok_Sat_Photo_color.jpg": "On Thursday, March 7, the Russian news agency RIA Novosti published statements by Russian scientist Serguei Bulat of the Institute of Nuclear Physics of St. Petersburg, according to which they would have discovered in Lake Vostok in Antarctica a type of bacteria hitherto unknown. Such bacteria were found in water samples extracted from Lake Vostok by the Russian expedition to Antarctica during the southern summer of 2012. Lake Vostok is not any lake. Far from this, it constitutes a huge body of underground water \u2013which in volume constitutes the sixth largest lake in the world\u2013, buried by an ice layer of about 3.5 kilometers thick. The existence of Lake Vostok was suspected since the 1950s, although this was not confirmed with certainty until four decades later by means of radar images taken from space. After a good number of attempts to drill the ice layer and access Lake Vostok to take samples of water, a Russian team was finally successful in February 2012. Doing this was not an easy company, not only because of the huge thickness of ice that there was to drill in the coldest region of the planet \u2013 which has the lowest temperature record ever recorded: less than 89 degrees Celsius \u2013 but because of the extreme care that was needed in order not to pollute the pristine water of the lake with the fluids used in drilling. To investigate the water of Lake Vostok has a great scientific interest, since it is believed that it was formed some fifteen million years ago and to exist there could have evolved isolated from the outside world following a path of its own \u2013 although it is not known with certainty if the water of the lake has actually been isolated for this number of years. According to Bulat in his statements last Thursday, the DNA of bacteria discovered in the water of Lake Vostok makes them significantly different from everything we know, which would imply that they evolved in an independent way. We would be in this way before a sensational discovery. As usual, however, not everyone agrees to qualify the finding as such. David Pearce of the British Antarctic Survey in statements collected by the scientific journal \u201cNew Scientist\u201d \u201cPearce also claims that it is still premature to talk about the discovery of a new type of bacteria and that more studies are needed before confirming or refuting it. The forum for disseminating and discussing a scientific finding is not, of course, the one offered by the mass media. For this, there are specialized journals that publish research articles, in which the procedures followed during the study, the results obtained and the conclusions reached are discussed in detail. The decision to publish an article is taken by the editor of the journal based on the opinion of other scientists, who are asked to express in writing a critical evaluation of the article under review. However, spreading a scientific discovery in the mass media is intended to reach a large number of people, many more than readers of a specialized scientific journal. This, of course, is important for a large-scale project funded by public funds \u2013 as is the case of the Vostok Lake expedition \u2013 which must be publicly accountable. So, when the explorers of Lake Vostok managed to penetrate it and obtain a sample of water in February last year, they gave part of it to the President of Russia at a public event \u2013 they did so, even though the water had a yellowish color, which is not clear if it was the result of contamination with the drilling fluid.The management of scientific discoveries and technological development for propaganda purposes is inevitable and of this we have had examples in recent times.Sometimes this management has been precipitated. Such was the case of the announcement made by NASA in December 2010 in relation to the discovery \u2013 on Lake Mono, in California \u2013 of bacteria capable of incorporating arsenic into its biological material, which would have constituted a revolution in the field of biology. This, however, could not be independently verified later by other researchers and did not pass from being a hasty media announcement. Will it be confirmed, beyond any doubt, that Lake Vostok is a seat of life different from that we find in other parts of the planet? Last Thursday was hasty? It is possible that we have an answer to these questions in the coming months, as long as the samples of water from Lake Vostok extracted this year are analyzed. Soon, regardless of what happens, the existence of a mysterious and huge lake, hidden under miles of ice on the coldest continent of the Earth, is certainly fascinating alone.",
    "https://upload.wikimedia.org/wikipedia/commons/f/fa/Cerebrum_animation_small.gif": "This is not a case of telepathy, much less, but the experiments reported this week in an article published in the journal \u201cScientific Reports\u201d by a group of researchers from the United States and Brazil are certainly to draw attention. Indeed, in that article it is reported that this research group achieved that a rat in the United States \u2013 at Duke University \u2013 communicated its thoughts to another rat in a laboratory in Natal, Brazil. The experiment was carried out as follows. First, the two rats were implanted electrodes in the brain, through which it was possible to access the electric impulses that the same generates. The electrodes also allow the brain to be stimulated by means of external electrical impulses. The two rats were also trained to actuate one of two levers in response to the stimulus of a red light. When the rat triggered the correct lever it was rewarded with a small amount of water. After training, one of the rats, the \u201ctransmitter\u201d was able to choose the correct lever 95% of the times that tried it. the \u201creceptor\u201d, apart from being subjected to the same training, was conditioned to respond to electrical impulses applied to the brain through the electrodes. During the experiment, the electrical impulses generated by the brain of the transmitter rat when it was put into the choice of one of the two levers. These impulses were immediately sent via the Internet to Brazil and then applied to the brain of the receiving rat, put it in a position to choose one of two levers, identical to those of the laboratory at Duke University. The result was that the receiving rat in Brazil chose the same lever selected by the rat originator of the stimulus, in seven of ten attempts. Thus, the rat in the United States conveyed its thought to the rat in Brazil, without there being a physical contact between the two. Although, according to a note published by the New York Times, some specialists were not particularly excited by this result, in other cases they considered it amazing. One of the authors of the article referred argues that these results represent a small step towards a future biological computer composed of numerous brains acting in synchrony to make a In this regard, it should be mentioned that when the receiving rat operated the same lever as the transmitting rat, the latter received an additional water reward and in this sense had a stimulus to transmit its thoughts in the best possible way.Of course, one thing is to speculate about a future biological computer and another to make it a reality, since a brain with superior cognitive functions is of extreme complexity. In this sense, the human brain, the most complex of all, is made up of about 100,000 million neurons, being able to have each neuron up to 10,000 connections. The brain in general and not only the human, is certainly of great complexity; so great, that we know very little about its functioning. In order to close this vacuum in our knowledge, the President of the United States announced on February 12 that he is preparing a ten-year project with massive funding, to discover the map of the functioning of the human brain. This map would contrast with one that simply described the position of brain neurons and their connections. In the words of George Church of Harvard University, \u201cthe difference between these two maps.\u201d It would be equivalent to knowing only the position and extent of all telephone lines, instead of knowing where, when and how, these lines transmit information.\u201d According to some researchers, the project to develop the map of the human brain has parallels with the project that in 2003 untangled the human genome. Not all experts, however, are equally enthusiastic about a project that would cost about $3 billion in ten years. Among other things, they consider that developing a map of the functioning of the brain is considerably more complicated than what it was to sequence the human genome and that the objectives set are not feasible in the short term. Soon, and waiting for the controversy to be clarified and we know the fate of the announced project, nothing prevents us from speculating on what it will mean and the benefits that it will bring us to know in detail how it operates an organ that has been described as the most complex object of the Universe. Much will have to advance science to convince a sufficient number of volunteers to participate as units of that computer. In particular, to agree to electrodes being implanted into their brain.",
    "https://upload.wikimedia.org/wikipedia/commons/9/9f/Valdivia_after_earthquake%2C_1960.jpg": "If you are a meteorite collector fanatic, you are sure to be placid by the asteroid or meteoroid that \u2013 unexpectedly \u2013 penetrated the atmosphere of our planet on Friday, February 15th, exploding about 20 kilometers high over the Cheliabinsk region in the Ural Mountains. Indeed, according to NASA, that asteroid had a weight of between 7,000 and 10,000 tons, and by disintegrating it would have dispersed a huge amount of fragments to the delight of collectors.Seeing the opportunity to do business, it took little time for meteorite traffickers to make their appearance in the Cheliabinsk region. According to a report published by the New York Times on the 18th, on the Monday following the explosion of the asteroid they made their appearance in the town of Deputskoye, where a large number of fragments fell, some of them offering various amounts of money for them. Similarly, offers of meteorites, supposedly from the Cheliabinsk meteorite, soon appeared on the Internet. In contrast, in 1492 it fell to land near the village of Tunguska in 1908. In both cases, the asteroids exploded in the air and it is not known that they have produced a crater, coming to land only small fragments. In contrast, in 1492 it fell to land near the village of Tunguska in 1492 it fell to land near the village of Tunguska in 1492 to find offers of meteorites that \u201ccome from the region of Cheliabinsk\u201d or that directly advertised as fragments of the meteor of the past day 15. Prices range from tens of dollars to hundreds of dollars, per meteorites weighing a few grams. The problem, of course, is to know if they are authentic. According to the New York Times report, being the illegal meteorite trade in Russia, it is difficult to secure it. Despite this, as the eBay page attests, collectors have not stopped acquiring the supposed Cheliabinsk meteorites that have been put on sale there. Ensisheim, Alsace, France, a 127 kg meteorite. This meteorite is the oldest meteorite that has been directly observed, and of which sufficient material is available for research, according to Ingrid Rowland of the University of California in Irvine, in an article published in 1990 in the magazine \u201cMeteorics\u201d. The meteorite of Ensisheim broke into several pieces when it fell. According to the stories of the time, it was found by a boy at the bottom of a hole a meter deep, in a field close to the walled city. It warned the inhabitants of the town, who cut pieces of the meteorite to take them away as a souvenir. As a result of this vandalism, and that later fragments of the meteorite were given to important characters from Europe, only one stone of just over 50 kilograms is now preserved. Ensisheim meteorite constituted an event at the time and was taken as a foresage of calamities to come, wars and diseases included. Rowland reproduces in his article the description of that event \u2013 from Siena, to where the news had come \u2013 in his time \u2013 in which he had been, the historian Sigismondo Tizio, \u201cAt this point it is necessary to mention the immense portent that was seen this year in Germany: on the seventh day of November, near the city of Ensisheim, a great stone fell from the sky, triangularly, charred and accompanied by thunder and lightning\u201d. In an illustration of the time, the meteor launched rays on the town, before the astonished gaze of its inhabitants. Today, more than five centuries after its arrival to the Earth, the meteorite of Ensisheim continues to attract attention, particularly in its native town, which holds an annual meeting to remember the arrival of its meteorite, and where it resides placed within a niche of glass. In addition, in order to protect its integrity, there is the \u201cHermandad de Guardianes del Meteorito de Ensisheim\u201d that, when they meet, dress up with red layers and white hats. Cheliabinsk, Tunuska and Ensisheim, are only three events that involve the fall of celestial bodies to our planet of the countless that have been given along. Fortunately, despite its spectacular nature, none of the three caused fatal casualties. In other cases it has not been so. The most famous is possibly the one that occurred 65 million years ago, when an airplane of considerable dimensions would have caused the mass extinction of species, including dinosaurs. It is speculated that the previous mass extinctions could also have been produced by the fall of asteroids to the Earth. Thus, the asteroids that surround our planet, can indeed cause major calamities as believed in the past. Although, as the saying goes, there is no harm that for the sake of not coming, and while it is true that an asteroid may have killed the dinosaurs, the mammals overcome the disaster and we still walk here. And with renewed forces.",
    "https://upload.wikimedia.org/wikipedia/commons/7/7b/Schlierenfoto_Mach_1-2_Pfeilfl%C3%BCgel_-_NASA.jpg": "In the spring of 1927, the mineralogist Leonid Kulik managed to arrive, after many efforts, to the place where he estimated a large asteroid had fallen 19 years earlier. This, in an area near the Tunguska river, in the heart of Siberia. Kulik knew from rumors of inhabitants of the region around Tunguska, that in 1908 a ball of fire had been seen in the sky that exploded with great noise, generating an expansive wave that felt tens of kilometers away.The rumors had not been confirmed, but Kulik considered that they corresponded to real facts; specifically, when a celestial body entered the atmosphere of our planet.In order to clear doubts, Kulik managed to get the Russian Academy of Sciences to finance an expedition led by him to the region of impact of the hypothetical asteroid. Once there, he could see that there was ample evidence that supported his assumptions.In effect, he found a large area where the trees had been shot down by a powerful explosion. It should also be noted that in this epicenter, although the trees were burned and without branches, they stood, giving the impression of a telegraphic post field.The latter was an indication of the violentness of the explosion, which tore off the branches of the trees without tearing down the trunks.Despite all the evidence that gave him the right, however, Kulik did not find the crater that he expected as a product of the impact of the meteorite on the ground.While several hypotheses have been given to explain the devastation of Tunguska \u2013 some exotic ones, such as the one that attributes it to an antimatter explosion \u2013 the most accepted at present is the one that originally defended Kulik; that is, that it was the result of the impact of an asteroid.According to the NASA website, it is estimated that the Tunguska asteroid had a size of about 40 metres, a weight of 100,000 tons and would have entered the atmosphere at a speed of approximately 50,000 kilometres per hour. The combination of temperature and air pressure due to the enormous speed with which it entered the atmosphere would have caused the asteroid's explosion at an altitude of about 8,500 meters above Tunguska. With these numbers, we are not surprised by what we know today: that 80 million trees were shot down in Tunguska and that the devastation spread over 2,000 square kilometers. It is not surprising that the effects of the explosion were felt in places as far away as London, where for several days the nights were illuminated by the light of the Sun dispersed by the remains of the asteroid suspended in the atmosphere. On the other hand and fortunately, given that the phenomenon occurred in an area with very little population, there are no known fatal victims.Although the Tunguska event happened more than a century ago, it has become news again because of the asteroid that surprisedly appeared last Friday in the Ural Mountains region, near the city of Chelyabinsk, exploding in the air, destroying window glass and hir According to NASA, the Chelyabinsk asteroid had a size of between 15 and 17 meters, with a corresponding weight between 7,000 and 10,000 tons. It entered the atmosphere at a speed of about 65,000 per hour and by effect, both from warming up by friction with the atmosphere, and from the pressure it was subjected to because of its speed, it exploded at a height of 20 kilometers, releasing an energy of 300 kilotons. This energy is equivalent to 18 atomic bombs as the one thrown over the city of Hiroshima at the end of the Second World War. Last Friday\u2019s asteroid was significantly smaller than the one it exploded over Tunguska in 1908. The latter, however, did so over a virtually unpopulated area and did not produce fatal victims, in contrast to the first one that disintegrated near a city with a population of more than a million inhabitants. Certainly, the probability that an asteroid the size of Tunguska will strike directly to a larger population centre is small. Chelyabinsk event, however, reminds us that we are permanently subject to bombardment from the sky.In this regard, NASA has established a program to monitor asteroids near our planet and determine the potential danger they represent, although we can do nothing to prevent it at the moment.As it may be, the Chelyabinsk asteroid was never spotted and took us all by surprise, when that same day we were waiting for another asteroid, which passed very close to Earth \u2013 in astronomical terms \u2013 without further danger, as had been anticipated.",
    "https://upload.wikimedia.org/wikipedia/commons/5/57/Cr%C3%A1ter_de_Chicxulub.jpg": "To study the remote past is certainly fascinating. It attracts, for example, to know that Pharaoh Ramses III, who reigned in Egypt more than 3000 years ago, most likely died killed as a result of a conspiracy of people close to him; or, to learn that our predecessors lived in Europe tens of thousands of years ago with Neanderthals and that they could even have crossed. Specialists investigate the past from multiple approaches, taking advantage of circumstances and using the most diverse techniques. Thus, we have to find out that through the Rosetta Stone, discovered in 1799 during Napoleon\u2019s expedition to Egypt, Jean Fran\u00e7ois Champolion was able to decipher the Egyptian hieroglyphics, which allowed us to delve into the history of Ancient Egypt. Likewise, using modern genetic techniques, it was possible to determine that the individual whose mummy was found along with that of Ramses III, was related to him and that, by other evidence, possibly took part in the conspiracy to assassinate him. As analytical techniques of all kinds are developed and increasingly sophisticated, multiply and become more sophisticated. The above hypothesis is based on the discovery of high concentrations of iridium in a geological stratospheric stratospheric stratospheric stratospheric stratospheric stratospheric stratospheric. In this sense, we can bring to light the episode concerning the mass extinction of species \u2013 including dinosaurs \u2013 that occurred approximately 65 million years ago. In an article published in 1980 in the magazine \u201cScience\u201d, which led as its first author Luis \u00c1lvarez, Nobel Prize in Physics in 1968, a hypothesis was ventured around the origin of this extinction of species. According to \u00c1lvarez and collaborators, it was the result of the fall to our planet of a meteorite of about 10 kilometers in diameter. The impact of an object of this size with the Earth would have raised a cloud of dust that dispersed throughout the atmosphere, remaining suspended for years.The dust cloud would have blocked the sunlight, making photosynthesis difficult. This discovery was carried out by Walter \u00c1lvarez \u2013 son of Luis \u00c1lvarez \u2013 in exposed geological strata of the mountains of northern Italy, as well as other places in the world. Iridium is very scarce on the earth's surface and a concentration as high as that found by the \u00c1lvarez suggests an extraterrestrial origin. Specifically, as the reference article suggests, it was the result of the impact of a meteorite that would have dispersed iridium throughout the Earth's surface. Something that gave additional sustenance to the meteor hypothesis was the discovery \u2013 post-death of Luis \u00c1lvarez \u2013 of the crater of Chicxulub, whose center is located in the sea, very close to the northwest coast of Yucatan. This crater, which has a diameter of 180 kilometers, was formed 65 million years ago and, according to the opinion of a large number of experts, is the origin of the mass extinction of species that marked the end of dinosaurs. Not all specialists, however, agree with this opinion and some have claimed that the fall of the Yucatan meteorite and the extinction of the dinosaurs. species were separate events for hundreds of thousands of years and consequently one could not have been the result of the other. Contrary to this view, an article appeared this week in the journal \u201cScience\u201d, published by researchers from universities in the United States, the Netherlands and the United Kingdom, offers new data indicating that both events, meteorite and species extinction, were given simultaneously. This conclusion is based on a study \u2013 employing highly accurate analytical techniques \u2013 of both materials laid off by the impact of Chicxulub, and of iridium-rich sediments associated with species extinction. Researchers found that both events occurred a little over 66 million years ago, separated just over 32,000 years ago. This last period is within the margin of error of measurements, and conclude that Chicxulub meteorite was very likely to have caused the extinction of species, if not the only one. Thus, modern investigative techniques provide us with a vision of those that could have occurred 66 million years ago. Of course, given the time elapsed, we would not expect absolute certainty. Very remote times, however, will surely be reduced as our analytical investigative techniques progress.",
    "https://upload.wikimedia.org/wikipedia/commons/1/19/Tombouctou.jpg": "As the 19th century broke out, the city of Timbuktu \u2013 located in the African country of Mali, on the southern border of the Sahara desert \u2013 was for Europeans an exotic, mysterious and fabled place, while one of the most distant and inaccessible places in the world. Such was the fascination of Europeans by Timbuktu, that the Geographical Society in Paris offered a prize 10,000 francs to that European who arrived to that city and returned safely and safely to tell it. This honor corresponded to the French Ren\u00e9 Cailli\u00e9, who performed the feat in 1828 disguised as a Muslim and successfully claimed the prize. To the disappointment of Europeans, however, Timbuktu turned out to be according to Cailli\u00e9 \u201ca mass of houses of pitiful appearance, made of land\u201d, far away from the splendid place that was expected. Judging by the images and video documentaries that one can find on the internet, while Timbuktu is certainly an exotic place, his appearance \u2013 with mud constructions and dusty streets without paving \u2013 hardly contradicts the appreciations of Cailli\u00e9. To assess the importance that Timbuktu had at some point, however, we should not let ourselves be carried away by his image today. Indeed, in addition to having an age of almost a millennium, Timbuktu had periods of great splendor, occupying a privileged place on the route of caravans that crossed the Sahara desert carrying salt, ivory, gold and slaves. In correspondence with its commercial splendour, Timbuktu was established as an academic center of great importance, with a university that came to have 25,000 students. As a legacy of its academic past, there are currently numerous private libraries in Timbuktu, maintained from generation to generation, and that are said to represent hundreds of thousands of manuscripts of great antiquity. To preserve this cultural heritage, which speaks of the intellectual past of Africa, the Government of Mali established in 1973 the Ahmed Baba Institute of High Islamic Studies and Research\u201d, which includes a documentation center that currently gathers 30,000 ancient manuscripts. These manuscripts, in some cases more than seven centuries old, were collected from Tom Baba\u2019s private libraries. The texts deal with art, medicine, science and calligraphy, among other topics, including ancient copies of the Koran. Given the great importance of the library of the Ahmed Baba Institute, great concern among the experts was caused by the news in the press at the beginning of this week that the library had been burned by the radical Islamists who had taken Timbuktu since April last year. As is known, in 2012 the National Movement for the Liberation of Azawad rebelled against the rule of Mali and unilaterally declared the independence of the Azawad, a region within which Timbuktu is located. This city was held by the rebels until last Monday when it was liberated by French and Malian troops. Fortunately, it seems that the news about the destruction of manuscripts in Timbuktu, attributed to the mayor of this city, is exaggerated and if some manuscripts would have been effectively destroyed, most of them would be safe. Tombuktu, who destroyed monuments in the city, the degree of destruction of manuscripts remains, however, in uncertainty.Because of the cultural importance of the library of Timbuktu, we must cross our fingers because the destruction has been minimal.The episode, on the other hand, puts into perspective two notable facts.First, of course, we must mention the rich intellectual tradition of the city of Timbuktu, which radically changes our vision of the cultural past of Africa. On the other hand, it does not fail to draw attention that particular collections of books could have been maintained, generation after generation, for hundreds of years and wars in between. Moreover, in a city that, although it had periods of splendor, has not had all of them with it in recent years, not to say centuries. This last is evident, at least since the time of Ren\u00e9 Cailli\u00e9.",
    "https://upload.wikimedia.org/wikipedia/commons/9/9b/Krasnoyarsk_hydroelectric_station.jpg": "As we know, the concentration of carbon dioxide in the Earth\u2019s atmosphere has increased steadily since the beginning of the industrial revolution two centuries ago. Today, this concentration is 390 parts per million, which is 37% higher than that of 1880. Concurrently, the average temperature of the Earth\u2019s surface has risen by almost a degree centigrade in the last hundred years, causing, among other phenomena, the fusion of Arctic and Antarctic ice. Although some deny that both increases are correlated, a majority of experts consider that the Earth\u2019s temperature has risen due to the growth of the level of carbon dioxide in the atmosphere. This growth, in turn, is the result of the burning of fossil fuels \u2013 oil, natural gas and coal \u2013 that contribute more than 80% of the total energy consumed by the world. While stabilizing \u2013 let alone eliminate \u2013 greenhouse gas emissions to the atmosphere looks problematic, specialists urge to take measures to slow their growth, given the climate emergency that crosses the planet. It is necessary to gradually replace fossil fuels with other non-polluting sources of energy. Alternative energies available to replace fossil fuels include hydroelectric, wind, nuclear, geothermal, biomass and solar. Not all of these sources of energy, however, have the same potential. Far from this, solar energy, by its volume, is by far the dominant one. Richard P\u00e9rez of the State University of New York in Albany, for example, estimates that the Sun has the potential to provide an amount of energy 1500 times greater than all the energy currently consumed by the world. In contrast, with the exception of wind energy, none of the other available sources of energy could in itself meet our energy needs globally. In addition to the above, and apart from the problem of atmospheric pollution, fossil fuels are a non-renewable source of energy that will eventually come to an end and that sooner or later we will have to replace it with renewable sources. In this regard, Richard P\u00e9rez believes that existing oil reserves, if consumed in the absence of any other energy, are equivalent to 15 years of energy at the current rate of global consumption. As far as nuclear energy is concerned \u2013 although it does not produce greenhouse gases, it is highly polluting from the environment \u2013 the existing uranium reserves are equivalent to a maximum of 19 years of global energy consumption.According to the above, the use of a tiny part of the Sun's energy could fully meet our present and most likely future energy needs. Thus, insofar as more and more sophisticated technologies are developed to trap and manipulate the Sun's radiation, it is to be expected that the world of the future will depend more and more on solar energy. What is the solar technology of the future? With the technologies of the present we can take advantage of the Sun's energy in different ways. We can, for example, use it to heat water for domestic consumption \u2013 an application that is becoming more widespread \u2013 or to generate electricity in thermo-solar power plants. Another option is that solar or photovoltaic panels offer us, which directly transform the Sun's energy into electrical energy. They also work quietly and without moving parts. One more option is exemplified by green plants, which are able to absorb and make use of solar radiation to reproduce and synthesize organic material, using the photosynthesis process. Photovoltaic panels and photosynthesis constitute two solar options with their own characteristics in a somewhat opposite way. On the one hand, the first ones are not in themselves capable of storing the energy they produce, which has to be consumed at the moment. On the other hand, plants store the energy they extract from the Sun in the form of chemical energy in the organic material they synthesize. It is interesting to compare the efficiency to take advantage of the Sun\u2019s energy of these two options, produced by one Nature and the other by a recent technological development. One might think that plants, as a result of thousands of millions of years of evolution, would be more efficient than solar modules. Far from this, a study published in the journal \u201cScience\u201d by an interdisciplinary group of scientists concludes that solar modules are in fact ten times more efficient than solar modules. So, for this time, we will have overtaken Nature, although it should be recognized that it may have never intended to participate in a competition to manufacture the most efficient solar device and that energy efficiency was not one of its priorities. As if it should be for us, if we are to overcome our climate difficulties.",
    "https://upload.wikimedia.org/wikipedia/commons/8/8b/GreenMountainWindFarm_Fluvanna_2004.jpg": "According to the National Oceanic and Atmospheric Administration (NOAA) of the United States, 2012 was the 10th hottest year in the world since 1880, the last year from which annual temperature records covering the entire planet are kept. 2012 was on average, according to the NOAA, 0.57 degrees Celsius hotter than the average global temperature throughout the 20th century. This, the experts consider, is indicative of the global warming that currently suffers the Earth and that causes extreme weather events, including droughts and floods, as well as episodes of intense cold and heat. Taken in isolation, the fact that any year shows an anomaly of temperatures is certainly not a test of a global climate change, since the climate continually undergoes variations \u2013 in one sense or another \u2013 in a natural way. However, the change observed in 2012 aligns with the trend recorded since 1976, when in a systematic way \u2013 for 36 years in succession \u2013 the annual average temperature has been higher than average. 1976 average annual temperatures at global level varied at random compared to the 20th century average, sometimes being higher and sometimes lower, the temperatures of all years since 1976 have been, in contrast, always higher. Even more, the twelve years of this century are among the 14 warmest years since 1880, and in this respect the record year is 2010 \u2013following 2005\u2013, with a temperature 0.66 degrees Celsius higher than average. According to experts, global climate change is the result of an increase in the concentration of greenhouse gases in the atmosphere. NASA measurements indicate that currently the atmospheric concentration of carbon dioxide \u2013 the main greenhouse gas \u2013 reaches 390 parts per million, while in 1960 it was 315 parts per million and in 1880 of only 285 parts per million. Thus, from 1880 to date, this concentration increased by 37%, with the consequent warming of the planet. The question is whether it is possible to achieve such stabilization. In an article published in 2004 in the journal \u201cScience\u201d by R. Pacala and R. Socolow of Princeton University, in the United States, it is argued that a levelling of the growth of carbon dioxide emissions can occur with the existing technology. This would stabilize the concentration of this gas to a value less than twice its pre-industrial level. For this, Pacala and Socolow propose to attack the problem on seven fronts, each of which will reduce the emission of carbon dioxide by the same amount until it stabilizes. These actions include: energy saving measures, the development of coal-based electricity generating plants \u2013 carbon-electric plants \u2013 twice as efficient as the current ones, the replacement of 1400 carbon-electric plants by natural gas-based plants, the development of automobiles with engines twice as efficient, and the capture and storage of carbon dioxide produced in coal-electric plants. As we can see, many of these measures are directed towards natural gas-based plants. The measures proposed to stabilize the emission of greenhouse gases also include: doubling the capacity to generate electricity of nuclear origin, increasing by a factor of 10 wind power generation by building 2 million windmills, increasing the generation of electricity by 100 times by solar means, and multiplying by 12 the production of alcohol fuel from maize or sugar cane. This would require a seven-year-old of all the arable land available in the world. Not all experts, however, agree that the solution is as \u201csimple\u201d as Pacala and Socolow put forward. In a discussion organized this week by the magazine \u201cScience\u201d to address the problem, in which Pacala participated, it is clear that the approach made eight years ago is already obsolete \u2013 since it was not taken at those times to reduce carbon dioxide emissions \u2013 and that more actions would be needed today than originally stated. I would like to point out that the proposed measures can lead to a solution for global warming, but it does not seem that in the next few years we will be witnessing a stabilization of carbon dioxide emissions, which means that climate change will probably continue with its current course.",
    "https://upload.wikimedia.org/wikipedia/commons/3/38/The_Woodlands_College_Park_Front_Image.jpg": "There was a time when the physical facilities of the Autonomous University of SanLuis Potos\u00ed, the oldest in the State, were largely reduced to the Central Building. Today, although these facilities have grown substantially and spread throughout the capital city and even outside it, the Central Building remains the symbol of the University. It is also a very relevant symbol, in keeping with the transcendence that the University has had and has in our midst.In fact, the Central Building is one of the oldest buildings in the city of San Luis Potos\u00ed and in its origin was precisely an educational center. It was built in the seventeenth century as the headquarters of the College of the Society of Jesus. At present, although its original appearance changed substantially after the renovation that it experienced in 1874 \u2013which modified its upper floor sufachaday \u2013 inside we can still appreciate the original construction of the ground floor, including its arcade around the central courtyard.After the expulsion of the Jesuits in 1767, the Central Building had a random fate that made it a barracks on more than one occasion. To his original vocation \u2013 although not necessarily always with the same approach\u2013, as the successor headquarters of: the Colegio Guadalupano Josefino in 1826, the Conciliar Seminary in 1855, the Scientific and Literary Institute in 1861 and, finally, the University of San Luis Potos\u00ed on 10 January 1923.This latest conversion has national relevance, since it meant the birth of the first autonomous university in MexicoThe direct predecessor of the UASLP was the Scientific and Literary Institute. In 1923, Governor Rafael Nieto had the initiative to bring this institute together with the Normal School and the Civil Hospital to form a single autonomous institution that was distant from the vaivenes of state policy, with its own heritage and government. The consequences of this initiative and the conditions of the environment that propitiated it are described in the books: \u201cThe first steps of university autonomy in San Luis Potos\u00ed 1922-1924\u201d, whose author is Mar\u00eda Gabriela Torres Montero, and \u201cThe Scientific and Literary Institute of San Luis Potos\u00ed\u201d, written by Mar\u00eda Gabriela Torres Montero, Enrique Delgado L\u00f3pez and Alejandro Guti\u00e9rrez Hern\u00e1ndez. Both books were published by the Potosina University Publishing House. The enthusiasm that higher education aroused in some sectors in our country in the decade of the 1920s is certainly not something that Mexicans can be proud of. In San Luis Potos\u00ed in particular, in a speech delivered in February 1921, in which he told of his plans to create an autonomous university, Governor Nieto said: \u201cThe Scientific and Literary Institute of San Luis Potos\u00ed, has conquered in recent times a large number of enemies. Many of these enemies argue that higher and professional education is a luxury in the meagreness of our economic and social environment; that if we are not able to attend even moderately to elementary and primary education of the State, it is absurd to spend a good portion of our budget on the formation of an intellectual aristocracy.\u201d He added that the poor resources dedicated to higher education can only result in \u201cmedium professionals that will swell the ranks of the intellectual proletariat.\u201d It is true that it is a reprehensible anomaly that we have a more or less attended professional establishment, and that we neglect elementary and primary education instead. The remedy is not, however, to suppress the good but to correct the bad.\u201d It is in the previous context, in no way favorable to the development of higher education, that we must appreciate the value of the autonomy achieved by the UASLP 90 years ago. Today, the Central Building of the UASLP \u2013 witness to the educational development of the State throughout its history, including the birth of university autonomy in Mexico\u2013 no longer houses teaching activities after having done it \u2013 albeit with interruptions \u2013 for more than three centuries. In a recent past, the Central Building was little abandoned by its students. First and in a paulatinous way by students of professional schools; then, by those of secondary and preparatory schools. The last school to leave the Central Building was the School of Physics, at the end of the 1970s. Thus, the events organized on January 10 by the UASLP and its Rector, architect Manuel Ferm\u00edn Villar Rubio, to commemorate the 90 years of autonomy, were culminated in a splendid spectacle of music and fireworks in synchrony. The latter launched \u2013of course \u2013 from the roof of the Central Building.",
    "https://upload.wikimedia.org/wikipedia/commons/0/04/International_Space_Station_after_undocking_of_STS-132.jpg": "For those interested in traveling to space, the Virgin Galactic company offers places on its six-seater SpaceShip2 ship for the modest price of $200,000 per person on a round trip. If the intention is to rent the SpaceShip2 for a Charter flight, the cost is even lower: a million dollars in total, that is, six tickets for the price of five. Virgin Galactic flights \u2013 starting on a date not yet determined \u2013 will have a duration of 2 hours and will reach a height of 110 kilometers. In addition, they will be sub-orbital flights, so that they will go up and down without giving a complete return to the Earth. Despite this, the lucky passengers of the SpaceShip2 will have the opportunity to experience the weightlessness for five minutes and to verify with their own eyes that our planet is, indeed, round, as the books teach us.On the other hand, while a height of 110 kilometers is considerable \u2013 the cruise altitude of a commercial jet plane is 10 kilometers\u2013, the journey of Virgin Galactic does not take us in Another would be the case of a trip to the Moon, to Mars or to some other planet or asteroid of our solar system that are at considerably greater distances. Indeed, we have that the Moon is at an average distance of 384,000 kilometers from the Earth and that a trip back and forth requires a week, in contrast to the two hours of Virgin Galactic\u2019s flight. The Moon, on its side, is relatively close compared to Mars, which is at an average distance of 225 million kilometers and takes more than six months to reach it. Moreover, the complications for a space trip increase disproportionally with the way to travel. This translates into costs. For example, when tourist trips were offered to the International Space Station \u2013 in orbit at about 400 kilometers \u2013 they had prices of about twenty million dollars \u2013 round trip, and accommodation and food expenses included. Although there have not been any trip to Mars so far, NASA has plans to make one at all. As well as 20 years. A Dutch businessman also has plans to send a mission to the red planet with private funding. The technical difficulties that must be overcome to carry out these plans, however, are capital ones. One of the biggest problems to overcome is cosmic radiations that permeate deep space. These radiations are made up of atoms that travel at great speeds driven during the explosion of stars, which are known to cause cancer, among other diseases. Thus, if astronauts are to remain for a long time in deep space, the spacecraft has to be shielded from cosmic radiation. To complicate things, in an article published this week in the magazine PLOS ONE by medical researchers from the University of Rochester in the United States, it is stated that the cosmic radiation to which astronauts would be exposed during the three years that the mission to Mars would last could accelerate the onset of Alzheimer\u2019s disease. This conclusion was obtained through the study of mice that were exposed to a dose of radiation of iron atoms equivalent to that astronauts would suffer on their journey to the neighbouring planet. They found that mice irradiated showed neurological alterations indicative of Alzheimer\u2019s disease. Even more, according to Kerry O\u2019Banion, the main author of the reference article, the iron atoms of cosmic radiation are so energetic that it would be necessary a shielding of two meters of lead or concrete thickness to effectively block them, which feels like difficult realization. While cosmic radiation fills all the deep space, here in our habitat and in its immediate vicinity we are protected from its influence by the magnetic field of the Earth. Thus, even though Virgin Galactic tourists are exposed in their journey to space to a dangerous environment, said medium is not at the end of accounts too different from that we have on the surface of our planet as to the conditions for life. Thus, it would not be surprising that, as some predict, the era of space tourism to places not too far away from our planet\u2013for the wealthy, of course\u2013it is already here to stay. It is not the case of travelers of deep space that they will find a tremendously hostile environment towards life as we know it. We would then have for a long time manned journeys to Mars, let alone groups of vacationers as summertime on the red planet. This even without taking into account the economic problems that the world is going through that indicate that, no matter how much plans are made, as far as journeys through deep space are concerned, the furnace is not for buns.",
    "https://upload.wikimedia.org/wikipedia/commons/6/6b/Portrait_de_Suzanne_Valadon_par_Henri_de_Toulouse-Lautrec.jpg": "What is the best remedy for a raw one? For some, this should certainly be a question of great relevance in these days of decembrina parties. This question, on the other hand, is not an orphan of answers. On the contrary, as in the case of diets to lose weight, there are numerous recipes to alleviate the consequences of the party of the previous night. Among the most well-served remedies in our country are: a dish of often, a very spicy chilaquiles, and a soup of equally spicy shrimp. A quick search on the internet gives us other options: orange or tomato juice, honey with lemon, a light meal \u2013 toasted bread \u2013 or greasy \u2013 bacon sandwich \u2013, aspirin, Alka Seltzer, ginger and coffee, to mention only a few few recommendations. Although of little practical value, on the internet there are also exotic recipes: plums in escabeche, you excrement rabbit or rhino horn, eyes of preserved sheep mixed with little practical value. Tomato juice, and fried canaries. Another group of recipes are based on the premise that, in order not to suffer a raw or hangover, you do not have to let it arrive, fighting it with more alcohol. Specialists, however, advise against this practice. Otherwise, unless you intend to stay drunk indefinitely, the hangover would arrive sooner or later. The above recipes are for when the raw has already arrived. To prevent it, as the first option it is recommended to refrain from drinking alcohol \u2013 which is undoubtedly inoperative in a good number of cases. Other less drastic recommendations are: drink with the full stomach, do it slowly \u2013 one drink per hour \u2013 so that the liver can process the ingested alcohol, eat a banana before starting to drink, or drink a glass of water between drink and drink. Despite the large amount of remedies to relieve the hangover that we can find around us, in an article published in 2005 in the magazine \u201cBritish Medical Journal\u201d by a group of researchers from Exeter and Plymouth Universities in Great Britain, It is concluded that there is no convincing evidence that any of these substances are actually effective.In this article, a study of the existing scientific literature on the anti-crude properties of different substances is carried out and it is found that while there are indications that some products might be effective \u2013 such as linoleic oil extracted from borage \u2013 further research is needed to confirm this.In relation to this last point, a study published by Korean scientists in 2009 in the journal \u201cJournal of Food Science\u201d found that asparagus are an effective medium for raw plants. Researchers found that the amino acids and minerals contained in these plants help protect the liver from the effects of alcohol, while accelerating its metabolization. In addition, they found that the concentration of these substances is higher in leaves than in the stalk of asparagus, which are normally discarded. Thus, traditional food by the end of the year next 31 December should be added asparagus, hoping that they will work in favour of those who drink. n because of more than one drink per hour, and thus they can enjoy, under reasonable conditions, the first day of the year. On the other hand, although a crude one at the beginning of the year affects the economy in a relative way only because it is January 1 on a holiday, the multiple hangovers throughout the year have appreciable effects on it. In this regard, Pittler and collaborators write that alcohol abuse costs the US economy between 12,000 and 30 billion dollars annually. Finding an effective cure for raw ones \u2013 as the Korean researchers claim to have done \u2013 is then of considerable economic importance. Pittler and collaborators also refer to the ethical aspects associated with the development of remedies for hangovers, for the possibility that this could encourage alcohol consumption. They consider, however, that there is little evidence that the effects of raw ones, however devastating they may be, inhibit the consumption of alcohol. The latter is certainly true, at least in a majority of cases. , with the raw one you owe me\u201d, we take it in a way more than festive.",
    "https://upload.wikimedia.org/wikipedia/commons/b/b7/KhonsuTemple-Karnak-RamessesIII-2.jpg": "It is not uncommon for the cause of the death of famous persons to be involved in controversy or speculation; particularly because of the suspicion that they might have been victims of a crime. This, for example, is the case of Alexander the Great, who died in Babylon a month after his 33rd birthday and of whom he was speculated to have been poisoned. It is also the case of Napoleon Bonaparte, who died in exile on the island of St. Helena at the age of 51. In relation to the latter character, although the autopsy report that was carried out shortly after his death indicates that he died of gastric cancer, there was someone who claimed that he was also poisoned.This assertion was based on the high levels of arsenic found in hair supposedly belonging to Napoleon.The death of Pharaoh Tutankamon, who reigned in Egypt more than three thousand years ago, has also been a cause of speculation. Tutankamon is the most famous pharaoh despite having died very young \u2013 before he turned 20 years old \u2013. This is because of the treasures found in his tomb that he was discovered intact in 1922. The case of Tutankamon grows the fascination that commonly awakens the forensic studies of famous characters, due to the great interest that produces everything regarding Ancient Egypt. The investigation of the cause of death of a famous character that occurred hundreds or thousands of years is certainly a fascinating exercise. This exercise, gathering modern analysis techniques, has produced in some cases more or less conclusive results. This is the case, for example, of Napoleon who today we know very probably \u2013 and after all \u2013 did die of gastric cancer as stated in his autopsy. Likewise, it is very likely that Tutankamon, with everything and his young age, has died of natural causes and not murdered as he speculated. One more successful forensic research work, thousands of years away from the criminal event \u2013 which was widely commented on in days past by the mass media \u2013 appeared this week in the magazine \u201cBritish Medical Journal\u201d. This work, carried out by Egyptian and European researchers headed by Zahi Hawass of the Supreme Council of Antig\u00fcdities of Egypt, refers to the murder of Rams\u00e9s. III as a result of the so-called \u201cconjury of the harem.\u201d There is historical information that Ramses III, who reigned in Egypt during the years 1186-1155 BC, was the victim of a conspiracy to assassinate him. Such a conspiracy was carried out by people close to Pharaoh. Among the principal conjurers of found Tye, a secondary wife of Pharaoh, and Pentaware, her son. The reason for the plot would have been Tye\u2019s discontent with Ramses III\u2019s intention to ignore Pentaware as his successor. The existence of the harem\u2019s conjura comes from the so-called Judicial Papyrus of Turin. According to Hawass and collaborators, however, it is not clear whether the plot succeeded and ended with the death of Ramses III or whether the Pharaoh survived the attack and died shortly thereafter. Thus, with the aim of clarifying this point, the investigators carried out a series of anthropological, forensic, radiological and genetic studies with the mummy of Pharaoh, as well as with another unidentified mummy. By means of tomographic images it was found that the mummy of Ramses III presents a deep cut in the throat, which had not been discovered until now by the thick layer of bandages that cover his neck. According to Hawass and collaborators, this lesion, which severed the trachea and esophagus and reached the spine, is severe enough to have caused the immediate death of Pharaoh. Although they do not rule out that the injury had been produced during the process of embalming the corpse, they consider that this is unlikely because something like this has not been found in another Egyptian mummy. Thus the conjura of the haren reported in the papyrus of Turin would be confirmed, also providing evidence that Ramses III died in the attack. It was found, on the other hand, that the alleged mummy of Pentaware corresponds to a subject who died at the age of 18-20 years, which is consistent with the hypothesis that it is the son of Ramses III. It also presents signs of strangulation, which suggests that he had a violent death. In order to determine the genetic filiation of both mummies, DNA tests were carried out on them, finding that they are indeed related and that it is probably about father and son. The mystery surrounding the last days of Ramses III is thus resolved with a good margin of certainty, more than three thousand years after his death. At the same time, however, there is another question regarding the circumstances surrounding the death of Pentaware, another of the main actors in the conjuring of the harem. In any case, the solution given to the case of the death of Ramses III exemplifies the capabilities that forensic science has achieved. Thus, and since \u201cwho can do the least\u201d, we could expect that few crimes committed today remain unclarified.",
    "https://upload.wikimedia.org/wikipedia/commons/b/bd/TeilhardP_1955.jpg": "A hundred years ago the British Empire enjoyed its utmost splendor and spread across the five continents, from Canada to Australia, through South Africa and India, among many other territories. England had also been the cradle of the Industrial Revolution and one of the centers where the scientific revolution developed in the 17th century, with Isaac Newton as an emblematic figure. Two centuries later, at the height of the rise of the British Empire, Charles Darwin provoked a new intellectual revolution with the publication in 1859 of his work The Origin of Species. With these and numerous other background by means, it is perhaps justifiable, or at least understandable, that the English have felt a hundred years ago as the center of the world. In this context, a curious event occurred a century ago in England as follows. On 18 October 1912, the renowned British paleontologist Arthur Smith Woodward, together with Charles Dawson, also paleontologist but amateur, made known to the London Geological Society the discovery of fossil remains of a supposed distant ancestor of ours, half human and half simio. From Piltdown, for having been excavated in a quarry of the village of Piltdown, in the south of England, consisted of some fragments of skull and a jaw with two teeth. The fossils of Plitdown had peculiar characteristics. Indeed, while the skull seemed to have a volume similar to that of modern man, the jaw and teeth were closer to those of an ape. This conformed to the beliefs \u2013 prejudices \u2013 in vogue, according to which during human evolution the brain grew first in size, which in turn would have led to an evolution of the other characteristics that distinguish us from the apes \u2013 now it is known that evolution proceeded just the opposite. Woodward and Dawson\u2019s announcement was accepted by the British scientific community without too much reticence, partly because it agreed with the prejudices of the experts, but also by other factors. In reference to the latter, an article published in February of this year in the British newspaper \u201cThe Guardian\u201d notes that at the time when the Piltdown fossils emerged, the French had already discovered the Cro-Magno fossils. n, while the Germans had done the same with the Neanderthals and Heidelberg. With Dawson\u2019s discovery, continues \u201cThe Guardian\u201d, the English now had their own fossil, which, we might add, claimed their position as the world\u2019s first empire. Moreover, as the land that saw Charles Darwin born, England should have played a relevant role in the evolution of the human species. The case is that the Piltdown Man turned out to be a fraud and the pieces of skull actually belonged to a modern man, while the jaw and teeth were of an orangutan. To consummate the deception, skull and jaw were dyed of brown color, the same color of the quarry where they were supposedly found. The fraud was carefully planned and more carefully executed; so much that it took 40 years to make it clear and there is no doubt that it was perpetrated by experts. It is still a mystery, however, who or who were the authors. An article published this week in the British magazine \u201cNature\u201d by Chris Stringel of the London Museum of Natural History gives some clues about it and listed to the authors. In any case, it may have been clear that the fossils had been artificially dyed. If they were not tested, it was for reasons of scientific prejudice or extreme nationalism that Dawson, who would have been the reason for the fraud, wanted to be scientifically recognized. Stringer also considers Woodward and Martin Hinton, who was Woodward\u2019s assistant. Hinton is a suspect because, already dead, bones and teeth were found among his belongings tinged in a manner similar to the bones of Piltdown. A suspicious fourth is Teilhard de Chardin, who in his youth helped Dawson in his excavations and contributed a third tooth to the Piltdown Man. Stringel is currently participating in an effort to clarify the mystery of the Piltdown and for this purpose is subjecting the fossil remains to a series of tests with analytical instruments that greatly exceed those of the existing instruments a century ago. However, it is interesting to note that according to experts, even with the analytical techniques available 100 years ago, fraud could have been easily detected. Even in a short time, let us hope that the mystery of Piltdown will be clarified in the coming months.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d5/Tragelaphus_strepsiceros_%E2%99%82_%28head%29.jpg": "The rhinoceros are fascinating animals for several reasons. First, because of their size, since after the elephant the rhinoceros are the largest terrestrial animals we know. Also because of their voluminous body, as well as because of their horn or horns above the nose and their supposed bad mood, that would cause them to be blinded in case of being provoked. We could not fail to mention their rough and wrinkled skin, with large folds in the Asian rhinos that give them a armored appearance. These last two characteristics \u2013 bad humor and wrinkled skin \u2013 motivated the children's tale of Rudyard Kipling that bears the title \u201cHow it was that rhinoceros made of their skin.\u201d In this story, the rhinoceros protagonist steals a cake before the owner's gaze, who can do little given the formidableness of the thief. Shortly thereafter, however, the victim had the opportunity to get rid: when the rhinoceros took off their skin in order to take a bath in the sea, he emptied a large amount of crumbly in the sea. Since then the rhinoceros has suffered from a chronic itch that makes it scratch permanently. For this it rubs violently against trees or against the floor. This custom has caused its skin to have been wrinkled and acquired the characteristic folds. And as it has not even managed to relieve the itch, the rhinoceros is always in a bad mood. The above is, of course, a fantasy. There are, however, a number of real stories in which rhinoceros are involved. One of these refers to the Asian rhinoceros \u2013 about three years old \u2013 that was donated to the Dublin Zoo by the Minister of Finance of India in 1864 and which had a tragic end. Indeed, as stated in an article published last October in the magazine \u201cProceedings of the Royal Irish Academy\u201d, the rhinoceros never adapted to his new house and was always \u201csmowed\u201d and ate little. Thus, he died in less than a year. The treatment given to the skin of the animal, however, was so wrong that doubts recently arose as to whether it was a rhinoceros from India \u2013 as it had been supposed \u2013 or a rhinoceros from Java. Both species differed morphologically, in particular by the folds of the skin. This, however, was stretched to such an extent when it was mounted on the skeleton that lost the folds. Fortunately a forensic analysis using DNA techniques identified unambiguously that it was a rhinoceros from India. Another rhinoceros history \u2013 which occurred millions of years ago \u2013 is referred to in an article published this November 21 in the online magazine PLOS ONE by researchers from France, Belgium and Turkey. According to that article, 9.2 million years ago an adult rhinocerosant from about 10-15 years ago was trapped by the lava of the Cardak volcano eruption in Turkey, dying instantly. -450 degrees centigrade \u2013 to which he was exposed, the rhinoceros\u2019 corpse quickly dried up. Later, the body was dismembered by the lava flow, separating the head from the body, which was baked at about 400 degrees centigrade. Researchers found the skull of the articulated rhinoceros with the jaw about 30 kilometers from the crater. The remarkable fact of the case is that with a forensic exercise, projected millions of years into the past, they were able to determine the circumstances of his death.The most shocking stories about rhinoceros, however, are those that are currently occurring and that have to do with the illegal hunting of these animals. Indeed, for about five years the number of animals killed by poachers has increased significantly.This because there is a great demand for rhinoceros horns in Asia for their supposed healing properties, particularly against cancer.The demand, driven by Asian economic bonanza, has increased the price of rhinoceros horns, which by weight are worth more than gold. As a result, while in the six-year period between 2000 and 2005 the corresponding number was hunted in South Africa \u2013 where most of the world\u2019s rhinoceros live \u2013 a total of 252 rhinoceros, so far this year the corresponding number is 455. If this trend continues, the experts consider that we could witness the extinction of rhinoceros in a few years. It should be noted that the most abundant species is the so-called white rhinoceros, of which it is estimated live about 20,000 individuals. At the other end, the Java rhinoceros remains only a few dozen specimens. It seems that rhinoceros are helpless, paying blame they should not. Certainly, the Kipling rhinoceros deserves for their actions the punishment of eternal eating. The bulk of rhinoceros, in contrast, has not earned in any way the treatment we give them. Besides, moral considerations aside, the world would lose much with their extinction.",
    "https://upload.wikimedia.org/wikipedia/commons/0/06/Tikal_Temple1_2006_08_11.JPG": "Towards the end of the first millennium of our era, the cities of the classic Maya period suffered a collapse that some experts have associated with the occurrence of prolonged episodes of severe drought. This hypothesis has been confirmed by an article published this week in the magazine \u201cScience\u201d, published by an international group of researchers led by Douglas Kennett of the Pennsylvania State University. In this article we present a detailed account of the periods of drought and humidity that occurred over 2000 years in the Mayan region and shows how these periods have a correspondence with events of the Mayan world, including the collapse of their institutions and cities about a thousand years ago. Determining whether a certain period thousands of years in the past was dry or humid does not seem to be a simple company. And it is not, in fact, to ask how it was achieved by Kennett and collaborators. The answer is that they did so by means of a 56-centimeter long stalagmite found in Yok Balum cave in Belize, not far from the Mayan city of Tikal, in the Pet\u00e9n region of Guatemala. It is known that a stalagmite is formed on the floor. The last 45 centimetres of stalagmite studied by Kennet and collaborators took 2000 years to deposit from the vault of the cave. The latter was determined by measuring the concentrations of radioactive isotopes of Uranium and Torio along the stalagmite known to provide a measure of the time that has elapsed since its deposit. Thus, it was possible to date the stalagmite of Yok Balum along its length by measuring the corresponding concentrations of isotopes. Once this information was available, the periods of humidity and drought over time were determined by measuring in the stalagmite \u2013 along its length \u2013 the concentration of a certain isotope of oxygen. This isotope is related to the climatic conditions that prevailed in the Yok Balum cave at the time of the formation of the stalagmite. As a result, the researchers were able to determine with great precision when periods of humidity and extreme drought occurred in a period of a period of time during which the formation of the stalagmite occurred. The precise knowledge of climate change over time allowed Kennett and collaborators to correlate these changes with events of various kinds recorded in the Mayan steles. Thus, they found that a period of exceptional humidity between the years 440 and 660 of our Era, resulted in a flourishing of the Mayan civilization and an increase in the population of its cities. However, the humid period followed a gradual drought between the years 660 and 1000. This period \u2013 and given the growth of the population of the favorable years, which would not have been sustainable in the new conditions \u2013 brought wars between cities, reduced agricultural productivity and political turbulence, which would have led to the eventual disintegration of the Mayan cities of the classical period. A subsequent episode of severe drought between the years 1000 and 1100 \u2013 already in the period called post-classic \u2013 would have given the tip to the era of the greatest splendor of the Mayan civilization. The severity of the consequences of droughts in Mexico is illustrated by that which occurred between 1535 and 1575, which affected the peninsula. This drought, which appears in the record of Yok Balum's stalagmite, caused about half a million deaths in 1535. This, according to figures mentioned by Kennet and collaborators. According to these authors, the collapse of the classical Mayan civilization would point to a population growth that proved unsustainable insofar as the conditions that initially propitiated it changed. Classical Mayan cities would thus have been victims of their own initial success.",
    "https://upload.wikimedia.org/wikipedia/commons/1/1c/SanJose_Infobox_Pic_Montage.jpg": "It seems that solar energy is contagious. At least this is what is concluded in a study published in the journal \u201cMarketing Science\u201d on September 20, by Bryan Bollinger of the Stern School of Business of the University of New York and Kenneth Gillingham of Yale University. In that study, Bollinger and Gillinham found that the decision of an owner to install solar panels in his house is influenced by panels that his neighbors may have installed in their respective homes. Bollinger and Gillinham\u2019s conclusion is derived from a study of the solar domestic facilities in the area of San Francisco Bay, California, which extends to the Silicon Valley to the south of the bay. It is found that such solar facilities become denser in certain geographical points. The higher concentrations of solar panels, moreover, do not necessarily correspond to areas with a higher population density. This could be indicative of outbreaks of \u201cepidemias\u201d of solar panels that have emerged in specific areas. Like in a real epidemic, solar panels would multiply by contagion. : an owner decides to install a solar system in his house after seeing one installed somewhere in the surroundings. He could have also decided on another way: for example, after his neighbor spoke to him about the virtues of the solar panels he has installed in his house. The above view is reinforced by comparing the geographical distributions of the solar panels of the years 2003 and 2006. Indeed, it is found that although there was an increase in the total number of solar systems installed in the area, the uneven concentration of panels observed in 2003 was maintained in 2006 with the same geographical distribution. The concentrations found in 2006 were, however, more pronounced than those in 2003, indicating an advance in the epidemic. Thus, the greater the number of solar systems installed, the higher the speed at which new systems are installed, and with this, the epidemic continues its upward course.The state of California has installed a capacity of generation of photovoltaic electricity \u2013 that is, by means of solar panels \u2013 of about 1500 megawatts, the greater part in the roofs of private houses. The rapid growth that California\u2019s solar capacity is experiencing is due, on the one hand, to the abundance of solar resources due to its dry climate and, on the other hand, to government incentives for Californians to install solar panels on the roof of their homes and self-generate part of the electricity they consume. With a domestic solar system, the excess electricity generated during the day is injected into the external electricity grid, while in the sunless hours, the required electricity is provided by the electric company. The energy delivered to the external network accounts positively for the owner of the house, which thus reduces its electricity consumption bill. The proliferation of domestic solar facilities has been limited by the investment needed to install the solar system. The price of solar panels, however, has remained in decline in recent years, reducing the amount of such investment. In addition, in the case of California, government incentives have provided ways of infection for the spread of the solar panel epidemic. On the other hand, this epidemic is positive, because it helps to reduce the generation of greenhouse gases that have caused the climate change that currently affects our planet. It is not, however, the only technological epidemic that we are witnessing. Far from this we have many examples. One of the most notorious is the epidemic of cell phones that has increased unchecked in recent years. One of the most serious ways of infection for this epidemic, which should be the only one, is the need to have a more convenient means of communication than the fixed phone.There are, however, other ways of spreading, such as the imitation of other people who already have a cell phone.Another example, with the most serious consequences for the city life, is the car epidemic that threatens to drown our streets and which also has in imitation of one of its ways of infection.The article by Bollinger and Gillinham points out that our decision to install a solar electricity generator system in our house may be influenced by the fact that our neighbor already has one is home.The imitation would therefore be one of the ways of installing solar electricity in our house. the spread of the solar panel epidemic. Unlike other epidemics, however, this one is welcome..",
    "https://upload.wikimedia.org/wikipedia/commons/4/41/Angkor_Wat.jpg": "Angkor Wat is a temple of great relevance to Cambodia. So much so that even its image is printed on the flag of that Southeast Asian country. Like the Indian Taj Mahal or the Egyptian pyramids, the image of Angkor Wat is unmistakable. In its core, the temple consists of three concentric courtyards. The innermost courtyard is a square of 60 meters long, with a tower in each of its four corners. In the center of the courtyard stands a fifth tower of higher height. It is these towers, the center of 65 meters, that give the temple its unmistakable profile from the outside. The complex is surrounded by a 4.5 meters high fence and a 3.6 kilometers long water pit. The temple of Angkor Wat was designated in 1992 by UNESCO \u201cPatrimonio de la Humanidad\u201d. The temple of Angkor Wat formed part of the urban settlement of Angkor that covered a considerable extent. A study of radar images taken remotely in an area of almost 3,000 kilometers, published in 2007 by an international group of researchers headed by Dakor Wat. At the University of Sydney, Evans revealed that the urban complex of Angkor was extending along and across an area of more than 1,000 square kilometers. This makes it the largest low density urban seat in the pre-industrial world. Angkor built a complex infrastructure for the collection, storage and distribution of water, which would have enabled the development of large expanses of rice crops. By the complexity and extension of this infrastructure, Angkor has been conceived as a \u201chydraulic city.\u201d On the other hand, Angkor\u2019s infrastructure in the long run constituted its weak point and led to its collapse over the course of two centuries. This, due to the great impacts to the environment that it meant. According to Evans and collaborators, \u201cThe modification of the environment in Angkor was extensive and substantial enough to have produced numerous and very serious ecological problems, including deforestation, overpopulation, soil degradation and erosion.\u201d All this would have been too much for such a complex and interdependent infrastructure as existed in Angkor. kor Wat. This was built between the 10th and 13th centuries of our era, employing from five to ten million blocks of stone with weights of up to 1500 kilograms. Stone blocks were extracted from quarries near the foot of the Kulen mountain, at a distant point about 30 kilometers from the temple. As for the means of transportation from the quarry to the temple building site, an article published online this week in the magazine \u201cProceedings of the National Academy of Sciences\u201d by two Japanese researchers shed light on this. In that article, researchers report that, observed maps of \u201cGoogle Map\u201d, discovered a linear structure of 2.4 kilometers long at the foot of the Kulen mountain. A field investigation showed that this structure, along which numerous quarries were located, was part of a system of channels for the transport of stone blocks to Angkor Wat, as well as to other temples in the Angkor area. The transport route, moreover, followed almost a straight line from the quarries to the construction sites. well the materials of the different quarries at the foot of the Kulen mountain are indistinguishable by their color, by means of magnetic measurements it was possible to distinguish them and establish the order in which the quarries located along the linear structure were exploited. It is not uncommon that such remarkable realizations as those that occurred in Angkor almost a millennium ago caused us amazement.The Khmers of Angkor Wat, however, had \u2013 obviously \u2013 enough time, resources, technology and artistic expression to carry out their company, which is not particularly surprising, since the same happened in other parts of the world in similar conditions.Nor did we be surprised that they did not foresee the consequences of disturbing the environment to the extent they did, which eventually led them to collapse.After all, we in the 21st century did not act very differently in this sense.",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Measles_US_1938-2019.png/1024px-Measles_US_1938-2019.png": "In a sound case a few years ago, the British physician Andrew Wakefield was accused of inappropriate scientific conduct in relation to an article published in 1998 by him and 12 other authors in the medical journal \u201cThe Lancet\u201d. An investigation carried out by the British General Medical Council found that Wakefield had carried out dishonest professional practices and stripped him of the possibility of practicing medicine in Britain. \u201cThe Lancet\u201d, for his part, withdrew that article from his records in February 2010. Wakefield\u2019s article and collaborators thus added to the growing number of scientific reports that had been withdrawn from circulation after it had been found that their authors had engaged in inappropriate practices that invalidated their findings. The Affair Wakefield, however, did not simply constitute one more case of proven bad scientific practices; this, due to the social repercussions it had. Indeed, the conclusions of the article established the possibility that triple vaccine against measles, mumps and rubella could cause severe gastrointestinal problems in autism children. There is a good number of incentives for this to happen. The researcher is currently under great pressure to get funds to sustain his or her activity, which are obtained on the basis of his or her previous research results reflected in his or her scientific production. This puts him or her in competition with other colleagues and may even threaten the stability of his or her job. These articles, if detected, can be removed from circulation by the magazine that published them. In an article published this week in the American magazine \u201cProcedings of the National Academy of Sciences\u201d, published by a group of researchers led by Arturo Casadevall of Albert Einstein Medical College of New York City, the phenomenon of the withdrawal of scientific articles is analyzed. Casadevall and collaborators analyze the causes of the withdrawal of 2047 articles from the biomedical area indexed in PubMed, which includes more than 25 million records from 1940. They find that of the 2047 articles studied, 21 % were withdrawn because they contained errors. In contrast, 47 % were for scientific fraud, 14 % because it constituted duplicate work and 10 % for plagiarism. The researchers found, moreover, that the number of articles removed for all causes is increasing and that scientific fraud, which is the majority cause, has increased by a factor 10 since 1975. Casadevall and collaborators They find that the list of countries with more items lost in disgrace is led by the United States, which is natural, because it is by far the country with the largest number of publications. The United States is followed by the number of articles withdrawn Germany, Japan and China, countries that also fall apart in the number of articles they publish. It is interesting to note, however, that while the United States heads the list of articles withdrawn for all reasons, the specific weight that this country has in the number of withdrawals due to scientific fraud is remarkably large.This could mean that the pressures that American scientists suffer are correspondingly greater than those of their counterparts, even in developed countries.Scientific fraud is possibly inevitable, because after all science is an activity practiced by humans with all its limitations.However, even with this negative aspect, scientific practice with all its cautious applications has proved to be enormously redeituable to us.After all, a scientific result that will eventually be inevitably detected and corrected. If it happens, scientific fraud can have negative consequences, as the Wakefield case has shown. Otherwise, nothing is perfect, not even science.",
    "https://upload.wikimedia.org/wikipedia/commons/3/35/YuanEmperorAlbumGenghisPortrait.jpg": "Eight centuries ago Gengis Kan embarked on military campaigns that, in the course of just two decades, extended the boundaries of the Mongol Empire to the east of the Pacific Ocean and to the west of the Caspian Sea. Gengis Kan led campaigns against his neighbors in northern China. He also lined up to the west to almost reach Europe and at its passage destroyed cities that opposed him to resistance such as Samarkand and Bukhara in the present Uzbekistan, sacrificing en masse or making slaves to its inhabitants. Over time, the successors of Gengis Kan extended the limits of the Mongol Empire even further, to the extent that on the surface it is the second largest empire that has ever existed, surpassed only by the British Empire. Experts explain that the reason for the success of Mongols, and in particular of Gengis Kan, resided in the military tactics that they employed and that they proved superior to those of their enemies \u2013 to those that they were able to overcome even in conditions of numerical inferiority. And to win battles, in addition to military tactics, they had to have enough food for their mounts \u2013 in addition to food for themselves, of course. In this regard, Amy Hessl of the University of East Virginia and Neil Pederson of Columbia University in the United States suggest that the expansion of the Mongols could have been the product of a period of abundant rains that Mongolia would have experienced in Gengis Kan times. Excess humidity would have caused more grass growth than usual and allowed support, both to horses employed in the war enterprises, and to cattle that in turn served as food for warriors. A climate fluctuation would thus have generated favorable conditions for the Mongolian military campaigns. Hessl and Pederson arrive at this conclusion after studying the remains of trees collected in a lava field in the vicinity of the Khorgo volcano in Mongolia, which is located in the region of origin of Gengis Kan. As the specialists explain, the concentric growth rings that are observed when cutting the trunk of a tree tell us the story In fact, it is known that these rings are due to the fact that throughout the year the rate of growth of the trees varies according to the season, being larger during the spring than during the winter. Thus, the wood grown during this last season is denser than that which grows in the spring, which becomes visible in the concentric rings. According to this, each ring corresponds to one year and to know the age at which a tree died it is sufficient to count the number of rings of its trunk. In addition, the date of death of a tree can be determined by comparing its ring pattern with the corresponding pattern of a tree that has grown at the same time and in the same climatic conditions, but that is still alive. On the other hand, the climatic conditions experienced by a tree in a given year determine the thickness of the corresponding ring. That is, if the conditions are favorable to the growth, the thickness of the ring will be greater. A variation in the thickness of the rings over a period then indicates a corresponding climatic variation. Studying the trees found in Khorgo, Hes Sl and Pederson find that, indeed, in the early decades of the 13th century, when the conquests of Gengis Kan took place, the climate in Mongolia was more humid and favored the growth of the trees and as a result of the herb that the Mongols needed to launch their military incursions.Although the Mongols ravaged everything in their wake, the establishment of an empire throughout Asia stimulated trade between Europe and the Far East and in this sense it could be said that there is no harm that for the sake of not coming and that the conquests of the Mongols had at least one positive consequence.It is possible, however, that the inhabitants of Samarkanada, Bukhara and other cities \u2013 who were exterminated or taken as slaves by the troops of Gengis Kan \u2013 would express their disagreement with the above, if they had the opportunity to do so.It may be contradictory to them that \u2013following Hesl and Pederson \u2013 the improvement in the climatic conditions in Mongolia, which would have resulted in a greater production of food and which apparently could only have positive consequences for the race. human \u2013 or, at least, not negative for those thousands of miles away \u2013 would have resulted in a disaster of such magnitude. For the victims of Gengis Kan, perhaps it would be more appropriate to say that in their case, there was a good \u2013 though not for them \u2013 that came to them out of harm.",
    "https://upload.wikimedia.org/wikipedia/commons/9/9e/D%C3%BCsseldorf_Hofgarten_2009.jpg": "The Antarctic continent is the coldest place on Earth. It was there \u2013 precisely, in the Russian station Vostok \u2013 where the lowest temperature ever recorded was observed in 1983: less than 89 degrees Celsius. Antarctica, with an average temperature throughout the year that does not reach zero degrees Celsius at best, is certainly not an attractive place to live. This, even though it is not considered to be permanently covered by an ice layer whose thickness is measured in kilometers, and which is the product of millions of years of bad weather. This ice layer, on the other hand, has great scientific importance, because in it the climate history of the Earth is recorded. In fact, Antarctic ice was formed by the accumulation and gradual compaction of snow over tens of millions of years. Thus, if we perforate the ice layer, as we penetrate below its surface we find strata that belong to increasingly ancient geological times. A study of the characteristics of ice at different depths will then give us information about the evolution of the climate of The Antarctic ice layer is also interesting because under its surface a large number of underground lakes are located. The largest of them, Lake Vostok, is of dimensions equivalent to Lake Ontario, which places it as the seventh largest lake on the planet. The water of Lake Vostok is subject to a huge pressure by the layer of ice it bears, which has a thickness of four kilometers. It is kept liquid by the thermal insulation provided by that layer and by the heat it receives from the interior of the Earth. Lake Vostok was buried by the ice tens of millions of years ago and since then is allegedly isolated without contact with the outside world. It would thus constitute a real lost world in which possibly living organisms that have followed their own evolution, taking into account the conditions of their environment. If there is, however, life would have to be limited to microbial forms, as the total absence of sunlight and the shortage of nutrients in the lake would have eliminated another more advanced form of life. For this purpose, a team of Russian scientists has already carried out, for a good number of years, a project to drill the ice sheet of Lake Vostok in order to access its surface. In February of this year, that group announced that it had finally succeeded and that it had managed to extract a sample of water from the lake. Drilling four kilometers of Antarctic ice in subhuman conditions and putting all the effort to avoid a possible contamination of the pristine water of Lake Vostok, was by no means a simple company, and to which it was understandably given great publicity. The Russian Minister of Natural Resources and Environment even gave Vladimir Putin part of the extracted water, presenting it as \u201cwater with more than a million years of antiquity\u201d. Putin, on his side, referred to the same as \u201cwater that the dinosaurs drank\u201d \u2013in an obvious exaggeration, as the dinosaurs would have extinguished about fifty million years before the lake \u201cVostok\u201d was sealed. Next December \u2013 with the beginning of the southern summer \u2013 the Russian team will resume explorations on Lake Vostok. On this occasion, however, it will not be alone in its efforts, as a team of British scientists in recent days announced that they will try a similar company, although in a different lake, Lake Ellsworth, on the other end of the Antarctic continent. Drilling kilometres of Antarctic ice, although complicated, is not really the main problem facing Russian and British teams. The most difficult thing is to prevent the pristine water of Lake Vostok from becoming contaminated during the operation, which would be catastrophic. Russians use a drilling technique that employs polluting fluids and has also been a source of criticism \u2013 in this regard, it is not clear whether the yellowish colour of the water given to Putin is the one that originates or is due to contamination with drilling fluids. To prevent this problem, the British will use only hot water to drill the ice. Having been ten to twenty million years old, the water it contains is not really that old, because it is continually being replaced by underground currents. If this were the case, the lake water would have been isolated for only 10,000 to 20,000 years. Thus, Putin would have double exaggerated his comment on the water that dinosaurs drank. In contrast, from the scientific point of view, the Antarctic underground lakes will maintain their importance and will probably broadly justify the resources invested in their exploration. We will, however, have to wait until February of the following year to know the results of Russian and British research.",
    "https://upload.wikimedia.org/wikipedia/commons/b/b2/M%C3%BCnchen_-_Max-Planck-Gesellschaft.JPG": "On its cover of the January 2000 issue, the magazine \u201cScientific American\u201d showed the image of a primitive human dressed in fur, along with that of another equally dressed but with distinctly different anatomical features. Next to the images we could read the text \u201cWe weren\u2019t alone.\u201d The cover refers to one of the articles in the interior of the magazine in which it is pointed out that over the last two million years we may have shared our habitat with other close relatives of ours. This with the exception of the last 30,000 years, during which we would have been alone on the planet after the disappearance of the Neanderthal. It is known that modern humans lived in Europe for ten thousand years with the Neanderthals. Genetic studies of Neanderthal fossils even indicate that both species crossed and mixed their genes. Some 30,000 years ago, however, while our species flourished, Neanderthals became extinct for uncertain reasons. In this sense, it is speculated that they could not survive the encounter with the most intellectually equipped modern humans. Neanderthals have not been, on the other hand, the Neanderthals. In fact, in 2010 an international group of scientists led by researchers from the Max Planck Institute of Evolutionary Anthropology in Germany announced the discovery of fossil remains of a girl of more than 50,000 years old, in a cave in southern Siberia. The remains are of a species other than the Neanderthal but closely related species, which has become known as Denisovana by the name of the cave in which the remains were found.The remains of the Denisovana girl are not spectacular, since they are hardly a small fragment of the little finger.However they have been of great importance, since their DNA has been relatively well preserved by the cold prevailing in the cave where they remained for tens of thousands of years and average zero degrees centigrade throughout the year. This, together with a new technique to decipher the genetic code developed at the Max Planck Institute, has made it possible to obtain genetic information from the Denisovana girl. With such precision that it is possible to compare it with that of a living species. Thus, despite only having a fragment of bone, we can know that it had brown skin, and brown hair and brown eyes. The results of the study have been reported this week in the magazine \u201cScience\u201d by the same group of researchers who originally announced the discovery in the Siberian cave. As with the Neanderthals, the genome of the Denisovans indicates that at some point they crossed with modern humans. Also, just as the first ones, the Denisovans became extinct for reasons still to be determined, but that they could have to do with an unequal competition with our species. A comparison of the genome of the Siberian cave with ours can shed light on this. Svante P\u011bvo, one of the authors of the reference article, notes that Denisovans show changes in genes associated with the \u201cbarbed\u201d of the brain and nervous system, and that it is tempting to speculate that what led modern humans was a change in their brain connections. ovano will be applied in the future to other fossil samples, in particular to Neanderthal fossils, which will certainly allow accurate comparisons between the modern human genome and that of extinct species. Another candidate in this regard is the fossil of a mysterious species of dwarfs \u2013\u201chobbits\u201d \u2013 one meter high discovered in 2003 on an island of Indonesia and which would have survived isolated until about 12,000 years ago. Decrypting the genetic code of extinct species will help us to understand that it has made us so successful, to the point of ending up as the dominant \u2013solitarian \u2013 species on Earth after millions of years of evolution. The period of time during which we have been alone will be updated in the future as research progresses. That we have been doing so for thousands of years is, however, a fact that will hardly be questioned.",
    "https://upload.wikimedia.org/wikipedia/commons/1/13/Mars3_iki.jpg": "As planned, on August 6, the explorer \u201cCuriosity\u201d entered the atmosphere of the planet Mars in a controlled manner and posed smoothly and without novelty on its surface by means of a complicated maneuver. Once on the ground, the explorer began the planned procedure to get in shape and begin his two-year exploration mission. He has begun by sending photographs of the Martian surface, first in black and white, and then in color and high definition. He is not \u201cCuriosity\u201d the first explorer to arrive at Mars. He was preceded by the twins \u201cSpirit\u201d and \u201cOpportunity\u201d in 2003. In fact, the latter is still active traveling the Martian surface and sending data and images to the Earth. The \u201cCuriosity\u201d is, however, a larger and more complex explorer than the twin explorers who have the size of a golf cart and a weight of about 180 kilograms. In comparison, the \u201cCuriosity\u201d weighs almost a ton and its size is close to that of a small car.Marte has received landcrafts since the 1970s. The first ones were not explorers and only intended as explorers. This was the case of the Soviet ship Mars 2, which in 1971 became the first object sent from Earth to reach the surface of Mars. It should be noted, however, that it did not do so softly because of a fault in its computer and ended up crashing on the Martian soil. Mars 2 was followed by Mars 3 which did manage to land softly, although it failed shortly and could not send scientific data to the Earth. The first spacecraft that, in addition to posing gently on the Martian surface was able to establish communication with our planet, was the American \u201cViking 1\u201d, which was followed by the \u201cViking 2\u201d, equally successful. From these two missions came the first images of the surface of Mars. To the \u201cViking\u201d ships followed other missions with the same destination. Some succeeded and others failed, but with the descent of \u201cCuriosity\u201d there are already twelve Earth ships that have reached the surface of our neighboring planet in one way or another. There may even be Martians who claim to have seen in the sky an object that resembled a flying saucer, and that it would be nothing other than the capsule within which the Curiosity entered the Martian atmosphere. If there were Martians there would be a possibility that there would be an equivalent of H.G. Wells that related in his novel The War of the Worlds the invasion of his planet by inhabitants of the neighbouring blue planet, who would arrive equipped with infernal machines capable of destroying everything in its passage by rays of fire. Our planetary neighbors would certainly see in the fallen objects of the sky over the last 40 years an indication of the imminence of the anticipated Earth invasion by that novel. Since it was observed through a telescope, it was fancied with the possibility that Mars would host intelligent life. One of the greatest enthusiasts of this possibility was the American astronomer Percival Lowell, who took seriously the observations of astronomer Giovanni Schiaparelli, who also indicated the existence of channels on the surface of Mars. Lowell is the American astronomer Percival Lowell. The ideas of Schiaparelli and Lowell were valid during the last decade of the 19th century and the first of the 20th century \u2013 and possibly influenced H.G. Wells who published the War of the Worlds in 1898\u2013. Such ideas, however, did not survive for a long time and even Lowell himself had to admit that they were possibly wrong. Today, we have a reasonable assurance that they are and that there is no intelligent life on Mars. The ships that have managed to reach its surface show it as an arid and dry place, without the slightest trace of life, although it could have been on a microbial level. It is fascinating, however, to see the similarity of the Martian landscape shown in the panorama sent a few days ago by the \u201cCuriosity\u201d with a desert on our planet. Such fascination persists even after reasoning that the similarity is in fact only apparent, and that the surface of Mars is an inhospitable place, incapable of harboring superior life such as the \u201cCuriity\u201d on our planet. In these circumstances, it is unlikely that there will be an H.G. Wells on Mars and that someone there will have been alarmed by the arrival of the \u201cCuriosity\u201d. Even if this had been the case, the concern would have been in vain, because on Earth we are not at this moment in possibility, let alone organize an invasion of Mars, but even send a manned mission. Thus, in the decades to come we will have to conform to the information and postcards that reach us in remote control from Mars. What, on the other hand, is not a small thing.",
    "https://upload.wikimedia.org/wikipedia/commons/d/da/Contenedores_de_residuos_en_Buenos_Aires.JPG": "An iconic construction of the city of New York, the old Yankee baseball stadium, was demolished in 2009 to give rise to a park. This, despite the protests of those who demanded it was preserved by its historical significance. This stadium was inaugurated in 1923 and served as a home for 85 years to the Yankees of Babe Ruth, Joe Dimaggio and Mickey Mantle. It witnessed 39 of the 40 league titles and 26 of the 27 World Series won by the Yankees, which make this team by far the greatest winner in the history of the Major Leagues. The historical role played by the Yankee stadium in North American baseball was unfortunately not enough to save it from the demolition that began as soon as the Yankees had a new stage. The new Yankee stadium was built alongside the old one and in its design some features of the original were retained as recognition of its historical significance, including the zenefa feature in its upper part. However, the fact is that the historical building ended up turned into a pile of rubble. The demolition of the old stadium of the Yankees can also be seen in the context of the waste it produced. The most common perception of garbage is focused on that generated by houses-rooms, offices and shops, and that is collected by municipal public services. In fact, however, this kind of waste is only a small percentage of the total. Indeed, it is found, for example, that the construction and demolition sector, together with mining and manufacturing, generates 75% of all waste produced by the 27 countries of the European Union. On the other hand, the consensus among experts is that the generation of waste in the world is not self-sustainable and that measures must be taken to mitigate its effects. In line with this, in the special issue of the magazine \u201cScience\u201d appeared this week, a section with several articles in which the problem of waste and ways of attacking it is addressed is included. In addition, from waste it is possible to manufacture fuels, medicines and cosmetics, at the same time that metals and plastics can be recycled several times. In the same way, some wastes can be used for the generation of electrical energy.The ease of recycling a product must be considered in its design.Some people think that the problem of waste is precisely due to a lack of design.That is, if a material or product cannot be recycled is because it needs to be redesigned.The conception of a product should not only contemplate the stages of manufacturing and marketing, but also a later phase of recycling.According to experts, barriers of not only scientific and technological nature, but also political, economic and even psychological nature must be overcome for an efficient disposal of waste.As an example of the latter, the natural resistance to considering as drinking water that obtained from the purification of black water, which is, however, technically possible, would not have been solved. We can take it, however, as an indication that we have to modify our perception of waste generation and take into account the environmental impact they produce.After all, building a new stadium was not absolutely necessary.All of this aside from the little consideration that was given to an enclosure of enormous historical \u2013 and possibly sentimental \u2013 significance for many Americans.",
    "https://upload.wikimedia.org/wikipedia/commons/8/8b/Ebers7766.jpg": "Suppose that for some reason you would like to send a message to the future, addressed to generations living within ten thousand years or even within a million years. What method would you choose? Thinking in a million years looks quite complicated, because besides that we would have to choose a transmitter vehicle that survives all this time, we face the problem of how to intelligible a message to those who will certainly be intellectually different from us. Sending a message ten thousand years into the future is also a difficult undertaking, although perhaps more manageable. Indeed we have close examples in this regard. One of these, the Egyptian pyramids, let us know, at a temporary distance of more than five thousand years, of the immense power enjoyed by the pharaohs in whose honor they were built. The greatest of all, the pyramid of Keops, has survived all this time thanks to its great dimensions, although it now looks somewhat misty by the onslaught of earthquakes and the deliberate destruction to which it has been subjected, in addition to the fact that the grave desecrators have made it its victim since early times. In recent decades, this has been the reason for detailed studies, because of the interest of alerting future generations to sites where radioactive waste has been deposited, both from power-generating nuclear power plants and from nuclear weapons manufacturing processes. As we know, one of the major problems of the nuclear power industry is the containment of the highly radioactive waste they generate, and most of it is stored in pools in the same nuclear reactors that produce them, or in their vicinity.The danger that this practice represents became evident during the accident of the nuclear power plant in Fukushima caused by the Tsunami that struck Japan last March, and that exposed to the environment some of the nuclear waste stored inside the buildings that house the reactors.One of the solutions proposed for the safe management of radioactive waste \u2013 and that have been implemented in a few cases \u2013 is its confinement to deposits located several hundred meters below ground.This makes it necessary to put warning signs around the site of confinement about its dangerousness. In addition, they consider that the signs would have to survive for as long as the radioactivity of the waste lasts, which means in some cases hundreds of thousands of years.Why could information be recorded that survives as much as the lifetime of the radioactive waste? At the \u201cEuroscience Open Forum\u201d congress held this week in Dublin, Ireland, Patrick Charton, a researcher at the French agency for the handling of radioactive waste, presented a possible solution. This consists of two sapphire discs of 20 centimeters in diameter. One of these discs is recorded with platinum the desired information, which is protected by hermetically linking the two discs. The creator of the device thinks that he could keep the information recorded \u2013up to 40,000 pages \u2013 for 10 million years. This, of course, does not completely solve the problem, since Charton himself is questioned, in which language would the warning of the radioactive danger be made for the inhabitants of the planet earth within 100 thousand years? The Egyptian hieroglyphics, for example, were decrypted by the Rosetta Stone, which contains These scriptures correspond to three periods in the history of Egypt, the last one near the beginning of our era. If we do not take the necessary providences, our distant descendants may have to resort to a Rosetta Stone to understand the messages.The U.S. Department of Energy took the bull by the horns and took on the task of developing a system of warning signs for confinement located near Carlsbad, New Mexico, dedicated to the storage of radioactive waste resulting from the manufacture of nuclear weapons.It is intended that this system will have a validity of 10,000 years.It is possible, however, that we are worrying too much and that ten thousand years in the future, with infinitely higher technology, our descendants will not need rudimentary warnings to protect themselves from radioactive material we have planted here and there.In any case, we may be being candil of the street and darkness in the house, more concerned about a distant and unpredictable future, than by a present full of radioactive waste maintained in vulnerable conditions, and that do not seem to be securely confined with the required speed.",
    "https://upload.wikimedia.org/wikipedia/commons/a/af/Deafness_and_hard_of_hearing_symbol.png": "In the last few days, the controversy over the death of Palestinian leader Yasser Arafat, which occurred in Paris in November 2004, has been revived because a recently released laboratory analysis found high doses of a highly radioactive substance in Arafat's clothes, suggesting that he died poisoned. While the public interest in the details of the Palestinian leader's death is fueled by the political implications of his possible poisoning, the cause of the death of a famous character is by itself a cause of curiosity. This curiosity, moreover, is not reserved for recently deceased people, and on the contrary increases as we move to the past. One example of this is the historical clinical-pathological sessions organized by the University of Maryland School of Medicine in the United States, which seeks to diagnose the health problems of famous characters based on available clinical information. Among the characters studied are Pericles, Alejandro Magno, Herodo, Columbus, Mozart and Darwin, among others. On 5 July, the case of Lenin, who died with convulsions at the age of 53 in January 1924, was studied before Lenin died in a disabled bed without being able to speak of not being monosyllable. On the basis of the symptoms he presented before and at the time of his death, as well as the autopsy performed on him, one of the presenters of the clinical-pathological session came to the conclusion that Lenin suffered from multiple strokes. Another participant, however, considered the possibility that Lenin would have been poisoned. The probable suspect in this case would have been Stalin, who benefited from his death. Of course, as with Arafat, the death of a famous character, beyond the curiosity that arouses him, is interested in the consequences that may have ensued. What if Lenin, by illness or murder, had not died at that time? Probably the history of the Soviet Union would have walked in different directions to those that followed in the subsequent decades. March 1827 at the age of 56. Beethoven suffered throughout his life from a whole catalogue of diseases, including smallpox, typhus, gout, arthritis, as well as episodes of abdominal pain, vomiting, diarrhea and constipation. He suffered, equally from pain of eyes, headache, nosebleeds, swelling of legs and asthma. And, of course, ironically at the age of 28, he began to lose the sense of the ear, becoming deaf at the age of 45. At the time of Beethoven\u2019s death, he was subjected to an autopsy that revealed severe damage to liver, kidneys and pancreas. Moreover, surprisingly, as Beethoven was composing music until very short before his death, his brain was also damaged. Beethoven\u2019s cause of death has been a cause of controversy. Some have attributed it to lead poisoning, based on chemical analysis of the composer\u2019s hair and skull bones that throws a lead content above normal. Lead would have come from cheap wine to Beethoven\u2019s amateur. . It has also been pointed out that the liver cirrhosis that was evident at the time of his autopsy \u2013 due to a high consumption of alcohol or another cause\u2013 could have contributed to his death. The Beethoven case is recorded in the book \u201cPost mortem: Solving the Greatest Medical Mysteries of History\u201d, whose author is Philip Mackowiak, organizer of the clinical-pathological sessions of the University of Maryland. Mackowiak writes that it is assumed that Beethoven\u2019s sufferings were not due to an unfortunate combination of multiple diseases, and that on the contrary such sufferings \u2013 including deafness \u2013 had only one cause, this probably was syphilis. Thus, the death of one of the greatest composers that have existed, that \u2013 according to testimonies of the time \u2013 it moved even to the very nature that triggered an electrical storm at the same time that the musician exhaled the last sigh, would have been more than ordinary. In the first instance we might think that they were negative, because they prevented the composer from listening to the music he created, in addition to putting him in a state of improper tension to develop his art. Some think, however, that deafness was positive and that the sound isolation actually helped him to create sounds that otherwise he would not have conceived. Thus the saying that, there is no harm that for good does not come.",
    "https://upload.wikimedia.org/wikipedia/commons/9/92/Umspannwerk-Pulverdingen_380kV-Trennschalter.jpg": "The US company Abound Solar, which manufactures solar panels, announced this week that it will file a bankruptcy claim. That company had received a $400 million loan guarantee from the U.S. Department of Energy for the construction of two solar panel manufacturing plants in Colorado and Indiana. Against this guarantee, Abound Solar obtained a loan of $70 million, from which it is considered that only $10 million to $20 million will be recovered after the bankruptcy.The loss will be absorbed by the taxes paid by US workers.Abound Solar is not the first solar module manufacturer company to be financially supported by the U.S. government and to go bankrupt. Previously, in September 2011, the California-based Solyndra company ran the same fate. Just like Abound Solar, Solyndra had obtained a credit guarantee from the Department of Energia, in its case for $535 million. Against this guarantee Solyndra received a $528 million loan from public funds. Both Abound Solar and Solyndra companies manufactured solar modules based on thin film cells. This material is the same as that used for the manufacture of the chips used by computers, but not with the same purity. Thin film cells have potential advantages over those based on silicon. Indeed, as its name suggests, this type of cells are manufactured by depositing a series of films with very small thicknesses \u2013 about a hundredth of the thickness of a hair \u2013 on a suitable support \u2013 a glass plate, for example. They require very little base material and therefore potentially could reach a low cost.In contrast, silicon cells have several hundred times larger thicknesses than thin film cells, so that for their manufacture much more base material is required which increases their cost.In practice, however \u2013 and for various reasons \u2013 solar modules based on thin film cells do not differ much in price from modules with silicon cells. In fact, these latter have traditionally dominated the world market for solar modules. Currently, between 80% and 90% of the total sold modules are silicon. As a result of both the emergence of China as a manufacturer of solar modules, and a reduction in silicon prices, the cost of solar panels based on this material has been significantly reduced \u2013 30-50% in 2011\u2013. This has led its thin film counterparts to lose competitiveness. In these circumstances \u2013 aggravated, moreover, by the reduction in demand for solar modules due to the economic problems that Europe is going through \u2013 it is easy to understand that Solyndra and Abound Solar could not have resisted the onslaught of Chinese companies and gone bankrupt. On the other hand, the reduction in prices of solar modules in recent years makes the generation of electricity by solar methods under certain circumstances become competitive with other traditional means of electricity generation \u2013 with the advantage that the Sun is a non-polluting source of the environment. This is the case in our country in the case of homes-habitation that are classified by the Federal Electricity Commission as having high consumption of electricity. In such case, it is economically advantageous to install solar panels for generation, not all the electricity consumed This is based on a scheme whereby solar modules are interconnected to the public electricity grid, so that all energy produced in excess during the day is purchased by the electricity supplier at the same price as it is sold to the user. Thus, while solar electricity is only competitive in certain special circumstances, we would hope that in the coming years its cost will be further reduced, to the extent that its use is widespread. We would thus take advantage of virtually inextinguishable, clean and free energy \u2013 once we have paid for solar modules, of course. For this, the Chinese will probably have to strive to reduce the cost of solar modules even further. Although on the way they could cause less competitive companies to break down, to the detriment, ultimately, of the moneys public.",
    "https://upload.wikimedia.org/wikipedia/commons/1/12/Buddy_Holly_%26_The_Crickets_publicity_portrait_-_cropped.jpg": "The 1960s witnessed one of the most notable events in the history of popular music: the so-called \u201cBritish Invasion\u201d to the United States, which, as we know, began in 1964 with the arrival of the Beatles to that country. On the arrival of the Beatles soon followed the arrival of a large number of English bands with a new sound that dominated the musical landscape of the United States for a good number of years.What is surprising about the case is that, according to the connoisseurs, the musical origins of the bands of the British Invasion are situated precisely in the United States. Precisely, and not to a small extent, in Rock and Roll, a musical style that appeared in that country in the 1950s and that was practiced by both black and white artists. Rock and Roll, in turn, had its roots in black music from the south of the United States that expanded into the industrialized north in the first half of the 20th century.In these circumstances it may be asked why the musical revolution that did take place in the United States did take place in England? English musicians who created a revolution of such great proportions from non-own musical roots? Wouldn\u2019t it have been more natural for their American counterparts to do so? Giving a precise answer to the above questions is complicated, to say the least. In general terms, musical evolution depends in a complex way on multiple factors of a social, cultural, economic, technological and even commercial nature, without forgetting the competition of composers and performers who are those who ultimately create and disseminate music. In an interesting article published this week in the magazine \u201cProceedings of the National Academy of Sciences\u201d of the United States by British researchers is shedding light in this regard. In that article, the listeners, consumers of music, are identified as one of the forces that determine the direction of their evolution. Even more, it is speculated that musical creation can take place even without the participation of composers and rest entirely in consumers. In this case, the creative force would be derived from the option that the latter have to choose the music they want to listen to. This conclusion is based on experiments made with a computer program called \u201cDarwin Tu\u201d. The experiment begins with the computer generating at random 100 sequences of sounds with characteristic \u201cdigital genes\u201d. Although the sounds in each initial sequence are repeated at fixed intervals, in all cases they constitute a cacophony that has little to do with any conception that we have of music. The sequences, however, have the opportunity to \u201cmatched up\u201d and generate offspring that inherits combined characteristics of parents, as if they were living organisms. In addition, during the reproduction process, random mutations are generated that introduce additional changes in the offspring. Thus, after playing for many generations, primitive sequences evolve into forms of music with a certain degree of complexity. The force that directs this evolution is the taste of the \u201cconsumers\u201d, who determine the sequences of sounds that are allowed to reproduce. For this purpose, 7,000 volunteers receive via Internet 20 sequences chosen at random among the 100 possibilities. To these sequences the participants give a rating with five levels, from \u201cI can\u2019t stand it\u201d to \u201cI like it\u201d. Tunes\u201d chooses the ten sequences that are on average best qualified and mates them to produce 20 descendants that replace the 20 sequences that were evaluated. Thus, a reserve of one hundred sequences of varied antiquity is maintained, subject to a natural selection process. As a result, after 2,500 generations that process transformed the original noise sequences into something structured with musical traits of a certain complexity. Thus music would have been produced through a natural selection process, based on chaotic sounds and without the help of a composer. On the other hand, as the authors of the aforementioned article recognize it, the factor that they have identified in their work is only one of several that determine the evolution of music. This evolution would be, moreover, determined by the composers, who introduce new sounds that do not necessarily prove pleasant in a first impression. Individual musical tastes, moreover, are influenced by collective tastes, a factor that was clearly visible in the revolution of the sixties. Another evident factor at that time was the commercial aspect that successfully handled the image of the British groups and the diffusion of their music \u2013 that in Mexico it worked unfortunately in the opposite direction, blocking English groups with few exceptions, for the benefit of some national groups not necessarily more creative.The article by British researchers is enlightening and reveals one of the mechanisms that drive the evolution of music.We are, however, far from fully understanding what caused the musical revolution of the sixties, a phenomenon more than fascinating.",
    "https://upload.wikimedia.org/wikipedia/commons/4/43/Gullivers_travels.jpg": "Jonathan Swift describes in \u201cThe travels of Gulliver\u201d the features of the protagonist in the country of the Liliputenses, similar to humans but only 15 centimeters high. Gulliver also visits Brobdingnag, a country of giants twelve times higher than us. According to Swift, the proportions of the body of dwarfs and giants would have been the same as those of our species, so that the inhabitants of Liliput and Brobdingnag would have looked the same as us, except for the scale.The Gulliver Travels were published in 1726 and it may not be reasonable to expect that Swift would have been very sharp in terms of caring for the consistency of his novel with the principles of mechanics. After all, these principles were discovered and published by Isaac Newton in 1686, just 40 years before the publication of Gulliver\u2019s Travels. Today, however, the elementary physics course of the preparatory school teaches us \u2013 or should teach us \u2013 that dwarfs and giants as Swift conceived them cannot exist; this at least on our planet. . In fact, even without the benefit of an elementary course of physics, we can easily convince ourselves of this impossibility. Let us think, for example, of a horse that by means of a magic technique we grow up to ten times its normal size, maintaining all its proportions. Thus, if initially the horse had a weight of 400 kilograms, after the growth it reaches a value 1000 times greater, that is, 400 tons! \u2013this figure is obtained by multiplying the initial weight by 10x10x10\u2013. In contrast, the resistance of the horse\u2019s legs only grows 100 times, because such resistance varies according to the transversal area of the same ones; that is, by a factor equal to 10x10=100.We would thus have a horse with legs too thin and ten times less resistant in relation to its weight than those of a horse of normal size. Such a horse could hardly stand up, let alone overcome a fall when running at gallop. All the above acquires relevance in relation to an article published last June 6 in the electronic magazine PLoS ONE by a group of researchers from the University. In that article, whose first author is Jean-Michel Mongeau, a study of the movements that cockroaches and lizards carry out when finding an obstacle is reported. In particular, they investigated the stunts that they perform when, when running at great speed, they suddenly meet the end of the track. For this purpose, they placed a cockroach on a suspended ruler in the air and put it to run along it. To keep it in touch, they filmed it with a high speed camera as it approximated the edge of the rule. The results were surprising. They found that, far from stopping its career as it approached the void, the cockroach followed in front. It did not fall, however, because at the last moment it grabbed the legs of the edge of the rule and with this it turned at great speed, landing on the lower face of the rule where it continued to run in the opposite direction. When they carried out the same experiment with the lizards they found a similar result: these animals rushed into the void at great speed and took advantage of the rule. It is worth noting the great speed with which, both cockroaches and lizards, carry out the rotation towards the lower face of the rule, an operation that only takes them 0.15 and 0.2 seconds, respectively. It is equally noticeable that this is possible by a scale effect. That is to say, only a small animal is capable of such acrobatics. Thus, for example, we could not expect to see an elephant \u2013 no matter how good the circus is \u2013 that runs loosely on a platform and when arriving at the shore is gripped with the hind legs and turns to finish face up with the legs supported below the temple. It might seem superfluous to investigate how lizards and cockroaches manage to circumvent obstacles. It is not, however, because in this way we find the solution that nature gave to a problem that is relevant to the design of robots, specifically those that require to move on rugged terrains. As is the case, as is the case, according to Mongeau and collaborators, of robots destined for the search of people buried by an earthquake. In line with the above, the reference article describes the development of a mini-robot inspired by the acrobatics filmed of cockroaches and lizards. This mini-robot, which can reproduce such acrobatics to a large extent, is an example of a design inspired by nature. Turning to nature to find solutions to technical problems has generally resulted in a productive strategy. This is not surprising, because after all, nature comes to its designs through hundreds of millions of years of evolution. And as the saying goes, the devil knows more by old than by devil.",
    "https://upload.wikimedia.org/wikipedia/commons/1/1a/Dszpics1.jpg": "Just as a swallow doesn't make summer, a single extreme climate event is not proof that our planet is experiencing global climate change. Many swallows, however, do announce the arrival of spring. Likewise, according to some climate experts, numerous extreme events of cold or heat, rain or drought would be an indication that our planet is experiencing gradual climate change.It is an accepted thesis by many researchers that the Earth's climate is effectively changing; this due to the increase in the concentration of greenhouse gases in the atmosphere that has occurred since the beginning of the industrial revolution two centuries ago.This increase has led to an increase in the average temperature of the planet's surface, which, although small and less than a centigrade degree, would be sufficient to generate extreme weather episodes of greater severity and frequency.As we know, our country is currently suffering an episode of drought that plagues several states in the center-north \u2013 including San Luis Potos\u00ed \u2013 and is reported to be the most severe in the last 50 years.It is not clear whether this drought is caused by climate change, as a major one of the world's population is suffering. Isolated extreme event such as the one we are suffering could obey other causes. I would, however, agree with those who predict extreme weather events with a greater frequency and severity due to the effect of global warming. On the other hand, according to the \u201cNational Oceanic and Atmospheric Administration\u201d, the United States has suffered the beginning of the year \u2013 January to May \u2013 hotter since the beginning of climate records in 1895. Thus, the average temperature recorded in the spring months \u2013 March-May \u2013 was almost 3 degrees Celsius higher than the average temperature in the period 1900-2000. It was also higher by more than a degree centigrade than the previous record, in effect since 1910. Like Mexico, the United States is suffering from an episode of drought and the first five months of the year have had on average less rainfall than normal. There are also contrasts throughout the country and there are states like Oregon and Washington on the west coast that have had more rainfall than usual. Global warming, apart from the expected climate effects, could also have less obvious impacts. . In this regard, in an article published on 3 June in the journal \u201cNature Climate Change\u201d, a group of European and North American researchers led by Michelle van Vilet of Wageningen University in the Netherlands, analyzed the impact that global warming could have on the electricity generation industry of Europe and the United States. Approximately 80% of the electricity consumed by the world is generated in thermo-electric and nuclear-electric power plants. While both types of power plants operate from very different primary energy sources, they share the last stage of the production process of the electric fluid. That is, both thermo-electric plants and nuclear-electric plants produce their energy using turbine-powered generators, which are in turn moved by steam at high temperature. In the case of thermo-electric plants, steam is produced by burning fossil fuels, while nuclear-electric plants use the fission of the atom for the same purpose. On the other hand, once the steam leaves the turbine has to be cooled to be reused, and for this purpose it is necessary to use water. Water is thus an indispensable element for the electricity generation industry, which in fact consumes a large part of the available freshwater \u2013 around 40% in Europe and the United States. It is not in this way difficult to understand that this industry can be adversely affected by the scarcity of water due to droughts or other climatic phenomena. Moreover, van Vilet and collaborators found that electricity generation can be affected not only by the scarcity of cooling water but also by the increase in the temperature of the same in rivers and lakes due to global warming. That is, at the higher temperature of cooling water due to an extreme climate event, the greater the volume of the same necessary to achieve the same effect. The conclusion of the study by van Vilet and collaborators is that, as a result of climate change, in the period 2031-2060, the United States and Europe will probably face reductions in their electricity production of 4-16% and 6-19% during the summer months, respectively.Global warming of the planet thus shows a new facet. This will lead to an increase in the level of the oceans, as well as permanent climate changes in the world. In addition to all this, the monster that represents global warming may well turn against greenhouse gas generating thermoelectric plants. To which, however, it owes much of its existence.",
    "https://upload.wikimedia.org/wikipedia/commons/1/12/1925_Ford_Model_T_touring.jpg": "It is possible that in the midst of traffic congestion and in the face of the evident increase year by year in the number of cars circulating in our city, more than one has questioned the rationality of using the car as a means of transport. However, we cannot fail to recognize that the car is an invention of a great utility; invention that, among other things, provides independence of movement and speed of transfer \u2013 if we do not find ourselves with a traffic jam, of course. It also allows us to choose a place to live without the distance to the workplace being a determining factor.Today the car has reached in many places in the world a predominant place and has become something indispensable and highly appreciated.In this context, it is strange to think that this was not always the case and that, on the contrary, in its first years of existence, the cars were often classified in the United States as dangerous vehicles, which put at risk the safety of pedestrians on the streets.As we know, the first self-propelled vehicles with gasoline engines were developed independently by Kart Benz and Gottllieb Daimler in Germany, in the 1980s of the 19th century. It was, however, largely in the United States where during the 20th century the automobile developed as a means of transport for mass use. At the beginning, at the end of the 19th century, cars were conceived essentially as horse carriages, but without horses. At the dawn of the 20th century this conception changed and the cars in the subsequent were designed entirely as self-propelled vehicles, with characteristics different from those of horse cars. Among the characteristics that differentiate a self-propelled vehicle from an animal-drawn carriage, is found the speed that the former can achieve and that is considerably higher compared to that of the latter. A higher speed implies, of course, a greater danger for pedestrians, so that the earlier friendly streets became random. Thus, the opinions against which many people expressed at the beginning of the 20th century with respect to cars are not surprising. Views that, however, were made favorable from the 1930s. Peter Norton, author In the book \u201cCombating traffic: the birth of the age of the motor in the North American city\u201d, he analyzes the causes that led to the change of attitude of Americans towards cars. As the author points out, in the decade of the 20s of the last century it was worrying for many people the traffic on the streets of motor vehicles that caused accidents and deaths among pedestrians. In the context of the first decades of the 20th century, in which the street was conceived as a space for pedestrians \u2013 in which even children could play \u2013 cars were dangerous intruders.Soon, however, the pressure of car manufacturers, the expansion of the streets for the traffic of them, as well as the obvious advantage that it represents to own a car, among other factors, led to a gradual change in the perception of the street \u2013 perception that would have been consolidated in the 1960s \u2013 now conceptualized as a space for cars in which the pedestrian became intruder. He thus acquired a shared responsibility with the motorist to avoid being run over. It was argued, for example, that the independence of movements brought about by the car is in accordance with the independent spirit of the Americans. Thus, for many reasons, according to Norton, the American cities entered fully half a century ago at the age of the engine and thus the pedestrian changed their status from owner of the streets to intruder in the same.In addition to the causes that led us in Mexico, as in the United States, to adopt the car as a means of urban transport, it is clear that in our country the streets belong entirely to the motorists and not far from the pedestrians. As such, we are intruders in our own streets and share with the motorists the responsibility of taking care of us to suffer an accident. Thus, we see things, and since the motorists arrived to stay, as pedestrians we should think of agreeing a fair deal with them and recovering ownership of some of our streets to which the cars arrived as \u201cparatrooperists\u201d. In this regard, we must recover for the pedestrians the entire historical center. of our city, which has a colonial trace that, of course, was never intended for automobiles, that more than legitimate owners of the old narrow streets look like strange intruders.",
    "https://upload.wikimedia.org/wikipedia/commons/e/e9/Fighting_Nyalas.JPG": "The cover of the magazine \u201cScience\u201d of this week shows the image of a Beirut building destroyed in 2006 by a bombing of Israel\u2019s defence forces. The cover page anticipates a special section in which different aspects of the conflicts between humans and the violence that they derive are analyzed. This section includes articles, both research and outreach, that analyze, among many other topics, the conflicts of racial and religious origin, human sacrifices, the military use of planes aimed at remote control, terrorism and the possibility of living in peace. One article that is particularly striking to us \u2013 because of the similarity with current events in our country \u2013 is the one that describes the finding of a series of mass graves near the site known as Tel Brak in the northeast of Syria, near the border with Iraq. The discovery was made with British archaeologists in the year 2006. One of these tombs, about 3 by 20 meters, contains the remains of 150 young people, with ages that fluctuated when they died between 20 and 35 years. The surprising thing about this happened in the Copper Age, almost 6000 years ago. n that the mass graves of Tel Brak may have had their origin in military confrontations between the urban center of Tel Brak and the cities of southern Iraq. This is based on the fact that the tombs did not contain remains of women, children or elderly people, and only of young people fit for war. Although there is no indication of those who were the victors, what is clear is that whoever they were celebrated the victory with a great meal, which included the slaughter of 75 cows and 300 sheep and goats. This is known because together with the human remains were found those of the feast, including the dishes used in it. One issue that is put into perspective in another of the articles of the special edition of \u201cScience\u201d is the relationship between violence and life in urban centers \u2013 of which Tel Brak is an early example \u2013 whose appearance implied more complex social structures than those of nomadic groups. There would be two views in this regard. That according to which violence diminishes with urbanization, so that today the probability of death is considerably lower than those of nomadic groups. In contrast, there are currently small societies in which violence is very small, as is the case with the Pueblo Indians of New Mexico, with only two murders in a year for every 100,000 inhabitants; this is in contrast to the cities of Baltimore and Detroit where the corresponding number is 34 homicides per year. Apart from this controversy, however, we cannot deny that violence goes and comes independently of urban development. In Mexico we suffered it for much of the 19th century and the beginning of the 20th century. Later we enjoyed a period of relative peace that lasted the rest of the century, to finally witness a violent resurgence in recent years.All this at the same time that Mexico became an increasingly urban country.On the other hand, regardless of any other characteristics that might be attributed to it, scientific knowledge has a utilitarian value. That is, if we knew the laws that govern a particular natural phenomenon, we could, in principle, develop a technology to control it, and even put it to work for our benefit. from computers to telecommunications systems that have changed our lives. Although among the most impact technologies are those related to sciences such as Physics, Chemistry or Biology, it would be expected that a greater knowledge of social phenomena and their causes would help prevent violence among humans. In this regard, in an editorial that is part of the special issue on human conflicts \u201cScience\u201d writes: \u201cOur species has a long history of distrust towards foreigners, of contempt for those who are not of our group and of fighting against each other in many ways and in many places, using the most deadly technology available at the moment. This special issue of \u201cScience\u201d on human conflicts illustrates the role of the scientific community in gaining a deep understanding of the evolutionary history of these conflicts and, most importantly, demonstrates how science can identify the greatest risk factors leading to mass violence.\u201d As science takes a more active role in preventing human conflicts, a reflection on Tel Brak leads us to conclude that in the matter of violence there is nothing new under the sun. At least not for six thousand years.",
    "https://upload.wikimedia.org/wikipedia/commons/d/dc/Cuba_flag.png": "In an interview that appeared earlier this week in the Cuban daily Juventud Rebelde, a researcher member of the Cuban Institute of Literature and Linguistics, he comments that in an attempt to be original Cuban parents are giving their children invented names that are not rarely extravagant, to say the least. In some cases these are obtained by combining, more or less creatively, common names of their own. Thus, we find names like Mayren, which is a hybrid of Mayra and Ren\u00e9, and Adaris, which is a hybrid of Ada and Dar\u00edo.Another way \u2013 less creative \u2013 in which Cuban parents find names for their children is simply by investing a common name of their own. Thus, Airam, it is obtained from Maria, and Ostenre from Ernesto. Although she does not give a solid argument, the Cuban researcher is concerned about the proliferation of their own names so unconventional and considers that the phenomenon must be studied thoroughly. On the other hand, those who could have well-founded concerns are the newborns. In the interests of originality, however, they invert the words resulting from Ordep Otrebla. This unpronounceable name would clearly be a future inconvenience to the directly affected. Apart from concerns, however, it is a fact that languages are in continuous evolution and that all names \u2013 like all words \u2013 had to have been born at some point. In this regard, a group of researchers from Italy, the United States and Israel, led by Alexander Petersen, carried out a study on the birth and death of words in the period 1880-2008. This study, published in the journal \u201cNature\u201d last March, was carried out with 10 million words belonging to three languages, English, Spanish and Hebrew. For this, researchers took advantage of the digitalization project of Google books, which covers 4% of all bibliographic material published to date. According to the reference article, the words are subject to a Darwinian process of evolution similar to that experienced by living beings. As we know, The three words were born after Wilhelm Roentgen discovered these rays in 1895, and the property that they have to go through the human body and print their fingerprints on a photographic film. By studying the database of Google, Petersen and collaborators found that from 1920 to 1980 \u2013 although with notable variations \u2013 of the three words, of the three words, of the three words, of the three words, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the two, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the four, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the four, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the two, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the three, of the two, of the two, of the three, of the two, of the two, of the two, of the two, of the two, of, of, of, of, of, of the The most frequently used was \u201cRoentgenogram\u201d. The above excepting a short period around 1920 in which it was surpassed by \u201cRadiogram\u201d. Instead, since 1980 the use of these two words declined to almost disappear at present when they were replaced by the word X-ray. Researchers speculate that this was due to X-ray is a shorter word than their competitors, which makes it better suited for the Darwinian struggle. One very interesting aspect of the article referred to is to have found that in the last 20 years the frequency with which new words are born has decreased. At the same time, it was found that it has increased the frequency with which existing words die. The latter, according to Petersen and collaborators, is attributable to the appearance of digital text processors equipped with word correctors. Indeed, during the digital edition of a text the words written with spelling errors are underlined as incorrect \u2013 or flat changed to the discretion of the corrector \u2013 and in this way tend to disappear. Thus, the digital edition of texts has modified the forces that mold the evolution of language. In this way, we might think that the concerns that have generated the emergence of new names on the island of Cuba are possibly exaggerated, because the survival of a new name depends on how well adapted it is for evolutionary competition. Unpredictable names \u2013 the result of inverting utterable words \u2013 would then enjoy an ephemeral existence. Instead, their own names such as Mayren and Adaris, short and easily pronounced, will have more chances of surviving for the benefit of our language. To this, much would help text correctors to incorporate them into their database.",
    "https://upload.wikimedia.org/wikipedia/commons/9/97/Discus_Thrower_Copenhagen.jpg": "As we know, discussions about religion \u2013 like those about football \u2013 are a never-ending tale. The reason for this is that religious beliefs \u2013 or anti-religious ones \u2013 are something that each person has, and to pretend to influence or impose views in this regard always leads to difficulties. Commonly, psychologists associate religious beliefs with intuitive thinking, which contrasts with analytical thinking. Intuitive thinking is immediate, as when we recognize a person by his face. Analytical thinking, on the other hand, is delayed and involves a certain process of reasoning. Both types of thought coexist in our minds, although analytics can be imposed on the intuitive in certain circumstances. On the other hand, while we generally assume that religious beliefs remain stable for a long time, in the last Thursday issue of the magazine \u201cScience\u201d, two researchers from the University of British Columbia, in Canada, published an article in which they conclude that the strength of religious beliefs can be diminished by manipulations that induce analytical thinking.The researchers based their conclusions on the results of five experiments. To find a correlation between analytical thinking and religiosity, it was carried out with 179 Canadian undergraduate students. Three problems were presented to them in order to measure their analytical reasoning. Drafting these problems suggested an intuitive quick response, which, however, was incorrect. To find the correct answer, the student had to reason it. As an example of the above, the participants were asked the following problem: if the lilies growing on the surface of a lake cover it completely in 48 days, at a rate of growth such that the covered surface is doubled every day in how many days is half the lake covered? The immediate intuitive answer \u2013 and incorrect \u2013 is 24 days. An analytical reasoning, in contrast, leads us to conclude that the lilies cover the surface of the lake in 47 days, for one day before it was completely covered, it was only in half. With the aim of correlateing the results of the previous experiment with their religious beliefs, students were also asked a series of questions to evaluate their religiosity. For example, if they believed in God, if in their life, they were asked, They felt the divine presence or if they turned to God when they were in trouble.The result was that the higher grade in the analytical tests, the lower grade they obtained in the religiosity tests.The most novel part of the study, however, was the one obtained with experiments designed to determine if it was possible to modify the religiosity of a person by inducing him to think analytically.For this purpose, questions were asked to two groups of students in order to evaluate their religious beliefs.Before this, a first group was presented with an image of Rodin's \u201cThe Thinker\u201d, which has a strong analytical connotation, while the second group was shown an image of the Miron Discobolo, which has a visual impact equivalent to that of Rodin's sculpture but without its analytical significance.The result was that the ratings of the degree of religiosity of the first group of students were inferior to those of the second. Similar results were obtained with other experiments.In stark contrast, evidence that had been made months before the same students, without seeking to induce them an analytical behavior, showed no differences between the two groups. So, surprisingly, it is possible to change religious beliefs through an induction into analytical thinking. Certainly, during the experiments of the reference article there were no spectacular changes \u2013 a believer did not become an atheist, for example \u2013 but did significantly diminish the religious attitudes of the first group of students. The study reported in \u201cScience\u201d is, of course, as any scientific, neutral study and seeks to establish objective bases for explaining religious disbelief. It does not seek, in any way, to make value judgments on it, nor on the merits of intuitive and analytical thoughts at the time of making decisions. In this the authors are very clear and express it explicitly at the end of their writing. The subject, however, easily generates controversy. In relation to this, an opinion article published in the magazine \u201cNature\u201d last Thursday is skeptical about the conclusions of the article of \u201cScience.\u201d In particular, it considers that religiosity is such a complex phenomenon that it may not even be susceptible to scientific study. Thus, when we have objective bases to explain religiosity \u2013 or the absence of it \u2013, we will consider it as a natural phenomenon without any connotation, positive or negative. For the time being, we may perhaps say that being or not being a believer is a reflection of the way we handle our intuitive and analytical thinking processes. That is, it is a matter of approach.",
    "https://upload.wikimedia.org/wikipedia/commons/3/34/Embalse_Guri.JPG": "It may sound unlikely that there is a direct connection between a dam of large proportions and the occurrence of tremors, also of large proportions, in its immediate vicinity.This, however, is what some geophysicists maintain in relation to the Wenchuan earthquake, China, which in May 2008 \u2013 a little before the Beijing Olympics \u2013 killed 80,000 people, and which would be related to the Zipingpu dam near the epicenter of the tremor.One fact that supports this association is that the filling of the dam started in September 2005 and two and a half years later the earthquake occurred.In a region, moreover, where there had not been an earthquake of this magnitude in at least 1,000 years, according to experts.In the past, a clear relationship has been established between the movement of large masses of water, as occurs during the filling or emptying of a dam, and the occurrence of tremors.These, however, have had a maximum magnitude of 6.3, which contrasts strongly with the magnitude 8 of the Wenchuan earthquake.As the geophysicals explain, tremors have their origin. In this context, the magazine \u201cScience\u201d in the number corresponding to the present one, in the continuous movement experienced by the different plates that form the earth\u2019s crust. As a result of this movement, the forces of friction along the geological fault between two plates can give rise to a great accumulation of energy. By reaching these forces a certain critical value, the accumulated energy is suddenly released generating a tremor. In the case of the Wenchuan reservoir, it is speculated that the enormous weight of the water mass \u2013 the curtain of the dam has an altitude of 156 meters \u2013 could trigger the tremor by the pressure it exerted on the geological fault, which is just below the reservoir at a depth of between 5 and 19 kilometers. Another possibility is that the water of the dam has been filtered to the fault, lubricating it and accelerating its fracture. The skeptics, however, argue that the water could not have penetrated to the maximum depth of 19 kilometers estimated for the epicenter of the earthquake, although others argue that in fact that the epicenter occurred at a depth of between 6 and 9 kilometers, until which the filtration could have occurred. The new reservoirs will be located up the river from the Three Gorges dam, and according to the critics, they will have four reservoirs in the Yangtze River, echoing the concerns of some geophysicists about the Chinese plans to create a series of reservoirs along the Yangtze River in an area with seismic activity. These reservoirs are intended to generate electricity, which China needs to sustain its accelerated economic growth.As we know, China has the largest hydroelectric power plant in the world, Tres Gorges, with an installed power of 21,000 KW. This is located in the Tres Gorges Dam, which retains the Yangtze waters and forms along its channel a small lake 600 kilometers long. We can see how enormous the Chinese installation will increase its capacity in 40,000 MW, which is almost the total capacity of our country in this area. The new reservoirs will be located upstream from the Three Gorges dam, and according to the critics they will have The economic development of the world, however, needs increasing amounts of electricity. Nowadays, this energy in its largest proportion is obtained from the burning of fossil fuels, which we know have caused climate change on our planet. China and other countries are looking to replace these fossil fuels with non-polluting renewable energy sources, one of which is precisely hydroelectricity. Hydroelectricity requires the creation of large artificial lakes, which therefore have a significant impact on the environment. In this it would be its biggest disadvantage, which would keep it away from being an ideal source of energy, which, of course, does not exist. Hydroelectricity, on the other hand, is a very attractive source because it takes advantage of the energy from water falls and does not release waste products that contaminate the environment. Energy in water falls, in addition, depends on the force of gravity \u2013 of which, as we know, we cannot rid ourselves of \u2013 and will end up in the environment, regardless of whether we use it. Hydroelectricity is thus presented as a highly attractive source of energy. This will possibly be maintained in the future. Although not in the event that speculations are true and that a giant reservoir near a seismic area is actually capable of causing an earthquake of great magnitude. In this circumstance, it would result that hydroelectricity has after all its bemoles. We could apply to it the saying that, \u201cnot all that shines is gold\u201d.",
    "https://upload.wikimedia.org/wikipedia/commons/2/29/Cristales_cueva_de_Naica.JPG": "Imagine that for a week he doesn't put order in the things he uses every day. He doesn't lay down his bed, nor does he go back to the toilet drawer the brush and comb he uses to comb himself. Nor does he wash the dishes after eating, let alone keep them in the place intended for that purpose. Nor does he order the newspaper when he finishes reading it and far from it throws it out here and there. In short, he uses the things and in the end he leaves them anywhere, without worrying where. With these practices, at the end of the week \u2013 possibly before \u2013 his house will reach a degree of disorder such that it will make it difficult to live in it. At this point he will have to make an effort to order it again if he wants to rescue it as a place to live.The tendency of things to mess up unless there is a force in the opposite direction is common in the Universe and it is not limited to our immediate environment, nor to what we do or stop doing to keep it in order.In particular, it happens in the world of atoms. In relation to this, we remember that the materials are composed of atoms. At the same time, in a solid material atoms are so close together that it seems homogeneous and impenetrable to us, and not a material composed of narrowly interwoven tiny parts.Knowing of their existence we can ask ourselves how atoms are placed within a solid material?In complete disorder like those attending a rock concert, or, on the contrary, ordered as soldiers of a regiment in progress?The answer is that there are two possibilities: there are both ordered and disordered materials.The former are called crystals and the latter amorphous.In addition, as we might have suspected, there are also materials with an intermediate atomic order between these two extremes.In contrast to humans, we hardly change habits, atoms are more flexible and the order within a material is determined by the way it was treated in the past. Thus, for example, we can obtain a highly ordered solid material if we warm it beyond the point at which it becomes liquid and then the order within a material is determined by the way it was treated in the past. On the contrary, if we cool it very quickly we will not give time to its atoms to be ordered \u2013 which, on the other hand, they naturally look for \u2013 and will end up occupying random positions within the solid material. Although crystals are not the most common materials in nature, we do find examples of them without difficulty \u2013 we can recognize them by their flat surfaces that form precise angles between them. As examples of natural crystals we can include grain salt and crystallized sugar, as well as diamonds and other precious stones. The most striking example of natural crystal, on the other hand, is proudly Mexican \u2013 though unfortunately not manufactured by us \u2013 and is located in a cave in the Naica mine in the state of Chihuahua. This cave, discovered in 2000, contains natural gypsum crystals \u2013 calcium sulfate \u2013 which are with much of the largest crystals in the world and have dimensions up to ten meters long and one meter in diameter. These crystals have been studied extensively by a group of researchers from the University of Granada, Spain, in With researchers from the University of Tohoku in Japan, they conclude that the extraordinary size of the Naica crystals is due to their slow formation, which would have taken about a million years to complete. During this time, the crystals would have formed in an aqueous medium, maintained at a temperature higher than 50 degrees Celsius, in which the materials that were slowly deposited on the crystals were dissolved, growing. Something like a pot in the stove, with liquid water and carefully chosen ingredients, and a controlled temperature of precise manara over a million years. It should be noted that until recent dates the cave of Naica, which is at a depth of 300 meters, was flooded, since the water tables are at a depth of 120 meters. Only after the exploitation of the mine began, it was by pumping water that the gypsum crystals were first discovered in a million years. Last Wednesday the referred group of the University of Granada won the cover of the magazine \u201cScience\u201d with an article in which they made clear the mechanism by which plaster crystals are formed. This sheds more light on what it was that enabled the formation of natural crystals of such unusual dimensions in the cave of Naica.In addition to the explanations, however, what is clear is that, given the right conditions, atoms are able to organize and order themselves on a large scale.",
    "https://upload.wikimedia.org/wikipedia/commons/9/95/New_shot_of_Proxima_Centauri%2C_our_nearest_neighbour.jpg": "In the work \u201cThe Chronicle of Nuremberg\u201d, published in Germany in 1493, we find illustrations of monstrous, supposedly human beings who would have lived in the confines of the then known world. The illustrations show us individuals with a human body but with an ostrich neck and beak, with a human head and a horse body, or with a human body and a dog head. They are also human with four eyes, with one eye, with six arms, without head but with eyes, nose and mouth in the chest, as well as dwarfs with only one leg topped by a huge foot, so large that to its owner it served as parasol if necessary. The latter, it was apparently very frequent, because the mono-foot dwarfs would have lived in a warm country and in fact they were drawn lying on their backs with their feet raised to become shade. Monsters with human characteristics were not, of course, invented by the Chronicle of Nuremberg and on the contrary they have been a constant in our history. In particular, as we know, Greek mythology includes cyclops, harps, Centaurs and sirens, among many of which have been invented by the Nuremberg Chronicles. The Roman writer Pliny the Elder, on the other hand, described at the beginning of our Age human monsters \u2013 including the mono-foot dwarfs \u2013 in his work \u201cNatural History.\u201d However, insofar as the planet was being explored and there were no traces of the expected monsters, the stories about them lost credibility. Although not entirely and even today we know of supposed half-human beings half-beasts living in difficult-to-reach regions. An example of this is Yeti, also known as the abominable snowman, who supposedly lives in the Himalayan mountain region and would be a kind of smart gorilla. As it is, since there are already very few unexplored places, it is becoming increasingly difficult to sustain the existence of human monsters in our immediate environment. Thus, given our fascination for fantastic beings, we have had to look for them outside our planet. Thus, a good number of stories have arisen about visits of aliens to Earth \u2013 including images \u2013 have, however, had limited credibility. The existence of intelligent extraterrestrial life has also been seriously addressed. In this sense, it is thought that in all probability there is an extraterrestrial intelligent life, given the immense number of stars in the Universe around which planets capable of maintaining it orbit. In order to detect it, since the seventies in the last century, the SETI project \u2013 a search for extraterrestrial intelligence, has been operating, which has searched the sky for decades in order to discover radio signals from advanced civilizations outside our solar system. There are also projects to detect the existence of extrasolar planets capable of sustaining life. For this, it is necessary for the planet to orbit around its star at a distance so that its temperature allows the existence of liquid water, which we know is essential for life as we know it on Earth. In relation to this, European astronomers working at the La Silla Observatory in Chile, recently concluded that only in the Milky Way there can be thousands of millions of \u201cSupper-Tierras\u201d \u2013 rocky planets with a mass up to 10 months of the mass of the mass of the Earth\u2013 gravitating around stars known as red dwarfs, at the right distance to allow life. Thus there would be about 100 Super-Lands habitable at a distance of 30 light years from our planet. In an interview published by the BBC, however, one of the astronomers responsible for the study notes that the fact that a Super-Earth is at the right distance from a red dwarf does not necessarily ensure that it is suitable for life. This is because in red dwarfs there are frequent solar eruptions that can bombard the plan with X-rays and ultraviolet radiation that are not exactly beneficial for life.Even with this one but, nevertheless, the enormous number of potentially habitable planets in regions that are now inaccessible to us \u2013 as were the confines of the world known to Europeans in the Middle Ages \u2013 assures us of the existence in the Universe of inhabited worlds apart from ours. We are thus free to fan out about the aspect that its inhabitants will have as our ancestors will. Although possibly now with a little more bases.",
    "https://upload.wikimedia.org/wikipedia/commons/7/7a/Limpieza_de_ventanas_en_la_calle_Peter%27s_Hill%2C_Londres%2C_Inglaterra%2C_2014-08-11%2C_DD_128.JPG": "In the mid-19th century, the two maternity clinics of the General Hospital of Vienna showed rates of mortality due to puerperal fever among the parturients that were inexplicable at first sight. Indeed, the statistics indicated that mortality in Clinic 1 reached twice as high as those in Clinic 2, although the medical procedures followed in both places were apparently the same. The mystery was solved by Ignaz Semmelweis, a physician associated with those clinics, who offered a surprising explanation at the time. According to Semmelweis, although the medical practices were the same in both establishments, the parturients were attended in each of them by professionals with different profiles: medical students at Clinic 1 and obstetric students at Clinic 2. This fact, apparently banal, made the great difference. Even today it seems surprising to us that the professional profile of the person attending to a parturient was an important factor for the health of the same. It should be remembered that at the time the germs had not been identified, in an incontrovertible way, as the agents had not been able to wash their hands thoroughly. Thus, lacking this custom, the students transported pathogens from the corpses to the parturients, with frequently fatal results for the latter. In Clinic 2, on the contrary, obstetrician students did not work with corpses and the mortality rate for puerperal fever was consequently lower. The solution to the problem of Clinic 1 was very simple and consisted of forcing the students to wash their hands before entering the delivery room \u2013 employing a liquid similar to the one used today to clean floors. With this measure, the mortality rate for puerperal fever dropped drastically immediately. Although it had far-reaching practical consequences, the explanation offered by Semmelweis was not immediately accepted by all, since it did not agree with the dominant ideas at the time about the origin of the diseases. Infectious diseases, so that Semmelweis could not satisfactorily explain what specifically the students were carrying from the amphitheatre that produced the puerperal fever. Soon, however, studies carried out by different researchers \u2013 Luis Pasteur, among them \u2013 made clear the role that germs play in diseases and with this we obtained the recipe to prevent them: we had to eliminate or, in any case, avoid and fight, microbes.In this sense, seeking cleaning and sterilization in all orders was a practice that should be adopted. Thus, over the last century \u2013 at least in developed countries \u2013 life became increasingly free of pathogens.This led to an impressive increase in the life expectancy of the population \u2013 as a result to a large extent of a decrease in infant mortality \u2013 which doubled globally in the course of a century. It is possible, however, that we have exaggerated the note a little and that, in the end, an extreme cleansing is not as positive as had been thought. . At least this is what the results of an article published this week in the journal \u201cScience\u201d by a group of researchers from the United States and Germany, according to which exposure to certain germs at an early age helps to develop the immune system and to prevent diseases of autoimmune origin such as asthma and ulcerative colitis. In this article the results of a study carried out with two groups of mice are reported. A first group was maintained in a sterile environment, while a second group grew in the normal laboratory environment. Both groups of mice were induced to either asthma or ulcerative colitis, and their immune response was studied. They found a more severe response in those mice that grew in a sterile environment, indicating that early exposure to germs fulfils the function of training the immune system to respond more moderately to the presence of foreign bodies. These results agree with the so-called \u201cHygienic Hypothesis\u201d, according to which the environment increasingly Although it is not clear to what extent the study referred to \u2013 carried out with mice \u2013 can be extended to the human species, it does give us an indication that further cleansing may not necessarily be synonymous with better health. In other words, \u201cpoison that does not kill....strengthens\u201d.",
    "https://upload.wikimedia.org/wikipedia/commons/3/3c/3phase-rmf-320x240-180fc.gif": "These machines would operate at a very low cost, in addition to not contributing to environmental pollution because they do not use fuel. Perpetual motion machines would, of course, solve many of the problems that afflict our planet, such as the timely supply of oil to countries that need it and the global warming from the burning of fossil fuels. Throughout history, a good number of perpetual motion machines have been proposed. These machines have consisted from rotating ingenuities to raise water to a certain height using gravity as the only driving force, to electric motor engines that take the energy to move from a battery, which is recharged by an electric generator driven by the engine. Certainly, perpetual motion machines look attractive and would certainly solve numerous problems. None, however, has been built that works as such \u2013 although there have been cases of alleged machines of this type that were subsequently fraudulent. It is not surprising that this is the case. We could not expect to build a pump to raise water entirely powered by the force of gravity, because this force \u2013 as we well know \u2013 rather than rise makes objects go down. Likewise, a car that moves using the electric current of a battery, whose charge is in turn provided by the same engine, would in some way be equivalent to a viper that to survive devours the tail.The ultimate reason that makes it impossible to build a first-rate perpetual motion machine is that it would violate the law of energy conservation \u2013 which constitutes a firmly established principle of physics \u2013 according to which it is not possible to extract energy from nothing.And yet, while it is impossible to build a machine that operates eternally without power supply, we can build ingenuity that from a practical point of view resembles a perpetual motion machine.An example of this is an electric motor powered by the electrical power provided by solar cell panels. Indeed, for every practical purpose the Sun is an inexhaustible source of energy that will remain shining for thousands of years. The energy of the Sun is also non-polluting. An ingenuity that operates with solar energy is then, and in many respects, equivalent to a perpetual motion machine. Yes, together with all of the above, we take into account that the energy of the Sun is very abundant \u2013 on the surface of the Earth affects a quantity of solar energy that is 7,000 times larger than all the energy consumed by the world \u2013 we can expect this energy to become the future panacea to overcome many of the problems that afflict our planet. However, it would have to overcome some obstacles earlier. Indeed, although solar fuel is free, abundant and practically eternal, to exploit it it it it is necessary to build the machines that transform it into other forms of energy that we can directly take advantage of. One type of machine that is particularly important in this regard is the solar cell, which transforms the energy of the Sun directly into electrical energy with efficiencies ranging from 10 to 20%. Building solar cells, however, has a cost and to the extent that it was traditionally high, there was not enough economic incentives to manufacture it. This situation is beginning to change and there are signs that in many countries \u2013 including ours \u2013 the cost of producing electricity by means of solar cells \u2013 the price of which was reduced by 30% in the last year \u2013 is already equal to the cost of electricity generated by other sources. One way to reduce the amount of electricity bills in our country \u2013 already used elsewhere \u2013 is through the installation of a solar system for electricity production.This system would interconnect with the CFE network and allow both the flow of electricity from that grid to the home \u2013 when the production itself was insufficient \u2013 and the flow in the opposite direction \u2013 when there was an excess in production.This way, the owner of the house would pay CFE for electricity consumption only the difference between the incoming energy flow and the outgoing flow.Given the evolution of the prices of solar cells in recent years, it is possible that in the near future the use of solar electricity will become more frequent and replace in increasing percentages the electricity generated by traditional methods. In this way, the dreams of those who for a long time wanted to manufacture first-rate perpetual motion machines will become a reality to make our existence easier, though perhaps unexpected to them, and without violating the laws of physics.",
    "https://upload.wikimedia.org/wikipedia/commons/b/b0/Ruche_artificielle.jpg": "As we know, the spirit of adventure of European navigators and explorers of the so-called \u201cEra of Discoveries\u201d \u2013 15th to 17th centuries \u2013 drastically changed the face of the world. In particular, it turned some European countries into colonial powers that survived for centuries \u2013 usually to the detriment of conquered countries and the prosperity of conquerors. The journeys of Columbus, Vasco da Gama and Magellan, among others, which sought to open new trade routes between Europe and the Far East, were certainly driven by economic interests. These trips would not have been possible, however, without the competition of fearless sailors, willing to risk life in the exploration of unknown worlds. The adventurous spirit is, of course, not unique to Europeans nor has it been given only at a particular time; on the contrary, it has been a constant throughout history \u2013 and prehistory \u2013 human. Thus, we know that the original settlers of the American continent crossed more than 10,000 years ago from Asia through the Strait of Bering \u2013 turned to the season into a land bridge for the effects of the American continent. The advance of these first settlers had to have been composed of adventurers willing to face the dangers \u2013 real or imaginary \u2013 that they might find in unknown lands. Despite their prevalence, the spirit of adventure is not widespread and, on the contrary, it is an attribute of only a minority. In relation to this, and by way of example, there were certainly not many those who went through their minds trying to reach the South Pole of the Earth a little more than a century ago, when this site had not yet been conquered \u2013 even today, probably not abound those willing to run the adventure. Today very probably we also do not find many people willing to travel into space on a rocket \u2013 although half a century has already been completed since the first space trip carried out by Yuri Gagarin. It could be that when orbital flights are a matter of routine \u2013 if ever happens \u2013 a majority is willing to experience them. Certainly, most of us prefer security, to venture along roads that have not already been exhaustively explored by others. One possible classification of humans \u2013 among many others that can be done \u2013 is between nato adventurers willing to run great dangers \u2013 a small minority \u2013 and those \u2013 the vast majority \u2013 who prefer safety. This classification is, of course, an oversimplification of the situation and many people \u2013circumstances in between \u2013 would fall into an intermediate point between the two extremes. One tends to think that tendencies towards adventure or sedentaryism, which reflect personality differences, are unique to humans and other vertebrates. However, in an article published in the latest issue of the magazine \u201cScience\u201d, published by researchers from American universities, it is found that among bees there are also differences that we could classify as personality. These differences make a minority more daring than the rest when undertaking new adventures. To reach this conclusion, the researchers referred selected a group of bees given to the adventure. It is known that within the group of bees gatherers, some \u2013 less than 5% \u2013 are more daring than the rest and that, when the hives have to be divided, Once this site is located, they communicate it to the rest of the swarm and direct it to its new habitat. Already selected the group of adventurous bees, the authors of the article investigated whether they acted equally as searchers of new food sources. They found that it is 3.4 times more likely that a bee looking for new places to nest is devoted at the same time to looking for new sources of food, that the latter will do so a passive bee that expects to indicate to it what its new home will be. This shows that the scout bees carry the taste for adventure in the blood.In fact, more than in the blood, the taste carries it in the genes, as well as humans. This according to the authors cited, who found great differences in the expression of such genes in the brain of the scout bees compared to those that are not. Thus, surprisingly, humans share characteristics \u2013 day or passivity \u2013 with the bees, despite the great evolutionary distance that exists between the two species. According to the researchers referred, this is not due to the fact that, There is a common ancestor, on the contrary, they speculate that both adaptations evolved independently.",
    "https://upload.wikimedia.org/wikipedia/commons/3/34/Adult_deer_tick.jpg": "In the autumn of 1991 two German climbers discovered in a ravine of the Alps of \u00d6tztal, on the border between Austria and Italy, the corpse of a man semi-buried on the ice. Such a discovery would not have been a particularly remarkable event, and would have gone largely unnoticed, had it not been because the man in question \u2013 later baptized as \u201c\u00d6tzi, the Ice Man\u201d \u2013 lived and died in the Copper Age, more than 5,000 years ago. \u00d6tzi died a series of fortunate circumstances helped to preserve his remains for thousands of years. First, the corpse was dried up and mummified by the prevailing climatic conditions, at the same time that, for some reason, it remained safe from being devoured by scavenging animals. Later, with the passing of the years, it was gradually covered by the ice by the advance of glaciers. Only recently, by reversing the latter by the effect of the current global warming, was that \u00d6tzi emerged to the surface to be discovered by chance. The latter include a copper axe, a knife, a wooden bow in the making phase and a carcaj with arrows, some of them also unfinished. The Ice Man is a window into a remote past that allows us to take a look at the life of our ancestors in times gone forever. Once discovered, \u00d6tzi was the subject of numerous scientific studies and today we know \u2013 or at least have reasonable certainty \u2013 many things about the life he was carrying and the circumstances surrounding his death. In relation to the latter, apparently \u00d6tzi had a violent end and died shortly after suffering an arrow wound in the back near the neck. We also know that as the last meal he consumed goat meat. He also died at a relatively early age around 45 years. On the other hand, tomomy tomography reveals that \u00d6tzi suffered from arteriosclerosis \u2013 an addiction to the disease \u2013 an improvement of goat meat. He also died at a relatively early age around 45 years. In an article published this week in the journal \u201cNature\u201d by an international group of researchers, more secrets of the Ice Man are revealed; this from having managed to sequence its genome. Thus, we now know that \u00d6tzi possibly suffered from Lyme disease, which is transmitted by tick bites and which, among other symptoms, produces inflammation of the joints. Likewise, it is likely that he had brown eyes, type O blood and that he suffered from lactose intolerance. He also had a genetic predisposition to cardiovascular diseases.The knowledge of his genome also made it possible to find that \u00d6tzi is related to the inhabitants of the Italian island of Sardinia in the Tyrrhenian Sea, which raises questions about the means that he used to reach the Alps of \u00d6tztal. In addition to the above and according to experts, the copper axe that \u00d6tzi carried at death is a sign of a high social status, since in his time the most common axes were made of Today, the risk factors for cardiovascular diseases include a bad diet, physical inactivity and smoking, which we could not expect to have the same effect 5,000 years ago. According to experts, the problems of arteriosclerosis suffered by \u00d6tzi would then be explained on the basis of their genetic predisposition to the disease.We may conclude that \u00d6tzi, despite his high social status, was not a particularly fortunate person because \u2013 apart from being killed \u2013 he suffered from a good number of diseases, in particular from arteriosclerosis. He suffered from this latest disease despite the fact that very possibly he did not incur in any of the current risk factors for the same \u00d6tzi was thus doubly unfortunate, because on the one hand he suffered from a potentially deadly disease \u2013 although in the end he did not die from it \u2013 which we consider to be a good product of our time, while on the other he did not have the means we have today to combat it.",
    "https://upload.wikimedia.org/wikipedia/commons/9/9f/Sir_Isaac_Newton_1702.jpg": "With more than 1.2 billion inhabitants \u2013 17% of the world\u2019s population \u2013 India is after China the second most populous country on Earth. Moreover, since Chinese population growth is less rapid than India\u2019s, India is expected to become the most populous country on the planet for a few decades. Demographically, India is a gigantic country that, by comparison, has a population ten times larger than Mexico\u2019s. India is also on the way to becoming a scientific and technological power; in fact, even now it stands out in some fields. It is, for example, a member of the select group of countries that possess nuclear weapons, a membership that reached in 1975 when it detonated its first nuclear bomb. In other technological achievements, in 1980 India put into orbit a satellite using its own rocket, while in 2008 it managed to place in a lunar orbit a probe for the study of our satellite, which it was able to identify for the first time water molecules on its surface. India also has a vigorous space program that includes plans to put astronauts into Earth orbit \u2013 and even beyond \u2013 As well as plans to place a scout vehicle on the lunar surface and send a probe to Mars. Currently, looking to expand beyond nuclear and space, India is making efforts to develop in a comprehensive manner in all scientific and technological areas. In the issue of the magazine \u201cScience\u201d published this week, several articles appeared, including an interview with Indian Prime Minister Manmoahan Singh, where he realizes these efforts. Among other indicators of India\u2019s scientific progress mentioned by \u201cScience\u201d, we have that between 2000 and 2010 this country doubled the number of scientific articles published to reach 40,000 per year. The impact they had \u2013 measured by the number of times they were cited by other authors \u2013 also grew significantly. One factor limiting India\u2019s scientific development is the lack of researchers. To alleviate this deficit, among other efforts are seeking to repatriate Indian scientists working abroad. For this, they are offering attractive working conditions that include abundant resources for research and competitive wages. In Pune \u2013 quoted by \u201cScience\u201d\u2013, \u201cA teacher who starts his career may be richer in India than in the United States.\u201d However, not all is honey on leaflets for researchers in India and \u201cScience\u201d records complaints about this. Some of these complaints \u2013 which are not surprising at all in our country \u2013 have to do with excessive bureaucracy that hinders the importation of inputs for research that imposes on the researcher frequent reports of the progress of his work. In this regard, one researcher comments: \u201cThey evaluate me as if I were building a road. They want a report every 3 kilometers.\u201d India plans to substantially increase in the immediate future the resources dedicated to science. According to \u201cScience\u201d, during the Indian Scientific Congress held last month, Prime Minister Singh announced a five-year plan to double Indian spending on research and development, up to 2% of GDP in 2017. This would represent $8,000 million a year. Science, as we know it, originated in Europe in the 16th and 17th centuries. Later, throughout the years, the years of the year of the year of India\u2019s history, 19th and 20th centuries \u2013 once enough scientific knowledge had accumulated \u2013 modern technology was born that is based on science. This technology makes use of scientific knowledge to create highly sophisticated ingenuity \u2013 increasingly \u2013 that would otherwise have been impossible, not only to manufacture, but even to conceive. Of these scientific ingenuity we have today numerous examples, which have drastically changed our living conditions on all orders. Throughout the second half of the last century, when the impact of scientific technology became more intense, the centre of gravity of science \u2013 or at least one of its centers \u2013 moved from its cradle in Europe to the west \u2013 the United States. Now, in the 21st century, it seems that such a centre will continue its journey to the west and will be parked in the decades to come in Asian countries. Among these, China and India stand out, both for constituting more than a third of the world\u2019s population, and for their vigorous policy of scientific development.In our continent, with the exception of Brazil, though later, \u201cthe \u201cIn Latin America we are seeing the scientific wave passing on its journey to the west without us riding on it. Assuming it did, will we have to wait in Mexico for it to happen for the second time?",
    "https://upload.wikimedia.org/wikipedia/commons/4/4e/John_Harvard_statue.jpg": "As a result of medical and public health advances over the past century, there has been a continuous increase in the average life of the population. According to World Health Organization data, life expectancy at birth at a global level increased from 31 years in 1900 to almost 66 years in 2005, while in countries such as Japan, Switzerland and Spain, it exceeds 80 years. Over the last century, among many other medical advances, infectious diseases have been eradicated that were previously devastating and techniques have been developed that would not long ago have seemed to us to be science fiction. The generation of new therapies and medical devices that crave scientific fantasy is, of course, not a thing of the past and are on the contrary continually emerging as a product of the great public and private investments that are engaged in biomedical research. A device that almost falls into this category was released the week that ends today at the congress of the American Association for the Advancement of Sciences, held in Vancouver, Canada. cience Translational Medicine\u201d, was carried out by researchers from several universities and research centers in the United States, including Harvard University and the Massachusetts Institute of Technology, in conjunction with the private company \u201cMicrochips\u201d which manufactures the devices. The reported device consists basically of a capsule for the controlled release of a drug for the treatment of osteoporosis. The capsule is implanted inside the body and the release of the drug is programmed wirelessly by means of an external computer. Such release can also be made at a certain time from the outside. The communication is, moreover, bidirectional, so that the implanted device can send information to the outside. The capsule has a size equivalent to that of a USB computer memory and contains two microchips and the control electronics and communications necessary for the operation of the device. The drug to be released \u2013in doses of only 40 millionths of gram\u2013 is placed in small compartments housed in the microchips \u2013 diez for each microchip, giving a total of 20 doses\u2013, which are sealed by means of a very thin membrane of a titanium and platinum alloy. The devices were tested with seven female patients aged 65 to 70 years, who were given a daily dose of the drug over 20 days. According to the reference article, the results of the study were equivalent to those obtained by the traditional procedure by administering the drug through daily injections. This demonstrates the great advantages of the new device, as it eliminates the discomfort that many patients experience before injections. The injections are eliminated, however, at the cost of undergoing the operation necessary to implant the device \u2013 in the abdomen \u2013 even if it is carried out in the doctor's office with local anesthesia. To relieve the discomfort of this operation \u2013 certainly greater than that of a simple subcutaneous injection \u2013 Microchips is developing a device for 400 doses, which would extend the time between implants to one year.According to Robert Farra of the Microchips company and one of the authors of the study, Microchips is developing a device for 400 doses, which would extend the time between implants. developed device could be used to administer drugs for other diseases, including cancer. The volume of containers in the microchip, however, is small by necessity, so that the technology could not be used for the treatment of other diseases, such as diabetes, that require larger volumes of the drug to be administered. It could be speculated that in the future devices will be developed that are implanted inside the body and that not only administer drugs in a controlled manner, but also include probes that provide the control computer with the necessary information so that it can adjust the dose to be released. With this, such computer would take full control of the fight against the disease. This certainly sounds like science fiction, although given the vertiginous biomedical progress, we cannot doubt that at some time it will come true. Before this happens, we must wait for the device announced this week to be commercially available, which would still take some years. The announced cost of the device \u2013 10,000 to 12,000 dollars \u2013 however, possibly make many, in any way, decide on the option of daily injections.",
    "https://upload.wikimedia.org/wikipedia/commons/6/62/Scott_of_the_Antarctic_crop.jpg": "This was carried out by the expedition led by the Norwegian Roald Amundsen, who in this way surpassed the British Robert Falcon Scott, who also intended to be the first to step on the southern pole. Scott also arrived at his destination, only a month after Amundsen did. It is worth noting that Scott\u2019s expedition proved tragic, since none of its members survived the harsh climatic conditions of Antarctica \u2013 where the South Pole is located \u2013 during the journey back to civilization. The Antarctic continent has an area of 14 million square kilometers, which places it as the fourth largest continent, after Asia, America and Africa. It is also the coldest and inhospitable continent, with an average temperature of 17 degrees Celsius below zero during the year. In fact, it is in the Antarctic where the lowest temperature ever recorded on the surface of our planet has been observed: 89.3 centigrade degrees. On 21 July 1983 at the Russian station Vostok. Due to the low temperatures prevailing in Antarctica, most of its surface is permanently covered by a thick layer of ice, which reaches a thickness of almost five kilometres in some places. Today, a century after the expeditions of Amundsen and Scott, Antarctica is still a source of great interest. In this regard, we know of a race between international teams with targets centered on this continent. Indeed, under Antarctic ice, at a depth of several kilometres, there are huge lakes that have not been explored until now. Among these the largest is Lake Vostok, which has an extension of similar to Lake Ontario, on the border between the United States and Canada, but with a volume of water three times greater. According to experts, it is possible that Lake Vostok has been isolated for a period ranging from 15 million to 25 million years and this gives it enormous scientific importance. A parallel has also been established between the conditions prevailing in the Antarctic lakes with those that would prevail in worlds outside our planet, including Europe \u2013 Jupiter satellite \u2013 where underground lakes are known to exist. In order to gain access to Lake Vostok, the Arctic Research Institute and the Antarctic of St. Petersburg, Russia, has been drilling ice above that lake for the last two decades. The southern cold end and the short summer at those latitudes has made the task extremely difficult. This seemed to have achieved success a year ago, towards the end of the southern summer. It was not, however, until last Wednesday, 8 February, that the Russian team confirmed having finally reached the surface of the lake after drilling almost four kilometres of ice, which was widely disseminated by the press. The end of the southern summer in the Antarctic, however, forced to suspend the work, of So that the investigation of the secrets that could be kept by Lake Vostok will have to wait until next December.There has been no lack of criticism of the exploration project of Lake Vostok. These have focused on the possible contamination of the pristine water of the lake by the antifreeze liquids used in the drilling of the well in the ice. The Russians, however, consider that this will not happen because the high pressure to which the lake water is located \u2013 due to the enormous weight of the ice it bears \u2013 will cause it to rise along the well by pushing the antifreezes up and preventing them from penetrating the lake. In particular, according to the Russian experts, during the drilling reported on 8 February, the water would have risen tens of meters, freezing in the well and isolating itself again to the lake from the outside. To the extent that they have a purely scientific interest, Antarctic research is plausible, even with the danger of contaminating environmental means that have remained isolated by times measured on geological scale. And explorations of Antarctica \u2013 and of course many other places on our planet \u2013 have been driven by entirely scientific purposes. To convince us of the latter, just take a look at the \u201cpolitical\u201d map of Antarctica, which shows the almost circular shape characteristic of this continent divided into sectors \u2013which slices of cake \u2013 each claimed by a different country.",
    "https://upload.wikimedia.org/wikipedia/commons/a/a2/HR_8799_Orbiting_Exoplanets.gif": "In a press release last Thursday, NASA announced the discovery of 11 planetary systems in our galaxy that include a total of 26 new planets, some with a size similar to that of the Earth and others of giant dimensions comparable to those of Jupiter. Each of the new solar systems includes two to five planets, with translation periods around their respective stars between 6 and 143 days. This discovery was made by NASA\u2019s Kepler spacecraft, launched into space in March 2009 in an orbit around the Sun. According to the US space agency\u2019s website, the purpose of the Kepler probe was to find planets outside our solar system with conditions similar to those of the Earth and that could harbor life as we know it. For this to happen, a planet must be within the \u201chabitability zone\u201d, that is, at such a distance from its star so that the temperature on its surface does not turn out as high or as low so that water can exist in liquid form, which we know is essential to life. The technique of detecting planets employed by the Kepler probe is in principle very simple and is based on the decrease of the apparent brightness of a star when the planet stands between it and the Earth. Thus, the periodic fluctuation of the brightness of a star will be indicative of the existence of a planet rotating around it. Likewise, the time between two fluctuations of brightness will correspond to the solar year of the planet, while the magnitude of such fluctuations will be indicative of its size. Discovering a planet using the previous technique might seem simple. On the contrary, it is by no means an easy task because of the extremely small changes in the star brightness that have to be measured. These, moreover, depend on the size of the planet in question, so that a small planet is more difficult to detect than a larger one. Above all, it is necessary to simultaneously observe a large number of stars in order to discover a possible fluctuation of the luminosity of only a few of them. For this purpose, the Kepler probe has repeatedly measured the brightness of about 150,000 stars in a narrow portion of the Milky Way. To date, it has confirmed the existence of more than 60 extrasolar planets, including the If discovering a planet orbiting a distant star is a difficult undertaking to carry out, finding out if it has conditions similar to those of Earth is even more complicated. In this sense, last December NASA announced that, for the first time, the Kepler probe confirmed the existence of a planet of similar size to Earth \u2013 2.4 times larger \u2013 within the habitability zone of a star similar to our sun. It is not clear, however, if that planet is actually similar to Earth, because it is not known whether it is rocky as our planet or gaseous as the giant planets of our solar system. In addition, we have that even within the habitability zone a planet can have climatic conditions radically different from those of Earth. Thus, Venus and Mars, despite being neighboring planets of ours, suffer from an inhospitable climate in nothing like ours \u2013 with all and the global warming that we suffer.In effect, Venus has an extremely dense atmosphere of carbon dioxide and the greenhouse effect that it generates permanently maintains the temperature on the planet's surface above the planet. In contrast, Mars is cold and has a very tenuous atmosphere \u2013 also of carbon dioxide \u2013 that does not manage to dampen the temperature variations between day and night that can reach 100 degrees Celsius.Surely in the months and years to come we will know of the existence of an ever larger number of extrasolar planets within the habitability zone of their respective stars \u2013 through the Kepler probe and by other means.We will also have evidence that some of these planets resemble ours in terms of climatic conditions and might well be a seat of advanced life similar to Earth.On the contrary, the fact that we have direct evidence of this latter is possibly much more improbable.So, as soon and as in the time of Giordano Bruno \u2013 who in 1600 was condemned for the Roman inquisition and executed in the bonfire for believing in the existence of other worlds similar to Earth \u2013 we have no choice but to speculate about the existence of intelligent life in other parts of the Universe. as dangerous as 400 years ago.",
    "https://upload.wikimedia.org/wikipedia/commons/c/c7/Small_sipix_ubt.jpeg": "According to information published last week in the Wall Street Journal, the Eastman Kodak company would be declaring bankruptcy at the end of this month of January or at the beginning of February. This would mark the fall of a company that greatly contributed to the development of photography and the film industry as we know them today. As we know, Kodak was by a century the dominant company in the photography industry and which it gave shape to to a large extent. Indeed, we can say that George Eastman \u2013 the founder of Kodak \u2013 invented the amateur photographer that almost all of us have inside, when he commercialized more than a hundred years ago the first Kodak camera, which advertised with the slogan \u201cYou press the button, we do the rest.\u201d This camera, placed on the market in 1888, was sold for $25 loaded with enough photographic film for 100 shots. Once the 100 photographs were exhausted, the camera had to be sent to Kodak\u2019s facilities in Rochester, N.Y., so that the film was revealed and the photographs printed. However, before the appearance of the first Kodak camera, photography was a matter of specialists, since to a photo session \u2013 in addition to its camera \u2013 the photographer had to carry with him a whole laboratory of discovery, since once the films were exposed they had to be processed in a matter of minutes. It is not surprising, then, that Eastman\u2019s success with his first camera was associated with it. In addition to the above, the amateur photographer received from Kodak a new impulse with the appearance in 1900 of the camera \u201cBrownie\u201d, easy to handle and with an accessible cost of only one dollar. Eastman Kodak\u2019s current decline is associated with the appearance of the digital camera that has replaced almost completely the analog or photographic cameras. As we know, the digital camera allows us to take photographs with a passable ease and with immediate results, which makes it possible to make corrections and repeat the take if necessary. This contrasts with analog photography that involves a certain waiting time. The digital camera is the product of the same electronic technology that has given rise to processors and computer memories, among other \u201cchips\u201d or integrated circuits. This technology had its beginnings more than half a century ago and since then the dimensions of these circuits have become smaller, following what is now known as Moore\u2019s Law. According to this law, the number of transistors \u2013 one of the basic electronic elements \u2013 contained in a chip is doubled approximately every two years. As a result, a two-centimeter chip by two-centimeter area can now contain thousands of millions of transistors. In a digital camera, the photographic film is replaced by a device called CCD, which consists of a large number of detectors \u2013\u201cpixels\u201d \u2013 arranged in a quadricle. The miniaturization law is also enforced for CCD devices, so that the number of \u201cpixels\u201d of a digital camera \u2013 as we know well \u2013 quickly grows with As a result, digital cameras can take sharper and sharper photographs. Thus, it is not surprising that analog photography, a technology typical of the first half of the 20th century, has lost the race to today\u2019s thriving electronics industry. In relation to the above, we can perhaps say that digital photography has given rise to a revolution in the way we conceive devices to capture images \u2013 which is evidenced by the large number of photographs and videos that continually appear in unexpected situations \u2013 and that this revolution has a similar reach to that generated by Eastman Kodak more than a century ago. Thus, we have nothing but longed for \u2013 to which we are old enough \u2013 time gone, of analog cameras and Kodak photographic films.",
    "https://upload.wikimedia.org/wikipedia/commons/1/1b/Violin_VL100.png": "In June last year the violin \u201cLady Blunt\u201d was auctioned\u2014made by Antonio Stradivari in 1721\u2014in the astonishing amount of $16 million. The violin was sold by a Japanese musical foundation and obtained was dedicated to a tsunami relief fund that hit Japan in March 2011. As amazing as the value that the Lady Blunt has reached has been the increase that this value has had with the years. Indeed, in 2008 that violin was sold by 10 million dollars in a private transaction, while in 1971 it reached a public auction value of 200,000 dollars. On the other hand, although the violin Lady Blunt has been the one that has reached the highest price at auction, other violins manufactured by Antonio Stradivari, as well as by its contemporary Giuseppe Guarneri \u2013 who lived in Cremona, Italy, in the seventeenth and eighteenth centuries \u2013 have reached auction prices of millions of dollars. Given the high prestige of the violins Stradivari and Guarneri have carried out a good number of investigations. This sound has been attributed to various factors; among these are the varnish applied to the instrument and the chemical treatment given to the wood with which the instrument was manufactured. It has also been proposed that the cold period that Europe suffered between the 16th and 19th centuries \u2013 known as the Little Ice Age \u2013 was decisive for the production of higher quality violins; this because the cold slowed the growth of trees that thus produced denser wood, which would have positively influenced the sound of violins made with it. Contrary to traditional belief, however, there might not be anything special in Cremona violinists. At least this is what an article published this week in the Memories of the National Academy of Sciences of the United States by researchers from institutions in France and the United States states. In this article, the results of a study involving 21 professional violinists were reported. Six old violinists \u2013 Stradivari of the 1700s and the United States \u2013 were provided with six old violins of the 1700s. 1715, and a Guarneri of 1740\u2013 and three modern violins, and were asked to evaluate them.The three ancient violins have a combined value of approximately $10 million, which is about 100 times the combined value of modern violins.In order to avoid prejudices, the participants were not given information about the provenance and age of the instruments and were only told that among them there was at least one Stradivari.The tests were carried out in a room with little light and the violinists wore soldering glasses; all of this in order that they could not identify the age of the instruments because of their appearance.In addition, a special perfume was applied on the chin holder so that there was no way to identify this age by means of the smell that fired the instrument.Two types of tests were done.In the first one, each participant was provided with all the instruments in pairs, consisting of an old violin and a modern one \u2013 in all nine combinations \u2013 and they were asked to compare their sound quality. Half of the participants pronounced themselves by an old violin, while the other half did so by a modern violin. The exception occurred when the Stradivari of the year 1700 was evaluated, which most of the participants \u2013 surprisingly \u2013 qualified as inferior in comparison to modern violins. In a second test the six violins were provided in turn to the participants and were asked to choose the best and the worst. As a result, one of the modern violins was chosen by 8 participants as the best and by none as the worst. In contrast, the Stradivari 1700 \u2013 which had not come out well from the first test \u2013 was chosen by 6 participants as the worst and only by one as the best.According to the above, there is no correlation between the value achieved by a violin in the market with the quality of the sound it emits, as the latter is perceived by professional violinists who likewise prefer an old violin than a modern one.The perception that Cremona violins built three centuries ago emit a special quality sound would not have objective bases and would enter the field of modern violinists. After 200 years of believing otherwise, we cannot expect this idea to be easily accepted. However, it is supported by an objective investigation that would have to be refuted by another equally objective investigation.",
    "https://upload.wikimedia.org/wikipedia/commons/7/7f/Influenza_A_-_late_passage.jpg": "When the Martians invaded our planet, according to the novel \u201cThe War of the Worlds\u201d by the British writer H.G. Wells, they encountered an unexpected enemy: the terrestrial microbes. For our fortune and misfortune of the invaders, the enemy proved so formidable that the latter ended up annihilated in a few days, even though they had advanced technology. The fictitious extermination of Martians, which would have occurred just over a century ago \u2013 the Wells novel was published in 1898 \u2013 was preceded by a large number of pandemics that led to the extermination \u2013 yes, real \u2013 of millions of people. One of the most famous was the bubonic plague epidemic known as the \u201cBlack Death\u201d, which in the 14th century brought to the grave a good part of the population of Europe. On the other hand, there was no waiting long after the publication of the \u201cWar of the Worlds\u201d for the next epidemic of great proportions: the influenza epidemic called \u201cSpanish Grime\u201d, which in 1918 killed about 20 million people. One of these is the H5N1 avian influenza virus, which was reported a few years ago when it was able to infect people who had been in close contact with sick birds in Southeast Asia. It is known that in humans this virus is lethal with a mortality rate greater than 50%. Fortunately it is not very contagious and only about 600 people are known to be infected; in addition, these have been mainly through contact with birds and not by contagion between people. In fact, the World Health Organization, which maintains close surveillance on the avian influenza virus, does not consider that at this time there is a particular concern about the possible occurrence of avian influenza pandemic. However, it is now known that the H5N1 virus can mutate and become highly contagious, while maintaining a high mortality rate. Indeed, during a meeting of virologists held last September on the island of Malta, a group of researchers from the Erasmus Medical Centre in Rotterdam reported the creation of a variant of the H5 virus. Although the studies were carried out with ferrets, it is considered that they can spread to humans. Thus, a virus would be able to spread easily between people but with a mortality rate of more than 50%. Moreover, this virus contains mutations that can occur naturally, which implies that it could appear without our intervention. An article with the results of this research has been submitted for publication to the journal \u201cScience\u201d. In an unprecedented situation, however, the National Scientific Advisory Council on Biosafety of the Government of the United States has asked the editor of that journal to delete details that would help reproduce the virus. The argument is that detailed information of the techniques used could be used by terrorist groups for the manufacture of biological weapons.\u201cScience\u201d, as well as the authors of the reference article, have been receptive to this request, provided that the details of the investigation are disseminated among other groups working on the subject. In an interview granted to the newspaper \u201cNew York Times\u201d, however, Ron Fo Fo uchier, one of the authors of the article, believes that it will be difficult to hide details of his work once they become the domain of other researchers because \u201cas soon as you share information with more than 10 people, the information will be on the street.\u201d He considers that the article should be published with all the details included.There is someone who criticizes that an investigation that led to the creation of such a dangerous virus has been carried out in a university laboratory, without the necessary security measures such as those that would be found in a military facility.There is even doubt about the relevance of developing a supervirus capable of producing a pandemic. Fouchier on his side claims that they have demonstrated the possibility of a highly lethal influenza virus, while at the same time having found the mutations that are responsible for its danger.This would help us to identify outbreaks of the supervirus that could become a pandemic.It would also help the development of vaccines and treatments to combat them. mutations of the H5N1.O virus in its absence, we could use the new knowledge against an artificial enemy that could be created by a terrorist group, using knowledge generated by an investigation carried out to manufacture a lethal virus, and thus avoid having an alien's own death.",
    "https://upload.wikimedia.org/wikipedia/commons/5/52/Tipos_de_azules.png": "The magazine \u201cScience\u201d contains an interesting article in its edition of last Thursday, December 15th, in line with the electoral year that is coming in our country. In that article, published by a group of researchers from universities in Europe and the United States, the results of an investigation regarding group decision-making processes in matters of collective interest are described. In particular, the study was aimed at ascertaining the influence that those uninformed members have in the decision of the group on the matter to be agreed with them. The results of the research, led by Iain Couzin of Princeton University, indicate that, while a minority with firm ideas about the matter to be agreed may guide the sense of the collective decision, this is not necessarily the case if there is a minimum of uninformed members in the group.To be more precise, in a group formed by a majority and a minority with conflicting and equally strong opinions, the views that will be imposed will certainly be those of the majority.The opinions of the minority, however, will prevail if they have a sufficiently high emotional burden; that is to say, the group\u2019s decisions will be guided by the majority. This last one, however, will not necessarily be true if there is also a third group of uninformed individuals, who by nature are highly influential and tend to follow the majority. Thus, the influence of the intransigent minority is weakened for the benefit of the majority group, which will see the scale tilt in its favor. This effect grows to the extent that the uninformed group becomes larger to a certain size, from which they cannot act coherently and the same choose one option as the other.The above conclusions were reached both through theoretical studies and through experiments carried out with goldfish, of the type used as bait.For this, the fish were trained to follow a blue or yellow white.The fish have a natural tendency to follow the yellow color, so that the group trained to follow this color corresponds to the minority with intransigent opinion, while those trained to follow the blue color would form the informed majority.The group of uninformed fish corresponds to a group of untrained fish. the fish were released into a water tank, within which the two whites were placed to follow. In a first test 6 fish trained to go towards the blue and 5 fish were placed to go towards the yellow. The result was that the latter dominated and all the cardumen was preferentially directed towards the yellow. This trend, however, was reversed when 10 fish were added without training so that now the whole group turned preferentially towards the blue color; that is, towards what the majorities dictated. Extending the previous results, obtained with fish, to the human processes, would result in the existence of a majority without strong opinions and therefore influenced \u2013 which normally has a negative connotation for us \u2013 playing after all an important role in the moment of making decisions by consensus. In the words of Iain Couzin, collected on the website of Princeton University, \u201cwe think that being well informed is good and that being misinformed is bad, but that is a human construction. much consensus\u201d and adds, \u201cThese experiments indicate that there is an evolutionary function in being uninformed, which is perhaps as active as being informed.\u201d Thus, uninformed groups would nullify intransigent minorities and underpin democracy. The conclusions of the article might seem absurd because how is it possible that being uninformed is not necessarily something negative but even fulfills the positive function of generating consensus? Such conclusions are, however, supported by scientific data. On the other hand, they must be refuted or confirmed by other research before they are widely accepted or discarded from the ground and we hope to see this in the near future. At the same time, however, they are fascinating.",
    "https://upload.wikimedia.org/wikipedia/commons/a/a2/Mammal_Diversity_2011.png": "During the football championship held in England in 1966, the North Korean team defeated Italy, which was one of the strongest teams in the competition. Subsequently, in quarterfinals, although North Korea lost 5-3 with Portugal \u2013 a team that finished third in the championship\u2013, it had the Portuguese 3-0 down at some point in the game. Prior to all this, there was nothing known about North Korea in terms of football, so that its performance in England \u2013 it had also tied with Chile \u2013 was greatly surprising. Thus, it was not long before a joke emerged that the Koreans had won because during the interruption of half-time the coach had completely replaced the players with others of refreshment without anyone, including the referee, having noticed. This joke has its basis in a real fact, because although we have great skills to identify through their face those people with whom we have some familiarity, doing so with people of another race is more difficult for us. This is, of course, general and valid for the whole world, including the Koreans. Thus, if football had originated in North Korea instead of England and if the 1966 world championship had been held in that country and not in the latter, the same joke might well have originated but in the opposite direction. This, if a series of victories had been given by a certain unknown team from the western region of the planet over a strong team from East Asia.Experts know that the human brain has a region specialized in facial recognition of people. That is, if a visual stimulus comes from a person\u2019s face the brain processes the information in a different way than it does if the stimulus comes from any other object. This characteristic we share with other mammals and it is possible that this is not surprising. On the other hand, if it is surprising that in an article published last Thursday in the magazine \u201cScience\u201d by a group of researchers from the University of Michigan in Ann Arbor, it is concluded that a certain species of avispas \u2013 \u201cpolistes fuscatus\u201d \u2013 also shares it.The experiments reported in that article were carried out with wasps that are known can be visually identified among them by means. The tests were carried out in a T-shaped tunnel with a low enough height not to allow the wasps to fly, which in this way are forced to remain in contact with the floor throughout the experiment. This is important because as part of the experiment the wasps are subject to electrical shocks as a means of forcing them to make decisions. For this purpose the tunnel floor is electrified, with the exception of a \u201csafe zone\u201d in one of the arms of the T. The experiment consists in training the wasps to find in which arm of the T is located the safe area, which, however, is randomly changed to one side or another of the T in each test. Each wasp repeats the test 40 times. At the beginning of the experiment the wasp is placed on the pre-seat of the tunnel in the lower part of the T. After a certain time of adaptation, the access door is opened and allowed to enter the tunnel, at the bottom of which there are two images of the same species of wasps, one on each arm of the T. The image that is placed in the region of the safe zone is always the same, so this is the key to reaching that area. Once at the bottom of the tunnel the wasp has to decide if it goes to the left or to the right in search of the safe zone. If it knows how to recognize the faces of wasp in the images that are shown to it, then it will quickly learn to find the way to safety. Otherwise it will always have a 50% chance to reach the wrong area. In addition to carrying out tests with images of wasp of the same species, tests were also carried out with images of other insects, or with images of wasps of the same species but deformed in some way \u2013 taking away the antennas, for example. As a result of the experiments, they found that when images of individuals of the same species were used, the wasps were less frequently wrong on the way to safety, which when these images were exchanged for other deformed or different species. This shows that the wasps \u201cfuscatus\u201d wereps are specialists in recognition of faces of wasps the same way. It remains to be seen whether the \"fuscatus polytes\" also make jokes at the expense of other wasps than themselves.",
    "https://upload.wikimedia.org/wikipedia/commons/1/1d/Masses_of_Jovian_moons_es.png": "The planet Mars, one of the closest to Earth, has been news in the last few days. On the one hand, we learned that the Russian ship Phobos-Grunt, launched into space on November 8, has trouble carrying out the mission entrusted to it. This ship was sent to explore the Martian satellite Fobos and, according to the original plans, had to descend on that satellite, take samples of materials from its surface and return with them to Earth. A loss of communication with the controlling station, however, prevented the propelling rockets that would take the ship from a terrestrial orbit to the Martian satellite. Without the impulse of these rockets, the Phobos-Grunt will inevitably return to the atmosphere of our planet at a close date. A good news about this, which arose in the last few days, is that contact with the ship had been achieved. However, this contact has been sporadic and it is not clear whether it will be possible to revive Phobos-Grunt. The mission, then, would have to be redirected to an achievable target \u2013 the Moon, for example. Another news about Mars was the successful launch yesterday \u2013 at a cost of $2.5 billion \u2013 of the explorer Curiosity to this planet. Curiosity is a NASA vehicle with a weight of about a ton, which will explore for a period of two years the Martian nuclear-powered surface. According to the website of this space agency, the vehicle is equipped with six wheels of 50 centimeters of diameter that move independently and that will allow it to advance smoothly by rocky terrain. According to the same site, on flat and firm ground it will be able to travel a maximum distance of 150 meters in an hour. This is not much for our standards on Earth but it is certainly impressive for a remotely controlled robot at a distance of 250 million kilometers \u2013 it must be considered that this distance is so large that orders are sent to the The \u201cCuriosity\u201d carries a series of sophisticated instruments for the analysis of the Martian soil to a depth of half a metre and, according to NASA, will seek to establish if there are or have existed in the past on Mars the conditions necessary for the development of life. The explorer also carries a good number of cameras for the obtaining of images in full color, and even video, of the Martian landscape, and from this point of view perhaps we could conceive it as an extension of our sense of view; that is, the equivalent of a telescope of great power that will allow us to observe in detail extraordinarily distant objects \u2013 just as the robots that preceded it but with greater detail. We know how important the telescopes have been \u2013 as an extension of our view \u2013 for scientific advancement. Indeed, when Galileo Galilei pointed in 1610 his telescope towards Jupiter discovered four bright points in continuous movement around the planet. For Galileo it was clear that these bright points, which are by no means visible to the naked eye, are satellites of Jupiter \u2013 the Galilee satellites, as we now know them. The discovery that Jupiter forms with its satellites a \u201cminiature solar system\u201d contributed to overcoming theories according to which the Earth is the center of the Universe around which all celestial bodies revolve. Similar to the telescope, the microscope as an extension of our senses \u2013 in this case to the very small \u2013 played an essential role in scientific advancement. In particular, the Dutch Anton van Leeuwenhoeck using microscopes that he himself built with great mastery, discovered in the 17th century the existence of bacteria, which are, of course, invisible without this extension of view. At this moment, according to the latest news, the Curiosity is heading without novelty towards the planet Mars, to which it will arrive in August of the following year. Assuming that everything will be as planned, in less than twelve months we will be able to enjoy detailed images of the surface of Mars, regardless of whether this planet is at such a distance that we simply see it as a point of light. Since these will not be the first images of the surface of Mars. We may not be as shocked as Galileo or Leeuwenhoeck when they made use of their view extensions. There is no doubt, however, that they will be fascinating.",
    "https://upload.wikimedia.org/wikipedia/commons/2/2b/Le%C3%B3nidas_en_las_Term%C3%B3pilas%2C_por_Jacques-Louis_David.jpg": "Phrases such as \u201cthe fierce fighters\u201d, \u201can almost incomprehensible scale of violence\u201d and \u201cthe encounters are brief and brutal,\u201d certainly bring to mind images of some of the many wars that have taken place throughout our history. These phrases, however, do not correspond to any human confrontation; far from this they were drawn from the article \u201cThe Ants and the Art of War\u201d in which Mark Moffett, of the Smithsonian Museum of Natural History, describes a war between ants he witnessed in the forests of Malaysia. This article was published in the latest issue of the magazine \u201cScientific American\u201d. According to Moffett, like humans, several species of ants wage ferocious wars, both against different species and against other colonies of their own species. Moreover, with motivations, not very different from ours. These include securing territories and food and, in some cases, getting slave workers. Surprisingly, moreover, ants employ some attack tactics similar to those used by our military strategists. Moffett, for example, As we know, the military formations known as phalanges were invented in the Greek state cities several centuries before our era. In the phalange the soldiers marched compactly in rectangular formations with depths of dozens of rows. The formation presented the enemy with a compact front of fighters armed with swords and spades up to seven meters in length pointing horizontally forward. In addition to individual protection with armors, helmets and shields, the soldiers in the phalange had their flanks covered and their backs covered by their same comrades in the formation. During the attack the soldiers in the first row were pushed towards the battle line by their companions marching behind them. The formation in phalange was responsible for a coalition of Greek cities headed by Esparta, with only 7,000 soldiers, having managed to stop 250,000 Persian soldiers in the battle of the Thermopyles in the year 480 before our era. a region of gorges that adapted especially well to the formation in phalanx and in which the Persians had many difficulties to impose their numerical superiority.,Although the ants prowling around do not use armor or spades in their warrior incursions, they do throw themselves in a group to attack, blindly and with great ferocity, the style of Spartans in ancient Greece. Moffett writes that, with their jaws as a deadly weapon, the tiny ants acting in a group are able to kill thousands of times larger animals than themselves and that \u201cin Gabon once I saw an an antelope in a trap that was devoured alive by an ants colony.\u201d Furthermore, according to Moffett, the ants prowling have a definite strategy about who is ahead in the battle. Indeed, it happens that ants of this species can differ greatly in size among them \u2013 up to 500 times \u2013 and are the smallest and weakest \u2013 though much more numerous \u2013 those in the first line of battle. combat is when the biggest ants come into action. Although at this point the marauding ants differ from the Spartan customs \u2013 whose troops were formed exclusively by those who were considered citizens of Sparta\u2013, the fact that the weakest serve as cannon meat has not been a rare military strategy. Moffett adventure that the warrior vocation is an effect of the size of the group of individuals in question. Thus, it is typical of colonies of 500,000 ants and not of small groups of these insects. In the same way, it has occurred over the last thousands of years among numerous human groups, but it would not have occurred during the time when our ancestors lived as hunter-gatherers in small groups. It also notes that, as far as warrior impulses are concerned, humans are more like the ants than the chimpanzees \u2013 our closest living relatives \u2013 who do not live in large groups. However, and of course, the similarity between humans and ants has a limit. And in effect, as we know, the battle of the Thermopyla It had a tragic end for the group of Greek soldiers who stood firm in their confrontation with the Persians. The culprit of the debacle \u2013 which opened the doors of the Greek region to the Persian invasion \u2013 was Efialtes, who betrayed the Spartans by pointing out to the Persians a path by which they could penetrate to the rear of those. Thus, under two fires, the Spartans and their allies ended up succumbing. In contrast to the human species, in a colony of ants, a traitor could hardly emerge that sold to their fellow men. At this point there is no doubt that there is indeed a difference between species.",
    "https://upload.wikimedia.org/wikipedia/commons/a/a4/Emile_Salmson_watercooled_radial_engine_1915.jpg": "What is the smallest car in the world? As oil prices skyrocketed in the 1970s, the aim has been to reduce the consumption of gasoline by producing smaller cars and making them more and more efficient at the same time. By searching the Internet we learn that they are on sale \u2013 or about to be \u2013 a good number of small cars manufactured in Germany, Japan, France, Norway and the United States, among other countries. Cars \u2013 some electric and others internal combustion \u2013 are found from 2.5 meters to 3.3 meters long, with weights around 1000 kilograms.The car that gets the record, however, is the Peel P50 model, manufactured by a British company between 1962 and 1965 \u2013paradoxically, at a time when there were not too many concerns about saving gasoline.The Peel P50 is really small: it measures 1.3 meters long, 1 meter wide, 1.2 meters high and weighs only 59 kilograms! In addition, it can only transport one person \u2013 in a comfortable position, by the way.The Peel P50 has advantages. And if this were not the case, we could pick it up at one of its ends and \u2013 as if it were a suitcase with wheels \u2013 take it with us to a place where we go \u2013 to see these possibilities, see the BBC video about it that can be found on the Internet. On the negative side, a car of the Peel P50 dimensions is dangerous for its occupant, which can easily be killed in a traffic accident \u2013 especially in disordered cities like ours. This, perhaps, is the reason why it was not very successful. On the other hand, if we redefine a car more broadly essentially as a self-propelled vehicle, without necessarily having the ability to transport people, then Peel P50 is not the smallest car in the world. Moreover, it turns out that this distinction does not fall, as we might have expected, in some motorized toy, but in a surprisingly small mechanism. Indeed, in an article published last November 10 in the magazine \u201cNature\u201d, a group of researchers from Holland and Switzerland published an article in This incredibly small car, which has two axles and two wheels per axle, has dimensions of only 4x2 nanometers \u2013 a nanometer is the one thousand millionth part of a metre. It is also electric, as some of its macroscopic congeners do. To move, however, it does not use batteries, but it works with the electric current that is provided through a metal wire finished in an extremely sharp tip. Another difference with its larger counterparts is that the electric current must be provided in a peculiar way: by jumps, each jump producing half a turn on the wheels. Using this technique, its creators managed the nano car to advance about 6 nanometers in a straight line on a copper surface. To make the tiny automobile advance 6 nanometers can be little on our macroscopic scale. It is not, of course, if we take into account the extraordinary difficulties that arise to manipulate an object of such small dimensions and in particular to get the four wheels to advance 6 nanometers on our macroscopic scale. The nano-car described above might seem like a scientific curiosity, albeit extraordinarily amazing. Far from this, and according to experts, it represents an important advance in the field of nanotechnology, demonstrating that it is possible to develop nano motors capable of inducing a movement on a surface and for which many applications are expected in the future that now only belong to the field of science fiction. Thus, as one of the authors of the reference article writes in a previous publication: \u201cThe molecular engine is a central element in molecular machines and it is conceivable that these engines and machines will play such a prominent role in the nano-technology revolution of the 21st century as the one played by their macroscopic counterparts \u2013 the steam and internal combustion machines \u2013 by provoking the industrial revolution of the 19th century.\u201d That is, despite the fact that nano-cars are not capable of transporting passengers \u2013 our size \u2013 it is possible that they will have a considerably greater future impact on our descendants than the macro-cars in the present time.",
    "https://upload.wikimedia.org/wikipedia/commons/0/0f/Monte_Verde_24.JPG": "Who were the first settlers of America? As we know, compared to other continents, America was populated until relatively recent dates. It is commonly assumed that the American peoples originated in an advance that crossed from Asia to America some 15,000 years ago through the bridge of Beringia \u2013 although there is no unanimous agreement regarding the date. This bridge, formed between Alaska and Siberia by the descent in the level of the oceans, allowed at the end of the last glaciation the transit of people between the two continents. As this level rose again, however, the bridge of Beringia disappeared, isolating the advance that entered our continent. Thus, American cultures evolved independently, without contact with the Old World. Throughout the last half of the last century it was considered that the Clovis culture, which flourished for a short period of time some 13,000 years ago, was the first in America. This culture is characterized to a great extent by the development of a technology to manufacture points of stone \u2013 known as \u201cclovis points\u201d\u2013 with characteristics The Clovis culture was named after the same name in New Mexico, where objects of this culture were first found in 1929. To survive, the Colvis were engaged in the hunting of the megafauna, which included mammoths and mastodons of several tons of weight. They had so much success in this activity that, according to some experts, they ended up extinguishing these great animals. Had it been so, since the Clovis culture was of very short duration \u2013 some 200 years \u2013 the extinction of mammoths and mastodons would have been very rapid. In this context, there has been a talk of a \u201cblitzkierg\u201d \u2013 lightning war \u2013 of Clovis against mammoths and mastodontes. Not everyone agrees, however, that the megafauna has become extinct so suddenly. Indeed, in recent years, evidence has been found \u2013 every time more than ever \u2013 that Clovis were not really the first settlers of the New World. and that there would have been earlier cultures that also contributed to ending the megafauna. Thus, it would have had a slower end than that resulting from a lightning war. In relation to the latter, in an article published last October 21 in the magazine \u201cScience\u201d by a group of researchers led by Michael Waters of Texas A&M University in the United States, it is concluded that there were megafauna hunters who preceded the Clovis for about 1,000 years. These concussions are based on a study of a skeleton of mastonte found near the Pacific coast on the border between the United States and Canada, which shows a bone tip of mastodon \u2013 from a different animal \u2013 housed in one of their ribs and which evidently was the product of an attack with hunting purposes. This skeleton has been assigned an antique of 13,800 years by means of carbon technique 14, which is pre-Clovis culture. Hunters of the mastodonte would then have to have belonged to a pre-Clovis culture. There is currently a debate of carbon 14 years ago. experts among those who defend the Clovis was the first culture of our continent and those who sustain the existence of previous cultures \u2013 of which there is evidence, not only in North America, but in some places in South America, notably in Monte Verde, Chile\u2013. Apart from the debate, however, what is incontrovertible is that the mammoths and the American mastodons ended up being extinct. In this regard, and even though extinction might have been due to natural causes \u2013 such as a changing climate \u2013 the Clovis and their predecessors point out as possible guilty of having contributed to reducing the biodiversity of the planet.If it had been so, however, we could not be too severe with them, for they certainly needed to hunt in order to survive. On the contrary, we would have to admire them for the technology they developed to make weapons that allowed them to hunt animals many times larger than their size. After all, having more urgent things to do, the conservation of biodiversity could not have been given the least importance in the Clovis era.",
    "https://upload.wikimedia.org/wikipedia/commons/1/15/Yersinia_pestis_fluorescent.jpeg": "As we know, in the middle of the 14th century Europe suffered an epidemic of bubonic plague known as the \u201cBlack Death\u201d. The bacteria that caused it reached the European continent on board a ship coming from the Black Sea, landing through a port in southern Italy. Once on the mainland, the bacteria quickly expanded to the north, sowing death in its path and arriving in Scandinavia in the course of a few years. It is estimated that in the epidemic it could have killed up to 50% of the population of Europe. In the centuries following the Black Death, new epidemics of bubonic plague have occurred repeatedly. In 1665, for example, the Great Plague of London killed 100,000 London and caused the escape of the city of many of its inhabitants, including King Charles II of England. Bacteria that have produced the epidemics after Black Death, however, have not had the same virulence, particularly those circulating around the world today. Given the mortality and rapid spread of Black Death, it is not difficult to understand. Today we know that bubonic plague is dispersed by rats infected by the bacteria \u201cYersinia pestis\u201d and that it is transmitted to humans by the bite of parasitic fleas from them. In the Middle Ages they did not have this knowledge, in particular, they did not know of the existence of bacteria or of their role as infectious agents. Thus, they would hardly have been able to discover the chain of transmission of the disease that carried from rats to humans. Thus, they gave some good explanations about the origin of the epidemic that we find absurd today. They believed, for example, that the disease was due to the bad smells in the air and that they could prevent it by eliminating them from the environment. Or, and this must have been even more frightening, that there could be infection through sight. There were also more sophisticated explanations, such as that offered by a group of sages to King Philip VI of France, according to which the epidemic had its origin in the conjunction of Mars, Jupiter. It is now clear to us that such explanations about the origin of Black Death are far from the truth and in no way surprising to us that the measures that were taken in its time to prevent or cure it have generally resulted in a resounding failure.In contrast, we now know enough about infectious diseases and in particular about the bacteria \u201cYersinia pestis\u201d, so that it no longer constitutes a greater danger. Knowledge about this bacterium, moreover, increases as research progresses, sometimes carried out with techniques that until a few years ago had been almost magical. As an example of this, on Wednesday, 12 October, an international group of researchers headed by Kristen Bos of McMaster University in Canada and Verena Schuenemann of the University of T\u00fcbingen in Germany published an article in the British magazine \u201cNature\u201d reporting the reconstruction of the genome of the bacteria causing the \u201cBlack Death\u201d bacteria. \u2013 over six centuries old \u2013 it was obtained from the teeth of victims of the epidemic buried in a cemetery in London, England. Thus, it was possible to find out the intimacies of a bacterium six centuries after it caused a fatality.The results of the above research show that the current plagues are caused by bacteria originated in those that caused Black Death, which would thus be the mother of all plagues.Furthermore, researchers do not find great differences between medieval and modern bacteria that could explain the great virulence of those in comparison with those in London.The difference in this respect should then be due to causes external to the bacteria itself, such as the best hygiene and feeding conditions today, compared to those prevailing in medieval Europe.In addition to the King of England, another of those who fled from the plague of 1665 in London was Isaac Newton \u2013 considered by many the greatest scientist who has existed \u2013 who, when closing Cambridge University by the epidemic moved to Whoolsthorpe, his hometown, waiting for the contingency to pass. highly fruitful years \u2013 according to him the most productive of his life \u2013 in which he developed ideas and theories that resulted in great significance for the later development of science. Thus, in this case the bubonic plague had a positive contribution.However, even seeing it on its good side, it is clear that bubonic plague is by no means our friend and we can only congratulate ourselves that today does not constitute a greater danger.",
    "https://upload.wikimedia.org/wikipedia/commons/2/23/12_Vista_general_del_techo_de_pol%C3%ADcromos.jpg": "It was in 1879 that an amateur archaeologist discovered the famous paintings of the Altamira cave, near Santillana del Mar in northern Spain. This cave consists of several cameras, the most famous of which \u2013 the so-called Great Hall or Hall of Polychromes \u2013 shows on its roof a large number of images in colour of bison in different positions, deer, boars and horses, which lived in that part of Europe thousands of years ago. Although initially there was controversy among experts about the authenticity of these paintings \u2013 given their artistic perfection\u2013, at the beginning of the 20th century it was finally accepted that they had a prehistoric origin. Today it is known that Altamira paintings have an antiquity that is around 14,000 years old. After overcoming the controversy about their authenticity, it was not long before the first guided visits to the cave were organized, which \u2013 given the spectacular nature of the paintings that it houses \u2013 had a great success. This, however, in the long run, resulted in the detriment of the paintings themselves. The cave of Altamira, isolated from the outside for 13,000 years by a collapse in its entrance, increased rapidly, reaching 50,000 in 1955 and increased to 175,000 in 1973. With this, the cave of Altamira, isolated from the outside for 13,000 years by a collapse in its entrance, showed signs of contamination by bacteria and fungi that put at risk the integrity of prehistoric paintings. Thus, the voice of alarm was given and Altamira was closed to the public in 1977. In 1982 it was reopened, but limiting the number of visitors per year to 11,000. As it was clear that even with this reduction the deterioration of the environmental conditions of the cave continued, Altamira was closed again in 2002 and has remained so far. In order to boost local tourism, there have been plans since 2010 to resume public visits to the cave of Altamira. An article published last Thursday in the magazine \u201cScience\u201d by a group of Spanish researchers, however, discourages it. The latter, because, as a result of massive tourist visits, Altamira cave suffers from microbial contamination. In relation to this, Spanish researchers have identified four different bacteria, distributed throughout. Most of them are housed in the entrance gallery of the cave, but some have already reached the Great Hall, where there are paintings showing green spots due to bacterial growth. One factor that has contributed to contaminating the environment inside the cave \u2013 according to the reference article \u2013 has been the use of artificial light for the illumination of the paintings. This has led to the proliferation of bacteria capable of carrying out photosynthesis \u2013 using the light of lighting lamps for this purpose \u2013 and which are the ones that have contaminated the paintings of the Great Hall. In addition to the contamination by bacteria, there is a contamination in the Altamira cave by fungi taken inside by insects, or fungi that grow there on the feces of rodents. Spanish researchers fear that, while at these times when the cave is closed it seems that the problem of contamination of the Altamira site is stabilized, it is reactivated from reopening the cave to the public. In particular, the flow of people into the cave would cause the entry of nutrients from the outside, which would trigger the growth of the cave. Also, the movement of air that would cause such a flow would transport bacteria lodged in the walls of the entrance gallery of the cave towards the interior of it. It could be reproduced in Altamira the disaster that occurred in the cave of Lascaux, in France. This cave is a prehistoric art site of importance similar to that of Altamira \u2013 in fact, both sites have been called the \u201cSistine Chapel of Prehistory\u201d \u2013 which suffered a serious contamination by fungi motivated by an intense flow of tourists and which has not been able to be overcome. 14000 years ago there were no photographic cameras and that, unfortunately, deprives us of the pleasure of appreciating images \u2013 with the detail that a photograph could provide us \u2013 of a remote past very different from the time in which we have had to live. In the absence of photographs, however, Altamira artists have bequeathed paintings of amazing realism, which allow us to take a look at their world. Altamira, moreover, and perhaps this is the most important thing, keeps secrets about the prehistoric societies that the experts are yet to discover. However, only if Altamira manages to get rid of those who want it to remain a business. h",
    "https://upload.wikimedia.org/wikipedia/commons/9/96/Schnorr_von_Carolsfeld_Bibel_in_Bildern_1860_007.png": "What time of day is a person in a better mood? Is there any day of the week or season of the year in which there is a greater enthusiasm to go to work? Scott Golder and Michael Macy, sociologists at Cornell University in the United States looked for answers to questions like these through the study of millions of messages sent through the social network Twitter. The results of that study were published last Thursday in the magazine \u201cScience\u201d. In recent years we have witnessed the extremely rapid expansion of social networks. Facebook, for example, reached 800 million registered users this month; that is, more than 10% of the world\u2019s population. Given its massive nature, social networks constitute an invaluable means for sociologists to access millions of people from different cultures throughout the world. Twitter, in particular, allows its users to send short texts of no more than 140 characters that implicitly include personal information from the sender. During their study, Golder and Macy analyzed 500 million of these texts \u2013 sent by 2.5 million people in 84 countries to For this purpose, researchers used a computer program that analyzes texts and searches for words that reveal positive emotions, such as enthusiasm or pleasure. To quantify the mood of a particular person at a given time, they divided the number of words of this type that appeared in their message by the total number of words contained in it. The results that the study gave are both interesting and expectable. It is found, for example, that the best mood days are on Saturdays and Sundays, which are precisely the days on which no work is done, which, of course, is not surprising. In contrast \u2013 which is not surprising either \u2013 according to Golder and Macy the positive mood falls noticeably on Monday \u2013 on returning to work \u2013 and it does so even more on Tuesday, which is the worst day of the week on this week. As of Tuesday and in view of the prospect of an ever closer weekend, the positive mood gradually rises. In reference to our country and according to the custom \u2013 in some cases \u2013 of doing \u201csan monday\u201d, in the first instance we would have hoped that the day less favorable for work would be precisely Monday and not Tuesday as Golder and Macy find. It is possible, however, that the determining factor in Mexico not to attend work at the beginning of the week is not a poor emotional state but some other indisposition as a result of the days of rest.Golder and Macy find, moreover, that the positive mood varies throughout the day. Thus, this is high during the first hours of the morning, gradually drops as the day progresses reaching its minimum during the afternoon, and is again high in hours of the night. It was also found that, in comparison with the days of work, during Saturdays and Sundays the maximum positive mood during the morning occurs about two hours later, as a consequence that on the weekends it lengthens. The variations of mood throughout the day occur both on working days and on Saturdays and Sundays, which indicates that they are not due to work pressures, and on the contrary follow the circadian rhythm and sleep period. The obligation to go to work, instead, if it would be the cause of the mood variations observed during the week. This is confirmed by the fact that in the United Arab Emirates, where the work week begins on Sunday and ends on Thursday, the days with high moods are Friday and Saturday, instead of Saturday and Sunday. Golder and Macy show, moreover, that we are facing a universal phenomenon: data for four regions of the world, the United States-Canada, Great Britain-Australia, India and English-speaking Africa, indicate that their inhabitants experience similar mood changes throughout the week. According to the above, Mexico, where we have throughout the year several holiday periods and \u201cbridges\u201d, including the already traditional \u201cGuadalupe-Reyes\u201d, could be one of the happiest countries of the week. This would possibly be true if not because work is an indispensable ingredient if we are to generate wealth and achieve a better standard of living.",
    "https://upload.wikimedia.org/wikipedia/commons/3/34/Friccion.png": "In the past week, the media have devoted considerable attention to the return to Earth of NASA's UARS atmospheric research satellite, after 20 years of remaining in space. NASA confirmed the re-entry of the UARS satellite \u2013 the six-ton-weight Higher Atmospheric Research Satellite \u2013 at an undetermined point in the North Pacific during the early morning of last Saturday. According to unofficial information, it would have fallen near Calgary, Canada. It was not expected that the six-ton satellite, the size of a bus, would fall just like the surface of the Earth; on the contrary, NASA predicted that most of the satellite's mass would disintegrate into the atmosphere. In the fall, however, the most friction-resistant parts of the satellite would generate 26 fragments with a total weight of half a ton \u2013 one of them about 150 kilos \u2013 that would reach the Earth's surface at great speed. Thus, the prospect of being reached suddenly by a projectile coming from the sky, naturally caused a certain level of alarm and was the object of interest of the Earth's surface. According to NASA, however, the probability that someone would be injured by a fragment of the UARS was very small. According to his calculations, that probability was only 1 in 3,200 \u2013 which is more or less the probability of getting out of the National Lottery by buying thirteen sets of banknotes. Moreover, dividing this probability by the number of people living in the world \u2013 about seven billion \u2013 the probability that a particular person would be reached by a fragment of the UARS is negligible.More than three decades ago the re-entry into Earth of the 75-ton Skylab satellite also attracted a great deal of media attention. Skylab was the first American space station. It was put into orbit in 1973 and returned to Earth six years later. The remains of the space station fell near the village of Esperance, in a remote region in western Australia. By the way, to the distaste of Australians, on that occasion NASA made unfortunate statements ensuring that the only ones that had been put in danger by the remains of the Skylab were the kangaroos in the western part of Australia. Since 1957, when the then Soviet Union launched the Sputnik 1 satellite into space, about 6,000 artificial satellites have been put into orbit, some 900 of which are currently in operation. A large part of these are circulating to Earth in orbits whose height is measured by hundreds of kilometres. Although at such heights the atmosphere is very rare and the air resistance against satellites is very small, it is not zero, so satellites are stopped continuously. This forces them to be permanently relocating in orbit, as otherwise they would inevitably return to the surface of the Earth. During the time they remain in orbit, on the other hand, satellites are exposed to catastrophic collisions between them \u2013 as happened in February 2009, when they collided with Russian Cosmos-2251 and US Iridium 33 at a speed higher than 40,000 kilometres per hour \u2013 or more commonly when they collide with fragments of space debris. This debris, which travels at extremely high speeds, is the result of the destruction of other satellites or material that has been left in orbit by means of orbit. This is a chain reaction that, according to experts, could increase the number of debris fragments to levels that would prevent future space missions.To avoid collisions between satellites and not contribute to the increase of space debris, it is necessary to bring them down once they have passed their useful life. Thus, the UARS satellite, upon its discharge in 2005, was transferred to an orbit closer to the Earth\u2019s surface, thus increasing its braking by friction with the air and thus precipitating its fall. Upon returning the UARS to Earth, a possible collision in space with the consequent formation of more space debris was avoided. At the same time, however, the collision of the satellite fragments with any of the planet Earth\u2019s inhabitants was made possible, although accepting NASA\u2019s calculations, the probability of this happening is small. It must be remembered, however, that during the time of the satellite fragments, the collision with any of the planet Earth\u2019s inhabitants was made possible. Skylab's fall in Australia a 17-year-old boy picked up a fragment of the space station from the courtyard of his home in Esperance, which he hastened to present to the San Francisco Examiner newspaper in order to claim the $10,000 prize that the newspaper had offered to the one who had a piece of the Skylab within 48 hours.",
    "https://upload.wikimedia.org/wikipedia/commons/4/40/SterkfonteinCave.jpg": "Charles Darwin defended the hypothesis that our human species and the great apes share a remote ancestor. Darwin also assumed that this ancestor lived in Africa, because it is on this continent where chimpanzees and gorillas live, that they would be our closest living relatives in evolution. Given the prejudices of the time, it is not surprising that these ideas have suffered a strong rejection, because they implied that we humans did not occupy, after all, a special place in the Animal Kingdom \u2013 he also crashed, the claim that our species would have originated in Africa, which did not agree with racist ideas very widespread in Europe, even today.Not long after, however, Darwin's speculations began to receive sustenance. Thus, in 1924, anthropologist Raymond Dart of the Witerwatersrand University in South Africa discovered in a quarry in the northwest of this country the fossil skull of an infant of about 3-4 years old and 2.8 million years old, which had intermediate characteristics between simians and humans, including the In 1936, paleontologist Robert Broom found in Sterkfontein, South Africa, the fossil remains of an old adult equivalent to those discovered by Dart. He was followed by other discoveries made by Broom himself, which ultimately led to the broad recognition of South African fossils as intermediate forms on the evolutionary path towards modern humans. Broom was a doctor of profession and paleontologist by hobby. In 1903 he lost his position as professor of Stellenboch University, in South Africa, by supporting the theory of evolution. This prompted him to practice his profession as a physician to survive, dedicating his free time to paleontology. The episode gives us an idea of the prevailing climate in the time with regard to these subjects. Today numerous fossils have been discovered showing the evolutionary line that has given rise to our species \u201cHomo sapiens\u201d, including Lucy, the famous skeleton of 3.2 million years old discovered. in Ethiopia in 1974, as well as the footprints of 3.5 million-year-old bipedal creatures, preserved in hardened volcanic ash, were found in Tanzania in 1978. The week just ended brought us the news of the latest discovery of pre-human fossils, which was carried out by a group of researchers led by Lee Berger of Witerwatersrand University. This discovery is described in a series of articles published by the journal \u201cScience\u201d on Thursday, September 8. In such articles two incomplete fossil skeletons discovered three years ago in Malapa, South Africa, not far from Sterkfontein where Robert Broom found his first fossils. It has been determined that the skeletons of Malapa have an age of about 2 million years. The creations to which they belonged \u2013 a child about 12 years old and an adult female \u2013 had a small brain, long arms and a chimpanzee body. They could also flex their hands like the simians, which would have enabled them to climb. At the same time, however, they had human characteristics, including short fingers and an elongated thumb that allowed them to manipulate objects, just as we do. Likewise, although their brain was only a little bigger than that of a chimpanzee, it apparently had an internal organization that anticipated the human one.Since the age of fossils corresponds to the moment when the human race appeared, Berger speculates \u2013 although he does not say so \u2013 that it could be the direct ancestor of that genus.The Malapa fossils, with their mixture of human and prehuman traits, are undoubtedly fascinating and experts do not doubt that they will eventually shed light on the evolutionary process of human gender and our own species, although it soon seems that they have generated more questions than answers.In relation to the latter, it is not clear, for example, whether they are really a direct ancestor of the human race or whether they correspond to an evolutionary line that eventually became extinct.In any case, seeking and finding an answer to this or other questions will not lead to anyone losing their work as a result of absurd prejudices. Broom, after a fruitful and long existence, died on April 6, 1951 at the age of 85, He died moments after finishing a manuscript on paleontology. He would have exclaimed: \u201cNow this is over...and so am I.\u201d",
    "https://upload.wikimedia.org/wikipedia/commons/1/18/Caliper_detail_view.jpeg": "As we were taught at school, calculating the area of a square or rectangular surface is easy: it is only necessary to multiply its width by its length. Doing it with an irregular surface, in contrast, is considerably more difficult \u2013 let us try, for example, to calculate the area of a surface limited by four sides, all of different lengths. However, given that measuring a surface has a great practical importance \u2013 to know the extent of an agricultural property, for example \u2013 the methods to do so were already developed a good number of years ago. Sumerians and Egyptians, for example, knew how to measure surfaces in times that go back several thousand years in the past. In the case of Egypt, after a flood of the Nile River \u2013 which occurred periodically \u2013 we had to delimit the agricultural plots again. On this side of the Atlantic, we know that Mayans had advanced mathematical knowledge that, among other things, included the use of zero. Some years ago, moreover, it was discovered that the Aztecs were equally competent in the subject. This codex \u2013 housed in the National Library of France \u2013 was developed by indigenous experts in 1543-1544, that is, during the early years of the colonial period. It includes a census of agricultural properties in the village of Tepetlaoxtoc, near Texcoco in the State of Mexico. As we know, the kingdom of Texcoco integrated the triple alliance with Tenochtitl\u00e1n and Tlacopan as part of the Aztec Empire. Since the manuscript provides both the surface of each site and the dimensions of its co-unitities, the researchers were given the task of trying to guess the methods used to calculate their surfaces. The study was done with 386 predios, of which 90 had a square area and 32 a rectangular surface. The rest of the predios studied, a total of 264, had a total of 386 predios. In the case of square and rectangular properties, the areas recorded in the codex coincide in an exact way with the corresponding long product by width, which leaves no doubt about the procedure used to calculate them. As the authors of the reference article comment, this shows that the people who prepared the calculations \u2013 which were assumed to be indigenous \u2013 had a clear idea of the abstract concept of area. To calculate the surface of an irregular quadrilateral it is necessary to use more complicated methods. An approximate technique \u2013 used by the Sumerians \u2013 consists in multiplying the averages of each of the two pairs of opposite sides. In this case, in addition to the multiplication operation, the operations of addition and division are required. There are additional techniques that also require several arithmetic operations. It was found that, although it is not possible to determine which particular method was used in each case by the authors of the Vergara Code to calculate the area of the predium, the values indicated in that code \u2013 area and length of colindancias\u2013 have meaning in 86% In addition, the imprecision in the calculated areas would be less than 10%. This, according to the authors of the article, suggests that these values were calculated using a method that required the execution of several mathematical operations. Thus, the Aztecs would have had surveying techniques that were not left behind in comparison with those practiced in Europe, not only in the 16th century, but even hundreds of years later. And yet, according to the authors of the article referred to, the Spanish conquerors did not take advantage of the indigenous experience and introduced from the peninsula to the New Spain a chaotic surveying system that would have made the first Viceroy Antonio de Mendoza say in 1535 that \u201cin this city there is no way to measure the land\u201d.",
    "https://upload.wikimedia.org/wikipedia/commons/a/ac/Valladolid_colegio_San_Jose_instalaciones_deportivas_1_lou.JPG": "Education is certainly one of the most valuable assets that a person can possess and that determines to a large extent his or her quality of life. It is thought, on the other hand, that the education that a child receives in his or her early years of life is fundamental to his or her later school performance. The question about the optimal age for an infant to start formal education is then of the utmost importance. As a result of scientific studies carried out in recent decades, some experts think that formal education of children should start at the preschool level. In this regard, a study, published on 15 July in the magazine \u201cScience\u201d by a group of researchers from the universities of Minnesota and Missouri in the United States headed by psychologist Arthur Reynolds, shows that preschool education \u2013 based on three years of age \u2013 can influence the quality of adult life in such areas as wage level, drug use and problems with justice. This study was conducted in Chicago, Illinois, with a total of 1,539 children from low-income families \u2013 mostly of black race. The aim of the study was to find out whether there was a difference in the quality of life between the two groups of participants when they reached an age of 28 years. It was found that this was the case. It revealed, for example, that those children who had a formal education since the age of three had a better academic performance and graduated from the preparatory school by a higher percentage compared to those children who had a higher percentage of those children. It was also found that at the age of 28 the participants of the first group had a better salary and that a higher percentage of them had a health insurance. Earlier education also led to lower drug use and fewer problems with justice. However, according to Jeffrey Mervis \u2013 editor of \u201cScience\u201d news \u2013 although the results of the above-mentioned study undoubtedly demonstrate the positive effect of early education on the particular group of children studied, it is not clear that such results can be extrapolated to other population groups \u2013 he considers, in particular the white and Latino populations. Given this uncertainty, it is difficult to implement the program on a large scale in the United States because of its high cost, which reaches several thousand dollars per pupil. Reynolds\u2019s study and collaborators could be relevant to our country, which has a large percentage of marginalized population. In Mexico, preschool education is compulsory. We know, however, that primary and secondary education has serious deficiencies \u2013 as indicated by the low profile of our students at the level. In the PISA test of the Organization for Economic Cooperation and Development, which covers three areas of competence: reading, mathematics and natural sciences, it is uncertain to predict the extent of the benefit that preschool education will bring to our children, and if it will come closer to that obtained by Reynolds and collaborators under more controlled conditions. In any case, we now know that, given the right conditions, the marginalized population in Mexico could perhaps achieve better educational standards and quality of life through early education.",
    "https://upload.wikimedia.org/wikipedia/commons/0/0f/Syracuse_Philistis_Tetradrachm_218_BC_80000114.jpg": "According to legend, King Hier\u00f3n II of Syracuse asked Archimedes to find out if the crown he had recently acquired was actually of gold as it was supposed. The king suspected that the craftsman who made it had deceived him and that the crown was partly of silver. Archimedes would have imagined a solution to the problem while taking a bath, observing that the water in the bathtub was rising at a level \u2013displaced by his body \u2013 insofar as it was submerged. He suddenly understood that to determine the chemical composition of the crown it was sufficient to immerse it in a container with water and measure the increase in the level it produced; that is, since silver is less dense than gold, to submerge it in water will displace a volume of liquid greater than an equivalent weight of gold.Although it is unlikely that things would have been given as described to us by the legend \u2013 based on a written, several centuries after the fact, of the Roman architect Vitruvius\u2013, the anecdote illustrates us a frequent human experience: the conception of ideas or procedures to solve a particular problem such as Archimedes was especially efficient in this regard, having created numerous mechanical devices and wits. For a long time we considered that the ability to conceive creative solutions was unique to humans. Now, however, we know that it is shared to some degree by certain animals. It is known, for example, that chimpanzees hunt termites as food and for this purpose, locate a termite and extract insects by introducing a thin rod \u2013especially prepared \u2013 through a hole in the walls of the same. Even, if necessary, they previously drill a hole in the wall of the termite with a thicker rod. This \u201ctechnology\u201d, which is transmitted from parents to children, was surely devised by some forefather chimpanzee at a start of inspiration,The elephants also have a great intelligence. In an article published a few days ago in the online magazine PLoS ONE by researchers from the University of New York City and the Smithsonian Zoo, the results of a study with three Asian elephants of 61, 33 and The study showed that the youngest elephant, named Kandula, confronted with the problem of reaching food beyond his reach, was able to discuss creative solutions.In a first experiment, in the courtyard where Kandula lived, various fruits were placed from which he used to eat. Fruits were suspended from a wire at a height beyond what Kandula could reach. In addition, it was placed on the ground near the place where the food was located, a bucket on which the elephant could climb the front legs to reach the fruits. Although from the beginning of the experiment Kandula became interested in food, he did not attempt to use the cube to reach it at his first chances. At some point, however, he \u201ctook the focus\u201d and understood the usefulness of the cube.From this point, the elephant always used the cube to reach the fruit, not importing that they had placed it \u2013 or even hidden \u2013 away from where that one was. When it was necessary he even dragged the cube with the tube to place it in the proper position. Moreover, when in a different experiment the cube was placed. In another experiment in which the bucket and the rim were removed from the courtyard, the elephant used a ball about the size of the cube that was within its reach in his endeavor. This despite the fact that with the top legs of the ball it was in an unstable situation and in danger of falling. Since there is clearly no such sharp division between humans and some animals as we once considered it, the latter are now the reason for some considerations on our part. Thus, for example, the experiments with elephants mentioned above had to be approved by the Committee for the Care and Use of Animals of the University of New York City, as well as by the Smithsonian Institute.In our country, a few days ago we learned from the press that a law initiative would be presented to the Legislative Assembly of the Federal District to penalize animal abuse until six years in prison. If passed, the law would end in the Federal District with activities such as bullfighting, in which it was abused. n animals to a degree that does not admit comparison with the hypothetical mistreatment of elephants in the experiments reported here. Most likely, however, even if the law is passed it will remain in dead letter, as often happens in Mexico.At least until the animals give us greater proof of their intellectual abilities.",
    "https://upload.wikimedia.org/wikipedia/commons/c/ce/Nagasaki_City_view_from_Hamahira01s3.jpg": "On Tuesday, August 9, the 66th anniversary of the atomic bombing of Nagasaki at the end of World War II \u2013preceded three days earlier by a similar attack on Hiroshima\u2013 was commemorated. Depending on the source, up to 250,000 nuclear victims of Hiroshima and Nagasaki have been estimated to have died instantly at the time of the explosion or during subsequent months. We also know of the fate of the \u201cHibakusha\u201d\u2014survivors of the atomic bombings\u2014wounded by a number of diseases associated with their exposure to nuclear radiation. Given this terrible experience, one might have expected Japan to be the last country in the world interested in nuclear technology; and not only for military use, but also for civil applications such as commercial power generation. However, under pressure from its shortage of energy resources, the Japanese have built 54 nuclear reactors in their territory from which, in round numbers, they obtain 30% of the electricity they consume. Japan is thus an ironically dependent country in large measure on energy resources. The accident of the Fukushima reactors caused by the earthquake and subsequent tsunami that ravaged the northern coast of Japan last March, however, has changed the mood of the Japanese in relation to nuclear power. A telephone survey carried out by Kyodo news last July points out that 70% of Japanese support the idea of a country without nuclear energy. A surviving \u201cHibakusha\u201d from Nagasaki, quoted by The New York Times, said: \u201cI would have liked to have had the courage to speak out against nuclear energy earlier.\u201d Meanwhile, at the ceremony commemorating the bombing of Hiroshima on 6 August, the Japanese Prime Minister said: \u201cThe country\u2019s energy policy is being fundamentally reviewed, after a deep reflection of the myth that nuclear energy is safe.\u201d Nuclear reactions release extraordinary amounts of energy, tens of millions of times larger than those generated by ordinary combustion. This means that the temperature reached in the center of a nuclear explosion is tens of millions of degrees Celsius \u2013 in Compared to the hundreds of degrees Celsius generated by the combustion of gas from the stove\u2013 Thus, the care we put in handling explosive substances in order to prevent accidents, must be taken to an extreme degree in the case of nuclear power if we do not want to cause a disaster. In practice, unfortunately, as Fukushima proves -and previously the accidents of \u201cThree Mile Island\u201d in the United States and Chernobyl in Ukraine -, accidents in nuclear plants eventually occur by human error or by deficiencies in safety procedures. In addition, nuclear energy generates high-hazard radioactive wastes that need to be safely confined. Although this can in principle be done, in practice it does not always happen. Thus, one of the factors that aggravated the Fukushima crisis was that the fuel used \u2013 which was stored in the building of one of the sinister reactors \u2013 was exposed to the air by releasing large amounts of radiation. Ordinary fire, with temperatures of hundreds of degrees \u2013 much higher than our body temperature \u2013 is of course incompatible with life. However, we have done to the air. In contrast, nuclear fire, millions of times more intense than an ordinary flame and, consequently, millions of times more deadly, is becoming very difficult for us to tame. Perhaps it is just a matter of giving us more time, because it has only been seven decades since we started to use it \u2013 both for good and for bad. However, while we are making progress in our attempt to domesticate nuclear fire, perhaps we would have to learn to use other more friendly sources of energy, both with us and with the environment. The Sun, which is indeed the source of life, is undoubtedly the most natural option. Otherwise, we would continue to play with a very dangerous fire.",
    "https://upload.wikimedia.org/wikipedia/commons/1/18/Ambassadors_training_13.JPG": "The Japanese novelist Soseki Natsume published in 1905 the novel \u201cI am a cat\u201d, in which the protagonist, a cat who enjoyed little appreciation among humans \u2013 even from his master, to the extent that he had not given him a name \u2013 describes his experiences in Japanese society a hundred years ago. Cats, however, as we know, do not have the ability to speak \u2013 and much less the ability to write \u2013 so that the cat in the novel is nothing more than a resource of the author to expose his vision of Japan of the time. Among the animals that we know can speak \u2013 though not write \u2013 we count parrots or pericos, who in captivity can remarkably imitate the human voice. Actually, the pericos can do more than that, as Alex, an African grey parrot, proved, who was trained by the psychologist Irene Peperberg of Harvard University over 30 years, until the death of the bird by natural causes in 2007. Alex had a vocabulary of 150 words in English, could count up to six and classify objects by color and form. In a recent article published in the journal \u201cScience\u201d by a group of researchers led by Karl Berg of Cornell University in the United States, new evidence was presented about the communicative abilities of parrots. Specifically, this article describes the results of a study carried out in Venezuela with wild green parrots, by which it was discovered that parents give names to each of their young when they are still in the nest in order to identify them. The chicks learn their name by imitation, similar to the way small children do. We would not expect, of course, that the names that the young children receive were something like Juan or Pedro. Far from this, the parents provide the chicks with a pattern of sounds emitted at great speed, which is slightly modified by each of them. This sound will later identify them, even after leaving the nest, which they visit for some time to be fed. Born or learned from parents, researchers exchanged eggs between nests in some cases, finding that the chicks actually acquired their name by imitation of parents and not by their genetic inheritance. According to Berg and collaborators, parrots could help unravel the origin of human speech, a matter in which experts do not yet agree. Among the difficulties they face is pointed out, for example, that while paleontology has fossil remains to interpret the past of life on Earth, there are no corresponding \u201clinguistic fossils\u201d that help explain the origin of the language. The research of parrots and their ability to imitate voices \u2013 the same as the study of the roaring and other canora birds that learn to sing by imitation \u2013 could be of great use in explaining the process by which we acquire our ability to speak. We know that other animals besides parrots are able to establish communication with each other: the great apes using screams and gestures and dolphins emitting sounds, for example. It is also known that cats and dogs understand. However, it is interesting that no mammal shows ease for speech, despite being evolutionaryly close to us; in particular the great apes, from whom we are separated for just about six million years, are far from our abilities in this sense. Parrots, in contrast, from those who separate us 300 million years of evolution, if they have the ability to learn sounds. Even more, we know now that they can not only do it in captivity, but regularly do it in a wild state. In light of new scientific discoveries and given that cats may be falling behind in terms of communication skills, if Soseki Natsume relives, we may perhaps suggest that he rewrite his novel and put it as \u201cI am a perico.\u201d With this he would possibly be more up to the times.",
    "https://upload.wikimedia.org/wikipedia/commons/f/f8/Agave_lechuguilla.jpg": "According to scientific reports of the last few months, our very Mexican maguey, in addition to its role as a raw material for the production of tequilas and mezcales \u2013 a highly appreciated paper by many, by the way \u2013 has potential for the manufacture of car fuel \u2013 as irreverent as this may sound. Indeed, according to experts, the agave has many virtues that could be exploited to mitigate the energy and climate crisis that the world is going through. It is argued, for example, that an increase in the production of agave would not displace agricultural land destined for the production of food, a situation that, according to its critics, does happen with the production of alcohol from maize \u2013 which represents in the United States 10% of the total automobile fuel consumed in the country\u2013. Agave, in fact, is adapted to dry climates, not conducive to agriculture and an increase in the production of this plant could be carried out in lands that would otherwise not be under cultivation. Thus, according to argument, the use of agave as a raw material to manufacture fuels would not enter into Moreover, since agave is not a food of the same importance as maize \u2013 an exception made by those who claim that pulque lacks a degree to be meat \u2013 its use as an energy would be relatively free from the criticisms made by the use of maize for the production of energy rather than devoting it to human consumption.Another key advantage of agave is its low water demand during growth, which does not put pressure on the reserves of this liquid on the planet. High water requirements and soil contamination by fertilizers are arguments that are used against biofuels. In addition to all this, according to an article published on 28 July in the magazine \u201cEnergy and Environmental Science\u201d by scientists at Oxford University in the United Kingdom: \u201calcohol obtained from agave is higher or at least comparable to maize and sugar cane in terms of energy and greenhouse gas balance.\u201d Considering the above, it would seem that a resource for the economic development of arid areas in our country would be the cultivation of aga. The apparent advantages of this plant for this purpose are not, however, sufficient to ensure its development in this direction, which depends crucially on economic factors. In this regard, the economic feasibility for the production of fuel alcohol is analyzed in an article recently published online in GCB Bioenergy, by researchers from the University of Illinois in Urbana-Champaign headed by H\u00e9ctor M. N\u00fa\u00f1ez. These researchers find, unfortunately, that based on the costs associated with the cultivation of agave as is done in Mexico for the manufacture of tequila and mezcal, it would be too expensive to produce fuel alcohol from this plant. This compared to the costs to produce it from maize or sugar cane \u2013 the latter production that is already done for several decades and with great success in Brazil\u2013. To take advantage of all the advantages promised by the agave would then have to make both its cultivation and the alcohol production process more efficient.N\u00fa\u00f1ez and collaborators point out that during the production of tequila only 62% of the agave are used. The pineapple of the agave, besides that other parts of the plant are not used, including the roots, the leaves and the waste of the pineapple. Taking full advantage of the agave plant is then a way to reduce the costs of producing fuel alcohol.We are, thus, in a situation that bears a certain similarity to that found by Brazil in the seventies when it decided to develop the technology for the production of biofuel from sugar cane, something that it managed to do with remarkable success.Brazil on that occasion was pressured by the excessive rise that the oil prices suffered by the embargo of the Arab countries. Mexico, which currently suffers a decrease in its oil production, could find a source of wealth in arid regions that offer little in conventional agriculture. It would be missing to see if it crystallizes the opportunity. If the case is, we would discover that the magueyes serve for something other than making us walk cats.",
    "https://upload.wikimedia.org/wikipedia/commons/4/49/Space_Shuttle_Program_Commemorative_Patch.png": "With the landing of the Atlantis spacecraft on 21 July at 5:57, Florida time, the space shuttle era, which had begun on 12 April 1981 with the launch of the \u201cColumbia\u201d ferry, was brought to an end. During this era, which was extended for thirty years, a total of 135 space missions were carried out with contrasting results. A count, in figures, of the achievements of the space shuttle programme was published a few days ago by the magazine \u201cScientific American\u201d in its electronic edition. It points out, for example, that through this programme more than 1,600 tons of cargo were placed in orbit, at the same time that more than 100 tons of debris were returned to Earth. The ferries also contributed substantially to the construction of the International Space Station, in addition to the orbiting of the space telescope. The space shuttle program, however, is possibly the most controversial of the programs carried out by the North American space agency. This is not only because of the tragic balance it had \u2013 of five vehicles built with orbital flight capacity, the \u201cChallenger\u201d was lost two, \u201c in 1986 and the \u201cColumbia\u201d in 2003, with a total of 14 dead \u2013 but because not all the expected results were achieved. And above all, because of the final cost of the program, which reached the astonishing figure of 200,000 million dollars. If we divide this amount by the total number of missions carried out, we get an even more remarkable figure: a cost of about 1,500 million dollars per mission. These figures \u2013 by their enormous magnitude \u2013 are difficult to appreciate without making some illustrative comparisons. We can note, for example, that the cost per mission of the ferry program is equivalent to the cost of building the Khalifa tower in Dubai \u2013 which with its 828 meters of height is by far the highest building in the world. We also note that this cost is greater than what was invested to build the new Dallas Cowboys stadium in Arlington, Texas. We can also note that, assuming a cost of construction per unit of one million pesos, the investment in the ferry program would have been enough to build more than two million houses, enough to accommodate the population of a city. The removal of space shuttles, on the other hand, has left the United States without the ability to perform manned space flights. For this purpose, NASA is developing the \u201cOrion\u201d capsule that will be able to accommodate four astronauts on missions of up to three weeks. This project, however, will take a few years to crystallize and the current economic crisis that the United States is going through is not promising in this regard. The United States government also trusts in the development of commercial spaceships for manned orbital flights. American private initiative, however, currently only has the capacity to perform suborbital flights of up to a hundred kilometers high. To send astronauts to the International Space Station in the near future, the United States will then have to rely on Russia, which is the only country that can carry them out in a routine manner. The space shuttle project is not quite stopped, according to its critics, compared to previous highly successful projects. Two of these, the \u201cManhattan\u201d project, developed by its critics. In particular, the project \u201cManhattan\u201d invested the equivalent of about $20,000 million today, that is, barely a tenth of what the program that ended last July 21 cost. The concept using the space shuttle\u201d \u2013 that is, a reusable orbital ship, with wings that allow it to return to the surface of the Earth and land like an airplane \u2013 has not survived. Thus, the concept of the ship \u201cOrion\u201d is closer to the \u201cApollo\u201d than to the space shuttles, which proved to be expensive and dangerous. In the end, it seems that NASA is suffering a \u201cspatial flood\u201d after the party and budgetary drunkenness that meant the space shuttle program. The party, for the rest, does not result all the fun that was expected.",
    "https://upload.wikimedia.org/wikipedia/commons/1/1d/Benedicto_XVI%2C_2011.jpg": "What is the first name of Pope Benedict XVI? Surely there will be those who immediately answer correctly. Most commonly, however, there will be those who do not remember it at that time \u2013 and perhaps have it at the tip of the tongue \u2013 or flatly do not know it. Fortunately, for these last two cases we have the Internet at our disposal. In fact, typing on a computer or smartphone the words \u201cBenedict XVI\u201d appears to us a link to Wikipedia where we quickly get the full name of the pope: Joseph Aloisius Ratzinger \u2013 although in the official biography of the Vatican page appears only as Joseph Ratzinger and in other places like Karl Joseph Aloisius Ratzinger\u2013. We also learn that he was born in Marktl an Inn, Bavaria, Germany, on 16 April 1927 and that he was ordained a priest on 29 June 1951, among many other of his biographical data. What applies to the pope's biography equally applies to virtually all public information, so that a few clicked on the computer is all that separates from us. a universe of information \u2013 although we should be careful with the sources consulted, because on the Internet we also find false information. Given the ease of obtaining information through the network, it is not surprising that we are adopting the Internet as a kind of extension of our memory, as reported in an article published last Thursday in the journal \u201cScience\u201d, the psychologist Betsi Sparrow of Columbia University in New York and her collaborators of Harvard and Wisconsin universities. According to Sparrow, the Internet is making us \u201cfloat\u201d to memorize facts that can be consulted through the network. Thus, we do not need to memorize everything concerning Joseph Ratzinger or any other character, if in a minute and effortlessly we can extract from our \u201cmemory extension\u201d what we need to know about the subject. Sparrow and collaborators came to this conclusion through several studies carried out with students of Harvard and Columbia universities. In an experiment, questions were asked to participants who had to be answered with a yes or a no \u2013 for example, \u201cThe eye of an ostrich is larger than The experiment was not intended for students to really answer the questions, but to find out if their intention to do so was to consult the Internet. It was found that this was indeed the case. In a second experiment, the participants were shown a series of questions and allowed to write them on the computer. Half of the group was told that what they had written would be stored in the memory of the machine, while the other group was mentioned that it would be deleted. Immediately, they were asked to write the questions by memory. The result was that those who were told that what they had written would be deleted would remember better the series of questions than those who knew that they would later have the information stored on the computer. This indicates that the latter group was more \u201cluggish\u201d to memorize the information, trusting that it was stored elsewhere.The authors of the article, however, point out that the most remarkable thing about their discoveries is that instead of memorizing data, we directed our effort to memorize procedures to find the place where they are stored. They were again shown a series of questions and then allowed to score them on the computer. The questions were then divided into three groups. A first group was saved in the overall memory of the machine, a second group was stored in a series of folders with given names and a third group was deleted. As in the previous case, the deleted questions were more easily remembered by the participants. These, however, had no problem to remember in which folder had been saved a certain question.The explosion of the Internet began barely two decades ago. In this short time, however, this technology has had a huge social impact. We know, for example, that the dissemination of information and news has had a great influence on recent social movements \u2013 in Egypt, for example, where it contributed to the departure of the President. Sparrow's study and collaborators pointed towards a new direction of impact of the Internet: the collectivization of our individual memory.",
    "https://upload.wikimedia.org/wikipedia/commons/2/24/Through_the_Looking-Glass.jpg": "The almost 7 billion human beings that inhabit planet Earth are divided by almost equal parts into men and women. Taking into account that the mechanism by which we reproduce ourselves is of a sexual nature, the fact that there are equal numbers of men and women is not surprising to us and we rarely ask ourselves why it is. In nature, however, there are organisms that reproduce asexually and this seems to have advantages from the evolutionary point of view. We have, for example, that asexual reproduction could occur twice as quickly as sexual reproduction, since it requires a division of the population between females and males which makes it less efficient. Thus, males, who do not have the ability to reproduce, would be occupying places that otherwise could be occupied by individuals who could do so. Sexual reproduction then has a cost that must be compensated in evolutionary terms in some way.The advantages of sexual reproduction can be understood through the hypothesis of the Red Queen, developed in 1973 by evolutionary biologist Leigh Van Valen. According to this hypothesis, species are continually evolving at last. The name of the hypothesis of the Red Queen was inspired by the homonymous character of Lewis Carroll\u2019s novel \u201cAlicia through the Mirror\u201d published in 1871. In a passage of this novel, Alice is running hurriedly next to the Red Queen, who urges her to run even faster. The curious thing is that Alicia finds that despite running as fast as she can, the objects around her do not seem to change place. \u201cBut how? If it seems that we have been under this tree all the time! Everything is the same as before!\u201d says Alice at the end of the race. So, just like Alicia running and seeing nothing changes, the species have to be continuously evolving simply to stay in the same condition of adaptation to the medium and not become extinct. As the Red Queen says: \u201cWhat is here, as you see, is necessary to run all that one can to stay in the same place. If you want to get to another place you have to run at least twice as fast.\u201d Applied to sexual reproduction, the hypothesis of the Red Queen tells us that to Through the mixing of the genes of the father and the mother, genetic diversity is generated that contributes to the defense of the species against parasitic organisms, which in turn are also evolving permanently. Organisms that reproduce in a sexuous way, in contrast, evolve more slowly and adapt to the environment in a less efficient way. In an article published last Thursday in the journal \u201cScience\u201d by a group of researchers from the University of Indiana, United States, are reported the results of a study that supports the hypothesis of the Red Queen. In it were used worms C. elegans, which can reproduce both sexually and asexually. In normal conditions, 20% of C. elegans reproduce sexually and the rest do so in a sexuous way. During the experiments the worms were exposed to the bacteria S. marcescens that are known to be toxic to them.For the study three groups of worms were prepared. As a result, it was found that the percentage of C. elegans that were sexually reproduced increased from the initial 20% to 80-90%. A second group of worms came into contact with S. marcescens bacteria that remained unchanged. In this case, after an initial increase in the percentage of worms that were sexually reproduced, the latter subsequently decreased and stabilized by 20%. A third group of worms evolved without contact with bacteria, maintaining the percentage of sexual reproduction by 20%. In an additional experiment a group of worms was created that could only reproduce in an asexuated manner. After exposing them to the bacteria S. marcescens, the group of worms became extinct in 20 generations. The results of the study show that the pressure that S. marcescens microbes exert on the worms C. elegans then causes them to change their dominant mode of reproduction from asexual to sexual, and that this is essential for their survival in the presence of the bacteria S. marcescens. Sexual reproduction in general could then be a process of sexual reproduction of sexual sex. marcescens. adaptation by the presence of parasitic organisms, without which the species would end up being extinct.Additionally, the study would break down the notion that males occupy expensive spaces from an evolutionary point of view. Notion that, moreover and surely, would be unpopular among the male population.",
    "https://upload.wikimedia.org/wikipedia/commons/6/6e/TerraformedMarsGlobeRealistic.jpg": "\u201cThe traveling robot \u201cOpportunity\u201d of NASA sent earlier today the first images of the site where it descended, revealing a black and surrealist landscape, unlike anything we have seen before Mars.\u201d This was how the press release of the US space agency of January 25, 2004, in which it announced the successful descent of the robot \u201cOpportunity\u201d to the surface of Mars after a journey of almost seven months from Earth. \u201cOpportunity\u201d, together with its twin the \u201cSpirit\u201d, was sent to Mars by NASA to carry out an exploration of its surface that has obtained unprecedented results. Both the \u201cOpportunity\u201d and the \u201cSpirit\u201d had a curious way to descend to the Martian surface: they went down wrapped in inflated balls, bouncing a good number of times before stopping. It was so \u2013 after jumping 26 times \u2013 that the \u201cOpportunity\u201d ended in the background of a small crater of 20 meters of diameter and three meters of depth, where it found a landscape qualified as a surrealist by NASA. Subsequent images transmitted by the two probes showed an arid, inhospitable, reddish-toned Martian surface, which looks strange at the same time as it recalls some of the driest regions of our planet. This similarity, however, is only apparent, as the conditions on the surface of Mars are completely different from those prevailing on Earth. We have thus the Martian atmosphere is much fainter than the Earth\u2019s atmosphere \u2013 less than 1% in density \u2013 and it is 95% composed of carbon dioxide. Also, as Mars is farther from the Sun than the Earth, its surface is considerably cooler than that of our planet, with a measured temperature around \u201350 degrees Celsius. The tenuous Martian atmosphere, in addition, does not provide enough shelter to moderate the temperature variation between day and night, variation that can reach one hundred degrees Celsius. Mars is then an inhospitable place where we could not survive from not having special equipment to breathe, as well as with equipment to isolate us from the extreme cold that prevails there. previous, and even if we could not walk on the surface of Mars as we do on Earth, the high resolution images that have sent the \u201cSpirit\u201d and \u201cOpportunity\u201d probes and that show the Martian landscape in great detail are fascinating. In them we can see mountains in the distance or we can look into a crater and observe the rock formations that pop up in its walls. Likewise, photographic approaches of Martian rocks allow us to almost palpate them.Marte is our close neighbor, although it is at such a distance that it takes several months to travel there. It is also the most similar planet the Earth \u2013with all its marked differences, including the one that has no liquid water\u2013 and the details of its surface can be observed from Earth. It is not surprising then that Mars has always exercised a great fascination over us and that on more than one occasion it has fantasized about the existence of Martian civilizations and even visitors or invaders of Mars to our planet. In comparison, Venus, our next neighbor, has terrible climatic conditions. A 100-fold denser atmosphere than that of the Earth \u2013 which does not allow us to observe its surface \u2013 and a temperature in the same one greater than 400 degrees Celsius, which certainly makes it attractive as a planet to explore. To continue with the exploration of Mars, NASA has at its door the launch to Mars of the \u201cCuriosity\u201d probe, a new mobile robot the size of a car and considerably greater capabilities than those of the twins \u201cSpirit\u201d and \u201cOpportunity\u201d: \u201cCuriosity\u201d will have greater mobility and will be able to overcome obstacles of 75 centimeters high and advance at a speed of 90 meters per hour. The probe is scheduled to launch between November 25 and December 18 of this year to arrive at Mars in mid-2012. Among other tasks, \u201cCuriosity\u201d will be dedicated to looking for organic molecules that could give an indication of the existence of life on Mars, both in the present and in a past time. We hope that \u201cCuriosity\u201d will arrive the year that comes without novelty to the Martian surface, which, however, we cannot assure if we have To take into account that since 1975, when NASA carried out the first controlled descent on the surface of Mars, more than a third of the missions to this planet have ended in failure.If the new robot failed, much of the $2.5 billion in development costs will have gone to the trash can. At the same time, we will have missed, among many other things, possible new surrealist images of the Martian surface.",
    "https://upload.wikimedia.org/wikipedia/commons/2/28/Rubens_old_man_dsc01655.jpg": "According to Artemio de Valle Arizpe, in his novel \u201cLa G\u00fcera Rodr\u00edguez\u201c, on an occasion when Mar\u00eda Ignacia Rodr\u00edguez de Velazco and Osorio, better known as the G\u00fcera Rodr\u00edguez, met with the son of a character of great alcurnia, fell on him and hit him so bitten in an arm that he almost ripped off his piece. He did this to show them that he still kept his teeth, because father and offspring had given themselves to the task of spreading a rumor according to which the G\u00fcera was so old that he had no teeth. This one, after the bite, would have spewed \u2013 pointed out with the index \u2013 at his father\u2019s raging son: \u201cLook at the child..... Tell the old fret that he now acts as your mother\u2019s husband, who still bites\u201d. Although after this episode it was undoubtedly proved that G\u00fcera Rodr\u00edguez had a very good teething, from Valle Arizpe\u2019s account is not clear if Mar\u00eda Ignacia was The results were corroborated by a second study with 60 people, 31 men and 29 women, who had been the victim of an infused age, or if on the contrary had exceptional quality teeth that had lasted longer than normal.If G\u00fcera Rodr\u00edguez had lived today, she would not have had to resort to such drastic methods to establish that she was not as old \u2013 if this had been the case \u2013 as her abusers said. Indeed, according to an article published on 22 June in the electronic journal PLoS ONE, by a group of researchers at the University of California in Los Angeles, it is possible to determine the age of a person with a precision of five years. As we age, DNA undergoes changes of various kinds. Through a study of the saliva of 34 pairs of identical male twins, aged between 21 and 55 years, researchers at the University of California were able to find changes in certain places of DNA that are closely related to age. Thus, the state of DNA in those places will indicate the age of the person. As we know that death is inevitable, the signs of aging are not generally pleasant to us \u2013 being understandable the irritation of G\u00fcera Rodr\u00edguez about the stories about her age. Thus, as a means of masking aging, the industry of surgeries has flourished to rejuvenate. In this sense, according to statistics from the American Association of Plastic Surgeons, 13 million cosmetic surgery interventions were performed during the year 2010 \u2013 including those minimally invasive. It is also noted that a few days ago it was announced that \u201cFood and Drug Administration\u201d approved a novel treatment to remove wrinkles around the mouth and nose based on the skin cells of the patient. We certainly know that death is inevitable. Throughout the last century, however, with the advent of new medical and surgical treatments and procedures, as well as with an improvement in hygiene conditions, life expectancy has increased substantially in most of the countries of the world, around 80 years old. In the future there is the possibility that life expectancy will increase even more; in relation to this, there are researchers who anticipate \u2013 although this is highly controversial \u2013 that life expectancy will one day reach 800 years.We do not know if this will happen one day.What we do know is that scientific knowledge has dramatically changed our lives.In this regard we can refer to another passage in Valle Arizpe's novel in which G\u00fcera Rodr\u00edguez, on the verge of giving birth, invites six gentlemen who \u201cpassed very calmly on the street\u201d to witness her birth. The reason for this unusual behavior was the need to have witnesses of her daughter's birth, as her pregnancy had been questioned by the relatives of her second husband \u2013 recently deceased \u2013 who claimed that she was faking it to stay with the deceased's inheritance. If she had been born two centuries later, G\u00fcera Rodr\u00edguez could simply have requested a genetic examination to prove her daughter's origin.",
    "https://upload.wikimedia.org/wikipedia/commons/3/37/Binnengasthuis_Area.jpg": "In what may seem to be a truth of Perogrullo, from a recent study by researchers at Michigan State University, led by William Schmidt \u2013 and published on June 10 in the journal \u201cScience\u201d \u2013 we could conclude that the best mathematics teachers in high school are generally those who know the most about the subject \u2013 although there will certainly be exceptions to it. This is the result of this study comparing the results of a 2010 test to study and evaluate the process of training mathematics teachers at the pre-university level, with the results of a 2003 examination to assess the performance of secondary school students. Both tests were conducted in 16 countries by the International Association for the Evaluation of Educational Achievements \u2013 IEA, by its acronym in English. The results obtained show that better preparation in mathematics results, years later, in better qualified teachers in this field. Since the reference article focuses on education in the United States, the authors emphasized a comparison of the process of mathematics teachers in that country, With the corresponding processes in Taiwan and Russia, the most successful countries in this regard. It is noted that American high school students are not particularly successful in international mathematics tests \u2013 the OECD PISA test, for example \u2013 and occupy half-table positions in lists led by some Asian countries \u2013 China-Hong Kong and Korea, among others \u2013 followed by some European countries. In line with the above, the article in question points out that the United States does not produce enough competitive mathematics teachers internationally. In particular, it states that in the preparation of mathematics teachers in the United States a greater emphasis is given to pedagogical aspects \u2013 both specific to mathematics and to pedagogical knowledge in general \u2013 to the detriment of mathematical knowledge; this compared with the less emphasis given to pedagogy in countries with the most successful students, where mathematical knowledge is fostered. Thus, poorly prepared teachers in the United States, who in turn train students who result in deficient mathematical knowledge. The authors of the reference article point out that in order to compete in the level of mathematical knowledge with countries such as Singapore and Taiwan, it would be necessary for future mathematics teachers in the United States to be chosen from among 25% of high school graduates with better qualifications. They consider, however, that this will not be possible if the salaries of teachers are not increased in that country.The only Latin American country included in the study was Chile, which occupied one of the last places together with Botswana and the Philippines. Mexico did not participate, but had it possibly had a similar performance to that of Chile. Indeed, as is known, our country occupied the last place in the PISA mathematics test 2003 among OECD member countries, and in the article by Schmidt and collaborators it is shown that this last test agrees to a large extent with the IEA mathematics test. Pedagogic knowledge is undoubtedly one of the most important tools available to a pre-university level teacher to transmit his knowledge. that a student expresses his dissatisfaction with any of his teachers. Pedagogy, however, makes sense only if the teacher dominates the knowledge that he is supposed to teach, and as Schmidt and collaborators point out, such knowledge is not always given the right emphasis. As we begin, we end this article with a statement that could equally sound true of Perogrullo: \u201cto teach something you must first learn it.\u201d",
    "https://upload.wikimedia.org/wikipedia/commons/b/b9/%E0%B4%95%E0%B5%87%E0%B4%B1%E0%B5%8D.jpg": "As Dr. Mario Molina, Nobel Prize laureate in Chemistry 1995, explained during his presentation last Thursday on receiving the Honoris Causa doctorate from the Autonomous University of San Luis Potosi, the emission of greenhouse gases due to the indiscriminate use of fossil fuels has increased its concentration in the Earth's atmosphere to unprecedented levels in hundreds of thousands of years. This has led to a concurrent increase in the temperature of the Earth's surface, which, among other things, has reduced the volume of ice in the Arctic and Antarctic regions and increased the occurrence of extreme weather events around the world. Thus, although it is not possible to secure it with a hundred percent certainty, the world's industrial development has probably also had a negative global impact that is changing the face of the planet.It is not the climate, however, the only victim of accelerated development that the world has experienced in the last two hundred years since the beginning of the industrial revolution; another victim in this regard has been the freshwater reserves of the planet, which in many regions are declining at a higher rate with which they are being replaced. An example of this occurs in the region. At the border with Pakistan \u2013 with an area of half a million square kilometres \u2013 the level of aquifers has declined between 2002 and 2008 at a rate of 30 centimetres per year. This follows from a study carried out by researchers from NASA and the University of California at Irvine from satellite data. The technique used for this study is based on the measurement of changes in the Earth\u2019s gravity force by the displacement of large volumes of water. Data provided by two twin satellites owned by NASA were used for the study, which were placed in orbit in March 2002 with the object, precisely, of studying the Earth\u2019s gravitational force. Satellites orbit at a height of 500 kilometres above the Earth\u2019s surface, maintaining a separation between them of about 220 kilometres. However, this separation undergoes minute changes when an aquifer changes its volume of water and modifies the Earth\u2019s gravity. Thus, the decrease in the volume of the aquifer over a certain period of time can be known through the change in the separation of the two satellites, a change that can be measured with a large amount of water. In addition, according to Mathew Rodell, from the NASA Goddard Space Flight Center, it is possible to detect changes in surface water as well as deep water, whether or not there is daylight or clarity in the sky, because \u201cgravity crosses all materials\u201d. Measuring the change in the volume of water from an underground reservoir remotely and from space seems magical. There is, however, today the knowledge and technologies needed to carry it out. Among the latter are not only those that allow to place two satellites in orbit and accurately measure the changes in distance between them, but also to the computing technology without which it would not be possible to analyze the data delivered by satellites in order to unravel them and obtain the information of interest. Moreover, it is not to point out the great convenience of a technique to measure from space \u2013 by surprising and non-conventional methods \u2013 the state of the world\u2019s aquifers, although this technique is necessarily complementary to other methods of measurement at the Earth\u2019s surface level. In the north-west of India, they indicate that in the San Joaquin Valley in California, the U.S., the level of groundwater is also declining gradually, which means that the speed at which the water is being extracted is greater than that at which it is replaced by natural means. These studies, like others carried out with different techniques, indicate that in many parts of the world aquifers are being depleted by the overexploitation to which they are subject and that in the coming decades the world could well suffer a crisis due to the lack of vital liquid.When this happens, we will have one further indication that, indeed, we have been abusing the planet for a good number of years.",
    "https://upload.wikimedia.org/wikipedia/commons/5/57/Honor%C3%A9_Daumier_003.jpg": "From time to time we learn of celebrities \u2013 film artists or singers, for example \u2013 who increase their fame for having been imprisoned for driving drunkards or for having committed crimes, sometimes serious. There is even the case of famous people who have no more ability than to provoke riots and to live from the rumors and gossip that they generate. For some celebrities, the generation of scandals has certainly become a lucrative business.This phenomenon \u2013which is not new, otherwise \u2013 illustrates the fascination we feel with rumors and gossip, the latter activity that, we would agree, is practiced in a very widespread and enthusiastic way. Such a common hobby, there is no doubt, should have a scientific explanation in terms of our social evolution. In this regard, a recent article published in the issue of 19 May last in the magazine \u201cScience\u201d by a group of researchers from several American universities, headed by Eric Anderson of Northeastern University, Boston, Massachusetts. That article describes experiments carried out in order to find out how the bad fame of an individual influences the visibility of an individual The tests involved a total of 66 people who were shown images of neutral faces \u2013 without expression \u2013 associating each face shown \u2013 in the manner of a rumor or gossip \u2013 with a specific social behavior. This behavior could be negative \u2013 for example, \u201che threw a chair at a classmate\u201d \u2013 or positive \u2013 \u201che helped an elderly lady with her mailbags.\u201d The behavior associated with the images could also be socially neutral. Participants were equally shown faceless faces that were not associated with some type of behavior. Experiments were carried out using a technique in which the participant was presented simultaneously with two different images. Such images are placed so that each eye sees only one of them \u2013 the left eye the left image and the right eye the right image. By a process that is not possible to consciously control \u2013 called \u201cbinocular juvality,\u201d the brain sets its attention on only one of the images by suppressing the other. This makes it alternate one and another eye. The time the brain fixes its attention on one of the images is one of the images is one of the brain. As a result, it was found that participants spent more time seeing images with a negative connotation compared to those associated with neutral or even positive behavior. Similarly, the brain showed preferences for \u201cbehavior\u201d over those about whom there was no information about their moral qualities. Thus, bad behavior helped to have greater notoriety. According to Anderson and collaborators, gossip \u2013 positive or negative \u2013 serves the purpose of providing information about a person without having to interact directly with him, which allows us to live in large groups of people. This information is important when assessing the desirability of establishing a certain friendship; or, if it were the case, of turning on red lights and avoiding the person in question. In this context, it might perhaps be expected that positive information about a person would be as important as a negative one. In fact, however, negative personal gossip is more frequent than positive, which would indicate that in our social evolution it has been more important to take care of our backs than to make friends. Reference article \u201cIt is easy to imagine that a preferred selection to perceive bad people can protect us from liars and cheaters, allowing us to have more time under observation and thus obtain more information about their behavior.\u201d Chismorreo is an activity that, despite its wide dissemination, does not enjoy social prestige \u2013 although some professionals of it represent a good business. According to experts, however, gossip plays an important role by providing social cohesion. Recognizing this latter may help us to reduce positions of conscience if at some point we come to surprise \u201ccohesioning\u201d our society.",
    "https://upload.wikimedia.org/wikipedia/commons/4/44/Placa_ojotsk_amuria_es.JPG": "The earthquake of March 11 that devastated the peaceful coast of Tohoku, in the north of the Japanese island of Honshu, and that has been the most violent experienced by Japan since records have been kept, could be followed by another earthquake of equivalent magnitude but with the aggravating fact that its epicenter would be closer to the Tokyo region \u2013 which concentrates a quarter of the Japanese population. This possibility is considered in an article published this week in the magazine \u201cScience\u201d by a group of researchers from the United States and France, headed by Mark Simons from the California Institute of Technology. Large earthquakes occur by geological faults along the border between two tectonic plates. As is known, the crust of the Earth is formed by plates that are in permanent movement, colliding with each other, moving away and/or \u201cfrosting\u201d one against the other. Thus, great efforts are made at the borders between two plates, gradually increasing a large amount of energy, which, when released suddenly, causes an earthquake whose magnitude depends on the other. Thus, the longer a geological failure remains stable without causing a tremor, the greater the probability that at the time of its rupture a major earthquake will occur.Japan is located at the confluence of four tectonic plates and is therefore one of the countries with the most seismic activity in the world.The earthquake of 11 March last had its epicenter near the border between the Pacific tectonic plate and the Ojotsk plate in the Pacific Ocean region opposite the coast of Tohoku. These two plates move against each other, with the result that the Pacific plate sinks at the same time as it slides under the Ojotsk plate. We note that on this last plate is located the northern part of the island of Honshu. The northeast coast of the island of Honshu has historically had a great seismic activity, with earthquakes of magnitudes 7 and 8, due to the failure of the Pacific and Ojotsk plates. The experts, however, were taken by surprise by the magnitude of the earthquake of March 11, which has been the most intense since records were kept and which meant tectonic plate movements up to 60 meters in some places. It is, in fact, necessary to go back in the historical records up to the year 869 of our era to meet, in the same region, with an earthquake of comparable magnitude \u2013 with tsunami included \u2013 to that of the earthquake of March to Tohoku. This has led to the postulation of Simons and collaborators that there are points along the fault in front of the Japanese peaceful coast that are able to accumulate enormous energies over hundreds or thousands of years before experiencing a rupture, something that before the earthquake of March 11, was not considered as a possibility. What is alarming, according to Simons, however, is the possibility that something like this may be happening in the southern segment of the failure that occurred in Tohoku earthquake, which could produce a comparable earthquake of magnitude. It recognizes, however, that the knowledge of the geological faults on which the Japanese archipelago is based is not solid enough \u2013 especially after Tohoku\u2019s unexpected earthquake and that it puzzled the experts \u2013 to offer a reliable prediction about it. Whatever it may be, taking a look at the distribution of tectonic plates on the earth\u2019s surface \u2013 which can be easily consulted on the Internet \u2013 one cannot help but conclude that Japan\u2019s geographical location, located in the vicinity of four tectonic borders, could hardly have been worse. This has forced Japan to make efforts to mitigate the impact of the frequent earthquakes it suffers. And if we add to an unfortunate geographical location that Japan, apart from being a mountainous country with a high population density, is not in any way a country rich in natural resources \u2013 including energy \u2013 one cannot fail to admire its success as a country, despite the problems now facing Japan due to the earthquake of March. It is not a country rich in natural resources, except, of course, in Japanese \u2013 if we classify them as natural resources \u2013 of which there are 130 million. That may have made a difference.",
    "https://upload.wikimedia.org/wikipedia/commons/7/70/Hkstarferry.JPG": "It seems that the space shuttle \u201cEndeavour\u201d wants to delay as much as possible the moment of its retirement: it was scheduled to take off on its last flight into space on 29 April, but technical failures have forced the suspension of that take-off on three occasions. At the present time its launch is scheduled for tomorrow, 16 May. The flight of the \u201cEndeavour\u201d will be the penultimate flight of NASA\u2019s space shuttle program, which will close with the flight of the ferry \u201cAtlantis\u201d on 28 June. A further delay in the launch of the \u201cEndeavour\u201d, however, could also lead to delaying the last trip of the \u201cAtlantis\u201d. At the end of the program, NASA will have carried out 135 space trips from the inaugural flight of the \u201cColumbia\u201d in April 1981. Among many other achievements, the space shuttle programme launched the Hubble Space Telescope in 1990 which has allowed unprecedented astronomical observations to be made and will be in service until 2014. The ferry programme has also contributed to the construction of the international space station. NASA built a total of unprecedented astronomical observations. five shuttles with orbital flight capabilities, two of which had a tragic end with the death of all their occupants: the \u201cChallenger\u201d, shortly after taking off on 28 January 1986, and the \u201cColumbia\u201d, upon their return to the atmosphere on 1 February 2003. With two catastrophes on 133 flights \u2013 not counting the two missions that are still pending \u2013 the ferries have in no way been shown to be the safest means of travel. Despite their misfortunes, the space shuttle program has been one of NASA\u2019s most glamorous colors. At the time of its launch, the ferries may seem grotesque; however, once they are released from the huge fuel tank and the two driving rockets, they have always been shining \u2013 with their delta wings, their white and black colors and their soft landing in the form of an airplane \u2013 considerably more attractive than other space vehicles \u2013 the Apollo capsules that brought Americans to the Moon, for example. In addition, the space shuttles were \u2013 and still are \u2013 the only vehicles that can be reused R in several orbital flights \u2013 in fact, only the orbital vehicle and the two booster rockets are reused, as the fuel tank is discarded after each launch. The record in this regard is the \u201cDiscovery\u201d ferry \u2013 now out of service \u2013 with 39 orbital flights made. Glamour and distinction, however, have their cost and NASA ferries are no exception in this regard. Indeed, a study carried out by Roger Pielke and Radford Byerly of the University of Colorado \u2013 reported in the issue of 7 April last of the magazine \u201cNature\u201d \u2013 shows that the total cost of NASA\u2019s ferry programme is around $200,000 million \u2013 in 2010 dollars. Thus, if this amount is divided by the total of flights made, it is achieved that each ferry trip to space had an average cost of about $1.5 billion. The space shuttle programme also intended to develop the technology necessary for frequent routine flights to space at a low cost. the results were clearly below expectations, since only an average of 4.5 flights were made per year, over the 30 years of operation of the program, at a high cost per flight. There were also periods of inactivity of more than two years after the accidents of the \u201cChallenger\u201d and the \u201cColumbia\u201d. With the completion of the ferry program, NASA loses the ability to carry out manned orbital flights. At the same time, however, the US private sector is entering the space business. In December 2010, the company \u201cSpaceX\u201d, based in California, became the first private entity to place a capsule in orbit and subsequently recover it. Likewise, other private companies are looking to develop the \u201cspace tourism\u201d, offering for sale suborbital flights. With costs between $100,000 and $200,000 per trip, however, this tourism will not be precisely mass. If everything goes out as planned, tomorrow at 7:56 a.m. it will take off the \u201cEndeavour\u201d for its last orbital flight and once it returns to the Earth will join \u201cDiscovery\u201d as a retiree, waiting for a definitive home in an American museum. One last shuttle will remain active and pending one last flight to be made; this will close the space shuttle era. In this regard, Pielke and Byerly write: \u201cThe space shuttle is the most expensive American program ever realized. Now that it comes to an end, we must celebrate its successes, and draw lessons for future human companies in space.\u201d",
    "https://upload.wikimedia.org/wikipedia/commons/6/63/Camponotus_sp._ant.jpg": "The ants of the species \u201cSolenopsis invicta\u201d, who are native to South America but who have infested the south of the United States since the 1930s, have a curious \u2013 and at the same time effective \u2013 way of surviving the floods: they group and form with their bodies a floating raft that sails until they find land and can land safely. Ants are then at the same time the raft and passengers. The raft-hormiga is formed of two layers, a lower layer that remains submerged in water and that is formed by ants that bond firmly with each other by means of their legs and jaws \u2013 and are therefore immobile \u2013 and an upper layer or layers that protrudes from the water formed by ants free to move. If it is possible that the ants of the bottom would have preferred to travel on the upper floor of the raft, they choose to sacrifice for the good of the whole group. The sacrifice, however, is only during the crossing, because at the end of the same, and in the assumption that the raft reaches a safe place. , all the ants \u2013 the \u201ctop\u201d and the \u201cbottom\u201d ones \u2013 have a happy ending. A first question arises from all this: how is it that the ants-hormigas manage to float? As we know, ordinary rafts are built with light materials \u2013 such as wood \u2013 that float on their own. Ants, however, are denser than water and in principle could not float. To find an answer to this and other questions, a group of scientists from the Georgia Institute of Technology in the United States carried out a detailed study of the behavior of reference ants when placed in water. The results of the study were published electronically on April 25th in the Memories of the National Academy of Sciences of the United States. It was found that the ants-hormiga use as floats air bags trapped among the bodies of their members \u2013 which is equivalent to the air floaters that children use when they are learning to swim. This result also responds to a second question regarding how ants in the submerged layer can. To survive for days or weeks in that position: they do so because they take the air they need to breathe from such floaters. They are then largely dry despite being below the floating line. Thus, in fact, the \u201cbelow\u201d ants sacrifice themselves but to a certain extent. As the authors of the reference article say, \u201cWithout taking into account their tiny size and their deficiencies, the ants rafts have attractive characteristics with respect to the devices to float made by Man. Simultaneously they provide cohesion and buoyancy to their passengers, in addition to being repellent to the water. They can be built quickly \u2013 in about a minute and a half \u2013 without any kind of equipment. They can transport billions of passengers with low zero. But perhaps the most shocking thing is that they are self-assembled.\u201d Furthermore, when a top layer ants are removed, their place is automatically occupied by an ants of the lower layer. The ants then have the ability to \u201cself heal\u201d after suffering a \u201cwound.\u201d The self-healing and self-assemble capacities are, according to To the authors of the article that we are dealing with, \u201ccharacteristics of living beings\u201d. Thus, the ants of the species \u201cSolenopsis invicta\u201d when threatened by water \u2013 and regardless of the chaotic nature of their movements \u2013 organize and act as a \u201csuperorganism\u201d to survive. The organized behavior of the \u201cSolenopsis invicta\u201d ants is in apparent contrast to our behavior as humans, which is sometimes far from cooperative. Let us think, for example, of wars that have been a constant in the history of civilization, in the nuclear power generating companies that put profits before the safety of the population, or in the Chamber of Deputies characterized by constant disagreements between their members. The ants, however, are \u201cmachines\u201d considerably simpler than a human and have far fewer options to act in a given circumstance. We would then hope that they will be more easily agreed, as indeed happens. Not all, however, is pink with the ants \u201cSolenopsis invictas\u201d. Although some of the ants \u201cbelow\u201d on the rafts were always there, others originally reside in the upper part and would have descended, not on their own, but \u201cobligated\u201d by their congeners. The article in question includes fascinating videos of the formation process and the strength of the rafts-hormiga that can be consulted at the following e-mail address: http://www.pnas.org/content/early/2011/04/20/1016658108/suppl/DCSuppl.",
    "https://upload.wikimedia.org/wikipedia/commons/a/a3/Bp_Logo_in_Bird_Nest_-_panoramio.jpg": "On April 20, one year after the explosion of the \u201cDeepwater Horizon\u201d oil rig in the Macondo well off the Louisiana coast, 11 were killed and 5 million barrels of oil spilled in the Gulf of Mexico, making it an even bigger accident than the infamous Ixtoc 1 well, which, between June 1979 and March 1980, spilled three million barrels of oil in the Gulf of Campeche before it could be sealed. As oil wells were depleted on land, deposits began to be explored and exploited in the sea, first in shallow waters \u2013 the Ixtoc 1 well was at a depth of 50 metres \u2013 and then in deep waters, as was the case of the Macondo well which was at a depth of 1,500 metres. At such depths, the conditions for drilling an oil well are severe, among other things due to the great pressures that occur in the seabed \u2013 1,500 metres deep the pressure is about 150 times greater than the pressure at sea level\u2013 and by reason of This is a conclusion reached by the committee of seven people appointed by President Obama to determine the causes of the Macondo accident. According to the report of that committee \u2013 published in January of this year \u2013 \u201cThe immediate causes of the sudden increase in the pressure of the well can be attributed to identifiable errors made by BP, Halliburton and Transocean, which reveal such failures in the management of risks that call into question the safety culture of the entire industry.\u201d The report also notes the lack of coordination between the companies involved in the drilling of the Macondo well, which did not share critical information about the conditions of the previous well to the previous one. The committee concludes that \u201cThe explosive loss of the Macondo well could have been avoided.\u201d The Science magazine, commenting on its January 6, 2011 issue, the report of the referral committee writes: \u201cDuring the drilling of the well, BP focused on maximizing profits and not necessarily on safety.\u201d On the other hand, in an incident also related to the energy industry, since March 11 \u2013 as a result of the tsunami that hit the northeastern coast of Japan \u2013 there is an emergency situation with the four nuclear reactors of the Fukushima I nuclear plant that have let large amounts of radiation escape. This has forced the Japanese government to order the mandatory evacuation of 140,000 people from an area of 20 kilometers around the plant and to gradually raise the severity index of the accident \u2013the Spanish newspaper El Pa\u00eds has described Fukushima as \u201cChern\u00f3byl in slow camera\u201d\u2013 from 4 to the maximum of 7.Fukushima nuclear reactors were damaged by the tsunami that flooded the plant and inutilized its cooling systems that are critical to prevent radiation leaks. The Japanese nuclear safety agency did not consider, however, that they posed a greater danger to the nuclear plant. In statements to the Washington Post, Japanese seismologist Yukinobu Okamura, who served as a member of a panel of experts formed in 2009 by the Japanese nuclear agency to assess the safety of Japanese reactors, pointed out \u2013 supported by historical data \u2013 the possibility that a large-scale tsunami would hit the Fukushima plant. His observation was not, however, taken into consideration by the agency.Macondo and Fukushima have been in the past year two major accidents associated with the power generation industry that the experts said could have been avoided if a correct assessment of the risks involved had been made. Both accidents have caused environmental disasters on an increasingly troubled planet. Coinciding with the anniversary of the Macondo disaster, last April 22, the \u201cInternational Day of Mother Earth\u201d, decreed by the United Nations Environment Programme, was held. In the course of a year, however, Mother Earth is on this occasion a little more battered than usual and has little to celebrate.Perhaps, on April 22, we should have wished her \u201ca few days of these.\u201d",
    "https://upload.wikimedia.org/wikipedia/commons/8/8c/Walton%27s_Five_and_Dime_store%2C_Bentonville%2C_Arkansas.jpg": "Half a century ago, to be more precise on May 16, 1960, lasers were born in the Hughes laboratories in Mailbu, California, and with this one of the inventions that have changed our daily lives the most. This statement, which might seem exaggerated, is, however, precise. One way to appreciate the importance of lasers today is to imagine that they disappear suddenly from the face of the Earth. In this way they would make us feel their absence and become paradoxically visible \u2013 similar to the way Californian Latinos did in the Hollywood comedy \u201cA Day Without Mexicans\u201d. Without lasers, for example, we could not listen to music in our compact disk apparatus, which uses precisely a laser to reproduce the sounds encoded on the disc. If that were our purpose, we would probably have to dust our old recorder \u2013 if we still conserve it \u2013 and our old audio cassettes \u2013 those that have survived the abuse they were often subjected to during reproduction. -ray: we would have to resort to the obsolete VHS video cassettes.In supermarkets we would probably have to make long queues in the cash register, because the bar reader \u2013 who with a quick look at the product label determines its price and classification \u2013 depends on the lasers to function and if they disappear the cashier would have to enter manually the price and description of the products we want to buy. And yet, while it is much more convenient to listen to music or watch a film in a disk format than in an audio or video cassette format \u2013 and it is always, of course, preferable to leave the supermarket quickly than to make long queues \u2013 where the lasers have had their greatest impact is in the telecommunications field, particularly on the Internet. In fact, without the lasers this network would not exist \u2013 at least not with the extension it has now \u2013 and as a result we could not consult the climate page with data for today, nor could we \u201cshit\u201d \u2013which, like so many things, has positive and negative aspects\u2013 sometimes thousands of kilometers away. Dr. Malacara, founder and first director of the Optics Research Center, was one of the pioneers of Optics in our country. Dr. Malacara, founder and first director of the Optics Research Center, was one of the founder and first director of the Optics Research Center in Optics. Dr. Daniel Malacara, who was one of the pioneers of Optics in our country, was one of the founders and first director of the Optics Research Center. Dr. Malacara, the founder and first director of the Optics Research Center, was also one of the first to make bank transfers instantaneously, and would not be able to access a massive encyclopedia \u2013 the \u201cwikipedia\u201d \u2013 which is in continuous process of evolution and self-correction. In fact, a laser-free day would largely equal a day without the Internet. There would also be no medical applications of lasers such as myopia surgery or tumor treatment. Guanajuato told us about the successful production of lasers in our country, a project he carried out almost half a century ago in the city of Le\u00f3n, very shortly after the invention of this device in California. Although he did not pursue commercial purposes \u2013 lasers were manufactured as tools for his research laboratory, since the cost of a laser in the 1960s towards prohibitive commercial acquisition \u2013 several lasers were sold to Mexican institutions, notably the Mexican Petroleum Institute. As he explained at his conference, the manufacture of lasers in Mexico at such an early time could have given rise to a Mexican industry of this type of devices. It was not given, since Dr. Malacara was invited by Dr. Guillermo Haro to join the then-created National Institute of Astrophysics, Optics and Electronics in Tonantzintla, Puebla, an offer that he accepted leaving his laboratory in Mexico City. One thing for another, but we lost the possibility of having in Mexico an industry of lasers, devices that, without exaggeration, are among the technological developments that In fact, lasers are so pervasive today, that if they suddenly disappeared from the face of the Earth \u2013 just like Mexicans in California \u2013 they would certainly be perfectly visible.",
    "https://upload.wikimedia.org/wikipedia/commons/3/3f/Composite_image_of_male_chimpanzee_%28left%29_and_male_bonobo_%28right%29.jpg": "According to news in the British press in recent days, chimpanzee meat is sold illegally in restaurants and street stalls in Britain. It is transported to the country from the African equatorial forests through a \u201cFrench connection\u201d via Charles de Gaulle airport in Paris. According to Marcus Rowcliffe, a researcher at the London Zoological Society \u2013 quoted by the British daily \u201cDaily Mail\u201d \u2013 five tons of \u201csalvaje\u201d meat \u2013\u201cbushmeat\u201d \u2013 arrive weekly from Africa to Paris airport for distribution in Europe. Of the total, 1% corresponds to meat of great apes: gorillas and chimpanzees. Chimpanzee meat, according to Rowcliffe, is not only used for consumption in restaurants and food stalls, but is also given medicinal uses and as a symbol of social status. The British reaction to the above information, as expressed in comments sent to the daily \u201cDaily Mail\u201d, goes from expressions of displeasure due to a qualified \u201ccanibal\u201d practice, as \u201c Chimpanzees are 99% human,\u201d even racist comments such as that of a reader who wrote that \u201cif Africans or British-Africans wanted to eat wild meat they would return to Africa where it is abundant,\u201d stating at the same time that \u201cBritish people do not eat that kind of meat.\u201d Another reader who lived in Britain is pleased to have left \u201cthat country forgotten by God\u201d and changed his residence to New Zealand, a country where \u201cthe environment and endangered species are cared for.\u201d One reader is not surprised and claims that the sale of wild meat \u201chas been given for a long time,\u201d meat that \u201cby the way stinks and leaves a horrifying bad breath.\u201d Neither did anyone who took it a joke, as the reader who wrote that \u201cnow understands how it can climb trees to lower the cat\u201d, what he thought \u201cwas due to vitamins.\u201d This whole matter could indeed be taken a joke if it were not because it involves an animal species that is in danger of extinction. In relation to this, the International Union for Conservation of Nature (IUCN) has included chimpanze in The IUCN estimates that there is currently a total population of between 170,000 and 300,000, which, however, is shrinking at an accelerated rate. IUCN estimates that over a period of three generations \u201360 years \u2013 the total population of chimpanzees has been reduced by more than 50%. Among the causes of the decline of the chimpanzee population cited by IUCN stands out the increase in tree felling and mining activities in the Central and West African region that has devastated its natural habitat. These activities have also resulted in the construction of roads that have opened up to hunting for chimpanzee regions that were previously inaccessible and in which they remained protected. Another important cause of the decline in the number of chimpanzees is diseases such as Ebola that have caused a population reduction of up to 90% in some regions.The hunting of chimpanzees can also be seen from another angle. It is known that among primates, chimpanzee is our closest relative, from which we separate evolutionary. In relatively recent times \u2013 about five million years ago \u2013 we share in this way 99% of DNA. Likewise, we also share other things, and just as we chimpanzees live in a group, use tools, are aware of themselves and are able to handle symbols \u2013 they hunt, in addition, other primates that occupy evolutionaryly a lower level. It has even been argued that chimpanzees societies could somehow reflect an early stage in human social development, which would make our closeness evident as species. Given the points of coincidence between chimpanzees and humans \u2013 yet the enormous differences in intellectual sophistication that exist between both species \u2013 it is understandable that some call hunting chimpanzees as a \u201cmurder\u201d and the act of consuming their flesh as a cannibalism. The extinction problems faced by chimpanzees by indiscriminate hunting and destruction of their habitat \u2013 composed by the other great apes, gorillas and orangutans, more serious even in the case of the latter\u2013 We would thus deprive ourselves of the opportunity to study live a species close to our own that could help us understand our own evolution. Thus, the best thing we can do as a species is to avoid consuming chimpanzee meat. With this we will do a great favor to future generations. We would also avoid a possible bad breath and the feeling that we commit an act of cannibalism, even in the face of the possibility that it would diminish our agility to climb trees.",
    "https://upload.wikimedia.org/wikipedia/commons/e/eb/Pulitzer_Prizes_%28medal%29.png": "American writer Pearl S. Buck, Nobel Laureate in Literature 1938, published in 1931 the novel \u201cThe Good Land\u201d with which she won the Pulitzer Prize a year later. In this novel Buck tells the story of Wang Lung, a Chinese peasant who, based on work, determination and skill, managed to overcome the condition of poverty in which she was plunged into her youth until reaching considerable economic well-being in her mature years. At a certain point in her life, however, a prolonged drought caused a famine that put him in a desperate situation and that even made his wife strangle her newborn daughter for having no way to feed her. To escape the catastrophe, Wang Lung decided to travel by train along with her family to a city southwards \u2013 any similarity with situations that occur in our country with Central American migration is not mere coincidence\u2013, where she survived working as a coachman pulling a \u201crickshaw\u201d and her family asking for charity. Famine \u2013 fiction \u2013 reported in \u201cThe Good Land\u201d has, of course, a real livelihood \u2013Pearl S. Buck lived a good part of her life in China previous life in China. The famine that occurred in Ireland in the mid-19th century, for example, caused the death or exodus of two million Irish people to the United States and other parts of the world.In Africa, famines are endemic and last year the Saheli region, south of the Sahara desert, suffered from a severe shortage of food that had to be alleviated with international help.In recent decades, there has been concern on the part of many specialists that the world population has already exceeded, or does so in the near future, the planet\u2019s ability to feed and provide it with a minimum of welfare conditions. In this case, famines would no longer be local phenomena that could be alleviated by migration \u2013 we would no longer have to go \u2013 or other aid measures by rich countries, but would constitute basically unresolved problems. Earth\u2019s capacity to host the human race was the subject of a symposium organized by the American Association for the Advancement of Science during its period of life. The symposium brought together specialists from universities and organizations in the United States and Great Britain who addressed issues such as the estimate of the billions of people our planet can maintain and whether, as humans, we should seek to flourish or simply survive. Our land reserves were also considered for food production and the search for ways to stabilize the world\u2019s population. It is estimated that the world\u2019s population, which currently stands at around 7 billion, will reach a peak of 9 billion by 2050 and will then begin to decline \u2013 a large proportion of the population increase will live in developing countries that are growing substantially faster than developed countries. In 40 years the planet would then have to feed 2,000 million more people. In fact, if we are to be fair, it would be more than 2,000 million, as the planet\u2019s resources are poorly distributed \u2013 in some cases, very poorly distributed \u2013 between developed and developing countries, and it is a fact that a significant proportion of the world\u2019s inhabitants are fed poorly. Thus, Jonathan Foley of the University of Minnesota in the The United States, one of the participants in the symposium, believes that world food production would have to be doubled by 40 years.Foley doubts, however, that this is possible and notes that agriculture now uses 40% of the area of arable land and 70% of the total water consumed.It also generates 30% of the greenhouse gases emitted into the atmosphere.It seems then that unless agricultural technologies are developed to make more efficient use of irrigation water and arable land, as well as to reduce greenhouse gas emissions into the atmosphere, future generations will have to tighten their belts.",
    "https://upload.wikimedia.org/wikipedia/commons/e/e6/Casaamazonica.jpg": "The Amazon River, which is born in the Peruvian Andes and flows into the Atlantic Ocean after 6,800 kilometers, is the largest \u2013 and also the longest \u2013 river in the world. It pours into the Atlantic Ocean each year the equivalent of 20% of the world\u2019s fresh water reserves. The Amazon basin covers an area of 7 million square kilometers of which 80% \u2013 almost three times the surface of our country \u2013 correspond to the Amazon rainforest. Given its enormous proportions, what happens in the Amazon rainforest can have a global impact. In this regard, in the years 2005 and 2010 the Amazon basin suffered severe droughts that could occur only \u201cevery hundred years\u201d. These highly atypical droughts caused a considerable drop in the levels of some tributaries of the Amazon River and in relation to this, we find ourselves in the media written with numerous photographs of boats and fish killed lying on dry beds of rivers. This has had serious consequences for the coastal populations that use rivers as communication routes. Iquitos, for example \u2013 city in the Peruvian Amazon jungle. a great development a century ago thanks to rubber fever and which currently has almost half a million inhabitants\u2013, it only communicates with the outside by river or air and suffered greatly the droughts of 2005 and 2010. Similarly, last year\u2019s drought reduced the level of the R\u00edo Negro \u2013 a tributary of the Amazonas River, which converges with it in the Brazilian city of Manaus\u2013 to its lowest level since it began to be measured a hundred years ago. This made it unnavigable, isolating the populations settled on its shores. On a global scale, the consequences that the droughts of 2005 and 2010 may have on our planet are still to be seen. However, it should be noted that the Amazon rainforest \u2013 called the \u201clung of the world\u201d \u2013 has a relevant role as regulator of carbon dioxide in the atmosphere \u2013 causing climate change \u2013 and that such droughts can compromise its ability to continue acting as such. We know that through the process of photosynthesis plants absorb carbon dioxide from the atmosphere and convert it \u2013 together with other nutrients. \u2013 in organic matter. The forest is then a sink of carbon dioxide. Drought, however, causes the death of a certain percentage of the forest trees, reducing their capacity as a \u201clung\u201d of the planet. Moreover, by breaking down, dead trees release carbon dioxide, contributing positively to the increase in the concentration of this gas in the atmosphere. An additional factor in this regard are the intentional forest fires used in deforestation, which are aggravated by drought. In an article published on 4 February in the magazine \u201cScience\u201d, a group of British researchers and the Institute of Environmental Research of the Amazon of Brazil, report a 2010 drought study using satellite data. They conclude that it affected an area of 3 million square kilometers of forest \u2013 once and a half the surface of Mexico \u2013 mainly in three regions: southwest of the Amazon, north-central Bolivia and the Brazilian state of Mato Grosso. By comparison, the 2005 drought was less severe, affecting an area of just 2 million kilometres concentrated in the southwest Amazon basin. Of course the precise origin of the events of 2005 and 2010 in the Amazon, the authors of the article in question argue that several climate models predict an increase, both in frequency and severity, in droughts in the Amazon region due to the gradual increase in the concentration of greenhouse gases in the atmosphere, which has been occurring for half a century because of the burning of fossil fuels. Droughts could then be originated, ultimately, by our actions. There are, however, no definitive results in this respect and the issue is still a subject of discussion among experts. It is, however, cause for concern that a drought event that was previously thought to occur once every hundred years, has been repeated in only five years. The concern increases when reading the phrase with which the article of the British and Brazilian researchers is closed \u201cIf the drought events continue, the era of an intact Amazon rainforest that acts as a buffer to increase carbon dioxide in the atmosphere could be a thing of the past\u201d.",
    "https://upload.wikimedia.org/wikipedia/commons/1/1f/Nofretete_Neues_Museum.jpg": "In recent days Egypt requested Germany \u2013 once again since 1930 \u2013 to return the famous bust of Queen Nefertiti, who is more than 3,300 years old and has remained in the European country since 1913. This bust was discovered by the German archaeologist Ludwig Borchardt in Amarna, on the eastern bank of the Nile River, in 1912 and transferred to Germany on the basis of an agreement established in order to divide between Egypt and Germany the archaeological pieces that were discovered during the excavations of Borchardt. Zahi Hawass, head of the Higher Council of Antiquities of Egypt, however, contends that recently they discovered documents that prove that the Egyptians were deceived by the German archaeologist, who would have covered the bust of Nefertiti with mud to conceal its historical and artistic importance, and to remove it from the attention of the Egyptians. The above is not recognized by the German authorities who claim, in turn, to have documents that prove precisely the opposite. They maintain that the bust belongs legally to their country and refuse to return it from the attention of the Egyptians. In this regard, the mayor of Berlin, the city where the museum of Egyptian antiquities houses the bust of the queen, declared that \u201cNefertiti stays in Berlin. Nothing was looted. There was a fair agreement and there is no reason to return it to Egypt.\u201d It is not clear who is right, but a simple view of the image of the polychrome bust of Nefertiti, of perfect features and elongated neck, and which immediately exerts an almost magnetic attraction, convinces us that if it had been appreciated in all its magnitude the Egyptians could not have agreed to leave their country \u2013 at least, of course, that there had been another kind of motivation. The Egyptian request to Germany, on the other hand, has not been timely given the sudden political problems that Egypt has experienced in the last days and that could have reinforced the arguments against the return of the bust. According to the Reuters agency, some of the most violent protest scenes have occurred in squares and streets close to the Egyptian Museum in Cairo and although It is reported that the Egyptian army has guarded its facilities, it is not clear if they are out of danger.In this regard, the looting suffered by the National Museum of Iraq when the seizure of Baghdad by the American army took place in April 2003. According to journalistic information of the time, the museum \u2013which houses archaeological pieces that represent five thousand years of history of the place that was the cradle of our civilization \u2013 suffered extensive looting over three days during which 170,000 objects were stolen \u2013 a number that has been reduced to 15,000 in recent estimates. This looting was possible because the American army did not protect the museum despite the request in that sense of the management of the museum. In addition, thieves who knew what they were stealing and were prepared to open locks and to transport objects of several hundred kilograms of weight. It was expected, then, that many of the stolen objects would later appear in the international black antique market. Indeed, in 2006 the United States government recovered in the United States and delivered to Iraq the statue of a Sumerian king who The statue has a weight of hundreds of kilograms and an age of 4,400 years. Archaeological objects are part of the cultural heritage of a town and from this point of view, regardless of how the Nefertiti bust has left Egypt \u2013 legally or illegally, with or without the consent of the Egyptian government \u2013 it must return to its place of origin. There are those who defend, on the contrary, that it should be in the place where it can be seen by the greatest number of people, which in this case possibly is Berlin. Those who think so, may also consider valid the argument of the safety of the archaeological piece, which at this time will surely be greater in Berlin than in Cairo. This, however, has not always been so. During the Second World War, the Nefertiti bust had to be removed in 1943 from the museum in Berlin where it was kept and placed in a safer place. This decision was fortunate because the museum was later destroyed. We would then have to be careful with the arguments to justify that objects that are part of the cultural heritage of a town \u2013 bustos , statues, obelisks, friezes etc.\u2013 reside outside their place of origin.",
    "https://upload.wikimedia.org/wikipedia/commons/f/f0/Hamerschlag_Hall_CMU.jpeg": "Imagine ingesting without limit every day the food that you like the most until you feel that you have satisfied your appetite \u2013 food that may be high in carbohydrates or fats of all kinds and is overflowing with cholesterol \u2013; imagine, moreover, that eating without limit does not bring serious consequences to your health. All this sounds good, but, of course, goes against the medical evidence that counts. And yet, a study recently published in the magazine \u201cScience\u201d (10 December 2010) by researchers from Carnegie Mellon University, in the United States, headed by Carey Morewdege, tells us that after all it is possible to eat everything that we like without affecting our health. This is the good news, the bad news is that part of the food that we ingest would have to be virtual; that is, it would be only in our imagination. In the reference study, which is entitled \u201cThinks instead of food: imagining consumption reduces actual consumption\u201d, it concludes that repeatedly imagining a certain food results at the end in a \u201cThought\u201d In this way, if you want to reduce the actual intake of a particular food, without becoming hungry, it would suffice to imagine several times that we consume it. These conclusions were reached through a series of experiments in which a group of people were asked to imagine eating a specific food, to investigate later how this affects the appetite for that particular food.In one of the experiments, a total of 51 people were divided into three groups and were asked to imagine carrying out a total of 33 actions. A first group was asked to imagine insert in a sequential manner 33 coins in a washing machine. A second group was asked to imagine insert 30 coins in the washing machine and also imagine ingesting three colored chocolate lunettes \u2013 according to the authors of the study, the actions of imagining depositing a coin in the slot of the washing machine and ingesting a luneta are processed in a similar way in the brain, so that both groups of people carried out the same number of operations. In the end, the three groups of people were presented with a glass with 40 grams of lunets and were allowed to eat as many as they wanted. It was found that the first two groups \u2013 the one that did not imagine consuming lunets and the one that imagined consuming three \u2013 ingested about the same amount of \u201creal lunettes\u201d. The \u201cconsumption\u201d of only three \u201cvirtual lunettes\u201d did not affect the appetite for them. In contrast, the group that \u201cingested\u201d 30 \u201cvirtual lunettes\u201d consumed only half of the \u201creal lunettes\u201d of the first two groups. When we eat a food that we fancy \u2013 for example, a chocolate bar \u2013 we know better the first bite than the tenth one. This is because to the extent that we consume the food we \u201chabit\u201d to the same, diminishing our desire to continue to ingest it. Morewedge and collaborators\u2019s results indicate that we can only live with a certain food not only if we consume it in real form, but also if only we consume it. According to the authors of the reference article, its results can be applied to the development of more effective methods to reduce the craving for drug use, as well as for the consumption of unhealthy foods. As part of a diet, our appetite could then be satiated in a healthy way by a judicious combination of \u201creal food\u201d \u2013 as usual \u2013 and \u201cvirtual foods\u201d. Before we sit at the table we could then imagine that we eat such or such food repeatedly \u2013 thirty times? \u2013 and this \u2013 according to the work of Morewedge and collaborators \u2013 would suffice to reduce the amount of such food that we then ingest. It should be noted, however, that we would have to do the same operation for every type of food we are going to consume, because the mechanism by which we used to a certain food \u2013 in both real and virtual way \u2013 works only for that particular food. Would this be a practical procedure to lose weight? It is not clear that it is, but if we have problems of overweight and sufficient time before the meal, it might be worth proving it.",
    "https://upload.wikimedia.org/wikipedia/commons/5/51/Head_of_a_barbarian_Athens.jpg": "How severe can the consequences of climate change be? Nobody knows for sure, but it could be that many of the events that shaped European history in the last two thousand years \u2013 including the fall of the Western Roman Empire and the rise of Black Death that struck Europe in the Middle Ages \u2013 have been linked to some degree to relatively rapid climatic variations. At least to this conclusion came a group of European and American researchers \u2013 headed by Ulf Buntgen of the Swiss Federal Institute of Forest and Snow Research \u2013 in an article published last January 13 in the magazine \u201cScience\u201d. In that article, Buntgen and collaborators report a study about the variability of the European climate over the last 2,500 years. For natural causes, the climate of our planet is continually undergoing changes. We know, for example, that during the Middle Ages the Earth temperature had a relatively high average value, which was followed by a period, known as \u201cLittle Ice Age\u201d, during which the temperature had a slight fall. To find out, they studied more than nine thousand samples of oak wood from Central Europe, both from living specimens and from dead trees that lived throughout the period of interest. We know that the trunk of a tree shows concentric rings whose number corresponds to its age. The rings appear because in latitudes with a marked contrast between seasons, there is a great variability throughout the year in the speed with which a tree thickens its trunk, which in turn produces changes in the density of the wood along the ring, thus marking its beginning and end. In addition to indicating its age, the rings contain information about the climatic conditions in which the tree grew. To unravel it, Buntgen and collaborators carried out a study on how humidity and temperature affect the growth of the rings and with this information they were able to reconstruct the climate history of a given tree. A tree, of course, tells us their own However, if we combine the stories \u2013 carried over over time \u2013 of a set of trees grown throughout the period of interest, we will have the whole story. This was what Buntgen and collaborators did for the last 2,500 years. They found that there is a correlation between periods of time during which marked climatic variations occur, and the occurrence of major historical events. They found, for example, that the Roman Empire of the West prospered during a relatively humid and warm time at the beginning of our Era, while the invasion of the barbarians, which led to the collapse of that Empire, occurred during a period when humidity and temperature had a marked descent. They also found that the emergence of the epidemic known as \u201cBlack Death\u201d, which devastated Europe during the years 1348-1351 killing about half of the population, was accompanied by a drop in temperature. The same happened in the 19th century with migrations from Europe to the United States. The study of Buntgen and collaborators is, of course, relevant given the current conditions of accelerated increase in the global temperature that is there. As the authors of the reference article point out, human history is complex enough to be considered the product of a single cause \u2013 climate change \u2013 and on the contrary it must be explained by taking into account also another type of \u201csocio-cultural factors that interact with climate change in a complex way.\u201d And yet they mention that: \u201cAlthough modern populations are potentially less vulnerable to climate fluctuations than societies of the past were, they are certainly not immune to the changes in temperature and precipitation that are predicted, especially considering that migrations to more favorable habitats as an adaptive response will not be an option in an increasingly populated world.\u201d For us, surely, the findings of Buntgen and collaborators are especially relevant, given the droughts that are predicted to occur in our country in the future.",
    "https://upload.wikimedia.org/wikipedia/commons/e/ec/PhrenologyPix.jpg": "In recent days, the media released the results of a survey on public perception of science in Mexico. The survey was carried out jointly by CONACyT and INEGI in 2009. As a result, among other things, we now know that more than 80% of our compatriots think that we have a lot of confidence in faith and very little in science. We also know that almost 60% think that scientists can be \u201cdangerous\u201d \u2013 it is not clear in what sense \u2013 because of their knowledge. In an apparent contradiction, however, about 80% think that there should be more people working in research areas in Mexico. Whatever it may be and regardless of surveys, contradictions or interpretations, it is clear that in our country the beliefs and practices that are described as non-scientific, including the cure of diseases with herbs and spells, astrology and magical diets are widespread. Although the article body describes in a reasonably balanced way the results of this survey, the title is somewhat tendentious, because the esoteric beliefs and practices are not exclusive to our country. In past days, for example, we learn from the media that the witches in Romania are very irritated because from last January they have to pay taxes for the profits generated by their practice. They argue that they earn very little \u2013 some 110 pesos per consultation \u2013 and that taxing them is stupid. Their irritation is such that they have threatened to cast spells and spells on the Romanian President, including the use of excrement of cat and dead dogs. They also threaten to throw mandrake at the Danube River. The President, on his side, apparently dressed in purple some days of the week to keep the devil at bay. In the United States, esoteric practices are not unusual either. In a Gallup survey of 2005 it was found that three of four Americans believe in the existence of paranormal phenomena. Thus, 41% of the U.S. population believes in extrasensory perception, 37% in enchanted houses, 32% in ghosts and spirits, and 25% in astrology. Esoteric beliefs are not, then, entirely the product of a poor educational level \u2013 like the one that unfortunately has our Country \u2013 and are also present in developed countries. Witchcraft, ghost hunting or astrology are activities that usually do not pretend to be scientific \u2013 although, in their case, the latter has been the predecessor of modern physics. In a survey conducted in 2008 by the National Science Foundation, for example, 63% of respondents said that astrology \u201chad nothing scientific,\u201d while 28% believed it was \u201csomething scientific.\u201d In contrast, other areas such as creationism or efforts to deny climate change, which do not follow a scientific methodology, do have this claim. This type of areas, which qualify as pseudosciences, have a good number of followers in the United States, although it is the country that leads technological leadership in the world. At this point it is interesting to recall the so-called incident of Roswell, which involved the alleged accident of an alien ship in Roswell, New Mexico in 1947. According to this story, which was fed for probably commercial purposes, the force of the North American area would be in possession of the crash ship, including the bodies of its occupants. The curious thing is that Roswell is not far from Trinity Site, where the first atomic explosion of the story took place in July 1945. It is curious because the explosion in Trinity Site \u2013 which was the result of the greatest scientific effort ever made \u2013 no doubt it happened, unlike the Roswell incident that was handled by rumors and assumptions. However, for some people both episodes are equally real. Mexico is certainly a country that has many educational shortcomings resulting in esoteric beliefs and practices. These, however, are not unique to the developing world and hence the title of the article of \u201cScience\u201d, which seeks to characterize us as inhabitants of the Middle Ages, is not to be appreciated. : \u201cAccording to the Mexican survey, scientists are both feared and respected, perhaps not in a different way from the old Aztec priests.\u201d It is unfortunate because, to begin with, most Mexicans are not descendants of Aztecs but of other indigenous groups.",
    "https://upload.wikimedia.org/wikipedia/commons/4/42/Blog_%281%29.jpg": "The last month of the year that has just ended brought us a scientific controversy that, as a sign of the times, has occurred largely through Internet blogs. The controversy had its origin in an article published last December 2 in the journal \u201cScience\u201d by a group of scientists from various research centers in the United States, including the NASA Astrobiology Laboratory, which reports the results of a research carried out with bacteria extracted from Mono Lake in California. Researchers found that these bacteria can grow in an arsenic-rich environment \u2013 which is the case of Mono Lake \u2013 and that, moreover, they are able to incorporate this chemical element \u2013 which we know has a high degree of toxicity under normal conditions \u2013 into their biological material in substitution for phosphorus. Following its publication, however, the reference article has received a lot of criticism from other specialists \u2013 published in mass media and Internet blogs. Critics acknowledge that, while finding bacteria that they can tolerate very high concentrations of arsenic constitutes an important discovery by themselves, they do not consider that the authors have \u201cNature\u201d is also critical of the attitude of \u201cNature\u201d is also critical of the attitude of \u201cNature\u201d as it was expected to provoke reactions \u201cbecause many scientists think that NASA is being given extravagant advertisements in the field of astrobiology.\u201d \u201cNature\u201d is also critical of the attitude of the \u201cNature\u201d and is also critical of the attitude of the \u201cnature\u201d as it is expected that this announcement would provoke reactions \u201cthat these bacteria would give it a biological use \u2013 by manufacturing proteins and incorporating it even into its DNA. Under normal conditions these criticisms would have nothing extraordinary and would rather be part of the standard validation process by which any scientific results should go through. It is the way NASA decided to present it. It is the way that it is made by means of a press conference in which it would release results of \u201can astrobiological discovery that will impact the search for evidence of extraterrestrial life,\u201d the British magazine \u201cNature\u201d \u2013 a competitor of \u201cScience\u201d and one of the most prestigious scientific journals\u2013 has been especially critical of the \u201cfanries\u201d and \u201ctrompetas\u201d with which NASA announced the discovery. \u201cNature\u201d writes: \u201cPerhaps you have seen NASA scientists claim to have discovered a bacterium that can replace phosphorus in your DNA with arsenic. Perhaps you have heard that this could help in the search for extraterrestrials. Even perhaps you have heard that this bacterium is by itself an extraterrestrial. What you have not seen or heard is a detailed response from NASA and the scientists involved to the criticisms that have been made of your work. In view of the global attention in the article, that NASA and the authors deliberately encouraged, the researchers have put their heads into the digital arena.\u201d Felisa Wolfe-Simon, the first author of the article referred to and who had kept silent saying that the discussion should take place, not in the mass media or on Internet blogs, but within scientific journals, as has traditionally been done, published on his personal blog on December 16 \u2013 one day after the editorial of \u201cNature\u201d \u201c\u2013 a plea supporting his original article. It included, however, the phrase: \u201cThe bacteria of Lake Mono can replace a small percentage of their phosphorus with arsenic,\u201d instead a total substitution as could have been understood from the original press conference. The NASA-Wolfe-Simon case includes a relatively new aspect in the field of scientific discussion that is the one regarding the use of the blogosphere to settle a controversy \u2013 whose usefulness, on the other hand, would be to be demonstrated. However, the blogosphere, by its informal nature, cannot replace the formal publication in scientific journals. Surely during the year just begun we will have results from other researchers \u2013 which will be published in scientific journals and not in personal blogs \u2013 confirming or denying the findings of Wolfe-Simon and collaborators. Only after this process will it be possible to establish solidly the existence of bacteria that feed on arsenic. In relation to this procedure, of course, there is nothing new under the Sun. Nor would there be, perhaps, as far as to exaggerate the importance of an investigation. As a result of the results achieved, it would seem that they were somewhat out of hand in the present case.",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/6/6e/Kyoto_Protocol_parties.svg/1000px-Kyoto_Protocol_parties.svg.png": "On December 11, the UN climate change convention concluded in Canc\u00fan, QR. This convention followed the one held at the end of last year in Copenhagen, Denmark, which was marked by the lack of understanding between developed and developing countries on the commitments to be made to combat climate change. On this occasion, given the Copenhagen experience, there were no high expectations regarding the agreements that could be reached and perhaps this is why the conference is considered to have been successful despite its modest results. According to The New York Times, \u201cThe agreement was limited with respect to the major changes that scientists say are necessary to prevent dangerous climate change in the following decades. But it sets the basis for stronger action in the future, if nations are able to overcome the emotional arguments that have paralysed the negotiations on climate change in recent years.\u201d For their part, The Washington Post notes that \u201cSome of the most thorny issues such as the future of the Kyoto Protocol were hardly discussed. The Cancun conference was more about rescuing the complex climate negotiation framework from irrelevance or even The main outcome of the Canc\u00fan conference was that it was not chaos and that there was a minimum of agreements. The fact, however, is that such agreements \u2013 which include a fund of $100,000 million dollars of aid for developing countries to combat climate change \u2013 are not mandatory and therefore nothing ensures that they are finally met. According to BBC News, \u201cthe pact is much less than the understanding agreement that many countries wanted at last year\u2019s Copenhagen summit and that they continue to seek. It leaves open the question of whether their measures, including emission reduction, will be legally mandatory.\u201d Global warming, of course, advances independently of the disagreements and discussions between countries during climate summits. According to NASA statistics, in the last three decades the average temperature of the Earth has been rising at a rate of 0.2 degrees Celsius every ten years. As a result, the last decade has been the hottest since 1880, the date from which global temperature records are held. While global warming is a fact, the consequences that will bring to our planet in the decades to come have a warmer since 1880, the date from which global temperature records are available. This is because of the complex nature of the Earth\u2019s ecosystem, which hinders the predictions of climate scientists who do not always agree. As an example of this, we can mention the study published last December 10 in the magazine \u201cScience\u201d by climatologist Andrew Dessler of Texas A&M University, about the effect that clouds have on global warming. Clouds, depending on the circumstances, can both raise and decrease the temperature of the Earth. Indeed, we have that these reflect the light of the Sun that affects our planet by preventing it from reaching the surface and thus contributing to reducing its temperature; they can nevertheless produce the opposite effect, because they also reflect the heat that is radiated by the surface of the Earth, which would otherwise be lost in space \u2013 we can convince ourselves of this last phenomenon if we consider that the clear nights tend to be cold, precisely because of the lack of the protective shield provided by clouds.\u2013 Thus, depending on which of the two possible effects it dominates, clouds can contribute both positively and negatively to global warming. Dessler concludes in his article that Global warming modifies clouds in such a way that they generate more warming, thus producing a kind of vicious circle in which each cycle aggravates the problem of climate change.This conclusion, however, is disputed by Roy Spencer of the University of Alabama who argues that clouds are not a consequence of global warming and therefore contribute negatively to it by blocking the Sun's radiation.The Dessler-Spence controversy has, in addition, another ingredient \u2013 which has nothing to do with climate science \u2013 because the latter accuses the magazine \u201cScience\u201d of having published the article of the first during the Cancun conference in order to influence its results, which both the magazine and Dessler deny.This latter aspect exemplifies the difficulties faced by the summit meetings on climate change. These difficulties, rather than scientific ones \u2013that science in any case has efficient methods to solve \u2013 are of an economic and political nature.This is not surprising if we consider that the energy that moves the world comes from almost 90% fossil fuel sources and that a drastic shift towards clean energy sources would have a high economic cost.",
    "https://upload.wikimedia.org/wikipedia/commons/2/26/Pisatest.jpg": "As widely disseminated, the week that ends today revealed the results of the PISA test carried out by the Organisation for Economic Cooperation and Development (OECD) in 2009. This test measures the knowledge and skills of 15-year-old students in three areas: reading, mathematics and science. The test is carried out every three years, always evaluating the three areas, but placing an alternating emphasis on one of them. The first PISA test was carried out in 2000, emphasizing the reading area. The following were carried out in 2003 (mathematics) and 2006 (science). In 2009 the reading area was again highlighted. In the PISA 2009 test seven levels of qualification were considered for reading ability. Level 6 corresponds to the maximum achievable qualification, while Levels 1a and 1b are for the lowest performance. According to OECD, students who reach levels 5 and 6 \u201cform a talent reserve that will help countries compete globally in the knowledge economy.\u201d Level 2 is considered the acceptable minimum, in such a way that the students who reach levels 5 and 6 \u201cform a talent reserve that will help countries to compete globally in the knowledge economy.\u201d Level 2 is considered the acceptable minimum, students who fail to reach it \u201cbattle to carry out activities of daily life that involve reading\u201d; besides that \u201cthe evidence from previous PISA tests shows that it is unlikely that these students will acquire the habit of learning permanently or of having a good performance in the labor market.\u201d Together with the 34 OECD member countries \u2013 an organization of which Mexico has been a member since 1994 \u2013 28 non-member countries participated in the PISA-2009 test, in addition to the Chinese cities of Shanghai, Hong Kong and Macao, as \u201ccollaborating economies.\u201d The PISA-2009 test was dominated by Asian countries and Chinese \u201ccollaborating economies\u201d. Thus, we find that, integrating the three areas, reading, mathematics and science, the first five places were occupied, in that order, by Shangai, South Korea, Finland, Hong Kong and Singapore. It is also worth noting that in the area of mathematics, Shanghai greatly surpassed the second place that Singapore was. Mexico in contrast, occupied 48 place among the 65 participants and the last place among the 34 OECD member countries. It is worth noting, however, , that the results that our country has obtained since the year 2000 show a positive evolution in the area of mathematics, evolution that the OECD classifies as \u201cstatistically significant\u201d \u2013 that is, that if it were to be carried out again, it would not produce radically different results. Mexico also shows a positive evolution in the areas of reading and science. In these cases, however, the OECD does not grant the same degree of reliability to the results by the reduced margin of improvement in the indicators; this is especially true for the area of science. Mexico\u2019s role throughout the PISA tests is analyzed in an OECD document that deals expressly with our country. In that document the OECD emphasizes, for example, that Mexico is the country with the greatest absolute increase in the performance in mathematics between 2003 and 2009. It should be noted, however, that in absolute terms, the qualification of Mexican students is the lowest within the OECD group, so that it improves their performance, although it is great in relative terms, in an absolute way it remains very poor. Similar considerations can be made with regard to the areas of reading and science. Statistics can also focus on the results that the results obtained since the year 2000 show a positive evolution in the results of the OECD. the two groups at the extremes of the scale: those below level 2 and those at levels 5 and 6. These statistics also show the great distance between our country and other OECD members. Thus, while in Mexico the percentage of students below level 2 in the area of mathematics is close to 50%, in countries like Finland and South Korea that percentage is below 10%. Similarly, Mexico is the OECD country that in 2009 had the lowest percentage \u2013 less than 1% \u2013 of students at the highest levels in mathematics. In contrast, between 25% and 50% of students in Taiwan, Hong Kong and Shanghai qualify at levels 5 or 6. Students in secondary school in Mexico, according to the PISA report, have improved their skills in mathematics in the last decade, while in the areas of reading and science we can say that there is no evidence that they have worsened \u2013 which is already gain. Given their low average performance, however, positive trends will have to be maintained for a good number of years if we have to reach the levels of reading and science. Even if some of them show a drop in their indicators, the saying that reads: \u201cBut the rich man has when he impoverishes that the poor when he enriches\u201d then has full validity.",
    "https://upload.wikimedia.org/wikipedia/commons/0/0c/DNA_animation.gif": "In recent days, a good number of articles and comments were published in the written press, as well as in numerous Internet sites, which speculated on the possibility that NASA would have found extraterrestrial life. Had this been true, it would have been one of the greatest scientific discoveries in history; a discovery that would have also crowned the efforts of the American space agency, which for many years has sought evidence of life in the Solar system outside our planet. The articles referred to had their origin in a NASA communiqu\u00e9 of 29 November, in which it cited a press conference to be held on 2 December next at its premises in Washington, with the aim of \u201cdiscussing an astrobiological discovery that will impact the search for evidence of extraterrestrial life.\u201d Predictably, a press release written in this way, coupled with the NASA strategy to make it known a few days before specifying the nature of the discovery \u2013 in the style of an suspense novel \u2013 had to generate journalistic notes and comments such as we saw in previous days. At the end, the discovery in question \u2013 the publication This lake is characterized by a great salinity and concentration of arsenic and the bacteria that inhabit it are, as a result, adapted in some way to live in contact with this element, which we know is a lethal poison for living beings. Reported experiments have shown that the bacteria of Lago Mono can effectively grow in arsenic-rich environments \u2013 they also do so in phosphorus-rich environments, as is the case in the journal \u201cScience\u201d by researchers from several American universities and research agencies, on the same day as the press conference in Washington, on December 2, although it turned out to be of great scientific importance, it was not to meet the expectations generated in the public. It had to do with extraterrestrials, but with microbes that inhabit the Mono Lake, in the state of California. The most interesting thing, however, is that in an environment rich in arsenic, these bacteria incorporate this element into their biological structure to replace phosphorus \u2013 including DNA. Thus, for the bacteria of the Mono Lake, arsenic, far from being a deadly poison, is a substantial food. Arsenic is an element with chemical properties that have a certain similarity with those of phosphorus. This fact is precisely what makes it a common poison for a living organism, since it is able to enter it in a surreptitious way and once inside cause damage. The similarity of chemical properties between arsenic and phosphorus, on the other hand, was what motivated Wolfe-Simon and collaborators to think that the former could be a substitute for the second as a component of biological material, given certain environmental conditions such as those prevailing in the Mono Lake. It is known that phosphorus, together with oxygen, nitrogen, hydrogen, carbon and sulfur, constitute the main components of living matter. With the new discovery, it turns out that this list is not after all definitive; At least as far as phosphorus is concerned. Thus, Wolfe-simon\u2019s study and collaborators give us an indication that the phenomenon of life is more complex than had been thought and that it could possibly occur in extreme environmental conditions \u2013 extremes, of course, from our earthly perspective. Thus, our catalogue of sites for seeking extraterrestrial life \u2013 soon within the Solar System \u2013 would not necessarily be limited to those places where environmental conditions similar to those of our planet prevail. While NASA\u2019s strategy to advertise it may be controversial, the discovery of Wolfe-Simon and collaborators has, after all \u2013 and still without a direct connection \u2013 relevance for the search for extraterrestrial life. Wolfe-Simon\u2019s results have, in this way, an unquestionable scientific value. They confirm, moreover, the popular saying that reads: \u201cVenum that does not kill strengthens",
    "https://upload.wikimedia.org/wikipedia/commons/1/16/Sam_Houston_at_San_Jacinto.jpg": "As it is in the public domain, in the manifesto known as Plan de San Luis, issued from San Antonio, Texas, Francisco I. Madero called for the armed uprising against the government of Porfirio D\u00edaz on November 20, 1910, precisely at six o\u2019clock in the afternoon. This fact was commented on last Monday\u2019s program of Carmen Aristegui\u2019s morning news, venturing the explanation that the uprising had been set at such a late hour of the day so that it would not interfere with the traditional nap that is usually taken in Mexico after lunch. While this is a possible explanation, a simpler \u2013 and therefore more likely \u2013 is that, given the spiritualistic inclinations of Madero, one of the spirits with which he had communication had indicated that such a date and such an hour were the most suitable to start the uprising. In case, it would not be the first time that our custom of taking siestas has had great consequences for the country. As we know, on April 21, 1936, General Texano Samuel Houston defeated Antonio\u2019s forces. L\u00f3pez de Santa Anna in the Battle of San Jacinto, near the current city of San Antonio, Texas, defeat that led to independence from Texas and, with time \u2013 after the Mexico-United States War \u2013 to the loss of half of the national territory. At the Battle of San Jacinto, the troops of Santa Anna were surprised by Houston when they were sleeping the nap, being defeated \u2013 and later massacred \u2013 in just 18 minutes, despite doubling the number of enemy troops. Sleeping the nap, however, is not necessarily a bad practice \u2013 just that you have to choose the right time to do it \u2013 as has been demonstrated in recent years through various scientific studies. For example, a research conducted jointly by the School of Public Health of Harvard University and the School of Medicine of Athens, Greece, carried out with 24,000 men and women for six years, found that those who slept naps of at least 30 minutes and for at least three times a week, had a 37 percent lower risk of dying from a heart condition than those who This percentage rose to 64 percent among working people. It has also been found that taking a brief nap reduces fatigue and improves concentration and, consequently, efficiency at work. This is still true \u2013 although less effective \u2013 even if the nap is taken on a chair and reclining on a desk, as the British Society of Physiology (Research Digest Blog, April 2010) comments. Contrary to the prevailing opinion in some industrialized countries, where it has traditionally been considered that naps are typical of lazy and lazy, it has even been suggested that workers should be given some time to rest so that they can take a short nap after lunchtime, with what would presumably increase their productivity. Following this idea, MetroNap, a company with presence in several countries, offers \u201cmedium-sized and large companies\u201d rental equipment \u2013 futurist-like chairs and loudspeakers to listen to music designed to take short naps. MetroNap\u2019s website, \u201ca nap of 15-20 minutes can increase energy for up to 8 hours\u201d \u2013 it\u2019s not clear, however, if MetroNap has dorms in its facilities to increase the productivity of its own employees. MetroNap also offers the possibility of taking a nap in its facilities; one of these is located in the \u201cEmpire State\u201d building in New York City, which offers 20-minute naps for $14. The power of naps was apparently known to Leonardo da Vinci 500 years ago, who, according to legend and to increase its productivity, would have slept only a total of one hour and a half a day, in siestas of 15 minutes every two hours. According to Science magazine (vol 249, 1990), this sleep practice was adopted by a 27-year-old contemporary artist who was able to maintain it for six months, sleeping an average of 2.7 hours a day \u2013 after which he had to suspend it for \u201cnot knowing what to do with all the time he had left free, since it was not another Leonardo.\u201d short in factories and offices, presumably to increase productivity, and as an extra bonus life expectancy? We cannot know right now, but if this is the case, in Mexico, as in other countries where nap is practiced, we will have anticipated our time.",
    "https://upload.wikimedia.org/wikipedia/commons/2/26/The_New_York_Times%2C_front_page_24_May_2020.jpg": "Where is the fastest computer in the world? Until a few weeks ago the answer to this question would have been: \u201cIn the National Laboratories of Oak Ridge, in Tenes\u00ed, USA.\u201d There, the supercomputer \u201cJaguar XT5\u201d, built by the American company Cray, able to operate at a speed of 1.7 petaflops, that is to say, to perform 1.7 billion calculations in a second \u2013 which is equivalent to hundreds of thousands of desktop computers. As of October 28, however, Jaguar XT5 was displaced by the Chinese supercomputer \u201cTianhe-1A\u201d, which is 40% faster. Tianhe-1A was built by the National University of Defense Technology of China and is housed at the National Supercompute Center in the city of Tianjin in the north of that country. Although it is not the first time that American computers have been overrunned by foreign machines \u2013 on different occasions in the past the title of the world\u2019s fastest computer has come from Japanese machines\u2013, Since 2004, the fastest computers have all been American. Moreover, on this occasion the United States was overtaken by China, a country that is the second world economic power, which is on the rise and stepping on its heels. This last one is, of course, very serious, being an area of technology of as much strategic importance as that of computing. According to Wu-chun Feng, a computer professor at the Virginia Technological Institute, quoted by The New York Times: \u201cWhat scares is that the US dominance in the area of high-performance computing is at risk\u201d and that \u201cIt can be argued that this strikes the foundation of our economic future.\u201d Tianhe-1A was designed and built by Chinese scientists and engineers at a cost of 80 million dollars, using parts manufactured by two North American companies: 14,000 Intel processors and 7,000 NVIDIA processors. The Chinese supercomputer is then North American in terms of its basic components, but definitely Chinese in terms of technology developed to integrate these components into a machine that has proved to be the fastest ever to be the fastest. In addition, according to an article published in the issue of 5 November in Science magazine, the Chinese are testing their own version of Intel processors on the Tianhe-1A computer. Moreover, the United States has already been overtaken by a rival power in a technological area of great strategic importance. Indeed, on 4 October 1957, with the launch of the first artificial satellite by the then Soviet Union, the United States was largely overtaken in space technology in the midst of Cold War. Soviet supremacy was confirmed on 12 April 1961 when it was put into orbit Yuri Gararin, the first man in space. On that occasion, the United States was barely able to respond with a suborbital manned flight 23 days later. As we know, however, President Kennedy made a public commitment in the summer of 1962 to bring an American to the surface of the Moon before the end of the decade, which was finally achieved in July 1969.The truth is that China is investing heavily in research and development, so, between 1996 and 2008, increased by a factor of 2.6 percentage of GDP. In addition, the Chinese economy is growing by around 10%, so that the resources invested in research and development are growing at an even higher rate in 2009. At the same time, the number of researchers in China grew by about 80% between 1995 and 2004. However, according to Jack Dongarra, a computer specialist at the University of Tenes\u00ed, cited by Science, Tianhe-1A is likely to lose his fastest computer degree in the world soon, given that there are five developing supercomputers in the United States and Japan that could reach speeds of 10 petaflops. Whether or not the previous prediction is being fulfilled, the high rate of scientific and technological growth that China is experiencing, like other Asian countries, will represent to the developed countries of the West an increasingly intense technological competition in a large number of areas.",
    "https://upload.wikimedia.org/wikipedia/commons/2/21/Antena_canal4.jpg": "On October 15, a group of researchers from the Georgian Institute of Technology, in the United States, sent for publication to the journal \u201cPhysics of Fluids\u201d a research paper describing experiments carried out to study the way a wet dog dries water vigorously shaking its body. As we know, dogs \u2013 like other mammals like rats and bears \u2013 are released from the water trapped in its hair by rocking and twisting its body at a high speed. Researchers from the Georgian Technological recorded dogs and wet rats on video, and measured the speed of their jolts by playing the video in slow motion. They found that such a speed depends on the size of the animal. Thus, a tiller dog shakes its body between four and five times each second, while, respectively, a mouse and a rat do it 18 and 27 times in the same interval. In contrast, a wet bear is shaken and contorted 4 times per second. As explained by one of the researchers involved in the study, it is essential to have a mammal with hair. a way of shaking the excess water of his body by a mechanical means \u2013 shaking and contorting \u2013 because otherwise he would have to evaporate it using the heat of the body and quickly enter into a state of hypothermia that would cause him to die \u2013 let us think, for example, of the feeling of \u201ccold\u201d that we experience when we rub the skin with alcohol and let it evaporate by taking heat from our body, or in the high probability that we have to get sick if we let wet clothes dry over the body. It is not surprising that, on the other hand, to get rid of the water the larger animals need to shake at a lower speed than the smaller animals, because the forces that tend to release a drop of water that is, for example, on the back of a bear, are greater than the corresponding forces on the same drop of water in the back of a rat. Reports of the study referred to had spread on North American television and, consequently, reached a great notoriety, which was reflected in the great number of articles that appeared on this subject. The nature of the study and its conclusions lend themselves, of course, to its wide dissemination, because we would hardly find anyone who has not witnessed the curious and predictable behaviour of a wet dog \u2013 very different, by the way, from that of our own species, who has lost his hair in most parts of the body over hundreds of thousands of years of evolution and can more easily get rid of the excess of water. It is positive that the mass media deal with a scientific or technological subject, since this can help to emphasize the essential role that science occupies in the present world and that it is not always clear among the general public, and in particular among those who are in a position to make decisions regarding their public support. Martin Rees, astronomer at Cambridge University, for example, points out that science and technology had in the nineteenth century in England a greater social visibility and public appreciation than they currently have, as evidenced by the national museums that consume, in relative terms, greater resources than those currently devoted to them. Some of them, for example, referred in a joke tone to the supposed custom of dogs to wait for a person to be near them to start shaking water; idea or prejudice that it is possible to be the product of the few cases in which a dog wets a person, at random, without taking into account all those cases in which it does not happen, which are the majority but which are not noticed. On the other hand, there is a tendency for researchers today to exaggerate the results of research, both by the researcher himself and by the university in which he works. In the present case, there is only one video in which various animals are shown shaking the water and not by a full article. We could not then give an opinion on this. As long as we have more information, we can enjoy the video. Reference (HYPERLINK \"http://arxiv.org/abs/1010.3279\" \\t \"_blank\"http://arxiv.org/abs/1010.3279) showing images in slow motion \u2013 including x-ray \u2013 of wet mice, dogs and a bear and shaking the water.",
    "https://upload.wikimedia.org/wikipedia/commons/3/3d/Graphite-233436.jpg": "The week just ended was one of Nobel Prizes. The awards for Medicine, Physics, Chemistry, Literature and the Nobel Peace Prize were awarded this year to Mario Vargas Llosa \u2013 who, by the way, a few years ago received the Honoris Causa doctorate from the UASLP\u2013, a Peruvian nationalized Spanish writer. As happens every year, the Literature Prize received greater attention than the Science Awards. This is natural, because the number of readers of, for example \u2013 and above all \u2013 Vargas Llosa, is considerably greater than the number of readers of scientific texts such as those on graphene films of the Nobel Prize winners in Physics this year. Beyond its media impact, however, the Nobel Prize in Science is awarded to works that have not only represented discoveries and advances that have changed our lives. The discovery of graphene \u2013 which is made up of carbon atoms, as well as the graphite at the tip of the pencils \u2013 represented Andrei Geim and Konstantin Novoselov, researchers of carbon atoms, as well as the graphite at the tip of the pencils\u2013 represented Andrei Geim and Konstantin Novoselov, researchers of the University of Manchester, the Nobel Prize in Physics 2010. Graphene is presented in the form of extremely thin carbon foils, with a thickness of exactly an atom \u2013 and it is, of course, the least possible. The discovery of graphene was carried out in an amazingly simple way: tearing off sheets of this material from a piece of graphite by means of an adhesive tape. Graphene in a material with unusual properties derived largely from its extreme thinness. If we could reduce our size to atomic dimensions and make of a graphene sheet our habitat, we would find a strange situation, as described by the English writer Edwin A. Abbot in his book \u201cFlatland\u201d \u2013 which we could translate as \u201cPlane World\u201d, published in 1884. \u201cFlatland\u201d is a two-dimensional world that contrasts with our three-dimensional one where we can distinguish between the length, width and height of an object. In \u201cFlatland\u201d there are only long and wide, and its inhabitants, with triangles, In this way, they are perceived only as straight lines. Like \u201cFlatland\u201d, graphene is a world where everything happens in two dimensions. It is thought that graphene could have a number of applications, including replacing silicon in the manufacture of the \u201cchips\u201d that are used, for example, in the processors and memories of computers. In a chip, very small electrical currents are required to be controlled by means of tiny electrical gates. A chip integrates millions of these gates, which become smaller and smaller in size as technology advances. It is thought, however, that it will soon reach a limit, beyond which silicon \u2013 the base element in the manufacture of the \u201cchips\u201d \u2013 will have to be replaced by other material. One of the candidates for this purpose is precisely graphene, which could potentially be the basis of \u201c The technological promises of graphene, however, are taken with caution by the experts, because their extreme weakness makes it very difficult to manipulate. In the past we have seen not a few cases of scientific discoveries that promise great applications that have ultimately proved difficult to concretize. Among these we have counted on the superconductivity of high temperature \u2013 a reason for the Nobel Prize in Physics 1987 \u2013 and nuclear fusion. That promised the manufacture of electric conductors with zero resistance for a number of applications, which has not been achieved, while nuclear fusion has already offered unlimited energy from sea water for many decades, without obtaining any practical results. There are even those who did not react enthusiastically to the Nobel prize awarded to Geim and Novoselov. In an article published in the issue of last 8 October of the magazine \u201cScience\u201d, which led by title: \u201cStill in childhood, a two-dimensional crystal receives a prize\u201d, it is noted that this award constitutes an anomaly if compared to other past recognitions, which rewarded the discovery of a two-dimensional crystal with a title: This year, however, not only has the Nobel Peace Prize sparked controversy, but it has been the result of a new physical effect or development that has led to ubiquitous applications over the course of decades. Walter de Heer of the Georgian Institute of Technology, in statements to the journal \u201cScientific American\u201d, considered that the prize is premature and that the graphene still needs to demonstrate its technological potential.",
    "https://upload.wikimedia.org/wikipedia/commons/2/20/AchenseeWinter05.JPG": "Do you believe in climate change? Are you convinced that the temperature of the Earth is rising because of us? Are you concerned that climate change is a real danger that affects not only the seals or polar bears but all the inhabitants of the Earth \u2013 including us, the humans \u2013 and that it threatens to change our way of life? Each person to whom these questions are asked would of course have their own answers. However, according to a study published by Aaron McCright of Michigan State University in the September of this year issue of the magazine \u201cPopulation and Environment, it is more likely to get affirmative answers if the questions are addressed to a representative of the female gender; this is at least among the American population. The study was carried out with results of Gallup surveys carried out in the years 2001-2008. According to this, 59% of the women consulted claimed to believe that climate change is real, compared to only 54% of the men who think so. that climate change is the product of human activities, while only 59% of men share this view. It was also found that 37% of women surveyed believe that climate change threatens their way of life, compared to 28% of men who have this conviction. In contrast, while women find themselves better informed about the scientific evidence that supports climate change, they show less confidence than men in their understanding of climate change. On the other hand, and regardless of the differences of opinion between men and women in the North American population regarding climate change, there is a good \u2013 if not a minority \u2013 percentage of skeptics who do not consider climate change to be real; or, if it does exist, it is due to natural and non-human causes. Public belief in global warming was affected by the theft of information from the Climate Research Unit server of the University of East Anglia in the United Kingdom, which occurred in November 2009, and which gave rise to the so-called \u201cClimagate\u201d. The information that was lost was distributed by the Internet and included e-mails exchanged among climate scientists in several cases. World research centers, in which climate change activists wanted to see evidence of anti-scientific practices attempting to present an aggravated picture of climate change.Although the accusations could not be proven, Climagate encouraged public scepticism about the reality of global warming.The last winter, in which temperatures were below normal in much of the northern hemisphere, including our country, did not help to generate the public\u2019s perception that the temperature of our planet is rising. Had we lived in the Arctic, however, we would have had the opposite perception, because in the past winter there were temperatures higher than usual. Similar experiences we lived them in the last months in San Luis Potosi, where we had a winter with very cold days and a month in May with high temperatures. There is solid scientific evidence that the average temperature of the Earth is increasing because of the indiscriminate use we have made of fossil fuels since the beginning of the industrial revolution. There will be colder winters in certain regions of the world than normal ones, as well as hoter summers, but on average the average. Earth temperature is rising slowly. No scientific result, on the other hand, is absolutely conclusive and will always be susceptible to being refuted by new evidence. Until now, however, the consensus in the scientific community is that global warming is a real fact, which has been provoked by human activities, and that if it is not mitigated will lead to an increase in the Earth's temperature of several degrees Celsius in the year 2100, with disastrous consequences for the world. Naturally, due to the great economic costs involved in moving towards a fossil-fuel-free economy, as well as to the interests that would be affected in the process, there are instances where climate change does not enjoy sympathy as the Climagate episode shows. In these circumstances, public opinion will be fundamental to reduce carbon dioxide emissions to the atmosphere and bring our planet out of trouble. When this is achieved, the world will be in debt to the female gender that is mostly inclined to believe in climate change \u2013 although, to be fair, in this regard the male gender does not remain too far behind.",
    "https://upload.wikimedia.org/wikipedia/commons/a/ae/Drinking_water.jpg": "This is the title of the article that appeared in the September issue of the scientific journal Scientific American, which considers the effect that human activities have had, both on the environment and on the inventory of natural resources that our planet has. The article establishes a time scale for various events that are predicted to occur in the next 100 years on a global scale and that include: the effects of climate change on food production and the supply of drinking water, the depletion of mineral and energy resources, and the massive extinction of biological species by immoderate fishing and pollution of the oceans. As we know, the increase in the concentration of greenhouse gases in the Earth\u2019s atmosphere during the industrial era \u2013 over the last 200 years, but especially in the last half century \u2013 has caused an increase in the temperature of our planet that manifests itself by \u2013 among other effects \u2013 the reduction of the volume of ice in the earth\u2019s poles and glaciers, and in the release of large masses of ice from the polar ice caps floating to the drift. Although small \u2013 it will produce changes in the distribution of rains, the volume of which would increase in certain regions such as Siberia and the east of the United States, but will be reduced in others, among which unfortunately much of our country is found.A decrease in the volume of rains would affect both agriculture and the supply of drinking water for human consumption.It is predicted that the lack of water will be a crisis in 50 years and that Mexico would be greatly affected, with a reduction of 25% in its agricultural production.A more imminent problem is the depletion of the reserves of some metals of great importance today such as silver, gold, Indian and copper. At the present levels of extraction, according to the data contained in the reference article, the natural reserves of these metals will be exhausted in periods ranging from 18 years for the Indian, to 34 years for copper. As we know, copper has wide applications and we find it in networks of electricity distribution, in pipes of water, in communication systems, including cellular phones, and in general in all kinds of electrical devices and appliances. In fact, oil is expected to reach its world-wide peak in 2014 and, from that year onwards, to enter a period of decline. Even in the case of coal, of which there are considerably higher reserves, David Rutledge of the California Institute of Technology, predicts that by the year 2072, 90 % of existing stocks will have been extracted, at the current rate of production, from the current stock. Fishing and the production of seafood are activities that are also threatened by over-exploitation. Among the marine species that are at risk, according to the article in question, are the hammer shark and sturgeon, which have reduced their population by 90 % in recent decades. Earth is shown as an immense place, which has been shaped by natural forces whose power is far above ours; consequently, it was not natural for a long time to think that through our actions we could disturb it on a global scale. Similarly, we tend to consider that the natural resources within our planet were immense and inexhaustible. Today, 200 years after the beginning of the industrial revolution, it is clear that our perceptions were wrong and that through the indiscriminate use of fossil fuels we have polluted the atmosphere of the planet and disturbed its balance; we have just as exhausted the oil and are on the way to doing the same with coal and other minerals essential to us as copper and Indian are. And despite all this, that is to say, having brought our planet to the limit, we have not been able to give dignified living conditions to a majority of the world's population.",
    "https://upload.wikimedia.org/wikipedia/commons/e/e6/Ice_age_fauna_of_northern_Spain_-_Mauricio_Ant%C3%B3n.jpg": "The National Institute of Anthropology and History (INAH) announced in its bulletin of 24 August the discovery, in the cenote Chan Hol in Tul\u00fam, Quintana Roo, of a human bear with an age of more than 10,000 years, which corresponds to the end of the Ice Age. Due to the little worn denture, it is known that the remains belong to a person who died young. The skeleton of the \u201cYoung Chan Hol\u201d, as it is known, was found 542 meters inside a cave submerged at a depth of 8 meters. According to the INAH, the body was placed in the cave in a funeral ceremony. The finding joins those of the skeletons of the Naharon Woman, the Palm Woman and the Temple Man, which were also recently found in submerged caves close to Tulum and which have antiques that also date back to the Ice Age.At the time when the Young Chan Hol lived, the cave where his remains were found was not submerged. 13,000 years, however, the last glaciation ended and the Earth's temperature began to rise gradually, to accumulate today an increase of about 8 degrees Celsius. With the rise of the Earth's temperature, the polar ice caps decreased in volume, in addition to the expansion of ocean water. As a result, the sea level rose about 80 meters in the last 12,000 years. According to INAH, the skeleton of Chan Hol's Youth \u2013 which was recovered by 60 percent, including limb bones, vertebrae, ribs and skull \u2013 provides evidence of the first human migrations to our continent. As we know, the classic theory about the origin of the indigenous population in America, which was widely accepted for a long time, presupposes that this is the result of the migration of nomadic tribes from Central Asia, which would have reached our continent at the end of the Ice Age through what is now the Strait of Bering. At that time, and because the depth of the sea around that strait is very little, a land bridge was formed between Asia and America as a result of the descent of the sea level. Once in the American continent, nomads would have moved southwards through an ice-free passageway in Canada. According to classical theory, the Clovis culture of New Mexico, with an age of 13,000 years, corresponds to the first inhabitants of the New World. Today, however, there are those who question this theory, as evidence of settlers has been found on our continent prior to the Clovis culture. This is the case of the Monte Verde site in southern Chile, which is awarded an age of 14,000 years. It is also argued that there were additional routes of migration to the south by sea along the west coast of our continent, which reached the southern end of it. There are also those who argue that the indigenous population of the New World is the result of migration of more than one ethnic group. Some researchers think, for example, that there were travelers from south-east Asia \u2013 and even from Europe \u2013 who arrived on our continent by sea route. According to INAH, the youth of Chan Hal. Like the other osamentes found in Tulum, it supports the idea that the New World was populated by waves of immigrants to the American continent coming not only from Central Asia, but also from South-East Asia. In a bulletin issued on July 24, INAH showed a reconstruction of the Woman of the Palms, carried out by a French laboratory based on the remains found in the cave near Tulum. If reconstruction was successful, the Woman of the Plamas \u2013 1,52 meters tall, 58 kilograms of weight and 44 to 50 years at death \u2013 had the appearance of a Indonesian villager in South-East Asia. The genetic evidence available, however, does not support the idea that the American continent was populated at the end of the Ice Age by several waves of immigrants with diverse genetic characteristics, as discussed by researchers from the Universities in Texas and Utah in the article \u201cDispersion of modern humans in the Americas in the Late Pleistocene\u201d, published in the magazine \u201cScience\u201d (14 March 2008). settled by immigrants from Central Asia who crossed the Bering Strait at the end of the Ice Age and gradually dispersed to the south, as it has been traditionally accepted? Or, on the contrary, were there several waves of immigrants from various parts of Asia, or even from places as \u201cexotic\u201d as Europe would be? Experts still do not have a solid answer to these questions, which we will surely not be late in having. Hopefully, in their search, Chan Hol\u2019s Young man can contribute his bit of sand.",
    "https://upload.wikimedia.org/wikipedia/commons/0/08/Pollution_plastique_2.jpg": "The regulation of the Solid Waste Act of the Federal District, which came into force on 19 August and which prohibits commercial establishments from giving plastic bags to their customers, has been a cause for much controversy in recent days. It is noted, for example, that what should be understood as biodegradable plastic has not been specified. Traders also argue that the cost of the bags provided to buyers is already included in the price of the products and would therefore be complying with the standard. According to data from the National Association of Plastic Industries, the commercial establishments in the Federal District provide 32 million plastic bags every day and, given these numbers, the non-biodegradable plastic bags rule is intended to mitigate their impact on the environment. Plastics have commercially great advantages, as they are cheap, easy to mold and durable. This latter characteristic, however, is the one that makes them unfriendly to the environment, since once they are discarded they can survive for a long time without degrading.There is growing concern among experts about the fate of the products. The oceans and marine fauna are particularly susceptible to plastic contamination. A study carried out two decades ago on the North Carolina coast with 1,000 birds, for example, revealed that 55% of them had plastics in their intestines. Another study, carried out 15 years ago, found that more than 80% of the garbage at the bottom of Tokyo Bay was made up of plastic materials. Plastics can be incorporated into the ocean carried from the urban centers to the coast by rivers or drainages, or they can be thrown into the sea from ships, accidentally or intentionally. Once in the ocean, marine currents drag and accumulate them in certain well-defined areas. It is known, for example, that in the Pacific Ocean, at the height of the Hawaiian archipelago, there is a region of concentration of plastic waste known as \u201cGreat Pacific Waste Spot\u201d, which has a larger surface than that of the state of Texas. Ultraviolet radiation causes plastic materials in the ocean to disintegrate into pieces \u2013 each time smaller to reach microscopic sizes\u2013 so that the surface is greater than the surface of the state of Texas. In an article signed by researchers from California and Hawaii, which appeared last Thursday in the magazine \u201cScience\u201d \u2013 published by the American Association for the Advancement of Science \u2013 a study of the pollution of the North Atlantic Ocean by plastic materials is reported. The study involves observations carried out in the period 1986-2008 and in it it was found that 60 percent of the more than 6,000 samples taken from the marine surface, contained plastic garbage with a typical size of the order of millimetres. A higher concentration of plastics was found in an area located about 1,500 kilometers east of the Florida peninsula, with an average density of plastic fragments between 50,000 and 100,000 per square kilometer. A surprising result of this study \u2013 carried out over more than two decades \u2013 is that the density of plastic fragments in the studied area has not increased over time. This despite the increase by a factor of five that has been given globally in the production of plastics in the last three decades. Although the authors of the reference article do not give an explanation for this discrepancy, among the possible reasons they consider that plastic materials may have been precipitated to the bottom of the sea by the process of fragmentation, a second possibility is that, once fragmented to a certain extent, they have been ingested by marine fauna.There could then be a more serious contamination of the oceans by plastics than is evident so far.In Mexico, 60% of the garbage on the beaches is made up of plastics, which does not differ substantially from what is happening in other parts of the world (J.G.B Derraik, Marine Pollution Bulletin, 2002). In addition to percentages and comparisons, however, it is evident that the problems of contamination by plastics have already been present in our country for some time, and not only on the beaches. It is then relevant the discussion that is taking place in the Federal District on the Solid Waste Law, as it is likely, and as often happens in Mexico City. will have repercussions for the rest of the country.",
    "https://upload.wikimedia.org/wikipedia/commons/7/79/Dampfturbine_Montage01.jpg": "One of the characteristics of the time in which we live is the increasing complexity of the technology around us. The Internet, for example, which barely existed two decades ago, has an increasing capacity to transmit information and exerts an increasing influence on our lives. In the same way, medicine continuously develops new drugs, treatments and surgical procedures, which have doubled our life expectancy over the course of a century.The increasing complexity of the technological devices around us cannot be explained without the competition of scientific knowledge.The current electronics, for example, required for the accelerated development that it experienced throughout the last half century of the invention of the transistor, which occurred at the end of the decade of the forties in the United States.This invention was guided by the scientific knowledge that was available at the time about the physics of solid materials, which was in turn the result of the middle of a century of basic scientific studies that occurred mainly at universities in northern Europe in the first half of the twentieth century.Although we are surprised by the complexity of the current technology, the most complex technological ingenuities that we know \u2013 the living beings \u2013 We can conceive of living beings as highly perfected \u201cmachines\u201d \u2013 through the natural selection mechanism \u2013 to fulfill certain functions, including reproduction. Living beings have structures with a complexity beyond what we could even dream at the moment in making, so that as a \u201cengineer\u201d nature far surpasses us, to say the least. To be fair, however, we must recognize that nature enjoys the enormous advantage of not having deadlines to finish its creations, which have taken it tens or hundreds of millions of years; in fact, they never reach a final form and remain in continuous evolution. We can take advantage, on the other hand, of the skill and experience of nature as an engineer copying and adapting its designs for our purposes. This is already being done and in some cases in a systematic way. A recent example is the development of the device to capture the energy of the Sun and store it in the form of sugars \u2013 as it happens in the normal process of photosynthesis, but with greater efficiency\u2013 recently reported by a group of researchers from the University. The development is inspired by the material with which the Tungara frog makes its nest, which inhabits tropical areas of the planet including our country. The efficient conversion of the Sun\u2019s energy into sugars is an intermediate step for the economically viable manufacture, from such sugars, of biofuels such as ethanol. The development of biofuels, and in general efficient methods to take advantage of solar energy, is key to the Earth\u2019s energy future. As we know, the indiscriminate use of fossil fuels has increased the concentration of carbon dioxide in the atmosphere, causing the rise of the temperature of the surface of our planet. A decrease in the emission of carbon dioxide to the atmosphere is then indispensable, and the substitution of fossil fuels by biofuels is one of the actions contemplated for this purpose. Tungara frog can thus provide us with a source of green energy, and not by the colour of the frog \u2013 which is rather coffee with some green stripes \u2013 but by being clean, i.e. free of emissions. In addition, we can mention that, as in the natural process of photosynthesis, the conversion of solar energy into sugars using the device based on the Tungara frog\u2019s nest material is carried out by absorbing carbon dioxide from the atmosphere and thus contributes to reducing its concentration. It could thus be used, according to its developers, in the vicinity of carbon dioxide-emitting plants to \u201chijack\u201d the carbon emitted and prevent its emission into the atmosphere. This and many other examples show us that, while nature has taken a considerable time to develop the life forms we see on Earth \u2013 and that with certainty, in the same or different form, they will have appeared on other sides of the Universe \u2013 so far it is evident that it surpasses us widely as an engineer. In these conditions, the most intelligent thing we can do \u2013 and in fact we are already doing \u2013 is to learn from its designs.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d3/B-29_in_flight.jpg": "On August 6, 1945, an American bomber B29 \u2013 nicknamed \u201cEnola Gay\u201d in honor of his captain\u2019s mother, Paul Tibbets\u201d \u2013 detonated a nuclear bomb on Hiroshima. Between 90,000 and 160,000 people died at the time of the explosion or in the course of a few months. Three days later \u2013 tomorrow will also be 65 years \u2013 a second atomic bomb was dropped on the city of Nagasaki. Unlike Hiroshima, which is a flat city, Nagasaki was partially protected by hills, with only 60,000 to 80,000 people being killed by the bomb.The anniversary ceremony of the Hiroshima explosion, which takes place year after year in the city\u2019s Peace Park, had a special significance on this occasion, as it had, for the first time, the presence of the United States ambassador to Japan, in addition to the UN Secretary-General and representatives of France and the United Kingdom. The bombings of Hiroshima and Nagasaki have always been a source of controversy and contradictory positions, and in this regard last Friday\u2019s ceremony at the Peace Park was no exception. As Eric Johnston, a reporter for The Japan Times, points out, although both the Mayor of Hiroshima and the UN Secretary General urged Japan to do its part in order to achieve the abolition of atomic weapons in the world, they did not mention anything with regard to exports of Japanese nuclear technology to countries that have not signed the treaty on the non-proliferation of atomic weapons, as is the case with India. With the different positions held with regard to the bombings of Hiroshima and Nagasaki it is possible to make a multifaceted mosaic, which includes both moral aspects, as well as testimonies and attempts to rationalize the use of the atomic bomb against the civilian population. As the first element of such a mosaic, it is necessary to include the \u201cHibakusha\u201d, that is to say the survivors of atomic bombings, with chilling stories about what they lived immediately after the explosion \u2013 Apocalyptic visions of people with broken eyes or walking like ghosts with no fixed direction with their skin hanging like jirons, among many other horrors \u2013 and of the health problems they have suffered throughout their lives for the effects of it. We contrast these testimonies with recent statements by Gene Tibbets, son of the Enola Gay pilot, in which he \u201cthrews\u201d against President Obama\u2019s administration for having sent his ambassador to Japan to the ceremony at the Peace Park. In statements to Fox News he said this is an implicit apology to the bombing of Hiroshima that his father would never have approved. He affirmed: \u201cIt is making it seem that the Japanese were a poor people, as if they had done nothing. Pearl Harbor was attacked and we were beaten. We did not kill the Japanese. We stopped the war.\u201d Back 65 years in time \u2013 in the manner of a film with \u201cflashback\u201d \u2013 we can imagine Robert Oppenheimer, scientific head of the Manhattan project through which the atomic bomb was developed \u2013 and an intellectually person According to Hans Bethe, also a participant and Nobel Prize laureate in Physics \u2013 to Enrico Fermi, Arthur Compton and Enrnest Lawrence, all Nobel Prize laureates in Physics, signing a letter expressing their recommendation on the immediate military use of the bomb against Japan, as the only means of shortening the war and saving American lives. The letter was addressed to the \u201cInterim Committee\u201d, a high-ranking committee formed in May 1945 by the US Secretary of War, who in turn made the recommendation that the bomb be used without prior warning against a military facility or manufactures surrounded by houses or other buildings likely to suffer damage. No less memorable is the photograph of the American physicist Luis Walter \u00c1lvarez \u2013 equally Nobel Prize laureate in Physics \u2013 posing in front of the bomber accompanying Enola Gay on his mission to Hiroshima, and nicknamed, ironically, \u201cThe Great Artist\u201d. \u00c1lvarez traveled as a scientific observer aboard this bomber and carried out measurements of the intensity of the explosion through parachute-mounted detectors, which were launched. It should be mentioned, however, that while there were high-level scientists who approved the military use of the bomb and who collaborated in its development, there were also attempts by other scientists to try to prevent it. These attempts, however, were fruitless. Beyond a moral imperative, as an argument against the use of the bomb, it was argued that such an action would trigger a nuclear arms race and that the United States would have no moral strength to stop it. Years have shown us the correctness of these reasonings.",
    "https://upload.wikimedia.org/wikipedia/commons/a/a4/Hurricane_Katrina_August_28_2005_NASA.jpg": "The hurricane \u201cAlex\u201d, which hit the northeast of our country at the beginning of this month of July, was the first tropical storm of the 2010 hurricane season in the Atlantic Ocean, which officially began on June 1. We did not have to wait long for the second storm, \u201cBonnie\u201d, to arrive. As we can see from the rains that we have suffered in the last days, being located right now in the northern Gulf of Mexico off the coast of Louisiana. There are those who argue that global warming, produced by the increasing concentration of greenhouse gases in the atmosphere \u2013 and that it has resulted in an increase of about a half degree centigrade in the temperature of the oceans in the last thirty years \u2013 is responsible for the occurrence of \u201cextreme\u201d climate events; that is, heat waves or cold waves, droughts, hurricanes, among other phenomena, with intensions above their average historical values. It can be noted, for example, that in an article published this year, researchers at Stanford University maintain that due to climate change, heat waves such as With regard to hurricanes, in recent years we have had some that have caused great devastation in our region. In 1988, Hurricane Gilberto devastated the Yucatan peninsula and, like Hurricane Alex a few weeks ago, seriously affected the northeastern part of our country. In 2005, Hurricane Katrina hit the city of New Orleans, causing one of the worst natural disasters in the history of the United States, while in 1998 Hurricane Mitch caused flooding and killed more than 10,000 people in northern Honduras. In addition, there have been years with a number of hurricanes far above the historical average. In 2005, for example, a total of 15 hurricanes occurred, 7 with a larger category (3, 4 or 5). Among the latter are Katrina and Wilma; the latter, the most intense hurricane ever observed in the Atlantic Ocean, with peak winds of 295 kilometres per hour. In recent decades, however, there has been no positive trend in the growth of the number of hurricanes worldwide and in particular hurricanes in the Atlantic Ocean. For example, the number of cyclones that have hit the coasts of the United States has maintained an average of approximately 18 per decade, if all categories (1-5) are included on the Saffir-Simpson scale, and 6 if we consider only the largest (3-5), without showing a clear tendency to grow or decrease. The fluctuations observed in the number of hurricanes would thus be due to natural causes and would not be related to climate change. We could not attribute the occurrence of a particular climate event, Hurricane Alex, for example, to global warming. However, Kerry Emmanuel of the Massachusetts Institute of Technology, through an analysis of the historical record of hurricanes, maintains that while these have not increased in number in recent years, their potency over their lifetime has increased in line with the rise of ocean temperature. On the other hand, the Intergovernmental Panel on Climate Change points out that if the rise in the temperature of the oceans by the greenhouse effect continues in the future, it is likely to increase simultaneously, both the maximum wind speed of hurricanes, as well as the rainfall that occurs. Will we witness in a future extreme weather events \u2013 hurricanes, droughts, heat waves or cold waves \u2013 caused by a growing global warming? At the moment, there may not be enough scientific evidence to answer this question in one direction or another. If we find in a future that the response is positive, however, our country would be very poorly equipped to deal with the problem. This is evident if we consider that the devastation caused by Alex in Monterrey occurred only two decades after the similar disaster due to Gilbert, without apparently taking sufficient preventive measures. If the frequency of major hurricanes increases in the future, we could not expect anything positive, neither for Monterrey nor for other cities in our country.",
    "https://upload.wikimedia.org/wikipedia/commons/a/ac/Retrato_de_Benito_Ju%C3%A1rez%2C_1861-1862.png": "During the almost two centuries that have passed since our political independence from Spain, we have seen that Mexico has suffered great difficulties in achieving sufficient social and economic development, and that it has been widely surpassed in this respect by other countries. These include the United States that began its expansion in the nineteenth century \u2013partly at the expense of Mexico \u2013 and Japan and South Korea, which in the second half of the twentieth century had impressive economic and technological growth. While there are many factors that have prevented Mexico from giving the \u201cstop\u201d forward, an insufficient educational system at all levels, and in particular at the higher level, has undoubtedly been a key element. Throughout independent Mexico, a good number of educational initiatives have been given, inspired by examples from developed countries. One of the most significant is the law that regulated public education in the Federal District and its territories promulgated by the government of Benito Ju\u00e1rez in 1867, and which was developed under the leadership of Gabino Barreda following the positivist ideas of Augusto Comte. One of the most significant was the law that led to the creation of the National Preparatory School, a great influence It is not enough, however, to transplant techniques and teaching methods developed in other latitudes, without adapting them to the environment in which they will be applied, since the students are not the same everywhere. In relation to this, in a recent article published by researchers of the University of British Columbia in Canada (J. Henrich and collaborators, \u201cBehavioral and Brain Sciences\u201d, 2010) the generalizations that are often made about some psychological aspects of the human species are criticized, and it is argued that many studies in this regard are carried out with populations of industrialized countries that are not always representative of the general population. They point out, for example, that aspects on analytical reasoning and cooperation between individuals are influenced by the cultural environment. Even aspects related to visual perception are determined by this environment and not by genes. For example, the optical illusion that occurs when two parallel lines of the same length are drawn, finished on both sides by arrows. One of the lines ends with missing arrows and the other one is well known. Although the two lines have the same length, the one drawn with the arrows found seems to have a smaller length than the other. This optical illusion, however, is not general, as Henrich and collaborators point out, and, for example, is not experienced by the members of the San tribe in southern Africa. We might conclude then that educational techniques must be designed specifically to the society in which they are to be applied. In reference to higher education in Mexico, texts produced in industrialized countries are often used in certain fields of knowledge. While a relatively small percentage of students have no problem taking advantage of these texts, it is not clear that they are so relevant to the rest. Both Japan and the United States, two of the most powerful countries economically, have a successful system of education of new researchers and high-skilled professionals in accordance with their economic development. Both systems have their own characteristics, adapted to the idiosyncrasy of Japanese or Americans as the case may be. It is known, for example, that the latter have an extreme individualism, while the Japanese tend to think more as a function of the group to which they belong. Thus, during his doctoral training, the tendency is for an American student to face up and solve for himself the problem that was assigned to him as thesis. A Japanese student, in contrast, tends to receive more help from his group colleagues and thus progresses faster in his thesis work. The latter, however, has a cost and it is possible that on average the American graduate tends to be more creative than his Japanese counterpart. The latter possibly generated the prevailing notion some decades ago that the Japanese \u201cdo not invent but only copy.\u201d True or false, however, this was not an impediment to Japan having had the impressive technological take-off that it had in past decades. In Mexico, in contrast, it has not yet been possible to establish a \u201cstyle\u201d of how to educate a graduate student. Mexicans do not have the individualism of Americans nor are we as gregarious as the Japanese. Our educational style should then be a combination of Japanese and American practices. Our tradition in the training of doctors, however, is still too young and incipient to have a defined personality. Hopefully it will not take us another two hundred years to achieve it.",
    "https://upload.wikimedia.org/wikipedia/commons/b/b9/Oktopus-Orakel_Paul_mit_Schuh.JPG": "South Africa\u2019s world football championship is about to end. It has been characterized by a large number of games that have been very closed, with extreme defensive and cautious play prevailing. From the point of view of the average number of goals scored per game, this championship has been one of the poorest ever held, being only surpassed in this respect by the tournament of Italy in the year 1990. In the midst of this climate of \u201cfootball desolation\u201d, the \u201cPulpo Paul\u201d has made a spectacular appearance, presumably having \u201cpsychic\u201d powers that have allowed him to predict successfully the results of the six football matches that Germany has held to date in South Africa. To enable him to express his predictions, Paul is presented with two transparent containers, identified one with the flag of Germany and the other with that of the opposing country, in which oysters or some other mollusk of those who serve him as food are placed. The prediction of the winner is established when the octopus chooses one of the two vessels, opens the lid and eats the mollusk. It is not clear, however, what happens next: If Paul simply ignores the second vessel to leave no doubt about his prediction, or if he also opens the other container and eats the second mollusk. The latter would give rise to skeptics to argue that what the octopus is actually trying to do is not predict the outcome of the football match but to eat the two mollusks \u2013 and that it has to start, of course, with one of them. It should also be recognized that the prediction mechanism is imperfect, for how could Paul predict a tie? eating the two mollusks? eating none? These questions are irrelevant once you reach the eighth stage of the end, when there has to be a winner; they are not, however, in the previous qualifying round.For Paul to have the ability to predict the results of football it would be necessary for the \u201cpsychic\u201d paranormal phenomena to exist that allow predicting the future. It would also be necessary for Paul to have a sufficient level of intelligence \u2013 just that he would share to a certain extent with other octopuses of his species \u2013 both to experience such phenomena and to express them in the right way \u2013 recono The German flag, for example, as soon as he saw it. Moreover, he should probably have football skills and be informed of Germany\u2019s ability and its possibilities in the cup. All this, however, is to assume too much. A simpler explanation is that Paul\u2019s predictions are actually the product of chance. In modern football, where defensive tactics prevail and teams play with great caution, the definition of a game often depends on a single defensive failure or lucky offensive action. This makes the prediction of the outcome of a football match uncertain, even for the connoisseurs of this sport. Thus, while recognizing that the team with better players or better game tactics has greater chances of success, a random prediction \u2013 equivalent to predicting the result obtained (aguila or seal) by throwing a coin into the air \u2013 in many cases it could be almost as good as a product of deeper considerations. Assuming, to simplify, that football results are the product of chance, how likely is Paul to have made by pure chance six correct predictions? This probability is the same for any possible combination of results. I mean, it was so likely that Paul would have made six correct predictions than six incorrect ones. It was equally likely that he would have predicted that Germany would win all its matches \u2013 he won five, losing only the second with Serbia \u2013, getting five correct ones and a failure. To know how likely it is to be right in all matches it is then necessary to find out how many possible combinations of results there may be. These combinations are 64, so that the probability of success in the six matches is 1 in 64. It seems in the first instance that a probability of 1 in 64 is very small, which would lead us to think that, after all, the octopus could have paranormal powers. We must consider, however, that Paul\u2019s case has been highly publicized, precisely because of its success, and that if it had failed \u2013 in its first two predictions, for example \u2013 most of us would not know of its existence. Besides Paul there are many animals with supposed paranormal powers in the world \u2013 probably many more than 64 \u2013 that have not been successful and that we do not know. The publicity generated by Paul, in recent days other \u201cpsychic\u201d animals have appeared in the press, including another octopus, a perico, a turtle and a seal, making predictions about the outcome of South Africa\u2019s final in one direction and another. Some will fail and others will succeed. The latter, however, will not prove that they have paranormal powers. The world football cup is one of the sporting events that most audiences capture. However, it is disconcerting to note that \u2013 perhaps due to the absence of goals \u2013 a \u201cdivine pulp\u201d has captured much of the attention that would be expected to be concentrated on football aspects.",
    "https://upload.wikimedia.org/wikipedia/commons/3/3e/Alcal%C3%A1_de_Henares_%28RPS_08-04-2017%29_Calle_WWW%2C_indicador.png": "Although it has not yet been two decades since the Internet began to expand around the world, our dependence on it has become critical. Today, the Internet is used for a multitude of activities that include banking operations, tax payments, the purchase of remote items, personal communication and the search for information of all kinds, to mention only some common uses of this modern communication system. So much has become accustomed to the Internet, that we often lose awareness of how much we have come to depend on it. The previous ones, of course, until the moment we are deprived of their use for some reason, as happened in recent days by the effects of cyclone Alex. The day we passed without \u201cnetwork\u201d gives us an opportunity to reflect on the Internet, one of the technological developments that has contributed the most to changing the world. The Internet had its origin in the so-called Arpanet network \u2013 financed by the United States Department of Defense \u2013 which in 1969 linked computers in four universities in California and Utah for data transmission. It was not, however, until the year 1991 \u2013 when the \u201cW\u201d was created. orld Wide Web\u201d \u2013 that the Internet began to function as we know it now. For this it was necessary, among other things, that the price of computers should go down enough so that its use would spread among the general population, what happened in the 1980s. Among other things, the Internet has revolutionized remote communications and has made the world smaller, so that today it is possible to establish contact practically instantaneously and at a reduced cost with people even on other continents. It is also possible to access the electronic version of newspapers from much of the world, with the latest local information. All this was unthinkable until very few years agoAnother revolution that has brought us the Internet \u2013 one of the most significant \u2013 has taken place in the field of dissemination of knowledge. This with the emergence of the \u201cwiki\u201d information banks, exemplified by the electronic encyclopedia Wikipedia. This encyclopedia, according to its website, today accumulates more than three million English articles of the most diverse subjects, which can be consulted free of charge. In contrast to a traditional encyclopedia \u2013 for example, the Encyclopedia Britannica \u2013 the author of an article on Wikipedia does not need to be an expert on the subject at hand. Furthermore, articles in this encyclopedia cannot refer to research topics, but should correspond to prior knowledge that can be validated. Wikipedia\u2019s open structure makes it vulnerable to the possibility that a particular author will enter false or unprecise information, either by mistake, by ignorance, or even deliberately as a vandal act. This has made it the target of criticism by those who consider it to be an unreliable source of information. However \u2013 as intrinsic to the opening of Wikipedia \u2013 an article published in it has to be subject to a process of continuous modification by those authors who consider it to contain errors. This presumably leads to the elimination of such errors. Wikipedia advocates even speak of a process of \u201cDarwikinian\u201d evolution \u2013 analogue to social Darwinism \u2013 through which an article published on Wikipedia undergo continuous improvements. It is noted, on the other hand, that in a study published in the journal \u201cNature\u201d in 2005 it was found that Wikipedia is actually only a little less precise than the Encyclopedia Britannica, which also contains errors. Despite reasonable doubts about the accuracy of the information contained in Wikipedia \u2013 which advises its use in a careful way \u2013 anyone who has used it can verify its usefulness, at least as a first approximation to the subject. One feature of the articles published on Wikipedia is that they contain references with links to other pages \u2013 even original, but not in all cases \u2013 that they can be consulted immediately. Thus, the speed with which Wikipedia can introduce us to a particular topic, including the immediate consultation of its sources of information is something that has no precedent. The Internet has so many advantages that we have quickly adopted and made part of our daily life \u2013 well we get used to it quickly. disappeared\u201d from our sight, only being noticed when it actually disappears, as it happened in past days.",
    "https://upload.wikimedia.org/wikipedia/commons/f/f6/EMBOTELLAMIENTO.jpg": "Those of us who live in the City of San Luis Potos\u00ed have been able to observe the congestion of vehicles that has occurred in recent years in our streets, especially the peak hours.This problem, which has affected Mexico City for decades, has become increasingly present in San Luis Potos\u00ed and other similar cities in our country.A look at statistical data from the INEGI shows us that, in fact and according to our assessments, the number of motor vehicles in our city is growing rapidly. An analysis of these data indicates that this number doubles approximately every nine years, a trend that has been maintained since the mid-1980s and until at least 2008 \u2013 the last year reported in the statistics of the INEGI. Thus, over the last quarter of a century, the number of vehicles in the city of San Luis Potos\u00ed has grown exponentially with a period of duplication less than a decade, with all the dangers that this represents. Thus, while in 1988 little more than 66,000 vehicles were circulating in our city, this one year. This increase is in sharp contrast to the corresponding increase in the population of the City of San Lu\u00eds Potos\u00ed of less than 100% in the same period.According to the previous numbers, in order to manage the growing number of motor vehicles, in the last quarter of the century the city of San Lu\u00eds Potos\u00ed would have to have multiplied by a factor of almost eight the capacity of its streets and fast roads to manage the growing vehicle traffic. The difficulty of achieving this explains also the increasing difficulties that we now experience to circulate in the city. Given the marked decrease in the production of vehicles in Mexico in the year 2009 due to the economic crisis \u2013 of 28%, according to data from the Mexican Association of the Automotive Industry (AMIA) \u2013 it is possible that the rate of growth in the number of motorists has decreased \u2013 which would have given us a sort of respite: a positive point among the multitude of problems that the economic crisis brings us. However, it is possible that the pace of growth in the number of motorists has slowed down. In the first five months of 2010 the same figures for the corresponding months of 2008, which would mean that the recovery has already been achieved or is on the way to being achieved. Moreover, as the case of Mexico City shows, winning the race to the accelerated growth of the number of cars is less than impossible, since the solutions always go back to the problem. According to the statistics of the INEGI, the average increase in the number of vehicles in the Federal District in the period 1980-2003 was considerably lower \u2013 and with ups and downs \u2013 than is currently observed in our city. However, it is possible that this is due to a kind of natural limit or physical impossibility to circulate in a small space \u2013 or possibly also to the process of decentralization of the capital of the country towards the states that includes the decentralization of traffic congestions. However, from 2003, the rate of increase of vehicles in the Federal District reached values similar to those of San Lu The automotive industry is one of the most important in our country, accounting for 3% of gross domestic product and 3% of employment. In the face of all its virtues, however, the sustained production of cars and the facilities to acquire them are congesting the streets of our cities and polluting the atmosphere with toxic waste and greenhouse gases. Although this could be considered a necessary evil for the time being \u2013 given the conditions of economic fragility of the country \u2013 in the immediate future a change in our lifestyle must be seriously contemplated, favouring public transport over car transport. If the number of cars in San Luis Potos\u00ed continues to grow at the current rate, in less than a decade the city would have to double the capacity of its streets to handle vehicle traffic; and this is only to preserve the current state of affairs. Otherwise, we could reach a situation where the number of cars in the city is self-limiting simply because there would not be enough space for their circulation. cars more like a \u201cplague\u201d than an advantage.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d6/Linbearbetning_masarns.jpg": "On June 13th, the Japanese Hayabusa probe returned to Earth after a 7-year journey to the Itokawa asteroid. This asteroid, which has the shape of a cacahuate of about 500 meters in length, follows an eccentric orbit around the Sun that brings it closer to the Earth\u2019s orbit and carries it beyond the orbit of Mars. Although it is not yet certain, the probe is expected to have returned to our planet with samples of asteroid material. The study of such samples would provide information about the origin of the solar system, since it is considered that celestial bodies such as Itokawa have remained unchanged since the formation of that system, in contrast to larger bodies such as the Moon or our own planet. Hayabusa arrived at the Itokawa asteroid in September 2005, descending a couple of times to its surface to collect samples. Due to the remoteness of Itokawa with the Earth, the probe had to carry out the descents autonomously, as the instructions that might have been sent to it from Earth would have taken several minutes to arrive on Earth. The last country to enter the space club was Iran, in 2009, on a date not distant from the return of its first artificial satellite. Today, there are ten countries, and two private North American companies, which have this capability. The last country to enter the space club was Iran, in 2009, on a date not distant from the date of its return, which would have prevented its control from being removed from the command centre. About three hours before entering the Earth\u2019s atmosphere, the Hayabusa ship expelled a capsule with the asteroid samples, which successfully descended in a desert region of southern Australia after enduring enormous temperatures from atmospheric friction. We will soon know if inside the capsule actually contains material from Itokawa. Although the Hayabusa probe experienced a series of failures that prevented it from completing all the projects that had been planned \u2013 for example, sending the Minerva probe of just half a kilogram to the Itokawa surface for a more detailed exploration of the same \u2013 the mission was an impressive achievement of Japanese technology. On April 20th, the Chamber of Deputies created the Mexican Space Agency (AEXA). According to the decree of creation, published in the Parliamentary Gazette, AEXA will have as its objective the definition, promotion and articulation of space activities in Mexico. As support it is stated that: \u201cThree aspects of opportunity were detected for Mexico in space matters, among them: the development of lunar terrain thanks to our proven capacity in the automotive industry; the development in the textile area, for the construction of lunar habitats, and the national operation of GPS system, in the area of small satellites.\u201d The project to create the AEXA was promoted by, among others, the American astronaut of Mexican descent Jos\u00e9 Hern\u00e1ndez Moreno, who traveled to the space station on board the Discovery ferry in August 2009. The AEXA has been labeled unnecessary and exotic in a country of great deficiency, and that it will become a white elephant. It would certainly be absurd to raise the possibility of sending an astronaut into space in the next decades with our means or to build an equivalent probe in a country of great deficiency. a Hayabusa, something that possibly not even the most determined promoters of the AEXA are proposing \u2013 at least in the short term. However, things that are considered in the same way are possibly beyond our reach, even in the medium term. It is not possible to think, for example, that the automotive industry in Mexico, which is basically a maquiladora, is an advantage for us to make a lunar vehicle, or that our textile industry enables us to make lunar habitats. The initiative to create the AEXA, however, will be positive if it generates an impulse to technologies that have been developed for and by the space industry. In this group we can include cells for the use of solar energy, prediction of the climate by means of satellites and the inventory of the natural resources of the country remotely using satellites, among many other applications derived from the space industry. A serious boost to the space activities in our country that will lead us in the future to the realization of projects of a certain magnitude \u2013 even without seeking to achieve the sophistication of projects such as the one of the Hayabusa probe\u2013 However, it will require considerably more resources than the 10 million pesos approved for the first year of AEXA\u2019s operation. This amount will be a great deal if this project results only in the creation of a bureaucratic office, and too little for AEXA to have a real impact on Mexico\u2019s scientific and technological development.",
    "https://upload.wikimedia.org/wikipedia/commons/4/4a/PrestigeVolunteersInGaliciaCoast.jpg": "More than six weeks have passed since April 20 when the deepwater Horizon drilling rig was set on fire in the Macondo oil field off the Louisiana coast. As it is in the public domain, as a result of the accident, the sinking platform caused an oil spill that to date has not been able to be controlled. British Petroleum, the company responsible for the platform, initially estimated that the oil leak was about 1,000 barrels a day, a figure that shortly thereafter increased to 5,000 barrels a day. Currently, this figure is considered to be between 12,000 and 19,000 barrels a day, although some experts believe that it could reach 100,000 barrels spilled every 24 hours. Whatever is clear now, what is clear is that the pollution caused by the \u201cDeepwater Horizon\u201d accident in the Gulf of Mexico, which now covers a larger area than that of the State of San Lu\u00eds Potos\u00ed, represents the worst oil and ecological disaster in the history of the United States. From the point of view of the volume of crude spill, it even has the potential to become the state of San Luis Potosi. At a rate of 19,000 barrels per day, the Deepwater Horizon spill would have reached the total volume dumped by Ixtoc 1 in six months. In the worst case considered, a 100,000 barrels of oil leak per day would have led to the Macondo well having already exceeded the volume dumped by Ixtoc 1. By comparing the accidents of the Campeche and Macondo oil wells there are coincidences: both were initiated by a sudden increase in pressure from the well followed by a failure of the device that must act in these cases to close it and avoid an uncontrolled leak of oil. The conditions faced by British Petroleum engineers to contain the oil leak from the Macondo well, however, are considerably more difficult than those encountered by Pemex specialists. 31 years. Indeed, while the marine depth of the Ixtoc 1 was only 50 meters \u2013 which allowed the use of divers the repair work \u2013 the mouth of the Macondo well is at a depth of 1,500 meters. At this depth the pressure exerted by the water is about 150 atmospheres, which makes it necessary to employ robots managed by remote control instead of divers. Even more, since the sunlight does not reach beyond a depth of about 200 meters, it turns out \u2013in addition to total darkness \u2013 that the temperature of the water is only a few degrees Celsius.Without possibly neither the high pressure nor the low temperature prevailing in the mouth of the Macondo well represent in itself great problems, the convergence of the two environmental conditions has proved fatal. This is because under such convergence, methane (natural gas) leaking from the well is combined with sea water to form crystals of methane hydrate. These crystals have been a headache in attempts to repair damaged well, covering up the methane well. In the fifth and last attempt to control the leak, last Thursday, 3 June British Petroleum engineers placed on the mouth of the Macondo well a bell-shaped device that seeks to capture most of the oil spilled and lead it to the surface. The operation, however, has had to be done very slowly in order to avoid the formation of methane hydrate crystals that would fret it. While it is reported that the new attempt has managed to reduce to some degree the oil spill, until the afternoon of Saturday 5 June it is not clear if it will finally succeed. In any case it represents only a temporary solution. The final solution \u2013 it is hoped \u2013 will be the two relief wells that are currently drilled by the rugged well and that are expected to be completed in the next month of August. These two wells will converge with the uncontrolled well at about 4,000 meters below the sea bottom. Once they are finished, they will be injected through them. This was precisely the procedure by which the Ixtoc 1 well was finally controlled. Thus, there would be similarities in both, the origin and the solution of the accidents suffered by both wells. It should be noted, on the other hand, that once the relief wells for the Ixtoc 1 were finished, three months passed before the escape was finally controlled. If the similarities between the two accidents were extended, then we would have to wait until next November to finally see the Macondo well under control. If so, the Deepwater Horizon accident would possibly constitute by far the worst ecological disaster in history.",
    "https://upload.wikimedia.org/wikipedia/commons/3/3b/Carter_leaving_Three_Mile_Island.jpg": "The decades of the 1960s and 1970s were a period of boom for the power generation industry through the disintegration of the atom. Half a century ago nuclear technology \u2013 then a relatively recent development \u2013 was seen as a way of obtaining abundant and reliable electricity. Some countries such as France and Japan \u2013 which do not have fossil fuel reserves \u2013 made nuclear energy one of their largest sources of supply; France even made it the largest. However, over the years, enthusiasm in the electricity core \u2013 especially in the United States \u2013 was reduced by high costs of building a nuclear reactor, as well as by the accident, in 1979, of the Three Mile Island nuclear reactor in Pennsylvania, USA. The situation was aggravated by the disaster in 1986 of the Chernobyl plant in Ukraine, which exploded and dispersed radioactive material in a large radius that reached northern Europe. For a decade, however, and despite the dangers it presents, interest in nuclear energy has recapped, motivated by the high prices of oil and due to the effects of atmospheric pollution from the use of oil. It is currently produced in 438 reactors, dispersed around the world, although located mainly in the United States, France, Japan and Russia, in that order. 54 reactors are currently under construction in the world and 148 more are under planning.From the point of view of atmospheric pollution by greenhouse gases, nuclear plants are certainly a \u201cgreen\u201d non-polluting option. Nuclear energy, however, presents serious problems of radioactive pollution, not only because of the always present possibility of a nuclear accident, but also because of the radioactive waste they generate, which must be confined to a safe place. Confinement is necessary not only to avoid accidental human contact with radioactive material, but also to prevent its theft by terrorist groups, something that today cannot be ruled out. As part of the \u201crebirth\u201d of nuclear energy, several private companies in the United States and Japan are developing nuclear reactors of reduced dimensions, with megawatts or tens of thousands. A Japanese manufacturer, for example, has developed a 200 kilowatt micro reactor \u2013 capable of providing electricity to some 100 homes \u2013 which measures only 7x2 meters. Micro reactors would not be intended to compete directly with nuclear power plants, but would have their largest application in remote locations away from electricity distribution lines, as there are many in underdeveloped countries. According to an American manufacturer, the small size of a micro reactor would allow it to be assembled and sealed in the United States with the charge of nuclear fuel inside it. Thus, users in the destination country would not have access to the reactor, which would have enough fuel to operate tens of years without interruption. Fuel recharge would be done in the United States, which would also be responsible for handling radioactive waste. This scheme, however, has provoked criticism. For example, Peter Wilk of the organization \u201cPhysicians for Social Responsibility\u201d states. That American public opinion would hardly agree: \u201cImagine if the Americans would agree to take the waste generated in other countries and manage it here.\u201d The proliferation of micro reactors in developed and underdeveloped countries would imply multiplying the danger of a nuclear accident. It would also present major problems in guarding the nuclear fuel housed inside micro reactors, which would be dispersed in multiple places. In these conditions it is difficult to understand the arguments of the companies that present micro reactors as a viable alternative to power generation and to curb global warming. Nuclear power in general and nuclear micro reactors in particular are certainly a \u201cgreen\u201d option that does not generate greenhouse gases and does not contribute to global warming. Micro reactors, however, could have \u201cblack\u201d consequences in the event of an accident or fuel theft, eventuality that would now be considerably more likely.",
    "https://upload.wikimedia.org/wikipedia/commons/3/37/Wilson1900Fig2.jpg": "The living beings are made up of chemical elements \u2013 carbon, hydrogen, oxygen, etc. \u2013 which can also be constituents of inanimate materials. This leads us to an elementary question: if both living and inanimate matter can be formed by the same atoms, why does one and the other behave so differently? The question has been in the air for a long time, without a conclusive answer being given. According to the vitalist point of view, there is a \u201clife force\u201d necessary to give life to the inanimate matter, which would make it qualitatively different from its inanimate counterpart. According to the opposite view, the living matter is formed by an aggregate of chemical elements, without the participation of a vital force of immaterial or spiritual nature. Last Thursday, May 20, a group of researchers working for the American private company, \u201cJ. Craig Venter Institute\u201d, headed by J. Craig Venter, reported in the magazine \u201cScience\u201d to have managed to manufacture a cell by artificial methods. This would be proof that living matter is no more than an aggregate of atoms \u2013 although, As a first step in the manufacture of the artificial cell, the genome of the bacterium \u201cMycoplasma mycoides\u201d was synthesized using the genetic information that was available. Subsequently, the artificial genome was inserted into the bacterium \u201cMycoplasma capricolum\u201d, replacing its natural genome. Thus, since the genome of an organism contains the necessary instructions for its reproduction, the host cell began to reproduce according to the pattern dictated by the synthetic genome. It was thus transformed into a different cell. In statements to the newspaper The Independent, Venter stated: \u201cThis is the first synthetic cell that has been made, and we call it synthetic because the cell was completely derived from a synthetic chromosome, made with four bottles of chemical substances in a chemical synthesizer, based on information stored in a computer.\u201d However, it had previously been able to modify the genome of an organism using different techniques \u2013 through species crossing or through genetic engineering \u2013 it had never been done on the scale on which the scientists of J. Craig Venter, Not all experts, however, agree that Venter\u2019s group has created a genuinely synthetic cell that represents a new form of life. George Church, a geneticist at Harvard Medical School, for example, points out that, although with small variations, the synthesized cell is actually a copy of an existing cell and therefore does not qualify as a new form of life (Science, May 20, 2010). Similarly, Steem Ramussen, professor of physics at the University of Southern Denmark, notes that the instructions contained in the genome are not enough to build living matter, but that a certain amount of energy is needed, which is provided by cell metabolism, as well as a protective barrier \u2013 the cell membrane \u2013 within which the whole process occurs. Venter\u2019s synthesis attended the genome part, but not the physical sustenance for the reproduction of living matter. Thus, the resulting cell would be only semi-synthetic. In the words of Jim Collins, professor of biomedical engineering at the University of Boston: \u201cFrankly, scientists do not know enough biology to create life. Although the human genome project has expanded the list of parts that make up a cell, there is no manual with the instructions to assemble them and produce a living cell. It is like trying to assemble a jumbo jet with only its list of parts. Although some of us who work in synthetic biology may have delusions of greatness, our goals are much more modest\u201d (Science, May 2010). However \u2013 delusions of greatness on the margin \u2013 even if biology is far from creating truly artificial life and we have to delay the definitive declaration of death of lifeistic ideas about the origin of life, it is clear that the outcome of the Venter group is a very strong blow. This result tells us that, very likely, sooner or later, a level of scientific knowledge will be reached. and technologically such that it will make it possible to build living organisms from scratch, with physical characteristics designed at will. It is possible, however, that some of us do not see it.",
    "https://upload.wikimedia.org/wikipedia/commons/b/b7/Lichte_en_zwarte_versie_berkenspanner.jpg": "One of the most eye-catching scientific results reported in recent months is the genetic evidence of the crossing of our human species with the Neanderthal species, which would have occurred in the Middle East some 80,000 years ago. This evidence, which was published last May 7 in the journal \u201cScience\u201d by an international group of researchers led by Svante Paabo of the Max Planck Institute of Evolutionary Anthropology in Germany, is based on the analysis of the Neanderthal genome extracted from bones found in a cave in Croatia, which have an age of about 40,000 years. According to this study, the genome of modern man has contributions from the Neanderthal genome, which demonstrates its hybridization. The first fossils of the Neanderthal species were discovered in Belgium in 1829. A second discovery was made in 1848 in Gibraltar. It was not, however, until a third finding was made in 1856 in the Neander Valley in Germany \u2013 where the Neanderthal species takes its name \u2013 that was recognized as a human species other than the Neanderthal species. Since then numerous sites with Neanderthal remains have been discovered in Europe and the Middle East. It is known that the Neanderthal species migrated from Africa to the Middle East and Europe hundreds of thousands of years ago and remained on the European continent until its extinction some 25,000-30,000 years ago. Thus, they would have lived with us in the Middle East and in Europe for tens of thousands of years and the necessary question is what kind of relationship we had with them. Possibly prejudiced, the answer that was initially given to this question is that our species had made war on the \u2013 supposedly inferior \u2013 Neanderthals until they ended. In recent years, however, it has been speculated that perhaps, after all, the relations between the Homo sapiens and the Neanderthal might have been \u2013 in some cases \u2013 more friendly. Thus, in 1998 they were discovered in Abrigo dogar Velho, Portugal, the remains of a four-year-old child, with an age of 25,000 years, who have an anatomical features. In a scientific paper published in 1999 by a group of Portuguese researchers and other European countries, this has been interpreted as evidence of the crossing between these two human species. Paabo\u2019s results and recently published collaborators add to Lagar Velho\u2019s archaeological evidence, new evidence \u2013 in this case genetic evidence \u2013 that modern man and Neanderthal were mixed at some point tens of thousands of years ago. So, as Paabo mentions, the Neanderthal somehow did not become extinct, but lives among us in the genes of a part of the world\u2019s population. An interesting result of genetic studies on the Neanderthal genome is that it is present in European and Asian populations but not in African populations. This suggests that the crossing between Neanderthal and Homo sapiens occurred after the latter left Africa, possibly in the Middle East. This conclusion was reached after comparing the genome of five native people from Africa, China, Papua New Guinea and France. Thus, while Europeans and Asians are related to Neanderthals, this is not the case for Africans. The discovery of our relationship with Neanderthal will surely change the way we see ourselves. When Charles Darwin laid out his theory of natural selection and evolution of species 150 years ago, he provoked strong reactions because of its implications for our position in the natural world. Little by little, however, we have adapted to these implications. Thus, for example, and although not universally, today we accept that chimpanzees and modern man have a common ancestor. This acceptance has possibly been facilitated by the fact that the common ancestor lived in an extraordinarily distant age, several million years, with which the parentage is extremely distant. Furthermore, our intellectual superiority over chimpanzees is incontrovertible.In contrast, we know that there was no marked difference in intellectual capacity or physical appearance between modern man and the Neanderthal, which had a larger brain. Both species, moreover, interacted in a relatively close time, at least 25,000-30,000 years ago, which is only three times the time since the invention of agriculture and the beginning of our civilization. Thus, there is an effect of proximity in time and intellectual capacity that makes it more than obvious that we do not occupy a special place in the world. So evident is that even a large part of the inhabitants of the world come from a hybridization of two human species, resulting from relations more than friendly.",
    "https://upload.wikimedia.org/wikipedia/commons/1/17/Vladimir_Lenin.jpg": "According to Evo Morales, President of Bolivia, the transgenics and chicken meat that are consumed in developed countries is a cause of baldness in their male population as well as of \u201cdiversions in their being as men.\u201d The latter is due to the female hormones that are added to the food of birds in order to increase their growth. The Bolivian President expressed these views during the opening of the World Conference of the Peoples on Climate Change and the Rights of Mother Earth, held in Cochabamba, Bolivia, from 20 to 22 April.In relation to the cause of baldness, Morales came to his conclusions by comparing the apparent number of bald people in industrialized countries with the corresponding number in the indigenous population in Bolivia, setting himself as an example. Evo Morales' comments produced negative reactions around the world and were crossed out of no scientific basis. Taking an open point of view and invoking free discussion of ideas, however, we should perhaps consider them as hypotheses based on observation of natural facts. The study was published in the journal \u201cNature\u201d in February of this year. Another major challenge facing Morales\u2019 approach is that chickens are not actually given hormones. It can be pointed out that, in this way, Evo Morales\u2019 observations or in the light of the results of experiments designed specifically for this purpose. Thus, Evo Morales\u2019 assertions resist little. For example, it can be noted that long before the transgenics were developed, bald people already existed. Among these \u2013 from different times and with different degrees of baldness \u2013 we can count Socrates, Julio C\u00e9sar, Leonardo da Vinci, Charles Darwin, Piotr Ilich Chaikovsky, Miguel Hidalgo, Vladimir Ilich Lenin and physicists Max Planck and Enrico Fermi. There is evidence, even, that they existed bald thousands of years ago, as concluded by an international group of researchers led by Morten Rasmussen of the University of Copenhagen. This group analyzed the DNA of the hairs of an individual who lived in Groeland 4,000 years ago, finding that he had a predisposition to baldness. , for example, that the \u201cFood and Drug Administration\u201d of the United States prohibits its use in chickens \u2013 although it allows its use in small quantities in the feeding of cattle. From all of this, we can then conclude that Evo Morales did indeed make his comments in a hasty manner and with little scientific support. The World People\u2019s Conference on Climate Change and the Rights of Mother Earth, according to Evo Morales, was necessary because of the failure of the climate change meeting held in Copenhagen, Denmark, last December, and in which quantitative greenhouse gas reduction targets could not be established. The Cochabamba conference issued a communiqu\u00e9, the \u201cPeople\u2019s Agreement\u201d, in which it demands that industrialized countries, which are responsible for global warming, take charge of remedying the climate crisis. Among other things, the statement raises the demand that industrialized countries reduce their greenhouse gas emissions by 50 per cent compared to 1990 levels, as well as the establishment of an \u201cAccommodation Fund\u201d to \u201cffront climate change\u201d, managed by developing countries. It is also stated that \u201cIt is the duty of developed countries to share their technology with developing countries, to create research centres for the creation of their own technologies and innovations, as well as to defend and promote their development and application in order to live well.\u201d Apart from the fact that some of the demands contained in the Peoples Agreement are clearly unviable \u2013 as is certainly the 50 per cent reduction in greenhouse gas emissions over a 10-year period \u2013 the document\u2019s approaches are morally fair. That is, if industrialized countries are most likely to cause the atmospheric pollution we suffer, it is just as well to cover the greater part of the cost of remedying it. We cannot, however, assume that a moral consideration is sufficient pressure on rich countries. In particular, we cannot expect that they will spontaneously transfer their technology to us and help us to establish research and innovation centres as set out in the Agreement on Climate and Environmental Justice. People. Even if this were the case, most developing countries, which do not have adequate scientific and technological infrastructure, would not have the capacity to absorb it. Evo Morales\u2019 uninformed and careless discourse, while recognizing that it has been magnified by the media and perhaps taken out of context, is a reflection of this situation. One thing is clear: if developing countries do not help themselves by creating their own scientific and technological research infrastructures, hardly anyone else will create them for them.",
    "https://upload.wikimedia.org/wikipedia/commons/2/23/Lasers.JPG": "Next May, the laser, one of the greatest inventions of the 20th century, will be 50 years old. This device was born in May 1960 in the research laboratories of the company Hughes Aircraft in Malibu, California. Its inventor was Theodore Maiman, who advanced to many other researchers in the race to build the first laser of history. Maiman published his discovery in the magazine \u201cNature\u201d in August 1960. Maiman\u2019s invention was a major scientific breakthrough that led to practical theoretical ideas about the possibilities of making a device with the characteristics of a laser. At first, however, and despite the great scientific progress that it constituted, the laser was not expected to have greater applications; in fact, it was described as an \u201cinvention in search of an application\u201d. In the end, 50 years after its invention, the laser has had a huge practical impact, comparable to that of the transistor. The utility of the lasers has to do with the very special characteristics of light they produce, which is radically different from that emitted by ordinary sources \u2013 the Sun, for example\u2013. If we compare the light emitted by a laser pointer to that which comes from an incandescent focus, we notice the light of the pointer travels in a straight line and has a pure color \u2013 often red\u2013, while the light of the focus travels in all directions and has a reddish color, resulting from the mixture of several pure colors. Straight line propagation and purity of color are two attributes that we can find in laser light and hardly in ordinary light. Taking advantage of its rectilinear propagation, by means of a laser we can, for example, measure distances with great precision. Thus, very precise measurements have been made of the distance between the Earth and the Moon by directing a laser towards the surface of our natural satellite and taking the time it takes to come and go after reflecting on its surface \u2013 for this we use the mirrors that the astronauts of the Apollo project placed on the surface of the Moon forty years ago\u2013. This type of measurements could hardly be made with ordinary light that spreads in all directions. Without lasers, the world would be very different today. For example, compact discs (CDs) \u2013 which use a laser to play music or video recorded on them \u2013 and we would most likely continue to use magnetic tapes to listen to music. Likewise, there will not be barcode readers used in supermarkets\u2019 register boxes, which would make our purchases take considerably longer. We would not have laser printers, with all the convenience they represent, nor would we have at our disposal ophthalmic techniques that use lasers to correct in an instant myopia or astigmatism, or to fix a detached retina. Lasers are also used to cut and solder metals, in optical tomography systems to see the inside of the human body, and to measure atmospheric pollution, among many other applications. Among the multiple and varied areas of application of lasers, telecommunications is possibly the field in which these devices have had their greatest impact. Indeed, today long distance communications are dominated by optical fibre-based communication systems, and laser \u2013 which is the generator device of lasers. The development of telecommunications, on the other hand, has had a great social impact; this is especially true in relation to the Internet, which has established new forms of personal interaction and knowledge exchange, including so-called \u201csocial networks\u201d. In reference to the above, the Internet has had an explosive growth in the last two decades. According to data from the International Telecommunication Union, an organization of the United Nations, the number of Internet users in developed countries rose exponentially in 2007 to 62 users per 100 inhabitants. In developing countries, the figures are smaller, but growth is accelerating. According to the same United Nations source, the number of Internet users per number of people in developing countries rose exponentially in the period 2000-2007, doubling approximately every two and a half years and reaching a figure of 17 users per 100 inhabitants in 2007. Our times are characterized by unprecedented technological advances and laser is one of the most significant. Many applications have been found and many more will surely be found in the future, a very special light.",
    "https://upload.wikimedia.org/wikipedia/commons/a/a6/World_Bank_building_at_Washington.jpg": "One news that was widely disseminated in recent days was the case of the account holder who in May 2004 sued Banamex Bank for payment of the interest on a 400 pesos deposit made in 1987. The deposit contract was valid for 28 days and specified its indefinite renewal under the same originally agreed conditions, unless there were instructions in another direction. As a result of the lawsuit, in 2006 the Supreme Court of Justice of Chihuahua ruled that the bank would have to pay the customer around 14 billion pesos for interest. This stratospheric sum was the result of the annual interest rate of 91.3 % agreed between the bank and the customer in the original contract. Inflation in Mexico in 1987 was higher than 100 % and a rate of return of 91.3 % was not unusual. Starting in 1989, however, inflation in our country has been considerably lower \u2013even in 1995, the year of the last major economic crisis \u2013 so that the renewal of the original bank deposit contract continued every 28 days, has generated an absurdly high return, which The conversion of 400 pesos to 250 billion pesos over a period of 23 years is an example of the dangers of geometric or exponential growth. An exponentially growing amount doubles every certain time interval. In the present case, an annual interest rate of 91.3 % with contracts to 28 days implies that the capital doubled approximately every ten months. Thus, the initial 400 pesos were converted to the ten months at 800 pesos and these at 1600 pesos after ten months, and so on. In the first years the increases in capital did not constitute any problem for the bank. Reached a certain point, however, the situation became critical. This is evident if we consider that between 2004 and 2010 the accumulated interest went from 14 billion to 250.000 million pesos, being this last amount clearly unpayable \u2013 said amount, in addition, it will double in ten more months and will quadruple in less than two years. Thus, a deposit of 400 pesos that seemed harmless at the beginning, became a formidable debt with the passage. Although there are not few examples of quantities around us that grow exponentially \u2013 the epidemics in their early stages, the population of the world in some times, the chains and schemes of the Ponzi type to rent money, the power of computers, the compound interest that is charged to credit cards and possibly the traffic of automobiles in some cities in our country, among other examples \u2013 we rarely think about the consequences that can bring us. The danger is that a quantity that grows exponentially does not look particularly worrying in its initial stages, until suddenly it explodes and becomes unmanageable. Exponential growth has consequences at first sight unsuspected. It is surprising, for example, to corroborate that a 28-day deposit contract with an annual rate of 91.3 % produces in the long term interest radically different from those that would produce a contract with the same interest rate but with expiration a year. In this last case, a bank deposit of 400 pesos would generate at the end of 23 years around 1500 million pesos instead of the 250,000 million pesos generated. On March 23, the Supreme Court of Justice of the Nation granted Banamex an amparo against the ruling of the Supreme Court of Justice of Chihuahua. The decision of the Supreme Court was based on an interpretation of the meaning of the words \u201csame conditions\u201d, set in the original deposit contract to refer to the conditions under which the contract would be renewed every 28 days. In reference to the interest rate, by \u201csame conditions\u201d the Supreme Court understood the maximum rate fixed by the Bank of Mexico at the time. Apart from technicalities and legal interpretations, however, the underlying considerations in the deliberations of the Supreme Court were those that derive from the inability of the bank to cover a stratospheric amount of interest, which is also doubled every ten months. Thus, Minister President Guillermo I. Ortiz Mayagoitia expressed: \u201cWe have said this many times, banks do not operate this type of business with their own money, they receive large amounts of money from savers.... And this money that is not theirs is the money that they lend to third parties... These conditions if the bank lends what is not its own, it is where the state necessarily intervenes to put clear rules that prevent ruinous operations that could lead to bankruptcy to a bank that was not careful, diligence in the conclusion of its contracts.\"The neglect in the elaboration and handling of the deposit contract that caused the legal conflict \u2013 and that deserved a scolding by Minister Ortiz Mayagoitia \u2013 can be attributed, at least partially, to the ignorance that we usually have about the consequences of exponential growth. Since around us there is a good amount of things that grow exponentially, we would do well to become aware of those consequences.",
    "https://upload.wikimedia.org/wikipedia/commons/1/1a/Charles_Darwin_by_G._Richmond.jpg": "The last issue of the British scientific journal Nature included an article signed by researchers from universities in the United States and Ireland that reports neurological experiments designed to determine the degree of rejection that humans have by situations of social inequality. Today, it is considered that altruism and cooperation between humans has been a necessary condition for the development of civilization and therefore must have become part of human nature through an evolutionary process. Even war, which has been a constant in the development of civilization, is considered a reflection of our altruistic nature, because \u2013 excluding mercenaries \u2013 an army could not otherwise be formed to defend a common cause exposing soldiers to a mortal danger. The reference study provides neurological evidence in favor of the fact that human beings have intrinsic tendencies that leads them to seek to reduce inequalities between people, even if this represents an individual cost. The experience was carried out with forty men without any kind of relationship between them. Twenty couples were formed and at the beginning all participants were given $30. In order to create a situation of inequality, one of the members of each couple was given 50 dollars more. The other member, instead, received no additional amount. Two groups were thus created: \u201crich\u201d and \u201cpoor.\u201d Once at this point, they were confronted with the possibility of receiving additional amounts of money and their neuronal response was measured in areas of the brain that are known to respond to monetary rewards. This response was determined indirectly by functional magnetic resonance techniques, which detect positive or negative changes in blood flow to certain parts of the brain resulting from an increase or decrease in neural activity. The study showed that the rich members had a greater positive reaction to the possibility of an additional transfer of money to their poor partner, than the one that showed before a possible monetary transfer to themselves. Just the opposite reaction was observed among the poor members of each couple. The general reaction was then in the direction of reducing inequality between rich and poor. In another study carried out also through functional magnetic resonance techniques by a group of researchers in the United States, Italy and Brazil, the activity was measured. The neuronal that takes place during the act of making a charitable donation, revealing the neurological bases of altruism. The belief in an altruistic nature of the human race has not always existed. In the nineteenth century, for example, the natural selection \u2013 postulated by Charles Darwin as the mechanism that originates the evolution of species and that is synthesized in the phrase \u201csurvival of the fittest\u201d\u2013 led to the concept of \u201csocial Darwinism\u201d \u2013 not subscribed by Darwin\u2013 that moved the natural selection from the biological field to the social. Social Darwinism served to support doctrines such as \u201claissez faire\u201d that it advocates for capitalism without any restraint on the part of the State and that inevitably leads to social inequality. It was also used in eugenicity that proposes a genetic improvement aimed at the human race and that served as an ideological foundation to Nazism. The results of the studies described above indicate that the ethical and moral teachings on the virtues of altruism effectively reflect human nature. However, they also point to the fact that they have a final foundation in the chemistry of the brain. that the organization of the brain determines the behavior \u2013 moral or immoral \u2013 of an individual has profound religious and legal implications, since it calls into question the concept of free will. However, no scientific theory or conclusion can be taken as definitive and subsequent results can confirm or refute it. Studies on the brain\u2019s neuronal response to moral disjunctives, which point to a benevolent human nature towards others, will have to be confirmed by future studies. At the moment, our daily experience \u2013 far from the rigor with which scientific research is conducted \u2013 indicates that if the human race is by altruistic nature, some of our fellows show a special commitment to conceal it.",
    "https://upload.wikimedia.org/wikipedia/commons/5/5d/Eug%C3%A8ne_Delacroix_-_Le_28_Juillet._La_Libert%C3%A9_guidant_le_peuple.jpg": "From 8 to 18 February, Vernor Mu\u00f1oz visited Mexico, Vernor Mu\u00f1oz Villalobos, Special Rapporteur on the right to education of the UN Human Rights Council. Vernor Mu\u00f1oz\u2019s stay included visits to Chiapas, Baja California, Nuevo Le\u00f3n and the Federal District, as well as interviews with the Secretary of Education, the Rector of UNAM and the Director of IPN. At the end of his stay, Vernor Mu\u00f1oz offered press conferences in which he announced some conclusions of his visit to our country, which are part of the report that will be presented next June to the United Nations Human Rights Council. Among other things, Vernor Mu\u00f1oz criticized the relationship between the Ministry of Public Education and the teachers\u2019 union that he described as \u201catypical simbiosis\u201d, which, although it has sometimes resulted in collaboration, in others has represented an obstruction. He also referred to the differentiated educational opportunities of the different socio-economic groups in Mexico. The decision to appoint a Special Rapporteur was taken by the UN Commission on Human Rights in 1998. The mandate of the Special Rapporteur focuses on the right to education as set out in article 26 of the Universal Declaration of Human Rights. This declaration establishes the right of every person to receive free elementary education, as well as widespread access to higher education on the basis of individual merits. It also establishes as an objective of education: \u201cthe full development of the human personality and the strengthening of respect for human rights and fundamental freedoms.\u201d In line with the above, according to the Universia-Mexico portal, during his visit to UNAM Vernor Mu\u00f1oz noted that education does not exist to solve the problems of employers \u201cas such would be reduced to the mandates determined by the world economy\u201d, but that its objective is to develop the human capacities that have to do with philosophy, letters and work. The ultimate goal of education must, of course, be the individual and collective well-being of the members of a society. As stated by the Organization for Economic Cooperation and Development, the economic development of a country depends on its capacity for innovation, and this in turn depends on the educational level of its population. Technological innovation then requires a training system of highly qualified scientists and engineers, which in the case of Mexico is not efficient enough. This is evident from the fact that a significant percentage of students who arrive at our higher education institutions do not have sufficient academic qualifications and, more seriously, sufficient motivation to pursue university studies. It is known that preschool children develop negative attitudes towards science-related activities in response to a poor perception that they themselves have about their own skills in this area. These negative attitudes are an obstacle to the successful realization of their present and future school duties around these activities, and prevent them from developing a taste for science that leads them to decide in the future for a scientific career. This article cites the work carried out by a group of researchers at Purdue University in Indiana, United States (www.purduesscientificliteracyproject.org), which developed a program to introduce preschool children to science issues, emphasizing the scientific method of seeking answers to natural phenomena. According to research from that group, it is possible to change negative childhood attitudes towards science with adequate training.Introducing science education at preschool level in Mexico is remote given the enormous challenges facing elementary education in our country.In fact, even in a developed country like the United States, it presents great difficulties. However, the prospect that industrialized countries in the near future will implant educational methods that lead them to produce more and better highly qualified scientists and engineers is worrying for a country like ours that at this point has not managed to solve their serious education problems, as Vernor Mu\u00f1oz pointed out.",
    "https://upload.wikimedia.org/wikipedia/commons/3/3c/Bacino_imbrifero_Niceto.png": "In recent weeks, the criticism of anti-climate change activists against the action of the Intergovernmental Panel on Climate Change (IPCC), especially against its president Rajendra Pauchari, began last November when numerous emails stolen \u2013 \u201chacked\u201d \u2013 from the Climate Research Center of the University of East Anglia in the United Kingdom were \u201cupped\u201d to the Internet. These emails are part of the correspondence between different climate experts working for the IPCC and from them it can be interpreted that these experts did not always act with strict adherence to the rules of scientific ethics of free discussion of ideas. In some mails there is even talk of concealing climate data that do not support the the the thesis of global warming. Something that made the situation worse for the IPCC is the recognition by its president that a prediction of the panel included in his 2007 report \u2013 in the sense that the Himalayan snow will have melted in 2035 because of global warming \u2013 does not really have a scientific basis. Pachauri, they question the seriousness of the work and reports of the organism. An essential characteristic of science is that its claims never have an absolute certainty and are always susceptible to be refuted by subsequent research. The free discussion of its results is what has given science an unprecedented predictive power in the history of civilization. This has made possible the emergence of technologies of a great and growing sophistication. It has led, for example, to the development of computers, artificial satellites, synthetic materials with non-existent properties in nature and drugs to cure diseases. The construction of a device as complex as a computer, or the development of new antibiotics to attack infectious diseases, requires a detailed knowledge of the laws of physics and biology. The predictive power of science, however, is not absolute, and depends on the complexity of the object under study or the scientific field that is considered. Thus, we can be reasonably certain that by tightening the button of a television set - a product of our advanced knowledge in the field of physics-, this will behave as we expect and a picture will appear on the screen. . On the other hand, when administering a drug to a patient there is a not negligible probability that it does not work. This reflects the difference of complexity between living matter and inanimate matter, which makes it inherently more difficult to discover the laws that govern the former in comparison with the latter. In the case of climate change, the object under study \u2013 the entire planet \u2013 is extremely complex and the predictive power of climate science is only relative. There is then some uncertainty about what will happen to the temperature of our planet in the years to come and from this have used the detractors of climate change to challenge it. There is, however, incontestable scientific evidence that the surface of the Earth is warming. In a report from the National Academy of Sciences of the United States, for example, it is concluded that the Earth temperatures in the last decades have been higher on average than those observed in the last 400 years. The increase in the temperature of the planet is also reflected in the North Pole's thaw during the last summers and in the retraction of ice in the glaciers. . We know, on the other hand, that the concentration of carbon dioxide in the atmosphere has increased gradually in the second half of the last century. Measurements of this concentration in Mauna Loa, Hawaii, show a gradual increase of more than 20% over the last 50 years.The probable cause of this increase is the burning of fossil fuels.Since it is known that carbon dioxide in the atmosphere generates a greenhouse effect, the increase in that concentration in parallel with an increase in the temperature of the earth\u2019s surface suggests that both increases are related and have a common origin in the use of fossil fuels.Global warming is a problem that requires urgent attention.It is necessary, specifically, to replace fossil fuels with renewable energy sources.In a world that has based its development on oil, gas and coal, the proposal to replace them with non-polluting sources has definitely given rise to resistances and political problems on the part of the interests created around fossil fuels.This is reflected in the anti-climate change activism. the most convenient for the health of the planet.",
    "https://upload.wikimedia.org/wikipedia/commons/0/04/Kluft-photo-Carrizo-Plain-Nov-2007-Img_0327.jpg": "In an interview with the scientific journal Scientific American on January 6, Robert Yeats, professor of Geosciences at Oregon State University, said he was less concerned about the possible earthquake of great magnitude that has been predicted for years to occur in Southern California, that the great earthquake that would most likely soon take place in Haiti. As we all know, Yeats \u2013 like other experts who thought in the same direction \u2013 unfortunately had a prophet's voice and less than a week later his prediction was fulfilled. Earthquakes occur when energy is released from portions of the earth's crust subject to enormous forces of tension or compression. This happens, for example, along the border between two tectonic plates. It is known that the earth's crust is formed by masses \u2013 tectonic plates \u2013 that are kept moving relative to each other. Thus, the forces of friction that are produced at the border between two plates moving in the opposite direction can accumulate an enormous amount of energy, which is released when the rocks at the border are broken by the tension. . There are well-identified geological faults along the Earth\u2019s surface where these tensions occur and therefore a source of telluric movements. One of the most studied is the San Andr\u00e9s fault, which crosses the state of California from north to south along 1300 kilometers and which corresponds to the border between the tectonic plates of the Pacific and North America. This failure was the cause of the earthquake that destroyed the city of San Francisco in 1906, causing between 700 and 3000 deaths, in what constitutes the worst catastrophe in the United States due to an earthquake. In more recent years, a geological failure near the city of Los Angeles caused in 1994 an earthquake that caused 72 deaths and caused damage for 20 billion dollars. A measure of the destructive power of an earthquake gives it its magnitude on the Richter scale. The San Francisco earthquake of 1906, for example, had a magnitude between 7.7 and 7.9, while the recent one in Haiti was of magnitude 7. To appreciate the difference in intensis, one point on the Richter scale must be considered to represent a multiplicative factor due to its magnitude. A magnitude 8 earthquake is then 30 times more destructive than a magnitude 7 earthquake that destroyed Port-au-Prince on January 12, causing as many as 200,000 deaths, had its origin in the Enriquillo fault located near the border between the North American and Caribbean tectonic plates. There had not been a major earthquake near Port-au-Prince in 150 years and experts considered as high the probability that this would happen in a short time.Comparing the earthquakes in California and Haiti, the contrast between the number of deaths and the material damage that occurred in San Francisco and Port-au-Prince was striking. This, however, is easily explained by the poor quality of the constructions in Port-au-Prince and the lack of prevention by the Haitian government in relation to the occurrence of a disaster such as the one suffered, despite the scientific evidence available. All of this in turn, reflects poverty in a country that occupies the last place in Latin America. Yeats was not the only one that expected a catastrophe in Haiti like the one that eventually occurred. Other experts in the world considered it very likely, Given the great amount of energy accumulated in Enriquillo\u2019s failure due to the many decades of seismic inactivity, the misfortune was, however, that although there was firm evidence of the imminent tragedy, there was actually very little to do to reduce it given the country\u2019s poor. Other regions in the world are in a situation similar to Haiti\u2019s, because cities close to geological faults have a great seismic activity. These include Lima, Karachi and Tehran. Like Port-au-Prince, these cities are largely unarmed with a sword of Damocles on their heads. In contrast, countries with resources like the United States have strict building regulations to increase seismic security of buildings and buildings and spend huge sums of money on natural disaster prevention. Surely, if they do occur, the expected great tremor in California will not have even remotely the same consequences as Haiti suffered. The saying says that the leanest dog is charged with fleas. If a dog is skinny it is because it does not have to eat and if it does not have for food less it will have for disinfectant.",
    "https://upload.wikimedia.org/wikipedia/commons/6/67/World_population_density_1994.png": "The Conference on Climate Change, organized by the United Nations with the participation of 192 countries, will be held in Copenhagen, Denmark, from 7 to 18 December. During this meeting agreements on reducing greenhouse gas emissions into the atmosphere are expected to be reached, extending the Kyoto Protocol beyond 2012. As is the case in the public domain, greenhouse gases that have been increasingly emitted into the atmosphere since the beginning of the industrial revolution 200 years ago \u2013 mostly carbon dioxide \u2013 have led to a slow increase in the temperature of the Earth that is anticipated to be catastrophic if the relevant measures are not taken. Indeed, the concentration of carbon dioxide in the atmosphere has risen from 280 parts per million (ppm), value that it had at the pre-industrial stage, to 385 ppm today. This has led to a rise in the temperature of the Earth\u2019s surface over the last century by 0.75 degrees centigrade. If the current trend is followed, the Earth\u2019s temperature will have increased by just over thirty years by two degrees centigrade. The Kyoto Protocol sets out a commitment to reduce greenhouse gas emissions by 5% over 1990 levels. In spite of the modestness of this target, however, the Kyoto Protocol was not ratified by the United States, which emits 20% of the total global greenhouse gas emissions with just 4% of the world's population. On the other hand, the countries that are most rapidly increasing their greenhouse gas emissions are those that are growing economically more rapidly, as is the case with China and India. China, in fact, recently surpassed the United States as the world's largest carbon dioxide emitter, which now occupies the second place by a narrow margin. The United States, however, emits four times more carbon dioxide per capita than China, and more than twice the average of the countries of the European Union. Carbon dioxide emissions to the atmosphere will be reduced as energy use is rationalized and fossil fuels replaced by non-pollutant energy sources. As in the case of solar and wind energy, some countries of the European Union have shown the greatest sensitivity in this respect. Denmark, for example, the seat of the current climate summit, obtains from wind energy 20% of the electricity it produces, in addition to discouraging the use of the car by imposing high taxes. Fossil fuels, however, cannot be completely eliminated, at least in the medium term, and the accumulation of carbon dioxide in the atmosphere will increase irremediably, to a greater or lesser extent, in the future. On the other hand, even with the gradual incorporation of new forms of clean renewable energy, we cannot expect that the current model of fossil fuel-based industrialization can be extended to the underdeveloped world, comprising four fifths of the world's population. That is, if the industrial development of one fifth of the world's population has led us to the disastrous state of environmental pollution and climate change, it is unthinkable that our planet can withstand similar development of the remaining four fifth parts. On November 18, the United Nations Population Fund published the State of World Population 2009 report in which it establishes a relationship between the growth of the planet's population in the last century and climate change. Although the UN has been accused of using the climate problem to promote neo-Malthusian policies of birth control, it is clear that our planet does not have sufficient capacity to provide all the world's population, present and future, with the same standard of living \u2013 and the energy consumption it entails \u2013 that the inhabitants of developed countries enjoy.In these conditions, the call made in the reference document by the United Nations Population Fund to redefine the concept of social progress makes sense.In the context of the above considerations, one would expect that at the Copenhagen climate summit there would be consideration by the industrialized countries, which caused the climate disaster, towards the developing world, which is not going to have the same opportunities as they had. , the United States occupies by far the first place, almost surpassing Canada.",
    "https://upload.wikimedia.org/wikipedia/commons/b/b4/LLNL_BGL_Diagram.png": "On November 18, during a congress on supercomputers held in Portland, Oregon, IBM issued a press release announcing that a group of researchers from its laboratory in Almaden, California, led by Dharmandra Modha, had managed to simulate in a supercomputer the brain of a cat. This simulation was carried out through the IBM supercomputer \u201cBlue Gene\u201d of the Berkeley National Laboratory, California, which has about 150,000 processors. A billion neurons were simulated with 10 million million connections between them. According to IBM\u2019s statement, the progress made constitutes a platform to understand the functioning of the brain and eventually build a computer that emulates the sensation, perception, action, interaction and cognition skills. Within a few days of IBM\u2019s announcement, however, researcher Henry Markram of the Federal Polytechnic School of Lausanne, Switzerland, made severe questionings, calling it bluntly fraudulent. To emulate the complexity of a cat's brain. In particular, and again according to Markram, the connections between the neurons employed in the model are too simplified and do not reflect the real neurons. Henry Markram leads the project \u201cBlue Brain\u201d in Lausanne that seeks to develop a synthetic brain with the capacity of a mammalian brain, and is therefore a scientific competitor of Modha. The Blue Brain project is also based on a supercomputer \u201cBlue Gene\u201d but only 10,000 processors. So far, as part of the Blue Brain project, they have managed to simulate a section of a rat's brain with 10,000 neurons. According to Markram's statements to the BBC, however, they expect in 10 years to be able to build an artificial brain in a supercomputer with functions equivalent to those of a human brain, potentially including the ability to experience emotions. The possibility of making a synthetic brain with our own capacity, including self-consciousness, is of course somewhat disturbing, and to carry out over 2,000 years of speculations It would show that our brain is nothing more than a machine, of extreme complexity and efficiency, but in the end only a machine that can be replicated by a set of computer chips if the arrangement of these is complex enough and if they are also programmed in the right way. Artificial intelligence, in addition to its philosophical and religious implications, of course has an enormous practical importance. Consequently, in research in this field a great amount of resources have been invested. We can mention, for example, that according to IBM\u2019s statement the Modha project recently got support of $16 million from the United States Department of Defense. Throughout its history artificial intelligence has suffered ups and downs due to the great expectations it has aroused and that it has not finally materialized in the time expected. The birth of this research field normally takes place in the year 1956, during a conference held at Darmouth College in the state of New Hampshire in the United States. At that time there was enormous confidence among the experts in which in the course of a generation the This optimistic vision is reflected in the science fiction film \u201c2001 Odyssey of Space\u201d directed by Stanley Kubrick, which was released in 1968. In this film, located in 1999, the \u201cHal\u201d computer in charge of a manned mission to Jupiter rebels by its own decision and kills all but one of the crew members. Against the overflowing optimism, however, 1999 arrived and the technology of the time was far from producing something like Hal, with its own reasoning and decision-making ability. In fact, by failing to meet artificial intelligence with the expectations it aroused, in the 1970s government support for research was diminished, which happened again in the next decade. Currently, the enormous speed at which the power of computers is growing has enabled projects such as the simulation of mammalian brain functions. Under these conditions, the near prospect of making computers with the capacity of the human brain has resulted in a strong argument to obtain funds for research. . Over the next ten years we will know if all these research efforts are finally successful, with all their scientific, technological, philosophical and religious implications; or, if optimism was once again too great.",
    "https://upload.wikimedia.org/wikipedia/commons/7/79/Rio_Collage.png": "Brazil is the fifth largest country in the world, both in territory and in population. Many things in Brazil are of great proportions. Most of the largest tropical forest on the planet \u2013 the Amazon rainforest \u2013 is located in its territory, in an area that is twice the surface of our country and that constitutes the largest lung in the world. It crosses its territory the Amazonas River, the most abundant in the world, as well as being the longest. Brazil has the largest freshwater reserves on the planet \u2013 almost twice the size of Russia, which occupies the second place. It is also, by far, the world\u2019s largest producer of sugar cane and ethanol biofuel obtained from it. In another order of ideas, the Maracan\u00e1 stadium, located in Rio de Janeiro, hosted in 1950 200,000 spectators in the final match of the soccer cup of the world between Brazil and Uruguay, which constitutes the largest number of people who have attended a football match. With the exception of the bathing suits on the beaches of Rio de Janeiro and the cups served in Uruguay. Brazil, however, and until a few decades ago, was less known in the world than Mexico, despite the great difference in territorial sizes between the two countries. Surely this was contributed by the fact that our country organized the 1968 Olympic Games with all the publicity and world exhibition that they implied. This situation, however, is changing rapidly and today Brazil is a country of great global notoriety for the economic development it has experienced in recent years. In 2001, economist Jim O\u2019Neill of the Goldman Sachs group coined the acronym \u201cBRIC\u201d as a reference to Brazil, Russia, India and China, four countries according to O\u2019Neill, together will reach in 2039 a Gross Domestic Product greater than that of the total countries of the G6 group \u2013 the United States, Japan, England, Germany, France and Italy. In particular, according to Goldman Sachs, the size of the Brazilian economy will exceed that of Germany in 2037. Brazil was an importer of oil in the 1970s and 1980s and suffered particularly from the oil crises of those years that considerably increased the price of oil \u2013 which led to the development of the bioethanol industry as a vehicle fuel, in which Brazilians currently have world leadership. Since 1980, however, Brazil has increased its oil production more than ten times and today is self-sufficient, in addition to being the 13th world producer. In 2006 Tupi\u2019s submarine oil field was discovered in the Santos basin opposite the Brazilian coast between Rio de Janeiro and the port of Santos. With reserves estimated at 8 billion barrels, this site constituted the most important oil discovery in recent years. Oil lies under a 2 km water layer and 6 km of rock, sand and salt. It is expected that the site will be in operation in 2011. A second site with a capacity similar to Tupi was discovered in its vicinity. With the discovery of the Santos basin oil deposits, the economic prospects for Brazil were the economic prospects for Brazil. They look promising and at this point a comparison with Mexico is inevitable. Unlike Brazil, Mexico has long been an oil country. In recent years, however, our oil production has been declining after reaching a peak in 2004, and this decline in production is attributed by the Federal Government \u2013 in part \u2013 to the economic problems we are going through. The contrast between Mexico and Brazil is evident. While we, despite having enjoyed decades of oil revenues, were not able to discover and open new deposits to exploitation, Brazilians, after decades of efforts, are working on the extraction of oil in extremely difficult conditions, using methods that are located on the edge of technology. Brazil currently has a promising future based, among other things, on the oil that it did not have thirty years ago. This future is symbolized by the cup of the world football that it will organize in 2014, as well as by the Olympic Games of 2016 that it will also organize. It is also symbolized by the high speed train that it plans to build between the cities of Rio de Janeiro and Sao Paulo and it expects to have. ready for the 2014 football world cup. In numerous articles and publications it is mentioned that the \u201cBrazilian giant\u201d is finally awakening, after having long been called the \u201ccountry of the future.\u201d In the case of Mexico, in contrast, there is uncertainty in the economic future of the country. Among other factors, because of our lack of foresight in oil matters.",
    "https://upload.wikimedia.org/wikipedia/commons/d/d3/V%2C23.jpg": "Last September the celebrations officially began for the two-hundredth anniversary of Mexico\u2019s independence. As we know, once this was completed, our country was plunged into a period of great political instability that lasted until the restoration of the Republic in 1867, and that included continuous struggles between liberals and conservatives, as well as wars and foreign invasions. On the other hand, although the political history of our country in the nineteenth century is widely documented, the fate of colonial science in the early days of independent Mexico is not equally known. Science in our country in the second half of the eighteenth century, at the end of the colonial period, had researchers with a high scientific level. Among these, Jos\u00e9 Antonio Alzate (1737-1799), botanist, astronomer and geographer, who is considered the most prolific of the Creole scientists of the time. Other Mexican researchers of great flight from the second half of the eighteenth century \u2013 included by C. Arias and C. Fernandez in the book \u201cHistory of Science in Mexico, XVIII Century\u201d\u2013 are, Jos\u00e9 Ignacio Bartolache (1739-1790), founder in 1772 of the first medical journal appeared in America; Joaqu\u00edn Vel\u00e1squez de Le\u00f3n (1736-1786), who carried out the first geodetic works of the Valley of Mexico, and Antonio de Le\u00f3n y Gama (1735-1802), astronomer and author of the work \u201cUniversal orthographic description of the eclipse of the Sun on June 24, 1778\u201d. The Royal Seminar of Mining of New Spain, inaugurated on January 1, 1792, had as mission the training of technicians and metallurgist engineers in advanced knowledge to strengthen the mining industry in Mexico, then in decline. As the first director of the new institution was named Fausto Elhuyar, Spanish chemist, discoverer of tungsten. The Royal Seminar of Mining is recognized as the most significant scientific institution of colonial Mexico that, moreover, survived the war of independence. Andr\u00e9s Manuel del R\u00edo was a prominent Spanish mineralogist \u2013 educated in European research centers of avant-garde, in which he had contact with researchers of the stature of Antoine Lavoisier\u2013, who was sent to Mexico by the Spanish government to cover the mineralogy chair of the Royal Seminar of Mining. The work of Andr\u00e9s del R\u00edo in Mexico, which he adopted as a second homeland and in which he died in 1849, was extremely fruitful. He devoted himself to enthusiastically transmitting his knowledge of the science of mineralogy to the students of the Royal Mining Seminar. For this purpose, he wrote the book \u201cElements of Orictognosia\u201d and translated into Spanish other texts on the subject. As a researcher, analyzing minerals from a mine in the State of Hidalgo, he discovered in 1801 a new chemical element which I call \u201cerythronium\u201d and which is now known as \u201cvanadium\u201d. The discovery of vanadium, however, is commonly attributed to the Swedish chemist Nils Sefstroem who reported it in 1831, \u201330 years after the original discovery of the River \u2013 giving it its current name in honor of a Scandinavian goddess. Despite the controversy that arose when it became clear that the first of the discovery of the vanadium was from the River and proposed to change its name, In addition to having been a leading scientist, the Rio was a remarkable engineer. He was commissioned, for example, to design a technique for extracting water from a mine flooded in the Real del Monte ore, as well as the design and construction of the first iron foundry in America, projects that he successfully completed. Since an activity such as scientific research requires very special conditions to prosper, it is not surprising that Mexican science, which had achieved a good state of development at the end of the colony, suffered major problems during the war of independence. Indeed, according to C. Arias and C. Fern\u00e1ndez: \u201cWith the struggle the links with foreign institutions were broken and it became difficult to maintain relations with the men of European science. The University was converted into a barracks; the classes of the Seminar and the Botanical Garden were affected by the irregular assistance due to the military service, in addition to the fact that the bad economic situation did not allow spending on research projects.\u201d Once independence was completed, the country\u2019s agitation was also not favorable for the continuation of scientific activity and, for example, Fausto Elhuyar returned to Spain in 1930. Andr\u00e9s del R\u00edo was absent from the country for some time, and although he finally returned to Mexico, he no longer had scientific achievements at the level of the previous ones.In the 19th century there were technological developments based on science, as important as the internal combustion engine, electric light and telegraphy, to mention just a few. During the period of political instability, the country lost precious time to follow the scientific development of the world and integrate into the technological era of the 20th century. We can affirm that from this point of view the war of independence occurred at \u201ctimeless\u201d.",
    "https://upload.wikimedia.org/wikipedia/commons/5/52/Logo_anuies.jpg": "The number of students enrolled in professional careers at universities in Mexico is one of the parameters that has increased the most over the last hundred years. Indeed, we have that at the end of the first decade of the last century, less than 10,000 students carried out university studies in comparison to the more than two million that do so today, which represents an increase by a factor greater than 200. This increase cannot be explained only by the increase in the population of the country, which grew by a factor of 7 in the same period.In fact, the enrolment of universities in Mexico did not grow in the last century in a uniform way, but did so by leaps. Thus, in 1950 the number of university students in the country did not exceed 30,000, while by 1970 this number exceeded 200,000, according to data from the National Association of Universities and Institutions of Higher Education (ANUIES). During the decade of the 1970s and beginning of the 1980s the enrolment of universities grew rapidly, exceeding 900,000 students in 1984, the year from which the rate of growth slowed to increase again since According to data from ANUIES, the growth in post-graduate enrolment has also been marked by leaps. Thus, we note that the number of students enrolled in master's programs in Mexico increased by 27% between 1992 and 1998, after having remained relatively stable since 1980. This behavior was even more marked, in the case of doctoral programs, which increased by 460 % between 1992 and 1998, without having changed for more than a decade.Universities in our country expanded mainly since 1970, when a process of increasing higher education began, which extended to the middle of the 1980s. This process is characterized by the fact that the Federal Government, the main support of the public university in Mexico, placed more emphasis on the growth of enrolment than on the quality of the supported academic programs. In contrast, since the 1990s, the Ministry of Public Education established various mechanisms for the evaluation and accreditation of work in universities, and based on the results of the evaluation to give them specific support. In this way, a classification of professional careers with three levels of competence was established, as well as an accreditation body for each discipline. Teachers, for their part, were given access to economic stimulus programs based on their academic performance. Since the 1990s, public universities in Mexico have been subjected to a series of pressures that respond to visions, often conflicting, about the role that the public university in Mexico must play, and that have been reflected in the support given to them by the Federal Government in recent years. On the one hand, the public university is conceived in purely mercantile terms as a factory of professionals and technicians. According to this extreme view, universities must be economically self-sufficient and the students who benefit from the education they receive must pay for it. There would be no space in this way for scientific and humanistic research \u2013 except for the very little that supported the private initiative \u2013 and universities would limit themselves to passing on to their students the knowledge generated in other places in the world. Under these conditions, universities would function better as public bodies as private institutions. .There are, on the other hand, those who think that the public university should fulfill a social function and provide quality education to all those who meet certain minimum academic requirements, regardless of whether they can or cannot afford it. The public university, moreover, should be the seat of research projects that have the purpose of advancing scientific knowledge and developing technologies to solve problems of social impact, and for this to necessarily require public subsidy. The degree of economic development of a country today is largely linked to its infrastructure of scientific and technological research and training of highly qualified scientists and engineers, and within this perspective the public university is an essential element. Much progress has been made in Mexico since the 1970s when the Federal Government increased support for the public university in Mexico and encouraged its growth. However, as the current discussion on budgetary allocations to public universities for the following year shows, it is clear that much remains to be done to finally reach the place Mexico requires.",
    "https://upload.wikimedia.org/wikipedia/commons/e/e9/Biodiesel.JPG": "The violent fluctuations in oil prices that have occurred since the 1973 oil crisis \u2013 when the price of oil quadrupled in the course of a few months \u2013 have spurred the development of various alternative sources of energy generation. These sources include biofuels obtained from organic matter of vegetable origin. The most widely used biofuel is ethyl alcohol or ethanol, used as a substitute for gasoline. In Brazil, for example, 50 per cent of car fuel is ethanol produced from sugar cane. The United States, on the other hand, has increased in recent years the production of alcohol from maize, to the extent that 25 per cent of the production of this grain is currently in the manufacture of bioethanol. Another biofuel of widespread use, although not in the measure of ethanol, is biodiesel obtained from oilseeds such as sunflower and soy. Biodiesel production is also on the rise and in 2007 7 per cent of the world production of oilseeds was devoted to its production. Biofuels are an option. In principle it looks very attractive as a source of energy, because it is renewable and because it does not face therefore a future exhaustion as is the case with fossil fuels. Biofuels were certainly an attractive energy option for Brazil in the 1970s and 1980s, when this country faced the oil crisis. In fact, Brazil established its program of substitution of gasoline by ethanol, which has been so successful to it, precisely because of this crisis. Biofuels are also very attractive because they are non-polluting of the environment \u2013 or at least to a lesser extent in which fossil fuels are. Not all, however, is honey on flakes in terms of biofuels. For example, according to a publication by the World Bank in July 2008, the increase in ethanol production recorded in recent years was the main cause of the increase in the price of food that made a crisis last year. According to that publication, the demand for maize in the United States for the production of alcohol caused that land dedicated to the cultivation of soybean migrate to the cultivation of corn, causing a shortage of soy and a consequent increase in its price. In the same way, responding to the increase in The demand for vegetable oil for the production of biodiesel, wheat-exporting countries such as Argentina, Canada and the European Union decreased the agricultural area destined for cereal to be used for the cultivation of oilseeds, which also led to an increase in the price of wheat.The production of biofuels for transportation is in competition with food production.This is evident if we take into account that to produce 100 litres of bioethanol \u2013 barely enough for a car to travel a few hundred kilometres \u2013 some 250 kilograms of maize are needed, that is to say what a person would consume in one year.To do the worst in the bioenergy landscape, an article published by Robert Service on 23 October in the journal Science of the American Association for the Advancement of Science mentions the possibility that a massive expansion of maize production in the United States for biofuels requires such an amount of irrigation water to generate problems of liquid scarcity in certain places. Service notes that biofuels require for their production of volumes of water considerably greater than those demanded by other means of generation. In addition, there is the problem of contamination of water by fertilizers and agricultural pesticides, pollution that reaches the Gulf of Mexico via the Mississippi River. In this way, while biofuels would contribute to solving the energy problem in the United States, they would create on the other hand a problem of supply and water pollution. Brazilian experience, however, has shown that if it is possible to develop a self-sustaining bioethanol industry. Unlike the United States maize-based industry, Brazil manufactures its ethanol from sugar cane. This difference, from the outset, is an advantage, since the yield in the production of ethanol per hectare of sugar cane is more than twice the corresponding yield for maize. All alternative sources of energy fossil fuels have advantages and disadvantages and in this regard biofuels are not the exception. In the future, however, bioenergetics will undoubtedly appear that will overcome some of the current problems. Their production can be increased without increasing neither the cultivated area nor the water for irrigation. What is certain, however, is that the substitution of fossil fuels will be done not on the basis of a single technology, but with diverse technologies based on sun, wind and biofuels, among many other sources of energy.",
    "https://upload.wikimedia.org/wikipedia/commons/2/22/Sign_sea_level_maps.jpg": "In recent days we find ourselves in the print media with a photograph in which the President of the Maldives and his cabinet appear signing documents during a working meeting \u2013 the Maldives are an archipelago of 1190 islands located to the south-west of India. The image would not have anything of particular if it were not because president and ministers appear founded in suits of divers \u2013 escapes and tanks of oxygen included \u2013, implements that were indispensable since the meeting was held six meters below sea level.The exhibition was intended to draw attention to the gradual increase in the level of the oceans that is causing global warming.According to the Intergovernmental Panel on Climate Change (PICC), this increase will reach about half meter in the year 2100 and in this perspective the inhabitants of the Maldives are right to be concerned, since more than 80% of their territory has an elevation less than one metre. Thus, to fulfill the predictions of the IPCC the country would disappear to a good extent \u2013 in fact it could disappear almost completely from agreement with other specialists who consider that the half meter of increase in the sea level reported by the PICC is too conservative and is more likely to reach one metre or even more. In contrast to their perception in the Maldives and according to a survey conducted by the Pew Research Center, released on October 22, the belief in global warming in the United States is decreasing among the population. Thus, at present, 57% of Americans believe that there is solid evidence of such warming, in contrast to 77% who thought so two years ago. There is, however, today much evidence that the Earth\u2019s temperature is rising. Global warming, for example, is melting the North Pole ice, as evidenced by the fact that in August 2007, the celebrated Northwest Passage \u2013 the channel along Canada\u2019s northern coast that communicates to the Atlantic and Pacific oceans \u2013 has been free of ice for the first time since memory. Global warming, now known, is linked to the Pauline increase in the concentration of carbon dioxide in the atmosphere that has occurred since the beginning of the industrial revolution two hundred years ago \u2013 carbon dioxide produces the so-called \u201c It took time, however, to come to this conclusion, as Spencer Weart puts it in his interesting book \u201cThe Discovery of Global Warming.\u201d According to Weart, the conclusion that the Earth is warming up as a result of our industrial activity originated in studies that sought to explain the causes of glaciations. As we know, the Earth has suffered during millions of years periods of low temperatures during which large areas of land surface remained covered with ice. Studies on the origin of glaciations date back to the 19th century. In 1896 Swedish scientist Svante Arrhenius wondered about the causes that can change the temperature of the Earth, reaching the conclusion that such temperature is controlled by the concentration of carbon dioxide in the atmosphere. Arrhenius, however, did not have sufficiently sophisticated research tools to go beyond his conclusions \u2013 which were largely speculative \u2013 and we had to wait until the second half of the 20th century to obtain evidence. This increase, coupled with the sensitivity of the global climate to small disruptions, makes uncertain the future evolution that could well have catastrophic results. Worry.",
    "https://upload.wikimedia.org/wikipedia/commons/4/49/Salar-de-quisquiro.png": "More than 3,600 meters high in the south-west of the Bolivian highlands, on an area of more than 10,000 square kilometers extends the Uyuni Salt Salar, the largest salt desert on the planet.Because it is flooded periodically and water dissolves the upper layer of salt, the Uyuni Salt Salar is extraordinarily flat, having variations of height less than one meter along its entire surface.This circumstance has made it one of the largest tourist attractions in Bolivia.It is estimated that the Uyuni Salt Salar contains about 10,000 million tons of salt and large amounts of potassium and manganese. Its greatest mineral wealth, however, is the 5 million tons of lithium that lie dissolved in water, in the form of lithium chloride, under the surface crust of salt and that they constitute half of the world reserves of this metal according to the United Sates Geological Survey. Bolivia is not, however, the largest producer of lithium in the world, a place that corresponds to Chile that has the second largest reserve of this mineral \u2013 B. olivia, in fact, has not yet begun the exploitation of its deposits. Chile contributes 45% to the world production of lithium that totals 27,000 tons per year. Chilean production comes from the Atacama Salt in the north of the country. Other important producers are Australia, China and Argentina. If we are to attend to recent news, Mexico could join the lithium producers\u2019 club soon. Indeed, on 7 October last, the newspaper Imagen de Zacatecas published an interview with geologist Mart\u00edn Sutti Courtade, director of the Zacatecan mining company Piero Sutti, in which he states that this company discovered large deposits of lithium in the Potosino municipalities of Salinas and Villa de Ramos, and in those of Villa Hidalgo, Villa de Cos and P\u00e1nfilo Natera in Zacatecas, which would be among the largest in the world. He also assured that Piero Sutti obtained a mining concession to exploit lithium deposits on an area of about 360 square kilometers. This news was later reproduced and expanded by various national and foreign media. Lithium is the third lighter chemical element that exists in nature. The first, however, is presented in gaseous form, so that lithium turns out to be the solid element with the least specific weight. The most important use that is given to lithium today is in the manufacture of batteries \u2013 both rechargeable and disposable \u2013 for various applications, from computers and cell phones, to electric cars. Since the industries of computers and cell phones are in a rapidly growing phase, the industry of rechargeable batteries is also expanding. Another area in which rechargeable lithium batteries have great growth potential is the industry of electric cars, which require batteries to store electrical energy. In this regard, the magazine Forbes in its issue of 24 November last year called Chile the \u201cSaudi Lithium Arabic\u201d, in reference to which electric cars can well make lithium what gasoline transports made from oil. It is expected that given the environmental pollution problems that internal combustion automobiles are generating, electric vehicles \u2013 and batteries recharges If the findings of lithium in Mexico are confirmed, our country would then be well placed as a producer of a raw material that will have a great demand in the future, in a similar way as it is today with respect to oil. The reports of lithium finding in Mexico, however, are still confusing. It is mentioned in various ways, for example, that the discovered deposits are among the largest in the world \u2013 even the largest ones \u2013 and that, according to Sutti, for every 10 meters of excavation depth 80 million tons of lithium will be produced, which is approximately eight times the world reserves. All this in an area of 360 square kilometers that is thirty times less than that of Uyuni Salt. An additional factor that would have to be considered is that the lower costs of producing lithium are obtained from raw material in liquid form, as is the case of the Salar de Uyuni and the Salar de Atacama in which Chile obtains its production of lithium. The raw material is apparently solid, which would probably increase production costs.In the coming weeks we will surely have a more accurate picture of the lithium findings in San Lu\u00eds Potos\u00ed and Zacatecas. Hopefully these will actually be confirmed and Mexico will become a producer of a material that will surely be strategic in the future.",
    "https://upload.wikimedia.org/wikipedia/commons/4/49/Fibreoptic.jpg": "The Nobel Prize in Physics for this year was announced on 6 October. The prize was awarded to Charles Kao for his work on the transmission of light in optical fibers and to Williard Boyle and George Smith for the invention of the CCD image sensor \u2013 the device that replaces the film roll in digital cameras. The Nobel Prize in Physics is awarded to researchers who have made transcendent discoveries in some area of physics; this, regardless of the immediate technological impact that such discovery has had. In some cases, however, the prize has been awarded for research that in addition to advancing scientific knowledge, led to technological developments of great impact. This is the case, for example, of the Nobel Prize in Physics 1909 and 1956 awarded, respectively, to Guglielmo Marconi and Kart Ferdinand Braun for the development of wireless telegraphy \u2013the immediate background of radio. This is the case, for example, to William Shockley, Walter Brattain and John Bardeen for the invention of the transistor. This is also the case of the Nobel Prize in Physics \u2013the immediate background of radio. The mention of the Royal Swedish Academy of Sciences awarded by the Nobel Prize in Kao\u2019s case was: \u201cfor its revolutionary achievements concerning the transmission of light in fibers for optical communication\u201d, while Williard Boyle and George Smith were distinguished by: \u201cthe invention of a semiconductor circuit for the formation of images \u2013 the RCD\u201d. When Alexander Graham Bell established in 1876 the first telephone link in history \u2013 in which he delivered to his laboratory assistant Thomas Watson the message: \u201cMr Watson, come here, I need to see you\u201d \u2013 he did not imagine the tremendous development that telecommunications would reach a century later. Bell\u2019s message to his assistant, which was in a neighbouring room, was transmitted through a copper wire by means of electric pulses generated by a primitive microphone. From the work of scientists and inventors like Graham Bell, during the first half of the 20th century the telephony grew rapidly. Thus, in 1956 the first transatlantic submarine cable with 34 communication channels came into operation and in 1962 the first communications satellite. Telecommunications technology began in the 1960s, when Charles Kao in 1965 publicized the idea \u2013 which has just been awarded the Nobel Prize \u2013 that the poor transparency of the optical fibers of the time, which quickly attenuated the light travelling along them, was due to the impurities contained in the glass from which they were made. Such transparency would then be likely to be increased by removing such impurities. If this were possible, optical fibers could be used as a means of transmitting information \u2013 a telephone call, for example \u2013 by means of pulses of light.The idea of sending information through light \u2013 optical communication \u2013 was not new in reality; the American Indians, for example, used smoke signals \u2013 a primitive version of optical communication \u2013 to transmit messages miles away.In more recent times, Alexander Graham Bell invented the photophone, a device that allowed him to transmit sounds through a ray of sun. Beyond these first applications, however, in 1965 light was seen as a vehicle of information transmission with many advantages. These advantages included a greater capacity to transmit information and immunity to electromagnetic interference. Kao\u2019s prediction of optical fibers was correct and by the end of the 1960s the first glass fibers were manufactured with sufficient transparency to be used in optical communication systems. Five years later, in 1975, the first commercial optical communication system came into operation in the United States. It should be noted, however, that for the development of optical communications technology another fundamental invention was also necessary: the semiconductor laser, which is the generator of light that transports information through fiber. This device was developed by Zhores Alferov in 1966 and by it received the Nobel Prize in Physics in 2000. From 1975 onwards, the optical fibre telecommunications network grew rapidly, both in extension and speed of data transmission, and today constitutes a central element in the global telephony system, especially in terms of long distance communications. For the development of the Internet, which is producing a social and cultural revolution in the world.The optical fibers for telecommunications, semiconductor lasers, CCD sensors and wireless telegraphy, are some examples of developments that have been distinguished at the highest scientific level, that have had a huge social impact, and that illustrate the central role that science plays in modern technology.",
    "https://upload.wikimedia.org/wikipedia/commons/3/3f/Fountain_of_Eternal_Life_crop.jpg": "Last October 2nd we learned from the New York Daily News about Ted Williams\u2019s painful fate \u2013 one of the biggest players in the major baseball leagues, a player in the Boston Red Sox all his life, a member of the Hall of Fame, twice winner of the triple batting crown and the last to bat in a season above the.400 in percent\u2013, which was handed over to his death in 2002 to Alcor Life Extension Foundation company in Scottdale, Arizona, for preservation. The course that followed Williams\u2019 body once it was admitted to the facilities of that company, according to the New York Daily News, is reported in the book \u201cFrozen\u201d, written by Larry Johnson, a former Alcor executive. The diary had early access to the book, which will be presented next Tuesday on the television news \u201cNightline\u201d of the American ABC chain. Alcor specializes in keeping corpses in liquid nitrogen at a temperature of 196 degrees Celsius below zero, with the hope of preserving them without physical deterioration until the time. The company offers two alternatives of preservation: the whole body or only the head. The first one costs about $120,000, while the second one is more economical, as it only has to be disbursed about $50,000. Ted Williams's debts were decided for the second option.Once in Alcor, according to Larry Johnson, Williams' head was separated from the body by technicians without the necessary medical certifications and after freezing it by submerging it in liquid nitrogen, it was beaten with a nut key in an attempt to separate it from the tuna can on which it had been placed to suspend it in the freezing liquid. With the blows several pieces of the head were released that were watered down the ground. Johnson further relates that before the submersion, several holes were performed on the head of Ted Williams in which microphones were placed, which recorded a total of 16 \u201ccracks\u201d of the brain mass according to its temperature of up to 196 degrees. The preservation of bodies at low temperatures, which is called Crionica, is considered by its advocates as a viable alternative to stop the natural deterioration of a corpse until a future time \u2013 indeterminate at present \u2013 in which it is possible to reverse the death of the \u201cpatient\u201d, which they consider not as definitive but as the beginning of a process that has been stopped with freezing. Many, however, place the Crionica more in the field of science fiction than in the field of scientific knowledge. They point out, for example, that at temperatures below the freezing point of water \u2013 not to be said to the temperature of liquid nitrogen \u2013 inside the cells form ice crystals that destroy them. Even considering that water is expelled from the cells during the cooling process, as is argued in response, ice crystals that form on the outside destroy structures, such as blood vessels, which are essential for the functioning of organic tissues that are thus irreversibly destroyed. Thus, it is argued that Crionic is closer to religion than science. Because it is more a question of faith than of objective scientific knowledge to believe that in the future it will be possible to resurrect frozen corpses, given the little scientific evidence with which it is currently counted. Crionica, however, has an enormous appeal because it offers the prospect of an eternal life, as most religions do. The Egyptians of ancient times, for example, practiced 3,500 years ago complex ceremonies that lasted 70 days, in which the bodies of the dead \u2013 those who had sufficient resources, of course \u2013 were mummified and prepared for the journey to the afterlife, where they would have to face a judgment on their earthly acts. If they were acquitted, their \u201cka\u201d and their \u201cba\u201d \u2013 something like their life force, and their soul or personality \u2013, separated at the time of death, could meet again and in this way achieve eternal life. Physical body preservation was, however, indispensable for it would be inhabited again by the \u201cba\u201d and hence the elaborate process of mummification. In both cases, immortality and the preservation of the body of the dead person are sought. Egyptian mummification required the removal of internal organs, including the brain that was extracted from the nose. The exception was the heart, which was not removed because they thought that the soul resided there. In Crionics, in contrast, the essential organ to preserve is the brain, which we now know is the place of residence of what we call consciousness. Finally, as another point of contact, if we are to believe what Larry Johnson told, in both practices, the Egyptian and Alcor company, the corpses were mistreated or mistreated beyond what is recommended for their eventual future resurrection.",
    "https://upload.wikimedia.org/wikipedia/commons/5/5e/Cropduster_spraying_pesticides.jpg": "On September 12, he died at 95 in Dallas, Texas, Norman Borlaug, known as the father of the \u201cGreen Revolution.\u201d This revolution marked a dramatic increase in wheat production in the 1950s in Mexico \u2013 and later in several Asian countries \u2013 which was the product of the development of improved wheat species carried out in our country by a group of researchers led by Borlaug. The Green Revolution was considered at the time the solution to the problem of food production resulting from the global population explosion. In the mid-20th century the world population increased exponentially by doubling every 35 years, in stark contrast to the 150-year doubling period of the 19th century. The transition in the population growth rate, which occurred in the first half of the last century, was the result of the improvement in the hygiene conditions of the population and the availability of antibiotics at the end of the Second World War. In 1798 Thomas Robert Malthus predicted that the difference between the rates of population growth and food production would eventually lead to the latter being insufficient to sustain the growing number of people, which would lead to a humanitarian catastrophe. In the second half of the 20th century, with a significantly larger population growth rate than that of the 19th century, Malthusian concerns were reborn.The solution to the problem of feeding the world, it was thought, would have to be given by two ways: a reduction in the rate of population growth and an increase in the efficiency of food production.In 1943, the Government of Mexico under the presidency of Manuel \u00c1vila Camacho established a cooperation program with the Rockefeller Foundation to carry out studies on plant pathology and wheat and maize production, in order to increase the production of these cereals in our Country. The Rockefeller Foundation possibly decided to support the program by foreseeing the global food problem that would be evident years later. Borlaug came to Mexico in 1944 as part of that program, with the mission of developing varieties of wheat resistant to pests and with a greater capacity to exploit fertilizers, which would result in a higher yield per hectare. He obtained varieties of dwarf plants that, however, produced more wheat than his higher counterparts. Wheat production in 1944 to be a net exporter in 1963, increasing the production of this cereal by a factor of six. Wheat seeds developed in Mexico by Borlaug were exported to India and Pakistan, where they also had a great success. Between 1965 and 1970 both countries almost doubled their wheat production and achieved self-sufficiency, Pakistan in 1968 and India in 1974. Borlaug\u2019s techniques were also extended to other cereals such as rice, with equally positive results. For his work in Mexico and other countries, Norman Borlaug was awarded the Nobel Peace Prize in 1970. Speaking of Norman Borlaug\u2019s contribution to world peace, the president of the Nobel Committee mentioned in her presentation of the award: \u201cDuring the 25 years that have passed since the end of the war, those of us who live in industrialized societies have debated almost in panic about the race between the world\u2019s population explosion and the food available to the world. Most of the experts who have expressed an opinion on this race have been pessimistic. The world has fluctuated between the fear of two catastrophes \u2013 the explosion. Both are a deadly threat. In this intolerable situation, with the threat of the end of the world over our heads, Dr. Borlaug appears on the scene and cuts the Gordian knot. He has given us a well-founded hope, an alternative of peace and life \u2013 the Green Revolution.\u201d Borlaug, however, has his critics, who argue, for example, that the techniques developed by him depend on an intensive use of fertilizers and pesticides, and that this inevitably has an environmental impact. Moreover, they argue that small farmers are displaced and a dependency is created with regard to large agro-industrial companies, which ultimately result in being the big winners. Borlaug argued that the criticisms were made by people installed in comfortable offices in Washington or Brussels, and that if any of them lived a month in the midst of the misery of a underdeveloped country, he would not hesitate to support his agricultural techniques. Apart from the controversy that his work has generated, what is incontrovertible is that Borlaug was an admirable researcher who decided to come to Mexico instead of accepting the work that It offered him a transnational company in the United States, and that would have been much more comfortable. Moreover, achieving a success of research and social impact like the one he had, in a country like Mexico of the forties, is not something we can find around the corner.",
    "https://upload.wikimedia.org/wikipedia/commons/9/98/Senate_House_UoL.jpg": "\u201cBut is the woman doomed not to receive philosophical and scientific education? Why not receive it if the nature that was pleased to make her work of art more perfect, also endowed her with intelligence? Eminent thinkers have believed that physically weaker than man, and having in nature a function that absorbs it all, the woman would suffer by instruction the effects of intellectual surmenage more easily than that, which would ultimately bring sterility, degeneration of the race and its extinction.\u201dThe previous paragraph was taken from the transcript of the speech delivered by Dr. Antonio F. L\u00f3pez \u2013discovered by Lic. Lucia Delgado Oviedo in the librarian archives of the UASLP \u2013 during a ceremony for the award of students held in 1901 at the Scientific and Literary Institute of San Luis Potos\u00ed, in which the Governor of the State was present. Dr. Antonio L\u00f3pez, who was Director of that Institute from 1901 to 1907, left no doubt what he thought about it when he later stated: \u201cFrom all this it is deduced that to the woman will be given the instruction as much as possible proportionally to her brain resistance, in order not to reach the surmenage.\u201d From a full reading of the reference speech it is clear that Dr. Antonio L\u00f3pez was a cultured person, versed in the positivist philosophy in vogue in Mexico at that time. As such, he was convinced that Science was the key to solving all our problems. Referring to the latter, he recognizes that the first step of the scientific method consists in: \u201cobserving the facts with precision stripping of all prejudice.\u201d However, like Aristotle, who claimed that women have less teeth than men, prejudicedly concluded that the relative muscular weakness of women compared to men extended to the brain. Fortunately, not all women agreed with this type of opinion. A prototypic example in this regard is Marie Curie, who received the Nobel Prize in Physics in the year 1903 \u2013 more or less at the time of the speech referred \u2013 and the Nobel Prize in Chemistry eight years later, becoming the first person \u2013 man or woman \u2013 to receive two Nobel Prize in the year 1903 \u2013 and the Nobel Prize in Chemistry eight years later. Another example to highlight, which occurred half a century later and which has the additional ingredient of having been repeatedly placed in the context of gender discrimination, is that of British chemistry Rosalind Franklin, who had a decisive role in the revelation of the \u201csecret of life\u201d, that is to say in the discovery of the molecular structure of DNA, which has been considered the most important of the twentieth century. In 1953, Rosalind Franklin was a researcher at King\u2019s College at the University of London and was dedicated to the study of DNA using x-rays. King\u2019s College at that time was a conservative institution that practiced gender discrimination \u2013 had, for example, a male-only dining room \u2013 and with which Franklin did not identify himself. Moreover, almost upon his arrival at the laboratory in 1951 he came into conflict with Maurice Wilkins, assistant director of the same, who apparently misinterpreted his hiring assuming that he came to work as his assistant. At the beginning of the 50s several research laboratories in the world competed for being the first to reveal the structure of the DNA molecule, among them King\u2019s. The winners were Francis Crick and James Watson of the University of Cambridge, who, together with Wilkins, were awarded the Nobel Prize in Medicine and Physiology in 1962. Franklin was not included because he had died in 1958 at the age of 37, a victim of ovarian cancer, and by regulation the Nobel Prize cannot be awarded posthumously.Watson and Crick, however, have been subjected to many criticisms because the inspiration for their discovery came to them after observing the photograph of a DNA x-ray experiment obtained by Franklin. This if nothing is wrong. The problem was, however, that the photograph was shown to them by Wilkins without the knowledge of Franklin. Watson and Crack, moreover, did not recognize this fact until years later. The early death of Rosalind Franklin and the circumstances surrounding the discovery of the DNA structure, have made it an icon of feminist groups. This was further encouraged by the book \u201cThe Double Helix\u201d published by James Watson in 1968, when Rosalind had already died, where it referred to as an icon of feminist groups. to her as \u201cRosy\u201d \u2013 a nickname she did not have in life \u2013 and as a researcher who did not know how to interpret her own experiments. Perhaps we find surprising the concepts referred to at the beginning of this article. We must, however, judge them in the light of the gender discrimination that prevailed a hundred years ago and from which we found remains in the case of Rosalind Franklin and in the fact that a university like King\u2019s College had exclusive canteens for men just half a century ago. Still today, discrimination persists, thus depriving the world of half of human intelligence.",
    "https://upload.wikimedia.org/wikipedia/commons/d/de/Medio_Oriente.png": "In October 1973, the oil-producing Arab countries decreed an oil embargo on the United States for its support of Israel in the Yom Kippur war. This embargo provoked an energy crisis that quadrupled the price of oil in a few months and set off alarm signals in the industrialized countries, which suddenly ceased to be assured of the oil flow from the Persian Gulf they needed to keep their economies running. The situation was alarming not only for non-oil producing countries, but also for the United States, which, despite its high level of crude oil production, depended largely on Arab oil. In response to the energy crisis, the governments of countries such as the United States, Germany, France and Japan sought to mitigate their dependence on oil by encouraging the development of alternative sources of energy. Thus, for example, France deprived nuclear energy and increased its nuclear power capacity by a factor of ten, to the extent that currently around 80% of electricity consumed in that country is of nuclear origin. Japan and Germany also substantially increased their nuclear power capacity \u2013 although not to the extent of nuclear power consumed in the United States. Although nuclear power has reduced energy dependence on Middle East oil, the production of uranium needed for nuclear power plants is concentrated, like oil, in a few countries, notably Canada and Australia. Moreover, nuclear fuel is non-renewable and will eventually be scarce and will increase in price. As a means of achieving energy independence, nuclear energy does not seem to be a viable option in the long term. In contrast to oil and uranium, some renewable energy sources, such as the sun and wind, are more \u201cdemocratically\u201d distributed and constitute a highly attractive energy option. Some countries have taken this option very seriously, notably Germany and Spain, which today generate from renewable sources of the order of 10% of the electricity they consume. Spain, by 2020, is expected to generate 15% of the electricity generated from the wind and even talks about the possibility that by 2050 the country will obtain its energy entirely from renewable sources. Although Mexico is still a top oil country, after reaching a maximum production of just under four million barrels per day in the year 2004, our crude oil production has steadily declined and, worse still, the proven reserves barely reach the current levels of extraction for a few 10 years. It would appear then that we could lose our status as an oil country in the future. Because of its geographical position and its orography, on the other hand, Mexico has large solar resources. This is especially true in the north of the country. In particular, the highland region of San Luis Potosi presents conditions of solar insolation above the national average. Every day they affect the Potosin altiplano for every square metre of surface approximately 6 kilowatts-hours of energy. This is equivalent to, for example, the energy needed to keep a small water pump on fire day and night. In some regions at the limit of our state with Zacatecas the solar radiation is even higher. However, it requires the development or adaptation of solar technologies for what are needed engineers and researchers that we are not producing in sufficient number. The solar experts that we need must be trained in our universities and these usually do not have sufficient resources. In the current context of the economic crisis \u2013 due largely to the decline in the currency that the country receives from the sale of oil \u2013, public universities even face budget reductions. In terms of research and postgraduate studies, the percentage of the gross domestic product that the country dedicates to science and technology is less than 0.4 percent that, as the director of CONACYT acknowledged in his recent visit to San Luis Potos\u00ed, is even lower than the Latin American average. Later or earlier, Mexico\u2019s oil will come to an end. When that happens, and if we do not take steps to replace it as a source of energy, we will regret not only for the currencies that we will not receive because of its export, but for which we will need to import the energy that we will not produce. Countries without oil such as Germany and Spain are showing us the way. . For the cuts announced in education and support for science and technology, it does not seem, however, that we are on the right path.",
    "https://upload.wikimedia.org/wikipedia/commons/1/1c/Europasaurus_holgeri_Scene_2.jpg": "Since the beginning of the industrial revolution at the end of the 18th century, the world has used increasing amounts of energy that it has obtained mainly from the burning of fossil fuels. At present, 80% of the energy we consume comes from such fuels. Fossil fuels \u2013 oil, gas and coal \u2013 have their origin in plant and animal organic matter long ago dead. It is believed that fuel coal comes from trees and shrubs that existed in the carboniferous period some 300 million years ago, which were buried by geological processes in sedimentary rocks. Gas and oil are accepted to have been generated from seaweeds and marine animals of the Jurassic period, which were also buried by sediments at the bottom of the sea. The high pressures and temperatures to which organic matter was subjected under the surface of the earth, over tens or hundreds of millions of years, did their work and generated the fossil fuels that we know and use today. However, by burning fossil fuels we are returning to the atmosphere the carbon dioxide that was extracted from it through photosynthesis, which would lead us to think that it is not a problem. Fossil fuels, however, are releasing a carbon dioxide that was fixed by plants in very remote times and therefore in the case of plants in very remote times and therefore in the In spite of the environmental problems, and although renewable energy sources are becoming increasingly important, it is anticipated that the use of fossil fuels will increase in the medium term. Given this situation, interest has developed in \u201ccarbon sequestration\u201d technologies, through which carbon dioxide produced, for example by a carboelectric plant \u2013 which generates energy from fossil coal \u2013 is captured and isolated from the atmosphere rather than emitted to it. Trees and plants in general provide us with the natural means to capture and store carbon dioxide, through the photosynthesis process. The increase of the land surface covered by forests is then a means to promote carbon sequestration. Carbon capture and storage can also be made by artificial means. For example, the carbon plant \u201cSchwarze Pumpe\u201d in eastern Germany has been operating since 2008 a small steam production pilot plant, which captures and stores in tanks the carbon dioxide it produces, which is subsequently sold to different companies \u2013 to producers of gaseous drinks. , for example. Carboelectric plants contribute 40% of global electricity production. Coal capture and storage techniques are then especially important for this type of plant. It is thought that carbon dioxide can be stored in large quantities in porous rock deposits underground. It can also be injected into oil fields that have lowered their production by a drop in pressure. Coal capture and storage projects, however, have been criticized by environmental organizations, which consider that they contribute to perpetuating carbon power plants and inhibiting the development of renewable energies. In any case, one of the major obstacles currently encountered by such projects in carbon power plants is the high costs of capturing carbon dioxide emitted, which substantially increases the cost of electricity produced. There is no source of energy that provides us with a magic solution to the problem of global warming. In the future, energy that the world will consume will come from renewable sources \u2013 certainly higher than today \u2013 but also from fossil fuels, in particular coal, of which countries such as the United States, Russia, China and India has considerable reserves. Mitigating the environmental effects of fossil coal burning, including carbon sequestration technologies, will then play a key role in the medium term.",
    "https://upload.wikimedia.org/wikipedia/commons/9/93/Heike_Kamerlingh_Onnes%2C_1878.jpg": "On the night of March 18, 1987, during the congress of the American Society of Physics that took place in the facilities of a hotel in the city of New York, a technical session was held otherwise unusual in this type of events. That session began at 19:30 \u2013with a considerable delay as the number of people in the conference room was greater than permitted by the regulations and had to wait to evict some of them\u2013 and ended later at three o\u2019clock in the morning. It was followed by about three thousand participants, mostly through television monitors scattered along the hotel corridors. The reason for so much interest was that in that session the latest research results obtained in relation to a very special class of materials known as superconductors would be discussed. Superconductors are amazing materials, which can achieve an electrical resistance equal to zero under certain conditions. All materials, with the exception of superconductors, are opposed to the passage of electric current through them; some of them in a railway way, as is the case of glass or plastic, and others in a timid way as happens with metals. In order for this to happen, however, they must not be cooled at very low temperatures. Lead, for example, becomes superconductor at a temperature of -266 degrees Celsius. These low temperatures are obtained using liquid helium as refrigerant, at great cost and difficulty of handling. Superconductive materials were discovered in 1911 by the Dutch physicist Heike Kamerlingh Onnes at the University of Leiden. Since that year a good number of superconductive materials have been discovered. Until 1986, however, they all required very low temperatures to act as such. Superconductors promise a large number of applications, some of which are already a reality. These materials, for example, are used for the generation of high-intensity magnetic fields in medical diagnostic systems by magnetic resonance. Many of the applications of superconductivity are, however, economically unviable at present due to the low temperatures required. One of the most important potential applications of superconductive superconductive materials, however, is the most important. In September 1986, physicists Georg Bednorz and Karl Muller working in the laboratories of the company IBM in Zurich, Switzerland, reported the discovery of a new class of superconductors with an operating temperature of -238 degrees Celsius, which was increased shortly after by a group of researchers from the universities of Houston and Alabama up to -183 degrees Celsius. s. Although this latter temperature is still extremely low, it represents a great advance because it is greater than the temperature of liquid nitrogen \u2013 the same as that used by dermatologists to remove moles from the skin \u2013 which can thus be a beneficial substitute for liquid helium as a refrigerant, at a much lower cost and difficulty of handling.The discovery of superconductors at temperatures higher than those of liquid nitrogen \u2013 called superconductors of high temperature \u2013 suddenly expanded the universe of potential applications of superconductivity, which largely explains the excitement of the community of physicists at the March 1987 meeting in New York. Unfortunately, although superconductors have now been obtained at temperatures up to -135 degrees Celsius, their metallurgical technology \u2013 for the manufacture of wires, for example \u2013 has encountered numerous difficulties and has not progressed at the same pace.The result has been that, despite all the noise they caused 22 years ago, the high temperature superconductors have not been up to expectations.Recently, a group of Japanese researchers from the Tokyo Institute of Technology reported a new type of high-temperature superconductors, of which there are hopes to be more technologically friendly. Thus, expectations have been revived that superconductivity will one day burst massively into the technological field. The answer will give us the years to come.",
    "https://upload.wikimedia.org/wikipedia/commons/a/ab/ThreeGorgesDam-China2009.jpg": "As is now evident, the increase in per capita energy consumption in developed countries since the beginning of the Industrial Revolution, a couple of centuries ago, has caused serious ecological problems at the global level. In particular, the emission of carbon dioxide into the atmosphere from the indiscriminate use of fossil fuels has led to the problem - now well known - of global warming, which anticipates ecological and climatic disasters in the years to come. Today, 80% of the energy consumed globally is obtained from fossil fuels. Consequently, to alleviate the problem of climate change it is necessary to reduce the consumption of per capita energy and at the same time seek to replace fossil fuels with options that do not emit carbon dioxide into the atmosphere.One form of energy that is particularly useful is electricity, which can be transmitted by long distances from the generating power plant to consumption centres - factories, public buildings, houses, etc.-. If we consider only electricity, we find that its generation at the global level comes from 66% of fossil fuels, while the remaining 34% is divided among several sources that are Two of these sources are hydropower and nuclear power, which have been used for decades and which are in fact the most important after fossil fuels: hydropower contributes 17% of the world total, while nuclear energy does so with 15%. The remaining 2% is divided between several technologies, some of them, such as wind and solar, in rapid growth. We note that with the exception of nuclear energy, the remaining carbon-free energies are renewable, in contrast to the fossil or nuclear fuels that will eventually be depleted. Three of the most potential renewable energies present and future are hydroelectric, wind and solar. The world\u2019s largest hydroelectric power plant, after Itaipu\u2019s on the border between Brazil and Paraguay, is the \u201cThree Gorges\u201d on the Yangtse River in central China, which will generate an electrical power of 18,000 megawatts - this is approximately 40% of Mexico\u2019s total electricity generation capacity-. The Three Gorge Dam will flood an area of 1, A thousand square kilometers that will extend hundreds of kilometers upstream, which has motivated the project to have been criticized for its environmental impact. In addition, it was necessary to relocate 1.3 million people who lived in the flooded regions. Three gorges will have a total cost of $24,000 million. Wind is one of the fastest growing renewable energy sources. The world\u2019s largest wind energy \u201cfarm\u201d is Horse Hollow\u2019s, 160 kilometers from Dallas, Texas. This farm is composed of 421 windmills that together generate 735 megawatts of electric energy. This power is roughly equivalent to that of the Villa de Reyes thermoelectric plant, San Lu\u00eds Potos\u00ed. Horse Hollow\u2019s plant occupies an area of 190 square kilometers, which in round numbers is one and a half times the area surrounding the peripheral ring surrounding San Luis Potos\u00ed. In hydroelectric and wind power plants, electric power is produced in turbine-powered generators, which are driven by the force of water or wind, as the case may be. In contrast, a solar cell electric power generation system is simpler, because electric power is obtained directly from the Sun, without any intermediate step. Although one might think that this feature gives it a decisive advantage over other renewable energy sources, this is not the case because of the high cost of manufacturing solar cells. However, and precisely because of the simplicity of the solar cell power generation scheme, these are having an increasing importance in the energy market. The largest solar cell farm currently is Olmedilla de Alarc\u00f3n in the province of Cuenca, Spain, with a maximum power of 60 mega watts - about a tenth of the Villa de Reyes plant - generated by 270,000 solar cell panels. The plant had a cost of $530 million and occupies an area of just under 1.5 square kilometers.All renewable energy generation technologies available at this time have advantages and disadvantages and no one will give us a magic solution to the problem of replacing fossil fuels in the immediate future. In this respect, wind energy is the most demanding, which necessarily has a negative social and/or ecological impact. However, and although in the immediate future we will not see a total substitution of fossil fuels by renewable energies, ecological imperatives will take an increasingly important role in the years to come.",
    "https://upload.wikimedia.org/wikipedia/commons/a/a5/Enola_Gay_81-9471.jpg": "On the morning of August 6, 1945, the B29 bomber named \u201cEnola Gay\u201d by its captain Paul Tibbets in honor of his mother, took off from the small island of Tinian in the Mariana archipelago, 2,500 kilometers south-east of Japan. He enfiled towards the city of Hiroshima on the island of Honshu, which at that time had a population of about 300,000 inhabitants. Tibbets\u2019 mission: to blow up on Hiroshima the first nuclear bomb in history to be used as an attack weapon. Once over the city, at a height of 10,000 meters, the Enola Gay dropped the bomb and turned sharply to get as far away as possible from the effects of the explosion. 600 meters from the ground \u2013 so it was planned to cause as much damage as possible \u2013 the bomb exploded with a force equivalent to 15,000 tons of TNT. As a result, from 80,000 to 140,000 people died and 100,000 were injured. More than two thirds of the buildings in the city were demolished and all, in a radius of 15,000 tons of TNT. As a result, more than 140,000 people died and 100,000 were injured. The deaths occurred mainly because of three causes: (1) the heat wave of the explosion, which reached temperatures of several thousand degrees Celsius when it arrived in the city and incinerated all those that it found in its passage; (2) the many fires that the heat wave ignited and that were dispersed by the expansive wave that followed it, leading to a widespread fire that devoured everything in an area of 7 square kilometers, and (3) by the effects of the high energy radiation produced by the nuclear reaction. Whereas the first two causes of death also occur with conventional bombs - although in Hiroshima they were presented on a scale never before seen - the radiation death was a new phenomenon, which was not even noticed during the first hours immediately after the explosion. The force released in a conventional explosion comes from the chemical transformation of the fuel material and the other elements involved. The energy that releases a nuclear reaction, on the contrary, is the result of the transmutation -the alchemists' dream - of a chemical element in different ones. , the liberated energy came from the fragmentation -fission - of uranium atoms into lighter atoms, which originated a fireball of 300 meters in diameter, with a temperature in its center of millions of degrees centigrade, which swallowed up the city as it expanded.The Manhattan project, by which the atomic bomb was developed, was a large-scale enterprise that required the technological capability of the United States and the competition of some of the most prominent American physicists of the time.The success of this project dramatically made evident the power of the scientific method employed in an organized and systematic way.With this success, science acquired a place of prominence.On the other hand, and perhaps because we are more than six decades away from the end of the Second World War, it is difficult to understand how it was that some of the most notable scientists of the time could join efforts to create something they knew could lead to something as terrible as the bombings of Hirsoshima and, three days later, Nagasaki. In opposition to this argument, others argue that Japan could not have maintained the war much longer and that, in any case, there was no need to launch atomic bombs against the civilian population. It would have been enough to demonstrate in an unpopulated manner the destructive power of the new weapons, which would make evident the futility of resisting. Indeed, apart from ending the war as soon as possible, the American military had the aim of testing the new weapons in a real situation. For this purpose they carefully chose the whites. Hiroshima was chosen because it had not been touched by the aerial bombings, so that the destruction that the bomb would produce would be better assessed. Thus, accompanying Enola Gay, another B29 bomber brought on board scientific observers who carried out measurements of the effects of the explosion.Hiroma and Nagasaki were victims of a tragedy to blame the war in the abstract, and specifically Americans and Japanese alike. This, however, seems to be an impossible undertaking, as since 1945 the number of countries that possess nuclear weapons has gradually increased to nine today. It seems that with the bombings of Hiroshima and Nagasaki the Americans opened a box of Pandora that we do not know how to reverse.",
    "https://upload.wikimedia.org/wikipedia/commons/3/33/Laika_ac_Sputnik_2_Replica_%286995685051%29.jpg": "On July 20, as widely disseminated by the written and electronic media, 40 years after the arrival of the first human beings on the surface of the Moon were fulfilled. The event crowned the offer of President John F. Kennedy, made before the United States Congress on May 25, 1961, to send a man to our satellite before the end of the decade. Putting a man on the Moon constituted a technological enterprise of great magnitude, which gave a measure of the technological power of the United States. It is widely accepted that one of President Kennedy\u2019s motivations to announce the government\u2019s plans to reach the Moon was the United States\u2019 backwardness in the space race with the Soviet Union. The USSR launched the first artificial satellite, Sputnik 1, on October 4, 1957, and thereby advanced to the United States and struck a strong blow in the minds of the American public. The apparent technological disadvantage of the United States was perceived, within the framework of the War, as a serious threat to national security. One month later, public unrest increased even further when the Sput was placed in orbit. The American shock reached a new level when the Vanguard rocket, which was to orbit the first American artificial satellite, exploded during its launch on December 6, 1957. The American press, beyond the alarm, reacted with sarcasm. In its edition of December 16, 1957, Time magazine wrote: \u201cAfter the water and carbon dioxide released by the automatic extinguishers extinguished the fire, the troubled rocket operators found the only survivor: the tiny North American satellite, intact, thrown from the nose of the rocket, radiating the signals that were supposed to be emitted from space. The American Sputnik emitted from the ground the correct frequency: 108 megacycles.\u201d The first North American satellite, Explorer I, competition of the Vanguard, was put into orbit on January 31, 1958, followed by Vanguard 1 on March 17, 1958. There was, however, a great disparity of weight between the North American and Soviet satellites: the Explorer 1 weighed 14 kg, while the The Vanguard 1 only 1.4 kg, compared to the half ton of the Sputnik 2. This disparity of weights motivated Nikita Kruschev to refer sarcastically to the Vanguard 1 as the \u201cTorron satellite\u201d. In the end, however, the Americans far surpassed the Soviets in the space race, at least in the spirit of public opinion, with the arrival of the astronauts of Apollo 11 to the Moon. The launch of the Sputnik also had a considerable impact on the American educational system. In the 1950s the system of teaching science and mathematics in the United States was under pressure. It was stated that American youth were not being adequately educated in these subjects, which were perceived as fundamental to the progress of the country. In this climate of criticism, the putting into orbit of Sputnik accelerated the development of new curricula in science and mathematics with the support of several government agencies, and produced what is known as the educational reform of the \u201cEra post Sputnik\u201d. The success of the Apollo project, with all its glamour and strong media dissemination, together with the new science and mathematics teaching plans designed by scientific research professionals, could be thought to be a powerful incentive for young Americans to choose careers in scientific and technological fields. However, this was not the case and, on the contrary, after the Apollo project there was a marked decline in interest in these fields. For example, according to the American Institute of Physics, from the 1970s there was a decline in the number of American students enrolled in the master's and doctoral programmes in physics offered by American universities. In another measure of the change of professional interest of Americans, according to data from the National Science Foundation, in 2005 only 50% of the doctoral degrees awarded by universities in the United States in the areas of engineering, mathematics, computer science, physics and economics were awarded to students in that country. , a direct connection between the Apollo project and the loss of interest of young Americans in science and technology, which in any case would have occurred. We note, however, the irony that this loss occurred precisely after a technological success of the magnitude of the Apollo project, which is a demonstration of the complexity of North American society.",
    "https://upload.wikimedia.org/wikipedia/commons/5/5c/Wright_R1820_Cyclone.jpg": "The use of fire goes back hundreds of thousands of years in time, to a time when modern man had not yet appeared. On the banks of Lake Hula in northern Israel, evidence has been found suggesting that hominids, possible forerunners of ours, had acquired the ability to use fire some 800,000 years ago. Although we will never come to know how they acquired this ability, we might imagine that they initially took fire from a natural source - for example from a tree set on fire by lightning - and kept it lit in a fire until the rain or some other contingency extinguished it. Later, over hundreds of thousands of years, they learned to generate their own fire - perhaps from the sparks produced by colliding two flints - and thus freed themselves from relying on the wild wild fires for access to fire. Fire results from the chemical reaction of organic materials with air oxygen, which releases energy in the form of heat. We may consider that a fire is an arrangement or device to produce heat energy from the chemical energy accumulated in the fire. Thus, the fires lit 800,000 years ago represent the oldest known example of heat generation for a specific use, perhaps to heat living spaces. Eight hundred thousand years later, in the year of 1876, the German engineer Nicolaus Otto developed the internal combustion engine used in automobiles. This engine is a device that converts the chemical energy stored in gasoline into mechanical energy. To achieve this, inside the engine cylinders is exploited in a controlled way a mixture of gasoline with air. The gases resulting from the explosion expand within the cylinders and the force of this expansion, transmitted to the car wheels, is the one that makes it move. Like a fire, an internal combustion engine is designed as a device to convert one form of energy into another for a specific use. Both in a fire and in an internal combustion engine this conversion must take place in a controlled way so that the devices are practical. Otherwise, the fire could spread to its surroundings and cause a catastrophic fire, or the engine could explode with catastrophic results as well. In fact, the internal combustion engine as we know it now, is an example of a science-based technology that required scientific advances that took place in the first half of the 19th century. In contrast, the discovery of the procedure for producing fire at will hundreds of thousands of years ago, was surely carried out by accident and using a test and error procedure. The industrial development of the last two centuries has required increasing amounts of energy that we obtain today from many different sources. One of these is nuclear energy, which represents approximately 6% of the total energy generated worldwide. Nuclear power generation is a prototypic example of science-based technology, which was made possible by the scientific knowledge of the atomic nucleus that was reached in the first half of the 20th century. Nuclear energy comes from the fission of uranium atoms, a process that releases a huge amount of energy. As we know, at the end of the Second World War the United States used nuclear fission to manufacture atomic bombs. The nuclear fission, however, can also be used to generate energy in a controlled way. This is achieved in nuclear reactors that are installations for the generation of electrical energy from the energy released by the controlled fission of uranium atoms. Energy has been an essential element for the development of human civilization. Around us we have found energy in different forms: solar, wind, hydraulic and as organic or fissionable fuels, to name but a few. This energy is at our disposal and is sufficient to meet our needs, but we must know how to control and exploit it. Since the acquisition of fire by our ancestors about a million years ago, we have made great strides in this direction, especially since the introduction of scientific knowledge into the process of technological development. The difference in technological sophistication between a nuclear reactor and a bonfire is enormous and gives us a measure of how far we have progressed. Suffice it to think that the vast majority of us would be unable today to light a fire without matches.",
    "https://upload.wikimedia.org/wikipedia/commons/f/f5/Petrol_pump_mp3h0355.jpg": "The year 1980 Brazil was not an oil country. Its oil production at that time was only 182,000 barrels a day. By comparison, Mexico, a smaller country, produced nearly two million barrels a day that year. It is not surprising, then, that Brazil suffered severely the oil crises of the 70s and 80s. The first of these crises occurred at the end of 1973, when the Arab countries decreed an oil embargo on the United States and other industrialized countries, which led to a quadrupling of the price of oil in the course of a few months. Subsequently, the Islamic revolution in Iran in 1979, which at that time was the second world oil producer, produced a second crisis that further increased the price of crude oil. All this significantly impacted Brazil's economy, which even had to resort to dollar loans to import the oil it needed to keep working. In response, and in order to reduce its dependence on imported oil, Brazil was given the task of developing technologies for mass production of ethyl alcohol, or ethanol, to be used as fuel in automobiles. . The raw material for ethanol production was sugar cane. The project was very successful and as a result, Brazil is the country that currently has the most advanced technology for the production of ethyl alcohol, as well as the largest experience in its use, pure or mixed with gasoline, in automobiles. Thus, 50% of the fuel currently consumed by cars in Brazil is ethanol. Brazil is not the world\u2019s largest producer of ethanol, a place that belongs to the United States, a country that produces it not from sugar cane but from maize. Brazilians are, however, considerably more efficient than Americans in producing ethyl alcohol. Indeed, Brazil has ethanol productivity per cultivated area that is approximately double that of the United States. In addition, the area used by Brazil for the production of ethyl alcohol is approximately 1% of its total cultivated area, in contrast to the United States that employs almost 4%. As a result, the cost of production of Brazilian ethanol is lower than the corresponding cost of American alcohol; and most importantly, Brazil does not subsidize its production while the United States does. The Brazilian experience is of great relevance in the context of the present environmental crisis - read global warming - due to the indiscriminate use of fossil fuels - oil, coal and natural gas. This crisis demands the replacement of non-renewable fossil fuels with renewable versions. Biofuels, obtained from organic matter and of which ethanol is an example, constitute a group of renewable energy of the greatest importance from the environmental point of view, since they are neutral from the point of view of carbon emission to the atmosphere. That is, the amount of carbon dioxide released by burning is -at least in theory - the same that was absorbed by the plants that synthesized them. We could not, of course, expect biofuels to completely suppress the emission of carbon dioxide to the atmosphere, since to obtain them it requires processes that use fossil fuels. Brazilians have shown, however, that the use of ethanol in automobiles reduces by 90% the amount of carbon dioxide emitted into the atmosphere. Among the Latin American countries, Brazil is one of the few that has taken seriously to use fossil fuels. This is demonstrated by the ethanol project which, on the other hand, is not the only example that it offers us. Mexico, in contrast, would hardly have had the capacity to develop a project of this magnitude and we can feel fortunate that the successive oil crises have affected us only indirectly because they are an oil country. Mexico, having a history and a culture close to those of Brazil, has no justification or explanation for the great difference in scientific and technological development that the two countries show today, except perhaps because of the lack of consistency that has always characterized our governments in terms of support for science and technology. At present, for example, Mexico invests in this respect a percentage of the gross domestic product that half of the Brazilian. Indeed, Brazil has multiplied by ten its oil production in the last thirty years and is today the 15th world producer. Mexico, for its part, shows a decline in its crude oil production, which has decreased 20% in the last five years. It is as if Mexico were playing the role of the cicarra and Brazil that of the an an ant. in the fable in which the cicada dies of hunger and cold in winter due to its lack of foresight in the summer days, while the ant is in good shelter and with enough food. Let us hope that support for science and technology in Mexico reaches the level it deserves in the not too distant future.",
    "https://upload.wikimedia.org/wikipedia/commons/2/2d/Energ%C3%ADa_e%C3%B3lica_en_Tecn%C3%B3polis.JPG": "The energy that today moves the world is obtained by 86% of fossil fuels, oil, natural gas and coal. These fuels, which were generated over the course of hundreds of millions of years under the surface of the Earth, are, of course, non-renewable and will see their end in a near future. On the other hand, the indiscriminate use of fossil fuels since the beginning of the Industrial Revolution two centuries ago, has produced an increase in the carbon dioxide content of the atmosphere, which in turn has generated global warming that threatens us with ecological disasters. The development of alternative energies that do not generate carbon dioxide and that are also renewable, is then a subject of primary importance. The Sun is the source of life of our planet. Without the Sun, the Earth would be a cold, dark and dead place. The secret of life is photosynthesis, which is possible thanks to the Sun. As we know, through this process plants and algae absorb carbon dioxide from the atmosphere and generate organic matter. Without the Sun, there would be no photosynthesis and there would be no plants on the face of the Earth; nor would there be plants; nor would there be any plants on the Earth. The sun is and has also been the source of most of the energy consumed on Earth since time immemorial. The energy of our muscles, for example, we get it from the plant or animal food we eat and as a consequence of the Sun in the last term. Wind energy, which allowed us to sail in times past on sailing ships of all kinds and which is now being used in windmill \u201cfarms\u201d, also has the Sun as a primary cause. This is also the case of water falls used to produce energy in hydroelectric plants, whose operation depends on the evaporation-raination water cycle that is in turn the result of solar warming. The same fossil fuels, which were generated from organic matter buried under the surface of the Earth in geological times, were the result of photosynthetic activity that occurred hundreds of millions of years ago. We have, on the other hand, that the largest users of solar radiation reaching the Earth, are and have been plants and green algae, which through the process of photosynthesis generate annually. organic matter with a carbon content that by weight is ten times greater than all the weight of coal consumed per year in industrial activities worldwide. The manufacture of organic matter by nature through photosynthesis exceeds, and by far, the dimension of any of our industrial activities. We can see then that the Sun, which brings to the surface of the Earth a quantity of energy that is 10,000 times greater than the total of world consumption, is undoubtedly the first option of renewable energy. For this, there are several schemes that can be used. We can, for example, take advantage of solar energy directly to heat water, or to generate electrical energy by means of solar cells. We can also take advantage of the Sun indirectly, through windmills or in hydroelectric plants. One option that looks particularly attractive as a renewable energy source is that provides us with photosynthesis itself, through which fuel material - the so-called biomass - is manufactured, converting solar energy into chemical energy stored in the synthesized material. In fact, the first material of this type used by our ancestors to make fire -wood- was manufactured by nature using the One advantage of making the fuel that we need in this way is that we would not increase the carbon balance on our planet; that is, by burning biomass and inevitably throwing carbon dioxide into the atmosphere, we would only be returning to it the carbon that was used with photosynthesis to make that biomass. On the other hand, a disadvantage of conceiving photosynthesis as a fuel factory is its low efficiency of converting solar energy into biomass chemical energy, which is of a few percentage units. It should be noted, however, that for some crops this efficiency is significantly greater. In the case of sugarcane, for example, it is in the order of 8% and hence its popularity as a renewable energy source. There is a great interest today in investigating the detailed mechanisms by which photosynthesis occurs. A better compression of these mechanisms will safely lead to the development of artificial photosynthesis processes with efficiencies greater than those of the corresponding natural processes. After all, this is the most primitive way to obtain energy, apart from giving us our own muscle strength.",
    "https://upload.wikimedia.org/wikipedia/commons/9/98/Caspian_Sea_from_orbit.jpg": "Those who attended secondary school a few decades ago may recall that the geography books taught us that the Aral Sea - located in Central Asia in the former Soviet republics of Kazakhstan and Uzbekistan - was by its size the fourth largest lake on the planet, only surpassed by its neighbour the Caspian Sea, by the Upper Lake on the border between Canada and the United States and by Lake Victoria in Africa. In the last 50 years, however, the Aral Sea has been dramatically shrinking by the decrease in the volume of rivers that feed it. In 1960 the Aral Sea covered an area of 68,000 square kilometres and its surface had an oval shape with almost 300 kilometres in its widest parts. Today, the Aral Sea has been divided into three unconnected bodies of water and its surface has been reduced by 90%. Of these three lakes, the North Aral Sea is located in Kazakistan, while the remaining two are in Uzbekistan. Muinak City in Uzbekistan, which was once a prosperous fishing port on the south coast of the A Sea. As the Spanish journalist Pilar Bonet, correspondent of the newspaper El Pa\u00eds, \u201cMuinak, the center of a district populated by 28,000 inhabitants, is today a depressed town. Its main attraction is the cemetery of boats. Distributed on the sand before a lookout, the barges that once crossed the sea are today bodies of scrap metal and symbols of the tragedy of the Aral Sea.\u201d The tributaries of the Aral Sea, the Amu Dari\u00e1 and Sir Dari\u00e1 rivers, are born in the mountains near the Chinese border, and cross agricultural fields in Uzbekistan the first and Kazakhstan the second. These fields, which are irrigated with water diverted from the Aral Sea tributaries, were created for the cultivation of large-scale cotton during the Soviet era, when Kazakhstan and Uzbekistan were part of the USSR. The use of water from the Amu Dari\u00e1 and Sir Dari\u00e1 rivers for agricultural purposes was, however, so massive that the sea level of the Soviet era was so high. Aral began to decrease gradually from the sixties until it reached the present state. The water of the Aral Sea was also severely contaminated by the pesticides used in the agricultural fields and by the increase in the concentration of salt that has made the life of fish impossible in two of the current lakes. The ecological disaster of the Aral has not only had economic consequences due to the affectation of fishing activity, but also severe health consequences and in the region there is a significantly high incidence of diseases such as tuberculosis, due to air pollution from dust and salt discovered as the waters recede. It has also had climatic consequences and now winters are colder and summers warmer than they used to be. Although not on the Aral Sea scale, in Mexico we are not left behind in ecological disasters. We have, for example, that Lake Chapala - the largest in the Country - stored on average in the last 20 years, according to data from the State Water Commission of Jalisco, only about 60% of the volume of water contained in the first half of the twentieth century. . After reaching a minimum level in 2002, below which it is considered critical, Lake Chapala has recovered in recent years due to an increase in rainfall catchment. However, some people consider that the lake is in danger of disappearing from a period of drought. To consider it in a critical situation, Lake Chapala was declared \u201cA threatened Lake of 2004\u201d by the Global Nature Fund. Similar to the Aral Sea, the decrease in the level of Lake Chapala is due to the diversion of its tributaries, in this case the Lerma River for agricultural and human consumption purposes. This river is born in the State of Mexico, crosses the agricultural area south of the State of Guanajuato and flows into Lake Chapala. Along its 700-kilometre route, the Lerma River is contaminated by urban and agricultural waste, which eventually pours into Lake Chapala. The Aral Sea and Lake Chapala are two examples of the use of water for economic growth, which, of course, has a social benefit. In the case of the Aral Sea, for example, the diversion of the Amu Dari\u00e1 River led to considerable economic growth in Uzbekistan, so important that it has even made it difficult to take measures to reverse the situation and return to the Aral Sea to its original state. Indeed, the two remaining lakes in its territory have been abandoned to their fate and one of them is expected to disappear in a few years. Given the ecological disasters that have been generated by inadequate use of water, and of which the Aral Sea is perhaps the most prominent example, it is now clear that we have a responsibility to manage water in a planned manner. Otherwise we will cause even greater disasters.",
    "https://upload.wikimedia.org/wikipedia/commons/f/f2/Karnak_Temples.jpg": "In 1950 the American writer Ray Bradbury published his famous science fiction novel \u201cMartian Chronicles\u201d in which he recounts a series of expeditions from Earth to Mars that eventually led to its colonization. The novel is located between the years 1999 and 2006, half a century ahead of the time when it was written, and in it it is described how travelers find a highly developed Martian civilization with natives able to communicate telepathically, as well as ruins of great antiquity. Moreover, although the Martian atmosphere in the novel was very dim, it contained enough oxygen so that explorers could breathe and perform moderate physical activities without the need for special equipment. Travellers also found plenty of water, as well as the channels that Italian astronomer Giovanni Schiaparelli thought to observe through the telescope on the Martian surface in 1877. Bradbury describes to us the arrival of colonizers in increasing numbers and the construction of villages with materials taken from the Earth. Martians, on his side, were exterminated in mass by the varicella brought to Mars by the first expeditions - similar to the population. In Mexico it was decimated by the smallpox brought by the Spanish conquerors in the sixteenth century-. The Mars that found the Spirit and Opportunity probes of NASA after reaching the surface of the planet in 2004 -half a century after the appearance of Martian Chronicles- was, without clutch, very different from the Mars of Bradbury. The first panoramic images sent by the Spirit probe in January 2004 from the Gusev crater near the Martian equator, showed a rocky and desolate plain with some elevations miles away, without visible traces of water. The Opportunity probe, which moored on the opposite side of the planet a few days after the arrival of the Spirit, did so at the bottom of a small crater and according to a press release from NASA on January 25, 2004, found a \u201csurrealist and dark landscape as never before seen on Mars.\u201d As we know, Mars is the fourth planet of the solar system and is found approximately 1.5 times farther away from the Sun than the Earth. Mars receives then less solar radiation. that our planet and is therefore colder, with an average temperature of 63 degrees Celsius below zero compared to the average Earth temperature that is about 14 degrees Celsius. On the other hand, the atmosphere on Mars is very tenuous with a pressure that is only 0.6 % of the atmospheric pressure on our planet. Moreover, it is composed of 95 % carbon dioxide, with a very small percentage of oxygen. It would be impossible for us to breathe on the surface of Mars without the help of an astronaut suit. It is then unthinkable that we could colonize Mars as Bradbury describes it in his novel. We also know that, although the NASA Phoenix probe that arrived at the Martian North Pole in 2008, it found ice buried at a shallow depth, there is no water on the surface of Mars in large quantities. The Opportunity probe found, however, that this has not always been so and that in a remote past there was liquid water on Mars.Bradbury knew, of course, that Mars was not as he described it in his novel and that, for example, the Schiapar canals ll \u2013 which at some point was maintained were built by an advanced civilization to transport water \u2013 had in fact been the product of an optical illusion. Far from this, Bradbury used the subject of space travel \u2013 which at the time were not far off because of the advances in rocket technology that had taken place during and after World War II \u2013 to deal with a number of issues of concern to him, doing so in a masterful manner and in an unusual scenario. Some of these issues had to do with criticisms of American society of its time and included racism, war, atomic weapons and censorship. It also included criticisms of capitalist society that \u201cif it has not put hot dog carts in the middle of Karnak temple in Egypt, it is because it is very far away and would not be profitable.\u201d This last issue was addressed by the argument that planet Mars could be severely damaged by American colonizers and at this point Bradbury is advancing several decades in its time, given the serious environmental pollution problems that currently afflict us. However, it has not been the exclusive product of capitalist economies but of socialists as well. Mars is actually too far from Earth to carry out colonization in the near future and the Martian Chronicles do not provide us with a feasible picture in this regard. The themes Bradbury deals with in his novel, however, are in fact problems typical of our civilization and such a novel could have been entitled \u201cEarth Chronicles\u201d.",
    "https://upload.wikimedia.org/wikipedia/commons/9/94/Jan_Verkolje_-_Antonie_van_Leeuwenhoek.jpg": "In August 1609, 400 years ago, Galileo Galilei made a public demonstration of an instrument built by him - the telescope, as was later known - that allowed us to visually approach distant objects. The demonstration was done from the bell tower of St Mark\u2019s Square in Venice. If we take into account that it is still difficult for us to resist the temptation to take a look through a telescope if the occasion is presented to us, it is not difficult to imagine the curiosity and amazement experienced by the spectators with the demonstration of the Galileo instrument, which increased the images about ten times. However, the telescope is commonly associated with Galileo Galilei, he was not the first to build such an instrument, and it was only after learning that in Holland there was a device that brought the distant objects closer, that Galileo was given to the task of replicating it. Galileo\u2019s telescope did not only result, however, superior to Dutch and, above all, much better handled from the point of view of public relations. Indeed, with the demonstration of St Mark\u2019s Square, carried out before members of the Venetian Senate, Galileo did not only succeed that his name In the second half of the year of 1609, Galileo made numerous astronomical observations with improved versions of the telescope of St. Mark's Square, discovering that the Moon has mountains, that there are many more stars in the sky than we can see at first sight, that the Sun has spots and that the planet Venus has phases similar to those of the Moon. Even more, in January 1610 he directed his telescope towards the planet Jupiter and discovered four luminous points around him, that they change their position continuously and that Galileo correctly identifies as satellites of that planet -the present Galilean satellites, Io, Ganymede, Europe and Calixto-. In the year of 1609, in which, in addition to Galileo's observations, the work \u201cAstronomia Nova\u201d by Johannes Kepler appeared, marks the beginning of modern astronomy. For this reason, this year, in which the 400th anniversary of this event, has been celebrated, it was The microscope, an instrument that is closely related to the telescope, is also associated with the name of Galileo Galilei. As we all know, the microscope, which allows to see small objects - microbes and cells, for example - impossible to perceive at first sight, has had a greater impact on the development of our civilization. By means of this instrument, for example, the Dutch HYPERLINK \"http://es.wikipedia.org/wiki/Anton_Van_Leuwenhoek\" \\o \"Anton Van Leeuwenhoek\" Anton Van Leeuwenhoek observed bacteria for the first time in the second half of the 17th century, which gave rise to bacteriology, a science that over time made it possible to identify the origin of infectious diseases and their cure in a large number of cases. Like the microscope, the telescope has had a huge scientific impact, allowing us to discover and observe objects that are beyond our visual capacity. The telescope, in addition, played a crucial role in the scientific revolution of the telescope. In fact, in the days of Galileo Galilei, science and its method, as we know them now, were not universally accepted - in reality they are not today either, although the situation of science in our time is considerably better than that of 400 years ago - and the medieval tradition, strongly influenced by Aristotle's ideas and based on the principle of authority to settle any controversy, had a great force. Following Aristotle, for example, all celestial objects were supposed to have perfect spherical forms and were themselves perfect, a statement that was shattered by the discovery of the mountains of the Moon and the sunspots. Another point of great discussion at the beginning of the 17th century was the heliocentric theory of Nicholas Copernicus, denied by the Church and defended, among others, by Galileo. Jupiter's observation and its satellites, which Galileo saw as a miniature solar system, provided objective arguments to defend that the Earth was not by necessity the center of the Universe as stated by the Galileo. In the end, as is well known, the defense of the heliocentric theory led Galileo to be tried by the Inquisition, and as a result to suffer home imprisonment for life and to abjure his ideas. In the long run, however, the evidence provided by the Galileo telescope helped crucially to demolish medieval ideas and to build the science of which we are beneficiaries today. The latter suffices to place the telescope among the greatest inventions ever developed.",
    "https://upload.wikimedia.org/wikipedia/commons/9/98/Juan_Peron_con_banda_de_presidente.jpg": "On November 1, 1952, the United States detonated the first ever-built hydrogen bomb - the H bomb, as it was then known - in the Eniwetok atoll in the South Pacific Ocean. The explosion, equivalent to 10 million tons of TNT, swept the small island of Elugelab into that atoll, leaving a crater of 2 kilometers in diameter and a depth of 50 meters. Years earlier, on July 16, 1945, the first nuclear explosion in history took place in the New Mexico desert. The destruction power of this first nuclear bomb \u2013 known as the A bomb \u2013 was, however, much less than the power of the Elugelab bomb. In fact, both were of a different nature: the A bomb was based on fission of uranium or plutonium atoms, while the H bomb obtained its energy through the fusion of hydrogen atoms.The A bomb was developed by the United States during the Second World War and used over the Japanese cities of Hiroshima and Nagasaki in August 1945. In this climate of confrontation between the two superpowers, Juan Domingo Per\u00f3n, President of Argentina, announced in a press conference that his country had managed to carry out a thermonuclear fusion reaction under controlled conditions. Although Per\u00f3n emphasized peaceful uses of nuclear energy, it became clear that the experiments reported put Argentina in a position to manufacture an H bomb. What was announced by the Argentine president is surprising if we consider that at the time it took place, the atomic fusion energy was still in the research phase. As it turned out, however, what was stated by Per\u00f3n had no objective basis and the supposed Argentine nuclear development turned out to be a fiasco. The history of the Argentine nuclear bomb was started with the arrival in Buenos Aires of the Austrian physicist Ronald Richter in August 1948. Richter was recommended by the prestigated German aeronautical engineer Kurt Tan. k, who worked in Argentina since 1947 after leaving his native country. Thanks to this recommendation, Richter soon had access to Per\u00f3n, who was impressed by the possibilities that he raised in the sense of developing in Argentina the nuclear energy by fusion \u2013 still unproven \u2013 as a low cost alternative to nuclear fission, technology that was already in the domain of the United States. What followed is told in the book \u201cThe atomic secret of Huemul\u201d by the Argentine physicist Mario Mariscotti. To say that Per\u00f3n was impressed by Richter is very little. In fact he received such a strong impact that immediately he hired him and put at his disposal everything necessary to carry out his nuclear project. Per\u00f3n\u2019s support reached the end of building for Richter installations of great magnitude on the island of Huemul, on Lake Nahuel Huapi in Argentinian Patagonia, leaving the island at some point under the authority of the Austrian as representative of Per\u00f3n. A 12-meter high concrete \u201cnuclear reactor\u201d was built, a diameter of 12 meters and walls of 4 meters thick, which was, However, later demolished by orders of Richter with the argument that it had a fissure of 50 cm long and a few centimeters wide and depth. To replace it, Richter ordered the construction of a similar installation, but now buried in the living rock. Everything that Richter demanded in hiring personnel and buying scientific equipment was granted to him. He also had at his disposal official planes to bring from abroad, with the maximum speed, any piece of equipment or material that he deemed necessary and smuggle it into Argentina. In the end, however, all the resources invested in the project went to the garbage, because Ronald Richter turned out to be a phony who took advantage of Peron\u2019s willingness to believe everything that came from a physicist of German tradition. Although, like all the successful phonists, Richter was an intelligent person and was aware of both the research in nuclear physics then in vogue, his approaches were wrong and his experiments could not give rise to a nuclear reaction, as demonstrated at the time by the Argentine physicist Jos\u00e9 Antonio Balseiro. In fact, the only thing that was Richter\u2019s \u201cnuclear reactor\u201d was a huge spark, which could perhaps impress a layman in the matter, but which were far from producing the temperature needed to get two atoms to fuse. Richter ended up being exposed and removed from the Argentine nuclear project. Per\u00f3n, for his part, was ridiculed and with some weights less. One lesson that we could draw from the Per\u00f3n and Richter episode is that in countries like ours, where science occupies a secondary place, the only defense against possible phonies of Ronald Richter\u2019s style, which even today could be carried around, is precisely to build a solid scientific tradition.",
    "https://upload.wikimedia.org/wikipedia/commons/e/e6/Thomas_Malthus.jpg": "In his \u201cEssay on the principle of population\u201d, published in 1798, the English economist Thomas Robert Matlhus argued that if the rate of geometric increase of the world population observed at that time continued, at some point there would be a catastrophe due to lack of food, which grew at an arithmetical rate; that is, much slower than the population. Matlhus did not think, of course, that the population of the world could grow geometrically indefinitely, but that at some point its rate of growth would stop for various causes, such as famines, wars, epidemics, etc. In this way, he had the vision of a world permanently struggling to achieve survival. Thomas Malthus noticed 200 years ago a fundamental difference between geometric and arithmetic growths, which even now we sometimes lose sight of despite the serious consequences that can bring us. A typical example of geometric growth gives us the number of bacteria in a biological crop, which is doubled at a constant pace while there is sufficient provision of food. It is not difficult. understand why the number of bacteria should grow this way if we take into account that each one of them is divided into two in a certain characteristic time. Thus, starting from a bacterium, after this time we will have two, which in turn will become four and these in eight, and so successively. Of course when the microorganisms do not have sufficient sustenance, geometric growth will not be able to be maintained and slowed down. Something that grows arithmetically, in contrast, increases by a fixed amount in each time interval. An example of this is the mileage that marks the meter of a car as it moves on a road at constant speed. One thing that we can say about geometric growth is that it is very misleading. Let\u2019s think, for example, of the king\u2019s fable that wanting to reward who invented the chess game offered him what he asked for. The request was for the amount of rice needed to fill a chess board in a geometric progression; that is, by placing a grain of rice in the first table of the board, two in the second, four in the third and So successively to complete the 64 tables of the board. If we consider that each gram of rice is about 40 grains, the number eight table at the end of the first line required little more than 3 grams and table 16 at the end of the second about one kilogram, which, of course, did not cause any problems. In table 29 on the fourth line, however, the count was already about seven tons, which doubled in table 30 and quadrupled in 31. At this point, those who carried the rice had to begin to suspect that something was wrong, which they would have been able to corroborate by calculating how much rice they would need for the last table: more than 200,000 tons!, something of course impossible to satisfy.There are many important amounts that grow in a geometric way. We have, for example, that the world population in the eighteenth and nineteenth centuries grew geometrically, doubling every 150 years. In another example, it is estimated that the number of people infected with the current influenza epidemic in Mexico, increased geometrically in the last days of last April with a period of doubling close to a week. In one example in another order, the number of transistors in the microcircuits used in computers doubles every two years. This growth has been observed over the last 50 years and is known as Moore\u2019s law. Geometric growth may in some cases have positive consequences. Moore\u2019s law, for example, has steadily increased the capacity of computers at the same time as it has decreased their price, to the extent that today a large proportion of the world\u2019s population has access to computers, whose capacity also grows geometrically. This has led to a technological revolution with profound social implications. On the other hand, geometric growth can also be dangerous by misleading. Indeed, a number that grows geometrically may seem harmless for a certain time, as shown by the fable rice and chess board, and in a sudden way, A clear example is given by the influenza epidemic, which during the first weeks or months of gestation, when it was small, did not produce public alarm, a situation that did occur, and abruptly, in the last week of April. Some people argue that humans tend to think arithmetically and not geometrically and that we sometimes make errors of judgment when assessing the consequences of geometric growth. This indicates that we must be alert, because the number of situations in which a quantity that is growing geometrically is perhaps greater than we imagine in the first instance. This is not the case. Another example is given by the problems of vehicular traffic in the city of San Luis Potos\u00ed. Although we have not found statistics of the increase in the number of cars in recent decades, it is clear that the rate of increase of cars far exceeded the growth of the capacity of streets and avenues to channel the growing traffic, a situation that made crisis more or less abrupt a few years ago."
}